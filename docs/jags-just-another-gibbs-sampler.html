<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>8 JAGS – Just Another Gibbs Sampler | (Re)Doing Bayesain Data Analysis</title>
  <meta name="description" content="Code, exercises and discussion to accompany a course taught from Kruschke’s Doing Bayesian Data Analysis (2ed)">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="8 JAGS – Just Another Gibbs Sampler | (Re)Doing Bayesain Data Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Code, exercises and discussion to accompany a course taught from Kruschke’s Doing Bayesian Data Analysis (2ed)" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="8 JAGS – Just Another Gibbs Sampler | (Re)Doing Bayesain Data Analysis" />
  
  <meta name="twitter:description" content="Code, exercises and discussion to accompany a course taught from Kruschke’s Doing Bayesian Data Analysis (2ed)" />
  

<meta name="author" content="R Pruim">


<meta name="date" content="2019-03-11">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="markov-chain-monte-carlo-mcmc.html">
<link rel="next" href="heierarchical-models.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">(Re)Doing Bayesian Data Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> What’s in These Notes</a></li>
<li class="part"><span><b>I The Basics: Models, Probability, Bayes, and R</b></span></li>
<li class="chapter" data-level="2" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html"><i class="fa fa-check"></i><b>2</b> Credibility, Models, and Parameters</a><ul>
<li class="chapter" data-level="2.1" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#the-steps-of-bayesian-data-analysis"><i class="fa fa-check"></i><b>2.1</b> The Steps of Bayesian Data Analysis</a><ul>
<li class="chapter" data-level="2.1.1" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#r-code"><i class="fa fa-check"></i><b>2.1.1</b> R code</a></li>
<li class="chapter" data-level="2.1.2" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#r-packages"><i class="fa fa-check"></i><b>2.1.2</b> R packages</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#example-1-which-coin-is-it"><i class="fa fa-check"></i><b>2.2</b> Example 1: Which coin is it?</a><ul>
<li class="chapter" data-level="2.2.1" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#freedom-of-choice"><i class="fa fa-check"></i><b>2.2.1</b> Freedom of choice</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#distributions"><i class="fa fa-check"></i><b>2.3</b> Distributions</a><ul>
<li class="chapter" data-level="2.3.1" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#beta-distributions"><i class="fa fa-check"></i><b>2.3.1</b> Beta distributions</a></li>
<li class="chapter" data-level="2.3.2" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#normal-distributions"><i class="fa fa-check"></i><b>2.3.2</b> Normal distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#example-2-height-vs-weight"><i class="fa fa-check"></i><b>2.4</b> Example 2: Height vs Weight</a><ul>
<li class="chapter" data-level="2.4.1" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#data"><i class="fa fa-check"></i><b>2.4.1</b> Data</a></li>
<li class="chapter" data-level="2.4.2" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#describing-a-model-for-the-relationship-between-height-and-weight"><i class="fa fa-check"></i><b>2.4.2</b> Describing a model for the relationship between height and weight</a></li>
<li class="chapter" data-level="2.4.3" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#prior"><i class="fa fa-check"></i><b>2.4.3</b> Prior</a></li>
<li class="chapter" data-level="2.4.4" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#posterior"><i class="fa fa-check"></i><b>2.4.4</b> Posterior</a></li>
<li class="chapter" data-level="2.4.5" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#posterior-predictive-check"><i class="fa fa-check"></i><b>2.4.5</b> Posterior Predictive Check</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#where-do-we-go-from-here"><i class="fa fa-check"></i><b>2.5</b> Where do we go from here?</a></li>
<li class="chapter" data-level="2.6" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#ch02-exercises"><i class="fa fa-check"></i><b>2.6</b> Exercises</a></li>
<li class="chapter" data-level="2.7" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#footnotes"><i class="fa fa-check"></i><b>2.7</b> Footnotes</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html"><i class="fa fa-check"></i><b>3</b> Some Useful Bits of R</a><ul>
<li class="chapter" data-level="3.1" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#style-guide"><i class="fa fa-check"></i><b>3.1</b> You Gotta Have Style</a><ul>
<li class="chapter" data-level="3.1.1" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#an-additional-note-about-homework"><i class="fa fa-check"></i><b>3.1.1</b> An additional note about homework</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#vectors-lists-and-data-frames"><i class="fa fa-check"></i><b>3.2</b> Vectors, Lists, and Data Frames</a><ul>
<li class="chapter" data-level="3.2.1" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#vectors"><i class="fa fa-check"></i><b>3.2.1</b> Vectors</a></li>
<li class="chapter" data-level="3.2.2" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#lists"><i class="fa fa-check"></i><b>3.2.2</b> Lists</a></li>
<li class="chapter" data-level="3.2.3" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#data-frames-for-rectangular-data"><i class="fa fa-check"></i><b>3.2.3</b> Data frames for rectangular data</a></li>
<li class="chapter" data-level="3.2.4" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#other-types-of-data"><i class="fa fa-check"></i><b>3.2.4</b> Other types of data</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#plotting-with-ggformula"><i class="fa fa-check"></i><b>3.3</b> Plotting with ggformula</a></li>
<li class="chapter" data-level="3.4" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#creating-data-with-expand.grid"><i class="fa fa-check"></i><b>3.4</b> Creating data with expand.grid()</a></li>
<li class="chapter" data-level="3.5" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#transforming-and-summarizing-data-dplyr-and-tidyr"><i class="fa fa-check"></i><b>3.5</b> Transforming and summarizing data dplyr and tidyr</a></li>
<li class="chapter" data-level="3.6" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#writing-functions"><i class="fa fa-check"></i><b>3.6</b> Writing Functions</a><ul>
<li class="chapter" data-level="3.6.1" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#why-write-functions"><i class="fa fa-check"></i><b>3.6.1</b> Why write functions?</a></li>
<li class="chapter" data-level="3.6.2" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#function-parts"><i class="fa fa-check"></i><b>3.6.2</b> Function parts</a></li>
<li class="chapter" data-level="3.6.3" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#the-function-function-has-its-function"><i class="fa fa-check"></i><b>3.6.3</b> The function() function has its function</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#some-common-error-messages"><i class="fa fa-check"></i><b>3.7</b> Some common error messages</a><ul>
<li class="chapter" data-level="3.7.1" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#object-not-found"><i class="fa fa-check"></i><b>3.7.1</b> object not found</a></li>
<li class="chapter" data-level="3.7.2" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#any-message-mentioning-yaml"><i class="fa fa-check"></i><b>3.7.2</b> Any message mentioning yaml</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#ch03-exercises"><i class="fa fa-check"></i><b>3.8</b> Exercises</a></li>
<li class="chapter" data-level="3.9" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#footnotes-1"><i class="fa fa-check"></i><b>3.9</b> Footnotes</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>4</b> Probability</a><ul>
<li class="chapter" data-level="4.1" data-path="probability.html"><a href="probability.html#some-terminology"><i class="fa fa-check"></i><b>4.1</b> Some terminology</a></li>
<li class="chapter" data-level="4.2" data-path="probability.html"><a href="probability.html#distributions-in-r"><i class="fa fa-check"></i><b>4.2</b> Distributions in R</a><ul>
<li class="chapter" data-level="4.2.1" data-path="probability.html"><a href="probability.html#example-normal-distributions"><i class="fa fa-check"></i><b>4.2.1</b> Example: Normal distributions</a></li>
<li class="chapter" data-level="4.2.2" data-path="probability.html"><a href="probability.html#simulating-running-proportions"><i class="fa fa-check"></i><b>4.2.2</b> Simulating running proportions</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="probability.html"><a href="probability.html#joint-marginal-and-conditional-distributions"><i class="fa fa-check"></i><b>4.3</b> Joint, marginal, and conditional distributions</a><ul>
<li class="chapter" data-level="4.3.1" data-path="probability.html"><a href="probability.html#example-hair-and-eye-color"><i class="fa fa-check"></i><b>4.3.1</b> Example: Hair and eye color</a></li>
<li class="chapter" data-level="4.3.2" data-path="probability.html"><a href="probability.html#independence"><i class="fa fa-check"></i><b>4.3.2</b> Independence</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="probability.html"><a href="probability.html#ch04-exercises"><i class="fa fa-check"></i><b>4.4</b> Exercises</a></li>
<li class="chapter" data-level="4.5" data-path="probability.html"><a href="probability.html#footnotes-2"><i class="fa fa-check"></i><b>4.5</b> Footnotes</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html"><i class="fa fa-check"></i><b>5</b> Bayes’ Rule and the Grid Method</a><ul>
<li class="chapter" data-level="5.1" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#the-big-bayesian-idea"><i class="fa fa-check"></i><b>5.1</b> The Big Bayesian Idea</a><ul>
<li class="chapter" data-level="5.1.1" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#likelihood"><i class="fa fa-check"></i><b>5.1.1</b> Likelihood</a></li>
<li class="chapter" data-level="5.1.2" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#when-bayes-is-easy"><i class="fa fa-check"></i><b>5.1.2</b> When Bayes is easy</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#estimating-the-bias-in-a-coin-using-the-grid-method"><i class="fa fa-check"></i><b>5.2</b> Estimating the bias in a coin using the Grid Method</a><ul>
<li class="chapter" data-level="5.2.1" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#creating-a-grid"><i class="fa fa-check"></i><b>5.2.1</b> Creating a Grid</a></li>
<li class="chapter" data-level="5.2.2" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#hdi-from-the-grid"><i class="fa fa-check"></i><b>5.2.2</b> HDI from the grid</a></li>
<li class="chapter" data-level="5.2.3" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#automating-the-grid"><i class="fa fa-check"></i><b>5.2.3</b> Automating the grid</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#working-on-the-log-scale"><i class="fa fa-check"></i><b>5.3</b> Working on the log scale</a></li>
<li class="chapter" data-level="5.4" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#discrete-params"><i class="fa fa-check"></i><b>5.4</b> Discrete Parameters</a></li>
<li class="chapter" data-level="5.5" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#ch05-exercises"><i class="fa fa-check"></i><b>5.5</b> Exercises</a></li>
<li class="chapter" data-level="5.6" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#footnotes-3"><i class="fa fa-check"></i><b>5.6</b> Footnotes</a></li>
</ul></li>
<li class="part"><span><b>II Inferring a Binomial Probability</b></span></li>
<li class="chapter" data-level="6" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><i class="fa fa-check"></i><b>6</b> Inferring a Binomial Probability via Exact Mathematical Analysis</a><ul>
<li class="chapter" data-level="6.1" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#beta-distributions-1"><i class="fa fa-check"></i><b>6.1</b> Beta distributions</a></li>
<li class="chapter" data-level="6.2" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#beta-and-bayes"><i class="fa fa-check"></i><b>6.2</b> Beta and Bayes</a><ul>
<li class="chapter" data-level="6.2.1" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#the-bernoulli-likelihood-function"><i class="fa fa-check"></i><b>6.2.1</b> The Bernoulli likelihood function</a></li>
<li class="chapter" data-level="6.2.2" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#a-convenient-prior"><i class="fa fa-check"></i><b>6.2.2</b> A convenient prior</a></li>
<li class="chapter" data-level="6.2.3" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#pros-and-cons-of-conjugate-priors"><i class="fa fa-check"></i><b>6.2.3</b> Pros and Cons of conjugate priors</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#getting-to-know-the-beta-distributions"><i class="fa fa-check"></i><b>6.3</b> Getting to know the Beta distributions</a><ul>
<li class="chapter" data-level="6.3.1" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#important-facts"><i class="fa fa-check"></i><b>6.3.1</b> Important facts</a></li>
<li class="chapter" data-level="6.3.2" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#alternative-parameterizations-of-beta-distributions"><i class="fa fa-check"></i><b>6.3.2</b> Alternative parameterizations of Beta distributions</a></li>
<li class="chapter" data-level="6.3.3" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#beta_params"><i class="fa fa-check"></i><b>6.3.3</b> beta_params()</a></li>
<li class="chapter" data-level="6.3.4" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#automating-bayesian-updates-for-a-proportion-beta-prior"><i class="fa fa-check"></i><b>6.3.4</b> Automating Bayesian updates for a proportion (beta prior)</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#what-if-the-prior-isnt-a-beta-distribution"><i class="fa fa-check"></i><b>6.4</b> What if the prior isn’t a beta distribution?</a></li>
<li class="chapter" data-level="6.5" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#ch06-exercises"><i class="fa fa-check"></i><b>6.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html"><i class="fa fa-check"></i><b>7</b> Markov Chain Monte Carlo (MCMC)</a><ul>
<li class="chapter" data-level="7.1" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#king-markov-and-adviser-metropolis"><i class="fa fa-check"></i><b>7.1</b> King Markov and Adviser Metropolis</a></li>
<li class="chapter" data-level="7.2" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#quick-intro-to-markov-chains"><i class="fa fa-check"></i><b>7.2</b> Quick Intro to Markov Chains</a><ul>
<li class="chapter" data-level="7.2.1" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#more-info-please"><i class="fa fa-check"></i><b>7.2.1</b> More info, please</a></li>
<li class="chapter" data-level="7.2.2" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#definition"><i class="fa fa-check"></i><b>7.2.2</b> Definition</a></li>
<li class="chapter" data-level="7.2.3" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#time-homogeneous-markov-chains"><i class="fa fa-check"></i><b>7.2.3</b> Time-Homogeneous Markov Chains</a></li>
<li class="chapter" data-level="7.2.4" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#matrix-representation"><i class="fa fa-check"></i><b>7.2.4</b> Matrix representation</a></li>
<li class="chapter" data-level="7.2.5" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#regular-markov-chains"><i class="fa fa-check"></i><b>7.2.5</b> Regular Markov Chains</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#back-to-king-markov"><i class="fa fa-check"></i><b>7.3</b> Back to King Markov</a></li>
<li class="chapter" data-level="7.4" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#how-well-does-the-metropolis-algorithm-work"><i class="fa fa-check"></i><b>7.4</b> How well does the Metropolis Algorithm work?</a><ul>
<li class="chapter" data-level="7.4.1" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#jumping-to-any-island"><i class="fa fa-check"></i><b>7.4.1</b> Jumping to any island</a></li>
<li class="chapter" data-level="7.4.2" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#jumping-only-to-neighbor-islands"><i class="fa fa-check"></i><b>7.4.2</b> Jumping only to neighbor islands</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#markov-chains-and-posterior-sampling"><i class="fa fa-check"></i><b>7.5</b> Markov Chains and Posterior Sampling</a><ul>
<li class="chapter" data-level="7.5.1" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#example-1-estimating-a-proportion"><i class="fa fa-check"></i><b>7.5.1</b> Example 1: Estimating a proportion</a></li>
<li class="chapter" data-level="7.5.2" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#example-2-estimating-mean-and-variance"><i class="fa fa-check"></i><b>7.5.2</b> Example 2: Estimating mean and variance</a></li>
<li class="chapter" data-level="7.5.3" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#issues-with-metropolis-algorithm"><i class="fa fa-check"></i><b>7.5.3</b> Issues with Metropolis Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#two-coins"><i class="fa fa-check"></i><b>7.6</b> Two coins</a><ul>
<li class="chapter" data-level="7.6.1" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#the-model"><i class="fa fa-check"></i><b>7.6.1</b> The model</a></li>
<li class="chapter" data-level="7.6.2" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#exact-analysis"><i class="fa fa-check"></i><b>7.6.2</b> Exact analysis</a></li>
<li class="chapter" data-level="7.6.3" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#metropolis"><i class="fa fa-check"></i><b>7.6.3</b> Metropolis</a></li>
<li class="chapter" data-level="7.6.4" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#gibbs-sampling"><i class="fa fa-check"></i><b>7.6.4</b> Gibbs sampling</a></li>
<li class="chapter" data-level="7.6.5" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#advantages-and-disadvantages-of-gibbs-vs-metropolis"><i class="fa fa-check"></i><b>7.6.5</b> Advantages and Disadvantages of Gibbs vs Metropolis</a></li>
<li class="chapter" data-level="7.6.6" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#so-what-do-we-learn-about-the-coins"><i class="fa fa-check"></i><b>7.6.6</b> So what do we learn about the coins?</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#mcmc-posterior-sampling-big-picture"><i class="fa fa-check"></i><b>7.7</b> MCMC posterior sampling: Big picture</a><ul>
<li class="chapter" data-level="7.7.1" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#mcmc-markov-chain-monte-carlo"><i class="fa fa-check"></i><b>7.7.1</b> MCMC = Markov chain Monte Carlo</a></li>
<li class="chapter" data-level="7.7.2" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#posterior-sampling-random-walk-through-the-posterior"><i class="fa fa-check"></i><b>7.7.2</b> Posterior sampling: Random walk through the posterior</a></li>
<li class="chapter" data-level="7.7.3" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#where-do-we-go-from-here-1"><i class="fa fa-check"></i><b>7.7.3</b> Where do we go from here?</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#ch07-exercises"><i class="fa fa-check"></i><b>7.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html"><i class="fa fa-check"></i><b>8</b> JAGS – Just Another Gibbs Sampler</a><ul>
<li class="chapter" data-level="8.1" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#what-jags-is"><i class="fa fa-check"></i><b>8.1</b> What JAGS is</a><ul>
<li class="chapter" data-level="8.1.1" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#jags-documentation"><i class="fa fa-check"></i><b>8.1.1</b> JAGS documentation</a></li>
<li class="chapter" data-level="8.1.2" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#updating-c-and-clang"><i class="fa fa-check"></i><b>8.1.2</b> Updating C and CLANG</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#example-1-estimating-a-proportion-1"><i class="fa fa-check"></i><b>8.2</b> Example 1: estimating a proportion</a><ul>
<li class="chapter" data-level="8.2.1" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#the-model-1"><i class="fa fa-check"></i><b>8.2.1</b> The Model</a></li>
<li class="chapter" data-level="8.2.2" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#load-data"><i class="fa fa-check"></i><b>8.2.2</b> Load Data</a></li>
<li class="chapter" data-level="8.2.3" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#specify-the-model"><i class="fa fa-check"></i><b>8.2.3</b> Specify the model</a></li>
<li class="chapter" data-level="8.2.4" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#run-the-model"><i class="fa fa-check"></i><b>8.2.4</b> Run the model</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#extracting-information-from-a-jags-run"><i class="fa fa-check"></i><b>8.3</b> Extracting information from a JAGS run</a><ul>
<li class="chapter" data-level="8.3.1" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#posterior-1"><i class="fa fa-check"></i><b>8.3.1</b> posterior()</a></li>
<li class="chapter" data-level="8.3.2" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#side-note-posterior-sampling-and-the-grid-method"><i class="fa fa-check"></i><b>8.3.2</b> Side note: posterior sampling and the grid method</a></li>
<li class="chapter" data-level="8.3.3" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#using-coda"><i class="fa fa-check"></i><b>8.3.3</b> Using coda</a></li>
<li class="chapter" data-level="8.3.4" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#using-bayesplot"><i class="fa fa-check"></i><b>8.3.4</b> Using bayesplot</a></li>
<li class="chapter" data-level="8.3.5" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#using-kruschkes-functions"><i class="fa fa-check"></i><b>8.3.5</b> Using Kruschke’s functions</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#optional-arguments-to-jags"><i class="fa fa-check"></i><b>8.4</b> Optional arguments to jags()</a><ul>
<li class="chapter" data-level="8.4.1" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#number-and-size-of-chains"><i class="fa fa-check"></i><b>8.4.1</b> Number and size of chains</a></li>
<li class="chapter" data-level="8.4.2" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#starting-point-for-chains"><i class="fa fa-check"></i><b>8.4.2</b> Starting point for chains</a></li>
<li class="chapter" data-level="8.4.3" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#running-chains-in-parallel"><i class="fa fa-check"></i><b>8.4.3</b> Running chains in parallel</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#example-2-comparing-two-proportions"><i class="fa fa-check"></i><b>8.5</b> Example 2: comparing two proportions</a><ul>
<li class="chapter" data-level="8.5.1" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#the-data"><i class="fa fa-check"></i><b>8.5.1</b> The data</a></li>
<li class="chapter" data-level="8.5.2" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#the-model-2"><i class="fa fa-check"></i><b>8.5.2</b> The model</a></li>
<li class="chapter" data-level="8.5.3" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#describing-the-model-to-jags"><i class="fa fa-check"></i><b>8.5.3</b> Describing the model to JAGS</a></li>
<li class="chapter" data-level="8.5.4" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#fitting-the-model"><i class="fa fa-check"></i><b>8.5.4</b> Fitting the model</a></li>
<li class="chapter" data-level="8.5.5" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#inspecting-the-results"><i class="fa fa-check"></i><b>8.5.5</b> Inspecting the results</a></li>
<li class="chapter" data-level="8.5.6" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#difference-in-proportions"><i class="fa fa-check"></i><b>8.5.6</b> Difference in proportions</a></li>
<li class="chapter" data-level="8.5.7" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#sampling-from-the-prior"><i class="fa fa-check"></i><b>8.5.7</b> Sampling from the prior</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#ch08-exercises"><i class="fa fa-check"></i><b>8.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="heierarchical-models.html"><a href="heierarchical-models.html"><i class="fa fa-check"></i><b>9</b> Heierarchical Models</a><ul>
<li class="chapter" data-level="9.1" data-path="heierarchical-models.html"><a href="heierarchical-models.html#gamma-distributions"><i class="fa fa-check"></i><b>9.1</b> Gamma Distributions</a></li>
<li class="chapter" data-level="9.2" data-path="heierarchical-models.html"><a href="heierarchical-models.html#one-coin-from-one-mint"><i class="fa fa-check"></i><b>9.2</b> One coin from one mint</a></li>
<li class="chapter" data-level="9.3" data-path="heierarchical-models.html"><a href="heierarchical-models.html#multiple-coins-from-one-mint"><i class="fa fa-check"></i><b>9.3</b> Multiple coins from one mint</a></li>
<li class="chapter" data-level="9.4" data-path="heierarchical-models.html"><a href="heierarchical-models.html#multiple-coins-from-multiple-mints"><i class="fa fa-check"></i><b>9.4</b> Multiple coins from multiple mints</a></li>
<li class="chapter" data-level="9.5" data-path="heierarchical-models.html"><a href="heierarchical-models.html#therapeutic-touch"><i class="fa fa-check"></i><b>9.5</b> Therapeutic Touch</a><ul>
<li class="chapter" data-level="9.5.1" data-path="heierarchical-models.html"><a href="heierarchical-models.html#abstract"><i class="fa fa-check"></i><b>9.5.1</b> Abstract</a></li>
<li class="chapter" data-level="9.5.2" data-path="heierarchical-models.html"><a href="heierarchical-models.html#data-1"><i class="fa fa-check"></i><b>9.5.2</b> Data</a></li>
<li class="chapter" data-level="9.5.3" data-path="heierarchical-models.html"><a href="heierarchical-models.html#a-heierarchical-model"><i class="fa fa-check"></i><b>9.5.3</b> A heierarchical model</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="heierarchical-models.html"><a href="heierarchical-models.html#other-parameterizations-we-might-have-tried"><i class="fa fa-check"></i><b>9.6</b> Other parameterizations we might have tried</a><ul>
<li class="chapter" data-level="9.6.1" data-path="heierarchical-models.html"><a href="heierarchical-models.html#shape-parameters-for-beta"><i class="fa fa-check"></i><b>9.6.1</b> Shape parameters for Beta</a></li>
<li class="chapter" data-level="9.6.2" data-path="heierarchical-models.html"><a href="heierarchical-models.html#mean-instead-of-mode"><i class="fa fa-check"></i><b>9.6.2</b> Mean instead of mode</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="heierarchical-models.html"><a href="heierarchical-models.html#shrinkage"><i class="fa fa-check"></i><b>9.7</b> Shrinkage</a></li>
<li class="chapter" data-level="9.8" data-path="heierarchical-models.html"><a href="heierarchical-models.html#example-baseball-batting-average"><i class="fa fa-check"></i><b>9.8</b> Example: Baseball Batting Average</a></li>
<li class="chapter" data-level="9.9" data-path="heierarchical-models.html"><a href="heierarchical-models.html#ch09-exercises"><i class="fa fa-check"></i><b>9.9</b> Exerciess</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="model-comparison.html"><a href="model-comparison.html"><i class="fa fa-check"></i><b>10</b> (Model Comparison)</a></li>
<li class="chapter" data-level="11" data-path="nhst.html"><a href="nhst.html"><i class="fa fa-check"></i><b>11</b> (NHST)</a></li>
<li class="chapter" data-level="12" data-path="point-null-hypotheses.html"><a href="point-null-hypotheses.html"><i class="fa fa-check"></i><b>12</b> (Point Null Hypotheses)</a></li>
<li class="chapter" data-level="13" data-path="goals-power-sample-size.html"><a href="goals-power-sample-size.html"><i class="fa fa-check"></i><b>13</b> (Goals, Power, Sample Size)</a></li>
<li class="chapter" data-level="14" data-path="stan.html"><a href="stan.html"><i class="fa fa-check"></i><b>14</b> (Stan)</a></li>
<li class="chapter" data-level="15" data-path="glm-overview.html"><a href="glm-overview.html"><i class="fa fa-check"></i><b>15</b> GLM Overview</a><ul>
<li class="chapter" data-level="15.1" data-path="glm-overview.html"><a href="glm-overview.html#data-consists-of-observations-of-variables"><i class="fa fa-check"></i><b>15.1</b> Data consists of observations of variables</a><ul>
<li class="chapter" data-level="15.1.1" data-path="glm-overview.html"><a href="glm-overview.html#variable-roles"><i class="fa fa-check"></i><b>15.1.1</b> Variable Roles</a></li>
<li class="chapter" data-level="15.1.2" data-path="glm-overview.html"><a href="glm-overview.html#types-of-variables"><i class="fa fa-check"></i><b>15.1.2</b> Types of Variables</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="glm-overview.html"><a href="glm-overview.html#glm-framework"><i class="fa fa-check"></i><b>15.2</b> GLM Framework</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html"><i class="fa fa-check"></i><b>16</b> Estimating One and Two Means</a><ul>
<li class="chapter" data-level="16.1" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#basic-model-for-two-means"><i class="fa fa-check"></i><b>16.1</b> Basic Model for Two Means</a><ul>
<li class="chapter" data-level="16.1.1" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#data-2"><i class="fa fa-check"></i><b>16.1.1</b> Data</a></li>
<li class="chapter" data-level="16.1.2" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#model"><i class="fa fa-check"></i><b>16.1.2</b> Model</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#an-old-sleep-study"><i class="fa fa-check"></i><b>16.2</b> An Old Sleep Study</a><ul>
<li class="chapter" data-level="16.2.1" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#data-3"><i class="fa fa-check"></i><b>16.2.1</b> Data</a></li>
<li class="chapter" data-level="16.2.2" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#model-1"><i class="fa fa-check"></i><b>16.2.2</b> Model</a></li>
<li class="chapter" data-level="16.2.3" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#separate-standard-deviations-for-each-group"><i class="fa fa-check"></i><b>16.2.3</b> Separate standard deviations for each group</a></li>
<li class="chapter" data-level="16.2.4" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#comparison-to-t-test"><i class="fa fa-check"></i><b>16.2.4</b> Comparison to t-test</a></li>
<li class="chapter" data-level="16.2.5" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#rope-region-of-practical-equivalence"><i class="fa fa-check"></i><b>16.2.5</b> ROPE (Region of Practical Equivalence)</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#variations-on-the-theme"><i class="fa fa-check"></i><b>16.3</b> Variations on the theme</a><ul>
<li class="chapter" data-level="16.3.1" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#other-distributions-for-the-response"><i class="fa fa-check"></i><b>16.3.1</b> Other distributions for the response</a></li>
<li class="chapter" data-level="16.3.2" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#other-priors-for-sigma-or-tau"><i class="fa fa-check"></i><b>16.3.2</b> Other Priors for <span class="math inline">\(\sigma\)</span> (or <span class="math inline">\(\tau\)</span>)</a></li>
<li class="chapter" data-level="16.3.3" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#paired-comparisons"><i class="fa fa-check"></i><b>16.3.3</b> Paired Comparisons</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#how-many-chains-how-long"><i class="fa fa-check"></i><b>16.4</b> How many chains? How long?</a><ul>
<li class="chapter" data-level="16.4.1" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#why-multiple-chains"><i class="fa fa-check"></i><b>16.4.1</b> Why multiple chains?</a></li>
<li class="chapter" data-level="16.4.2" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#what-large-n.eff-does-and-doesnt-do-for-us"><i class="fa fa-check"></i><b>16.4.2</b> What large n.eff does and doesn’t do for us</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#looking-at-likelihood"><i class="fa fa-check"></i><b>16.5</b> Looking at Likelihood</a></li>
<li class="chapter" data-level="16.6" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#exercises"><i class="fa fa-check"></i><b>16.6</b> Exercises</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">(Re)Doing Bayesain Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="jags-just-another-gibbs-sampler" class="section level1">
<h1><span class="header-section-number">8</span> JAGS – Just Another Gibbs Sampler</h1>
<p>This chapter focuses on a very simple model – one for which JAGS is overkill.
This allows us to get familiar with JAGS and the various tools to investigate
JAGS models in a simple setting before moving on to more interesting models soon.</p>
<div id="what-jags-is" class="section level2">
<h2><span class="header-section-number">8.1</span> What JAGS is</h2>
<p>JAGS (Just Another Gibbs Sampler) is an implementation of an MCMC algorithm
called Gibbs sampling to sample the posterior distribution of a Bayesian model.</p>
<p>We will interact with JAGS from within R using the following packages:</p>
<ul>
<li>R2jags – interface between R and JAGS</li>
<li>coda – general tools for analyzing and graphing MCMC algorithms</li>
<li>bayesplot – a number of useful plots using <code>ggplot2</code></li>
<li>CalvinBayes – includes some of the functions from Kruschke’s text and other things to make our lives better.</li>
</ul>
<div id="jags-documentation" class="section level3">
<h3><span class="header-section-number">8.1.1</span> JAGS documentation</h3>
<p>You can find JAGS documentation at <a href="http://people.stat.sc.edu/hansont/stat740/jags_user_manual.pdf" class="uri">http://people.stat.sc.edu/hansont/stat740/jags_user_manual.pdf</a>.
This can be useful if you need to find out particulars about things like
the distributions that are availble in JAGS.</p>
</div>
<div id="updating-c-and-clang" class="section level3">
<h3><span class="header-section-number">8.1.2</span> Updating C and CLANG</h3>
<p>Based on limited testing, it appears that things are good to go and you
should not need to do this.</p>
<p><del>To use the newest versions of JAGS, Stan, and the R packages that accompany
them, we need to use a newer version of some software than is standard for
&lt;rstudio.calvin.edu&gt;. I have taken care of this at the system level,
and that may suffice, but if things don’t work in your account,
take the following steps:</del></p>
<ol style="list-style-type: decimal">
<li><p><del>Open a terminal with Tools &gt; Terminal &gt; New Terminal</del></p></li>
<li><p><del>Copy-and-paste this into the terminal window.</del></p></li>
</ol>
<pre class="sourceCode bash"><code class="sourceCode bash"><span class="bu">echo</span> <span class="st">&quot;source scl_source enable devtoolset-7 llvm-toolset-7&quot;</span> <span class="op">&gt;&gt;</span> ~/.bashrc</code></pre>
<p><del>This tells the server to use a newer version of C++ and CLANG.</del></p>
<ol start="3" style="list-style-type: decimal">
<li><p><del>Close the terminal</del></p></li>
<li><p><del>Restart R with Session &gt; Restart R</del></p></li>
</ol>
<p><del><strong>You should only need to go through these steps once.</strong></del></p>
</div>
</div>
<div id="example-1-estimating-a-proportion-1" class="section level2">
<h2><span class="header-section-number">8.2</span> Example 1: estimating a proportion</h2>
<div id="the-model-1" class="section level3">
<h3><span class="header-section-number">8.2.1</span> The Model</h3>
<p><img src="images/Bernoulli-model.png" width="65%" /></p>
<p>That is
<span class="math display">\[\begin{align*}
Y_i &amp;\sim {\sf Bern}(\theta)
\\
\theta &amp;\sim {\sf Beta}(a, b)
\end{align*}\]</span></p>
</div>
<div id="load-data" class="section level3">
<h3><span class="header-section-number">8.2.2</span> Load Data</h3>
<p>The data sets provided as csv files by Kruschke also live in the <code>CalvinBayes</code>
package, so you can read this file with</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(CalvinBayes)
<span class="kw">data</span>(<span class="st">&quot;z15N50&quot;</span>)
<span class="kw">glimpse</span>(z15N50)</code></pre>
<pre><code>## Observations: 50
## Variables: 1
## $ y &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,…</code></pre>
<p>We see that the data are coded as 50 0’s and 1’s in a variable named <code>y</code>.
(You should use better names when creating your own data sets.)</p>
</div>
<div id="specify-the-model" class="section level3">
<h3><span class="header-section-number">8.2.3</span> Specify the model</h3>
<p>There are at least three R packages that provide an interface to JAGS:
rjags, R2jags, and runjags. We will primarily use R2jags.
Kruschke primarily uses rjags.
The main advantage of R2jags is that
we can specify the model by creating a special kind of function. <a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a>
The avoids the need to create temporary files (as rjags requires)
and keeps things tidier in our R markdown documents.</p>
<p>The main part of the model description is the same in either style, but notice
that the using the function style, we do not need to include <code>model{ ... }</code>
in our description. Here’s how we describe our simple model.</p>
<pre class="sourceCode r"><code class="sourceCode r">bern_model &lt;-<span class="st"> </span><span class="cf">function</span>() {
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>N) {
    y[i] <span class="op">~</span><span class="st"> </span><span class="kw">dbern</span>(theta)  <span class="co"># each response is Bernoulli with fixed parameter theta</span>
  }
  theta <span class="op">~</span><span class="st"> </span><span class="kw">dbeta</span>(<span class="dv">1</span>, <span class="dv">1</span>)    <span class="co"># prior for theta</span>
}</code></pre>
<p>Some things to note:</p>
<ul>
<li><p><code>dbern()</code> and <code>dbeta()</code> are JAGS functions. The JAGS distribution
functions are similar to, but not identical to the ones in R. (R doesn’t
have Bernoulli at all, for example.) Sometimes the parameterization
are different. Importantly, JAGS doesn’t have named arguments, so the
arguments must go in the order JAGS requires. Notice that we are only
giving the distribution name and its parameters. (So the first argument
that R requires is not part of this in JAGS.)</p></li>
<li><p>JAGS is also not vectorized the way R is, so we will need to write
some explicit for loops to say “do this to every that”. In the example
above, the for loops says that for each row of the data (<code>i in 1:N</code>),
the response (<code>y[i]</code>) is Bernoulli with paramter <span class="math inline">\(\theta\)</span> (<code>dbern(theta)</code>).</p></li>
</ul>
</div>
<div id="run-the-model" class="section level3">
<h3><span class="header-section-number">8.2.4</span> Run the model</h3>
<p><code>R2jags::jags()</code> can be used to run our JAGS model. We need to specify
three things:
(1) the model we are using (as defined above),
(2) the data we are using,
(3) the parameters we want saved in the posterior sampling.
(<code>theta</code> is the only parameter in this model,
but in larger models, we might choose to save only some of the parameters).</p>
<p>The data do not need to be in a data frame, and this usually means a bit
more work on our part to tell JAGS things like how much data there is.
We will prepare all the information JAGS needs about the data in a <strong>list</strong>
using <code>list()</code>.</p>
<p>There are some additional, optional things we might want to control as well.<br />
More on those later. For now, let’s fit the model using the default values
for everything else.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the R2jags package</span>
<span class="kw">library</span>(R2jags)

<span class="co"># Make the same &quot;random&quot; choices each time this is run.</span>
<span class="co"># This makes the Rmd file stable so you can comment on specific results.</span>
<span class="kw">set.seed</span>(<span class="dv">123</span>)    

<span class="co"># Fit the model</span>
bern_jags &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">jags</span>(
    <span class="dt">data =</span> <span class="kw">list</span>(<span class="dt">y =</span> z15N50<span class="op">$</span>y, <span class="dt">N =</span> <span class="kw">nrow</span>(z15N50)),
    <span class="dt">model.file =</span> bern_model,
    <span class="dt">parameters.to.save =</span> <span class="kw">c</span>(<span class="st">&quot;theta&quot;</span>)
  )</code></pre>
<pre><code>## module glm loaded</code></pre>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 50
##    Unobserved stochastic nodes: 1
##    Total graph size: 53
## 
## Initializing model</code></pre>
<p>Let’s take a quick look at what we have.</p>
<pre class="sourceCode r"><code class="sourceCode r">bern_jags</code></pre>
<pre><code>## Inference for Bugs model at &quot;/var/folders/py/txwd26jx5rq83f4nn0f5fmmm0000gn/T//RtmpJHPT4z/modelcb2574ecfdf8.txt&quot;, fit using jags,
##  3 chains, each with 2000 iterations (first 1000 discarded)
##  n.sims = 3000 iterations saved
##          mu.vect sd.vect   2.5%    25%    50%    75%  97.5%  Rhat n.eff
## theta      0.308   0.064  0.191  0.261  0.306  0.351  0.435 1.001  3000
## deviance  62.089   1.395 61.087 61.186 61.571 62.459 65.770 1.001  3000
## 
## For each parameter, n.eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor (at convergence, Rhat=1).
## 
## DIC info (using the rule, pD = var(deviance)/2)
## pD = 1.0 and DIC = 63.1
## DIC is an estimate of expected predictive error (lower deviance is better).</code></pre>
<p>Some notes on the output above:</p>
<ul>
<li><code>3 chains</code>: The Gibbs sampler was run 3 times with 3 different starting
values. Each chain ran for 2000 steps, but only the last 1000 steps were saved.</li>
<li><code>n.sims = 3000</code> (1000 in each of 3 chains).</li>
<li><code>mu.vect</code>: We see that the average value of <code>theta</code> in our
posterior sample is
0.308.<br />
</li>
<li><code>n.eff = 3000</code> is the number of effective samples.
In this case, JAGS is being very efficient,
as we would expect since it is just sampling directly from the
posterior distribution.</li>
<li><code>Rhat = 1</code>: This is a check for possible convergence problems.
If an MCMC sampler has converged, <code>Rhat</code> will be 1. So if the value
we see is not very close to 1, that is a sign of problems. Any value
greater than 1.1 is a cause for concern.</li>
<li>We’ll talk more about deviance later.</li>
</ul>
</div>
</div>
<div id="extracting-information-from-a-jags-run" class="section level2">
<h2><span class="header-section-number">8.3</span> Extracting information from a JAGS run</h2>
<div id="posterior-1" class="section level3">
<h3><span class="header-section-number">8.3.1</span> posterior()</h3>
<p>We can plot the posterior distribution, using <code>posterior()</code> to extract
the posterior samples as a data frame. Since we know the posterior
distribution should be Beta(16, 36), we’ll add that to our plot as a
reference to see how well our posterior sample is doing.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(CalvinBayes)
<span class="kw">head</span>(<span class="kw">posterior</span>(bern_jags))</code></pre>
<table>
<thead>
<tr class="header">
<th align="right">deviance</th>
<th align="right">theta</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">61.85</td>
<td align="right">0.2455</td>
</tr>
<tr class="even">
<td align="right">61.13</td>
<td align="right">0.3129</td>
</tr>
<tr class="odd">
<td align="right">61.13</td>
<td align="right">0.2860</td>
</tr>
<tr class="even">
<td align="right">61.13</td>
<td align="right">0.3133</td>
</tr>
<tr class="odd">
<td align="right">61.83</td>
<td align="right">0.3577</td>
</tr>
<tr class="even">
<td align="right">62.85</td>
<td align="right">0.2193</td>
</tr>
</tbody>
</table>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">gf_dhistogram</span>(<span class="op">~</span>theta, <span class="dt">data =</span> <span class="kw">posterior</span>(bern_jags), <span class="dt">bins =</span> <span class="dv">50</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">gf_dens</span>(<span class="op">~</span>theta, <span class="dt">size =</span> <span class="fl">1.5</span>, <span class="dt">alpha =</span> <span class="fl">0.8</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gf_dist</span>(<span class="st">&quot;beta&quot;</span>, <span class="dt">shape1 =</span> <span class="dv">16</span>, <span class="dt">shape2 =</span> <span class="dv">36</span>, <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>)</code></pre>
<p><img src="Redoing_files/figure-html/ch08-berg-jags-post-1.png" width="65%" /></p>
</div>
<div id="side-note-posterior-sampling-and-the-grid-method" class="section level3">
<h3><span class="header-section-number">8.3.2</span> Side note: posterior sampling and the grid method</h3>
<p>It is also possible to generate posterior samples when we use the grid method.
The mosaic package include the <code>resample()</code> function that will sample rows
of a data frame with replacement using specified probabilities
(given by the posterior, for example). Here’s how that works.</p>
<pre class="sourceCode r"><code class="sourceCode r">Grid &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">expand.grid</span>(
    <span class="dt">theta =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">by =</span> <span class="fl">0.001</span>)
  ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">prior =</span> <span class="kw">dbeta</span>(theta, <span class="dv">1</span>, <span class="dv">1</span>),
    <span class="dt">likelihood =</span> <span class="kw">dbinom</span>(<span class="dv">15</span>, <span class="dv">50</span>, theta),
    <span class="dt">posterior =</span> prior <span class="op">*</span><span class="st"> </span>likelihood,
    <span class="dt">posterior =</span> posterior <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(posterior) <span class="op">/</span><span class="st"> </span><span class="fl">0.001</span>
  )

Posterior &lt;-<span class="st"> </span><span class="kw">resample</span>(Grid, <span class="dt">size =</span> <span class="dv">5000</span>, <span class="dt">prob =</span> Grid<span class="op">$</span>posterior)
<span class="kw">gf_dhistogram</span>(<span class="op">~</span><span class="st"> </span>theta, <span class="dt">data =</span> Posterior, <span class="dt">bins =</span> <span class="dv">50</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gf_dens</span>(<span class="op">~</span>theta, <span class="dt">size =</span> <span class="fl">1.5</span>, <span class="dt">alpha =</span> <span class="fl">0.8</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gf_dist</span>(<span class="st">&quot;beta&quot;</span>, <span class="dt">shape1 =</span> <span class="dv">16</span>, <span class="dt">shape2 =</span> <span class="dv">36</span>, <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>)</code></pre>
<p><img src="Redoing_files/figure-html/ch08-grid-resampling-1.png" width="65%" /></p>
</div>
<div id="using-coda" class="section level3">
<h3><span class="header-section-number">8.3.3</span> Using coda</h3>
<p>The <code>coda</code> package provides output analysis and diagnostics for
MCMC algorithms. In order to use it, we must convert our JAGS object
into something <code>coda</code> recognizes.
We do with with the <code>as.mcmc()</code> function.</p>
<pre class="sourceCode r"><code class="sourceCode r">bern_mcmc &lt;-<span class="st"> </span><span class="kw">as.mcmc</span>(bern_jags)
<span class="kw">plot</span>(bern_mcmc)</code></pre>
<p><img src="Redoing_files/figure-html/ch-8-bern-mcmc-1.png" width="65%" /></p>
<p><strong>Note:</strong> Kruschke uses <code>rjags</code> without <code>R2jags</code>, so he does this step using
<code>rjags::coda.samples()</code> instead of <code>as.mcmc()</code>. Both functions result
in the same thing – posterior samples in a format that <code>coda</code> expects, but
they have different starting points.</p>
</div>
<div id="using-bayesplot" class="section level3">
<h3><span class="header-section-number">8.3.4</span> Using bayesplot</h3>
<p>The mcmc object we extracted with <code>as.mcmc()</code> can be used by the
utilities in the <code>bayesplot()</code>. Here, for example is the <code>bayesplot</code>
plot of the posterior distribution for theta.
By default, a vertical line segment is drawn at the median of the posterior
distribution.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(bayesplot)
<span class="kw">mcmc_areas</span>(
  bern_mcmc,            
  <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">&quot;theta&quot;</span>),     <span class="co"># make a plot for the theta parameter</span>
  <span class="dt">prob =</span> <span class="fl">0.90</span>)           <span class="co"># shade the central 90%</span></code></pre>
<p><img src="Redoing_files/figure-html/ch08-mcmc-areas-1.png" width="65%" /></p>
<p>One advantage of <code>bayesplot</code> is that the plots use the <code>ggplot2</code> system and
so interoperate well with <code>ggformula</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mcmc_trace</span>(bern_mcmc, <span class="dt">pars =</span> <span class="st">&quot;theta&quot;</span>) </code></pre>
<p><img src="Redoing_files/figure-html/ch08-mcmc-trace-1.png" width="65%" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># spearate the chains using facets and modify the color scheme</span>
<span class="kw">mcmc_trace</span>(bern_mcmc, <span class="dt">pars =</span> <span class="st">&quot;theta&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gf_facet_grid</span>(Chain <span class="op">~</span><span class="st"> </span>.) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gf_refine</span>(<span class="kw">scale_color_viridis_d</span>())</code></pre>
<pre><code>## Scale for &#39;colour&#39; is already present. Adding another scale for
## &#39;colour&#39;, which will replace the existing scale.</code></pre>
<p><img src="Redoing_files/figure-html/ch08-mcmc-trace-2.png" width="65%" /></p>
<p>We will encounter additional plots from <code>bayesplot</code> as we go along.</p>
</div>
<div id="using-kruschkes-functions" class="section level3">
<h3><span class="header-section-number">8.3.5</span> Using Kruschke’s functions</h3>
<p>I have put (modified versions of) some of functions from Kruschke’s book
into the <code>CalvinBayes</code> package so that you don’t have to source his files
to use them.</p>
<div id="diag_mcmc-diagmcmc" class="section level4 unnumbered">
<h4>diag_mcmc() [diagMCMC()]</h4>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">diag_mcmc</span>(bern_mcmc, <span class="dt">par =</span> <span class="st">&quot;theta&quot;</span>)</code></pre>
<p><img src="Redoing_files/figure-html/ch08-diagmcmc-1.png" width="65%" /></p>
</div>
<div id="plot_post-plotpost" class="section level4 unnumbered">
<h4>plot_post() [plotPost()]</h4>
<p>The <code>plot_post()</code> function takes as its first argument a vector of posterior
sampled values for one of the parameters. We can extract such a vector
a couple different ways:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">## # these produce the same output</span>
<span class="kw">plot_post</span>(bern_mcmc[, <span class="st">&quot;theta&quot;</span>], <span class="dt">main =</span> <span class="st">&quot;theta&quot;</span>, <span class="dt">xlab =</span> <span class="kw">expression</span>(theta))</code></pre>
<p><img src="Redoing_files/figure-html/ch-08-plot_post-1.png" width="65%" /></p>
<pre><code>## $posterior
##       ESS   mean median   mode
## var1 3000 0.3075 0.3056 0.2982
## 
## $hdi
##   prob     lo     hi
## 1 0.95 0.1896 0.4342</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">## plot_post(posterior(bern_jags)$theta, main = &quot;theta&quot;, xlab = expression(theta))</span></code></pre>
<p>There are a number of options that allow you to add some additional
information to the plot. Specifying <code>quietly = TRUE</code> will turn off
the numerical display that <code>plot_post()</code> generates along with the plot.
Here is an example.[^08-2]</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot_post</span>(bern_mcmc[, <span class="st">&quot;theta&quot;</span>], <span class="dt">main =</span> <span class="st">&quot;theta&quot;</span>, <span class="dt">xlab =</span> <span class="kw">expression</span>(theta),
         <span class="dt">cenTend =</span> <span class="st">&quot;median&quot;</span>, <span class="dt">compVal =</span> <span class="fl">0.5</span>, <span class="dt">ROPE =</span> <span class="kw">c</span>(<span class="fl">0.45</span>, <span class="fl">0.55</span>), 
         <span class="dt">credMass =</span> <span class="fl">0.90</span>, <span class="dt">quietly =</span> <span class="ot">TRUE</span>)</code></pre>
<p><img src="Redoing_files/figure-html/ch08-plot_post-args-1.png" width="65%" /></p>
</div>
</div>
</div>
<div id="optional-arguments-to-jags" class="section level2">
<h2><span class="header-section-number">8.4</span> Optional arguments to jags()</h2>
<div id="number-and-size-of-chains" class="section level3">
<h3><span class="header-section-number">8.4.1</span> Number and size of chains</h3>
<p>Sometimes we want to use more or longer chains (or fewer or shorter chains
if we are doing a quick preliminary check before running longer chains later).
<code>jags()</code> has three arguments for this:</p>
<ul>
<li><code>n.chains</code>: number of chains</li>
<li><code>n.iter</code>: number of iterations per chain</li>
<li><code>n.burnin</code>: number of burn in steps per chain</li>
<li><code>n.thin</code>: keep one sample per <code>n.thin</code>.</li>
</ul>
<p>The default value of <code>n.thin</code> is set to save about 1000 values per chain.
So in the example below, we end up with only 4000 samples (1000 per chain)
rather than the 16000 you might have expected.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">76543</span>)
bern_jags2 &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">jags</span>(
    <span class="dt">data =</span> <span class="kw">list</span>(<span class="dt">y =</span> z15N50<span class="op">$</span>y, <span class="dt">N =</span> <span class="kw">nrow</span>(z15N50)),
    <span class="dt">model.file =</span> bern_model,
    <span class="dt">parameters.to.save =</span> <span class="kw">c</span>(<span class="st">&quot;theta&quot;</span>),
    <span class="dt">n.chains =</span> <span class="dv">4</span>, <span class="dt">n.iter =</span> <span class="dv">5000</span>, <span class="dt">n.burnin =</span> <span class="dv">1000</span>,
  )
bern_jags2</code></pre>
<p>Setting <code>n.thin = 1</code> will save them all.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">76543</span>)
bern_jags2a &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">jags</span>(
    <span class="dt">data =</span> <span class="kw">list</span>(<span class="dt">y =</span> z15N50<span class="op">$</span>y, <span class="dt">N =</span> <span class="kw">nrow</span>(z15N50)),
    <span class="dt">model.file =</span> bern_model,
    <span class="dt">parameters.to.save =</span> <span class="kw">c</span>(<span class="st">&quot;theta&quot;</span>),
    <span class="dt">n.chains =</span> <span class="dv">4</span>, <span class="dt">n.iter =</span> <span class="dv">5000</span>, <span class="dt">n.burnin =</span> <span class="dv">1000</span>,
    <span class="dt">n.thin =</span> <span class="dv">1</span>
  )
bern_jags2a</code></pre>
</div>
<div id="starting-point-for-chains" class="section level3">
<h3><span class="header-section-number">8.4.2</span> Starting point for chains</h3>
<p>We can also control the starting point for the chains. Starting different
chains and quite different parameter values can help</p>
<ul>
<li>verify that the MCMC algorithm is not overly sensitive to where we are
starting from, and</li>
<li>ensure that the MCMC algorithm has explored the posterior distribution
sufficiently.</li>
</ul>
<p>On the other hand, if we start a chain too far from the peak of the
posterior distribution, the chain may have trouble converging.</p>
<p>We can provide either specific starting points for each chain or a function
that generates random starting points.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">gf_dist</span>(<span class="st">&quot;beta&quot;</span>, <span class="dt">shape1 =</span> <span class="dv">3</span>, <span class="dt">shape2 =</span> <span class="dv">3</span>)</code></pre>
<p><img src="Redoing_files/figure-html/ch03-bern-jags3-1.png" width="65%" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">2345</span>)
bern_jags3 &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">jags</span>(
    <span class="dt">data =</span> <span class="kw">list</span>(<span class="dt">y =</span> z15N50<span class="op">$</span>y, <span class="dt">N =</span> <span class="kw">nrow</span>(z15N50)),
    <span class="dt">model.file =</span> bern_model,
    <span class="dt">parameters.to.save =</span> <span class="kw">c</span>(<span class="st">&quot;theta&quot;</span>),
    <span class="co"># start each chain by sampling from the prior</span>
    <span class="dt">inits =</span> <span class="cf">function</span>() <span class="kw">list</span>(<span class="dt">theta =</span> <span class="kw">rbeta</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">3</span>))    
  )

bern_jags4 &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">jags</span>(
    <span class="dt">data =</span> <span class="kw">list</span>(<span class="dt">y =</span> z15N50<span class="op">$</span>y, <span class="dt">N =</span> <span class="kw">nrow</span>(z15N50)),
    <span class="dt">model.file =</span> bern_model,
    <span class="dt">parameters.to.save =</span> <span class="kw">c</span>(<span class="st">&quot;theta&quot;</span>),
    <span class="co"># choose specific starting point for each chain</span>
    <span class="dt">inits =</span> <span class="kw">list</span>(
      <span class="kw">list</span>(<span class="dt">theta =</span> <span class="fl">0.5</span>), <span class="kw">list</span>(<span class="dt">theta =</span> <span class="fl">0.7</span>), <span class="kw">list</span>(<span class="dt">theta =</span> <span class="fl">0.9</span>)
    )
  )

<span class="kw">mcmc_trace</span>(<span class="kw">as.mcmc</span>(bern_jags4), <span class="dt">pars =</span> <span class="st">&quot;theta&quot;</span>)</code></pre>
<p><img src="Redoing_files/figure-html/ch03-bern-jags3-2.png" width="65%" /></p>
<p>It is a good sign that our three traces look very similar and overlap a lot.
This indicates that the chains are mixing well and not overly affected
by their starting point.</p>
</div>
<div id="running-chains-in-parallel" class="section level3">
<h3><span class="header-section-number">8.4.3</span> Running chains in parallel</h3>
<p>Although this model runs very quickly, others models may take considerably
longer.
We can use <code>jags.parallel()</code> in place of <code>jags()</code>
to take advantage of multiple cores to run more than one chain at a
time. <code>jags.seed</code> can be used to set the seed for the parallel
random number generator used. (Note: <code>set.seed()</code> does not work when
using <code>jags.parallel()</code> and <code>jags.seed</code> has no effect when using <code>jags()</code>.)</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(R2jags)
bern_jags5 &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">jags.parallel</span>(
    <span class="dt">data =</span> <span class="kw">list</span>(<span class="dt">y =</span> z15N50<span class="op">$</span>y, <span class="dt">N =</span> <span class="kw">nrow</span>(z15N50)),
    <span class="dt">model.file =</span> bern_model,
    <span class="dt">parameters.to.save =</span> <span class="kw">c</span>(<span class="st">&quot;theta&quot;</span>),
    <span class="dt">n.chains =</span> <span class="dv">4</span>, <span class="dt">n.iter =</span> <span class="dv">5000</span>, <span class="dt">n.burnin =</span> <span class="dv">1000</span>,
    <span class="dt">jags.seed =</span> <span class="dv">12345</span>
  )</code></pre>
</div>
</div>
<div id="example-2-comparing-two-proportions" class="section level2">
<h2><span class="header-section-number">8.5</span> Example 2: comparing two proportions</h2>
<p>We have seen this situation before when we compared two coins.
This time we’ll be a little more personal and compare two people.
We will also work with a data set in a slightly different form.
But the main point will be to see how we describe this familiar model
to JAGS.</p>
<div id="the-data" class="section level3">
<h3><span class="header-section-number">8.5.1</span> The data</h3>
<p>Suppose we want to compare Reginald and Tony’s abilities to hit a target (with a
dart, perhaps). For each attempt, we record two pieces of information: the
person making the attempt (the subject) and whether the attempt succeeded
(0 or 1).</p>
<p>Kruschke’s provides a data frame for this, but the names he uses are not
good practice, so let’s remanme them to be more like what you might see
in a real data set.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(mosaic)
<span class="kw">head</span>(z6N8z2N7)   </code></pre>
<table>
<thead>
<tr class="header">
<th align="right">y</th>
<th align="left">s</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="left">Reginald</td>
</tr>
<tr class="even">
<td align="right">0</td>
<td align="left">Reginald</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="left">Reginald</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="left">Reginald</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="left">Reginald</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="left">Reginald</td>
</tr>
</tbody>
</table>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Let&#39;s do some renaming</span>
Target &lt;-<span class="st"> </span>z6N8z2N7 <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">hit =</span> y, <span class="dt">subject =</span> s)
<span class="kw">df_stats</span>(hit <span class="op">~</span><span class="st"> </span>subject, <span class="dt">data =</span> Target, props, <span class="dt">attempts =</span> length)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">subject</th>
<th align="right">prop_0</th>
<th align="right">prop_1</th>
<th align="right">attempts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Reginald</td>
<td align="right">0.2500</td>
<td align="right">0.7500</td>
<td align="right">8</td>
</tr>
<tr class="even">
<td align="left">Tony</td>
<td align="right">0.7143</td>
<td align="right">0.2857</td>
<td align="right">7</td>
</tr>
</tbody>
</table>
<p>Reginald was more successful than Tony, but neither had very many attempts.</p>
</div>
<div id="the-model-2" class="section level3">
<h3><span class="header-section-number">8.5.2</span> The model</h3>
<p>Now our model is that each person has his own success rate –
we have <strong>two <span class="math inline">\(\theta\)</span>’s</strong>,
one for Reginald and one for Tony.</p>
<p><img src="images/Bernoulli-model2.png" width="65%" /></p>
<p>We express this as
<span class="math display">\[\begin{align*}
Y_i|s &amp;\sim {\sf Bern}(\theta_{s})
\\
\theta_s &amp;\sim {\sf Beta}(a, b)
\end{align*}\]</span></p>
</div>
<div id="describing-the-model-to-jags" class="section level3">
<h3><span class="header-section-number">8.5.3</span> Describing the model to JAGS</h3>
<pre class="sourceCode r"><code class="sourceCode r">bern2_model &lt;-<span class="st"> </span><span class="cf">function</span>() {
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>Nobs) {
    <span class="co"># each response is Bernoulli with the appropriate theta</span>
    hit[i] <span class="op">~</span><span class="st"> </span><span class="kw">dbern</span>(theta[subject[i]])  
  }
  <span class="cf">for</span> (s <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>Nsub) {
    theta[s] <span class="op">~</span><span class="st"> </span><span class="kw">dbeta</span>(<span class="dv">2</span>, <span class="dv">2</span>)    <span class="co"># prior for each theta</span>
  }
}</code></pre>
<p>JAGS will also need access to four pieces of information from our data set:</p>
<ul>
<li>a vector of <code>hit</code> values</li>
<li>a vector of <code>subject</code> values – coded as integers 1 and 2 (so that <code>subject[i]</code>
makes sense to JAGS. (In general, JAGS is much less fluid in handling data than
R is, so we often need to do some manual data conversion for JAGS.)</li>
<li><code>Nobs</code> – the total number of observations</li>
<li><code>Nsub</code> – the number of subjects</li>
</ul>
<p>We will prepare these as a list.</p>
<pre class="sourceCode r"><code class="sourceCode r">TargetList &lt;-
<span class="st">  </span><span class="kw">list</span>(
    <span class="dt">Nobs =</span> <span class="kw">nrow</span>(Target),
    <span class="dt">Nsub =</span> <span class="dv">2</span>,
    <span class="dt">hit =</span> Target<span class="op">$</span>hit,
    <span class="dt">subject =</span> <span class="kw">as.numeric</span>(<span class="kw">as.factor</span>(Target<span class="op">$</span>subject))
)
TargetList</code></pre>
<pre><code>## $Nobs
## [1] 15
## 
## $Nsub
## [1] 2
## 
## $hit
##  [1] 1 0 1 1 1 1 1 0 0 0 1 0 0 1 0
## 
## $subject
##  [1] 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2</code></pre>
</div>
<div id="fitting-the-model" class="section level3">
<h3><span class="header-section-number">8.5.4</span> Fitting the model</h3>
<pre class="sourceCode r"><code class="sourceCode r">bern2_jags &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">jags</span>(
    <span class="dt">data =</span> TargetList,
    <span class="dt">model =</span> bern2_model,
    <span class="dt">parameters.to.save =</span> <span class="st">&quot;theta&quot;</span>)</code></pre>
</div>
<div id="inspecting-the-results" class="section level3">
<h3><span class="header-section-number">8.5.5</span> Inspecting the results</h3>
<pre class="sourceCode r"><code class="sourceCode r">bern2_mcmc &lt;-<span class="st"> </span><span class="kw">as.mcmc</span>(bern2_jags)
<span class="co"># Kruschke diagnostic plots</span>
<span class="kw">diag_mcmc</span>(bern2_mcmc)</code></pre>
<p><img src="Redoing_files/figure-html/ch08-bern2-mcmc-1.png" width="65%" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># bayesplot plots</span>
<span class="kw">mcmc_acf</span>(bern2_mcmc)</code></pre>
<p><img src="Redoing_files/figure-html/ch08-bern2-mcmc-2.png" width="65%" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mcmc_acf_bar</span>(bern2_mcmc)</code></pre>
<p><img src="Redoing_files/figure-html/ch08-bern2-mcmc-3.png" width="65%" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mcmc_pairs</span>(bern2_mcmc, <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">&quot;theta[1]&quot;</span>, <span class="st">&quot;theta[2]&quot;</span>))</code></pre>
<p><img src="Redoing_files/figure-html/ch08-bern2-mcmc-4.png" width="65%" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mcmc_combo</span>(bern2_mcmc)</code></pre>
<p><img src="Redoing_files/figure-html/ch08-bern2-mcmc-5.png" width="65%" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mcmc_combo</span>(bern2_mcmc, <span class="dt">combo =</span> <span class="kw">c</span>(<span class="st">&quot;dens&quot;</span>, <span class="st">&quot;dens_overlay&quot;</span>, <span class="st">&quot;trace&quot;</span>, <span class="st">&quot;scatter&quot;</span>), 
           <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">&quot;theta[1]&quot;</span>, <span class="st">&quot;theta[2]&quot;</span>))</code></pre>
<p><img src="Redoing_files/figure-html/ch08-bern2-mcmc-6.png" width="65%" /></p>
<p>Here is a list of <code>mcmc_</code> functions available:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">apropos</span>(<span class="st">&quot;^mcmc_&quot;</span>)</code></pre>
<pre><code>##  [1] &quot;mcmc_acf&quot;               &quot;mcmc_acf_bar&quot;          
##  [3] &quot;mcmc_areas&quot;             &quot;mcmc_areas_data&quot;       
##  [5] &quot;mcmc_areas_ridges&quot;      &quot;mcmc_areas_ridges_data&quot;
##  [7] &quot;mcmc_combo&quot;             &quot;mcmc_dens&quot;             
##  [9] &quot;mcmc_dens_chains&quot;       &quot;mcmc_dens_chains_data&quot; 
## [11] &quot;mcmc_dens_overlay&quot;      &quot;mcmc_hex&quot;              
## [13] &quot;mcmc_hist&quot;              &quot;mcmc_hist_by_chain&quot;    
## [15] &quot;mcmc_intervals&quot;         &quot;mcmc_intervals_data&quot;   
## [17] &quot;mcmc_neff&quot;              &quot;mcmc_neff_data&quot;        
## [19] &quot;mcmc_neff_hist&quot;         &quot;mcmc_nuts_acceptance&quot;  
## [21] &quot;mcmc_nuts_divergence&quot;   &quot;mcmc_nuts_energy&quot;      
## [23] &quot;mcmc_nuts_stepsize&quot;     &quot;mcmc_nuts_treedepth&quot;   
## [25] &quot;mcmc_pairs&quot;             &quot;mcmc_parcoord&quot;         
## [27] &quot;mcmc_parcoord_data&quot;     &quot;mcmc_recover_hist&quot;     
## [29] &quot;mcmc_recover_intervals&quot; &quot;mcmc_recover_scatter&quot;  
## [31] &quot;mcmc_rhat&quot;              &quot;mcmc_rhat_data&quot;        
## [33] &quot;mcmc_rhat_hist&quot;         &quot;mcmc_scatter&quot;          
## [35] &quot;mcmc_trace&quot;             &quot;mcmc_trace_highlight&quot;  
## [37] &quot;mcmc_violin&quot;</code></pre>
<p>The functions ending in <code>_data()</code> return the data used to make the corresponding plot. This can be useful
if you want to display that same information in a different way or
if you just want to inspect the data to make sure you understand the plot.</p>
</div>
<div id="difference-in-proportions" class="section level3">
<h3><span class="header-section-number">8.5.6</span> Difference in proportions</h3>
<p>If we are primarily interested in the difference between Reginald and Tony,
we can plot the difference in their theta values.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(<span class="kw">posterior</span>(bern2_jags))</code></pre>
<table>
<thead>
<tr class="header">
<th align="right">deviance</th>
<th align="right">theta.1</th>
<th align="right">theta.2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">21.98</td>
<td align="right">0.5002</td>
<td align="right">0.5821</td>
</tr>
<tr class="even">
<td align="right">18.75</td>
<td align="right">0.5718</td>
<td align="right">0.3790</td>
</tr>
<tr class="odd">
<td align="right">17.87</td>
<td align="right">0.8429</td>
<td align="right">0.3192</td>
</tr>
<tr class="even">
<td align="right">18.26</td>
<td align="right">0.5912</td>
<td align="right">0.2855</td>
</tr>
<tr class="odd">
<td align="right">17.68</td>
<td align="right">0.6661</td>
<td align="right">0.3230</td>
</tr>
<tr class="even">
<td align="right">18.69</td>
<td align="right">0.6519</td>
<td align="right">0.4671</td>
</tr>
</tbody>
</table>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">gf_density</span>( <span class="op">~</span>(theta<span class="fl">.1</span> <span class="op">-</span><span class="st"> </span>theta<span class="fl">.2</span>), <span class="dt">data =</span> <span class="kw">posterior</span>(bern2_jags))</code></pre>
<p><img src="Redoing_files/figure-html/ch08-bern2-post-density-1.png" width="65%" /></p>
</div>
<div id="sampling-from-the-prior" class="section level3">
<h3><span class="header-section-number">8.5.7</span> Sampling from the prior</h3>
<p>To sample from the prior, we must do the following:</p>
<ul>
<li>remove the response variable from our data list</li>
<li>change <code>Nobs</code> to 0</li>
<li>set <code>DIC = FALSE</code> in the call to <code>jags()</code>.</li>
</ul>
<p>This will run the model without any data,
which means the posterior will be the same as the prior.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># make a copy of our data list</span>
TargetList0 &lt;-<span class="st"> </span><span class="kw">list</span>(
  <span class="dt">Nobs =</span> <span class="dv">0</span>,  
  <span class="dt">Nsub =</span> <span class="dv">2</span>,
  <span class="dt">subject =</span> <span class="kw">as.numeric</span>(<span class="kw">as.factor</span>(Target<span class="op">$</span>subject))
)

bern2_jags0 &lt;-
<span class="st">  </span><span class="kw">jags</span>(
    <span class="dt">data =</span> TargetList0,
    <span class="dt">model.file =</span> bern2_model,
    <span class="dt">parameters.to.save =</span> <span class="kw">c</span>(<span class="st">&quot;theta&quot;</span>),
    <span class="dt">n.chains =</span> <span class="dv">2</span>, <span class="dt">n.iter =</span> <span class="dv">5000</span>, <span class="dt">n.burnin =</span> <span class="dv">1000</span>,
    <span class="dt">DIC =</span> <span class="ot">FALSE</span>)</code></pre>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 0
##    Unobserved stochastic nodes: 2
##    Total graph size: 20
## 
## Initializing model</code></pre>
<div id="note-about-in-jags-and-in-r" class="section level4">
<h4><span class="header-section-number">8.5.7.1</span> Note about : in JAGS and in R</h4>
<p>From the JAGS documentation:</p>
<blockquote>
<p>The sequence operator <code>:</code> can only produce increasing sequences. If n &lt; m then <code>m:n</code>
produces a vector of length zero and when this is used in a for loop index expression the
contents of loop inside the curly brackets are skipped. Note that this behavior is different
from the sequence operator in R, where <code>m:n</code> will produce a decreasing sequence if <code>n &lt; m</code>.</p>
</blockquote>
<p>So in our JAGS model, <code>1:0</code> correctly represents no data (and no trips through the for loop).</p>
</div>
<div id="what-good-is-it-to-generate-samples-from-the-prior" class="section level4">
<h4><span class="header-section-number">8.5.7.2</span> What good is it to generate samples from the prior?</h4>
<p>Our model set priors for <span class="math inline">\(\theta_1\)</span> and <span class="math inline">\(\theta_2\)</span>, but this implies a distribution
for <span class="math inline">\(\theta_1 - \theta_2\)</span>, and we might like to see what that distribution looks like.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">gf_density</span>( <span class="op">~</span>(theta<span class="fl">.1</span> <span class="op">-</span><span class="st"> </span>theta<span class="fl">.2</span>), <span class="dt">data =</span> <span class="kw">posterior</span>(bern2_jags0))</code></pre>
<p><img src="Redoing_files/figure-html/ch08-bern2-jags0-density-1.png" width="65%" /></p>
</div>
</div>
</div>
<div id="ch08-exercises" class="section level2">
<h2><span class="header-section-number">8.6</span> Exercises</h2>
<!-- Exercise 8.4. [Purpose: Explore the prior on a difference of parameters implied from the priors on the individual parameters.] -->
<ol style="list-style-type: decimal">
<li><p><strong>Sampling from priors.</strong>
You want to know who is the better free throw shooter, Alice or Bob.
You decide to have each shoot a number of shots and record their makes
and misses. You are primarily interested in the difference between their
free throw shooting proportions (<span class="math inline">\(\theta_2 - \theta_1\)</span>), and you are curious
to know how your choice of priors for <span class="math inline">\(\theta_1\)</span> and <span class="math inline">\(\theta_2\)</span> affects the
prior for <span class="math inline">\(\theta_2 - \theta_1\)</span>. For each situation below, use JAGS to
sample from the prior distribution for <span class="math inline">\(\theta_2 - \theta_1\)</span> and create
a density plot. (In each case, assume the priors for <span class="math inline">\(\theta_1\)</span> and
<span class="math inline">\(\theta_2\)</span> are independent.)</p>
<ol style="list-style-type: lower-alpha">
<li><p>Both priors are uniform. What distribution do you think the
prior for <span class="math inline">\(\theta_2 - \theta_1\)</span> is?</p></li>
<li><p>Both priors are <span class="math inline">\({\sf Beta}(0.2, 0.2)\)</span>. Explain why the prior
for <span class="math inline">\(\theta_2 - \theta_1\)</span> looks the way it does.</p></li>
</ol>
<p>Hint: Don’t forget to set <code>DIC = FALSE</code> when sampling from the prior.</p></li>
<li><p>Now suppose that Alice makes 25 out of 30 shots and Bob makes 18 out of 32.
Is this enough evidence to conclude that Alice is the better shooter?
Do this two ways. In each case, use a <span class="math inline">\({\sf Beta}(4, 2)\)</span> prior for both
<span class="math inline">\(\theta_1\)</span> and <span class="math inline">\(\theta_2\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Create data and use a model like the one used elsewhere in this chapter.
[Hint: <code>rep()</code> is handy for creating a bunch of values that are the same.]</p></li>
<li><p>Instead of using <code>dbern()</code>, use <code>dbin()</code> (JAGS version of the binomial
distribution). This should allow you to get by with simpler data that
consists only of the numbers 25, 30, 18, and 32. Note: the order of
arguments for <code>dbin()</code> is probability first, then number of trials. This is
reversed from the order in R.</p></li>
</ol></li>
<li><p>In the previous problem, what does this prior say about
the beliefs about Alice and Bob’s shooting before gathering data?</p></li>
<li><p>Let’s think about Alice and Bob some more.
We don’t know how to do this yet,
but explain why if you knew very little about basketball,
you might like to have a prior for <span class="math inline">\(\theta_1\)</span> and <span class="math inline">\(\theta_2\)</span>
that was not indpendent.
How might the priors for <span class="math inline">\(\theta_1\)</span> and <span class="math inline">\(\theta_2\)</span> be related?</p></li>
<li><p>Consider the model below.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Create a plot of the <strong>prior</strong> distribution of
<code>theat1</code> and <code>theta2</code>. A scatter plot with overlayed density plot
works well. How does this prior compare to the priors in problem 1.
(Hint: Don’t forget to use <code>DIC = FALSE</code> when sampling from the
prior.)</p></li>
<li><p>Fit the model to the Alice and Bob data. How does this
choice of prior change things?</p></li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">diff_model &lt;-<span class="st"> </span><span class="cf">function</span>() {
  z1 <span class="op">~</span><span class="st"> </span><span class="kw">dbin</span>(theta1, n1)
  z2 <span class="op">~</span><span class="st"> </span><span class="kw">dbin</span>(theta2, n2)
  theta2 &lt;-<span class="st"> </span>theta1 <span class="op">+</span><span class="st"> </span>delta
  theta1 <span class="op">~</span><span class="st"> </span><span class="kw">dbeta</span>(<span class="dv">4</span>, <span class="dv">2</span>)
  delta <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">400</span>)  <span class="co"># Normal with mean 0 and sd = 0.05</span>
}

diff_jags &lt;-
<span class="st">  </span><span class="kw">jags.parallel</span>(
    <span class="dt">model =</span> diff_model,
    <span class="dt">data  =</span> <span class="kw">list</span>(<span class="dt">n1 =</span> <span class="dv">30</span>, <span class="dt">z1 =</span> <span class="dv">25</span>, <span class="dt">n2 =</span> <span class="dv">32</span>, <span class="dt">z2 =</span> <span class="dv">18</span>),
    <span class="dt">parameters.to.save =</span> <span class="kw">c</span>(<span class="st">&quot;theta1&quot;</span>, <span class="st">&quot;theta2&quot;</span>, <span class="st">&quot;delta&quot;</span>),
    <span class="dt">n.iter =</span> <span class="dv">5000</span>,
    <span class="dt">n.chains =</span> <span class="dv">4</span>
  )</code></pre></li>
<li><p>Redo problem 5 using the grid method.</p></li>
</ol>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="6">
<li id="fn6"><p>This is a bit of a trick that R2jags uses. The function created is never
run. The code is inspected and taken as the description of the model.
If you were to run the funtion, all it would do is create R formulas.<a href="jags-just-another-gibbs-sampler.html#fnref6" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="markov-chain-monte-carlo-mcmc.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="heierarchical-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["Redoing.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
