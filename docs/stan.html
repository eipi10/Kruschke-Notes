<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>14 Stan | (Re)Doing Bayesain Data Analysis</title>
  <meta name="description" content="Code, exercises and discussion to accompany a course taught from Kruschke’s Doing Bayesian Data Analysis (2ed)">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="14 Stan | (Re)Doing Bayesain Data Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Code, exercises and discussion to accompany a course taught from Kruschke’s Doing Bayesian Data Analysis (2ed)" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="14 Stan | (Re)Doing Bayesain Data Analysis" />
  
  <meta name="twitter:description" content="Code, exercises and discussion to accompany a course taught from Kruschke’s Doing Bayesian Data Analysis (2ed)" />
  

<meta name="author" content="R Pruim">


<meta name="date" content="2019-04-24">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="goals-power-sample-size.html">
<link rel="next" href="glm-overview.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">(Re)Doing Bayesian Data Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> What’s in These Notes</a></li>
<li class="part"><span><b>I The Basics: Models, Probability, Bayes, and R</b></span></li>
<li class="chapter" data-level="2" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html"><i class="fa fa-check"></i><b>2</b> Credibility, Models, and Parameters</a><ul>
<li class="chapter" data-level="2.1" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#the-steps-of-bayesian-data-analysis"><i class="fa fa-check"></i><b>2.1</b> The Steps of Bayesian Data Analysis</a><ul>
<li class="chapter" data-level="2.1.1" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#r-code"><i class="fa fa-check"></i><b>2.1.1</b> R code</a></li>
<li class="chapter" data-level="2.1.2" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#r-packages"><i class="fa fa-check"></i><b>2.1.2</b> R packages</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#example-1-which-coin-is-it"><i class="fa fa-check"></i><b>2.2</b> Example 1: Which coin is it?</a><ul>
<li class="chapter" data-level="2.2.1" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#freedom-of-choice"><i class="fa fa-check"></i><b>2.2.1</b> Freedom of choice</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#distributions"><i class="fa fa-check"></i><b>2.3</b> Distributions</a><ul>
<li class="chapter" data-level="2.3.1" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#beta-distributions"><i class="fa fa-check"></i><b>2.3.1</b> Beta distributions</a></li>
<li class="chapter" data-level="2.3.2" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#normal-distributions"><i class="fa fa-check"></i><b>2.3.2</b> Normal distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#example-2-height-vs-weight"><i class="fa fa-check"></i><b>2.4</b> Example 2: Height vs Weight</a><ul>
<li class="chapter" data-level="2.4.1" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#data"><i class="fa fa-check"></i><b>2.4.1</b> Data</a></li>
<li class="chapter" data-level="2.4.2" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#describing-a-model-for-the-relationship-between-height-and-weight"><i class="fa fa-check"></i><b>2.4.2</b> Describing a model for the relationship between height and weight</a></li>
<li class="chapter" data-level="2.4.3" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#prior"><i class="fa fa-check"></i><b>2.4.3</b> Prior</a></li>
<li class="chapter" data-level="2.4.4" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#posterior"><i class="fa fa-check"></i><b>2.4.4</b> Posterior</a></li>
<li class="chapter" data-level="2.4.5" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#posterior-predictive-check"><i class="fa fa-check"></i><b>2.4.5</b> Posterior Predictive Check</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#where-do-we-go-from-here"><i class="fa fa-check"></i><b>2.5</b> Where do we go from here?</a></li>
<li class="chapter" data-level="2.6" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#ch02-exercises"><i class="fa fa-check"></i><b>2.6</b> Exercises</a></li>
<li class="chapter" data-level="2.7" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#footnotes"><i class="fa fa-check"></i><b>2.7</b> Footnotes</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html"><i class="fa fa-check"></i><b>3</b> Some Useful Bits of R</a><ul>
<li class="chapter" data-level="3.1" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#style-guide"><i class="fa fa-check"></i><b>3.1</b> You Gotta Have Style</a><ul>
<li class="chapter" data-level="3.1.1" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#an-additional-note-about-homework"><i class="fa fa-check"></i><b>3.1.1</b> An additional note about homework</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#vectors-lists-and-data-frames"><i class="fa fa-check"></i><b>3.2</b> Vectors, Lists, and Data Frames</a><ul>
<li class="chapter" data-level="3.2.1" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#vectors"><i class="fa fa-check"></i><b>3.2.1</b> Vectors</a></li>
<li class="chapter" data-level="3.2.2" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#lists"><i class="fa fa-check"></i><b>3.2.2</b> Lists</a></li>
<li class="chapter" data-level="3.2.3" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#data-frames-for-rectangular-data"><i class="fa fa-check"></i><b>3.2.3</b> Data frames for rectangular data</a></li>
<li class="chapter" data-level="3.2.4" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#other-types-of-data"><i class="fa fa-check"></i><b>3.2.4</b> Other types of data</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#plotting-with-ggformula"><i class="fa fa-check"></i><b>3.3</b> Plotting with ggformula</a></li>
<li class="chapter" data-level="3.4" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#creating-data-with-expand.grid"><i class="fa fa-check"></i><b>3.4</b> Creating data with expand.grid()</a></li>
<li class="chapter" data-level="3.5" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#transforming-and-summarizing-data-dplyr-and-tidyr"><i class="fa fa-check"></i><b>3.5</b> Transforming and summarizing data dplyr and tidyr</a></li>
<li class="chapter" data-level="3.6" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#writing-functions"><i class="fa fa-check"></i><b>3.6</b> Writing Functions</a><ul>
<li class="chapter" data-level="3.6.1" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#why-write-functions"><i class="fa fa-check"></i><b>3.6.1</b> Why write functions?</a></li>
<li class="chapter" data-level="3.6.2" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#function-parts"><i class="fa fa-check"></i><b>3.6.2</b> Function parts</a></li>
<li class="chapter" data-level="3.6.3" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#the-function-function-has-its-function"><i class="fa fa-check"></i><b>3.6.3</b> The function() function has its function</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#some-common-error-messages"><i class="fa fa-check"></i><b>3.7</b> Some common error messages</a><ul>
<li class="chapter" data-level="3.7.1" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#object-not-found"><i class="fa fa-check"></i><b>3.7.1</b> object not found</a></li>
<li class="chapter" data-level="3.7.2" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#any-message-mentioning-yaml"><i class="fa fa-check"></i><b>3.7.2</b> Any message mentioning yaml</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#ch03-exercises"><i class="fa fa-check"></i><b>3.8</b> Exercises</a></li>
<li class="chapter" data-level="3.9" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#footnotes-1"><i class="fa fa-check"></i><b>3.9</b> Footnotes</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>4</b> Probability</a><ul>
<li class="chapter" data-level="4.1" data-path="probability.html"><a href="probability.html#some-terminology"><i class="fa fa-check"></i><b>4.1</b> Some terminology</a></li>
<li class="chapter" data-level="4.2" data-path="probability.html"><a href="probability.html#distributions-in-r"><i class="fa fa-check"></i><b>4.2</b> Distributions in R</a><ul>
<li class="chapter" data-level="4.2.1" data-path="probability.html"><a href="probability.html#example-normal-distributions"><i class="fa fa-check"></i><b>4.2.1</b> Example: Normal distributions</a></li>
<li class="chapter" data-level="4.2.2" data-path="probability.html"><a href="probability.html#simulating-running-proportions"><i class="fa fa-check"></i><b>4.2.2</b> Simulating running proportions</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="probability.html"><a href="probability.html#joint-marginal-and-conditional-distributions"><i class="fa fa-check"></i><b>4.3</b> Joint, marginal, and conditional distributions</a><ul>
<li class="chapter" data-level="4.3.1" data-path="probability.html"><a href="probability.html#example-hair-and-eye-color"><i class="fa fa-check"></i><b>4.3.1</b> Example: Hair and eye color</a></li>
<li class="chapter" data-level="4.3.2" data-path="probability.html"><a href="probability.html#independence"><i class="fa fa-check"></i><b>4.3.2</b> Independence</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="probability.html"><a href="probability.html#ch04-exercises"><i class="fa fa-check"></i><b>4.4</b> Exercises</a></li>
<li class="chapter" data-level="4.5" data-path="probability.html"><a href="probability.html#footnotes-2"><i class="fa fa-check"></i><b>4.5</b> Footnotes</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html"><i class="fa fa-check"></i><b>5</b> Bayes’ Rule and the Grid Method</a><ul>
<li class="chapter" data-level="5.1" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#the-big-bayesian-idea"><i class="fa fa-check"></i><b>5.1</b> The Big Bayesian Idea</a><ul>
<li class="chapter" data-level="5.1.1" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#likelihood"><i class="fa fa-check"></i><b>5.1.1</b> Likelihood</a></li>
<li class="chapter" data-level="5.1.2" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#when-bayes-is-easy"><i class="fa fa-check"></i><b>5.1.2</b> When Bayes is easy</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#estimating-the-bias-in-a-coin-using-the-grid-method"><i class="fa fa-check"></i><b>5.2</b> Estimating the bias in a coin using the Grid Method</a><ul>
<li class="chapter" data-level="5.2.1" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#creating-a-grid"><i class="fa fa-check"></i><b>5.2.1</b> Creating a Grid</a></li>
<li class="chapter" data-level="5.2.2" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#hdi-from-the-grid"><i class="fa fa-check"></i><b>5.2.2</b> HDI from the grid</a></li>
<li class="chapter" data-level="5.2.3" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#automating-the-grid"><i class="fa fa-check"></i><b>5.2.3</b> Automating the grid</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#working-on-the-log-scale"><i class="fa fa-check"></i><b>5.3</b> Working on the log scale</a></li>
<li class="chapter" data-level="5.4" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#discrete-params"><i class="fa fa-check"></i><b>5.4</b> Discrete Parameters</a></li>
<li class="chapter" data-level="5.5" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#ch05-exercises"><i class="fa fa-check"></i><b>5.5</b> Exercises</a></li>
<li class="chapter" data-level="5.6" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#footnotes-3"><i class="fa fa-check"></i><b>5.6</b> Footnotes</a></li>
</ul></li>
<li class="part"><span><b>II Inferring a Binomial Probability</b></span></li>
<li class="chapter" data-level="6" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><i class="fa fa-check"></i><b>6</b> Inferring a Binomial Probability via Exact Mathematical Analysis</a><ul>
<li class="chapter" data-level="6.1" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#beta-distributions-1"><i class="fa fa-check"></i><b>6.1</b> Beta distributions</a></li>
<li class="chapter" data-level="6.2" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#beta-and-bayes"><i class="fa fa-check"></i><b>6.2</b> Beta and Bayes</a><ul>
<li class="chapter" data-level="6.2.1" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#the-bernoulli-likelihood-function"><i class="fa fa-check"></i><b>6.2.1</b> The Bernoulli likelihood function</a></li>
<li class="chapter" data-level="6.2.2" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#a-convenient-prior"><i class="fa fa-check"></i><b>6.2.2</b> A convenient prior</a></li>
<li class="chapter" data-level="6.2.3" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#pros-and-cons-of-conjugate-priors"><i class="fa fa-check"></i><b>6.2.3</b> Pros and Cons of conjugate priors</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#getting-to-know-the-beta-distributions"><i class="fa fa-check"></i><b>6.3</b> Getting to know the Beta distributions</a><ul>
<li class="chapter" data-level="6.3.1" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#important-facts"><i class="fa fa-check"></i><b>6.3.1</b> Important facts</a></li>
<li class="chapter" data-level="6.3.2" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#alternative-parameterizations-of-beta-distributions"><i class="fa fa-check"></i><b>6.3.2</b> Alternative parameterizations of Beta distributions</a></li>
<li class="chapter" data-level="6.3.3" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#beta_params"><i class="fa fa-check"></i><b>6.3.3</b> beta_params()</a></li>
<li class="chapter" data-level="6.3.4" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#automating-bayesian-updates-for-a-proportion-beta-prior"><i class="fa fa-check"></i><b>6.3.4</b> Automating Bayesian updates for a proportion (beta prior)</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#what-if-the-prior-isnt-a-beta-distribution"><i class="fa fa-check"></i><b>6.4</b> What if the prior isn’t a beta distribution?</a></li>
<li class="chapter" data-level="6.5" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#ch06-exercises"><i class="fa fa-check"></i><b>6.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html"><i class="fa fa-check"></i><b>7</b> Markov Chain Monte Carlo (MCMC)</a><ul>
<li class="chapter" data-level="7.1" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#king-markov-and-adviser-metropolis"><i class="fa fa-check"></i><b>7.1</b> King Markov and Adviser Metropolis</a></li>
<li class="chapter" data-level="7.2" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#quick-intro-to-markov-chains"><i class="fa fa-check"></i><b>7.2</b> Quick Intro to Markov Chains</a><ul>
<li class="chapter" data-level="7.2.1" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#more-info-please"><i class="fa fa-check"></i><b>7.2.1</b> More info, please</a></li>
<li class="chapter" data-level="7.2.2" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#definition"><i class="fa fa-check"></i><b>7.2.2</b> Definition</a></li>
<li class="chapter" data-level="7.2.3" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#time-homogeneous-markov-chains"><i class="fa fa-check"></i><b>7.2.3</b> Time-Homogeneous Markov Chains</a></li>
<li class="chapter" data-level="7.2.4" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#matrix-representation"><i class="fa fa-check"></i><b>7.2.4</b> Matrix representation</a></li>
<li class="chapter" data-level="7.2.5" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#regular-markov-chains"><i class="fa fa-check"></i><b>7.2.5</b> Regular Markov Chains</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#back-to-king-markov"><i class="fa fa-check"></i><b>7.3</b> Back to King Markov</a></li>
<li class="chapter" data-level="7.4" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#how-well-does-the-metropolis-algorithm-work"><i class="fa fa-check"></i><b>7.4</b> How well does the Metropolis Algorithm work?</a><ul>
<li class="chapter" data-level="7.4.1" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#jumping-to-any-island"><i class="fa fa-check"></i><b>7.4.1</b> Jumping to any island</a></li>
<li class="chapter" data-level="7.4.2" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#jumping-only-to-neighbor-islands"><i class="fa fa-check"></i><b>7.4.2</b> Jumping only to neighbor islands</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#markov-chains-and-posterior-sampling"><i class="fa fa-check"></i><b>7.5</b> Markov Chains and Posterior Sampling</a><ul>
<li class="chapter" data-level="7.5.1" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#example-1-estimating-a-proportion"><i class="fa fa-check"></i><b>7.5.1</b> Example 1: Estimating a proportion</a></li>
<li class="chapter" data-level="7.5.2" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#example-2-estimating-mean-and-variance"><i class="fa fa-check"></i><b>7.5.2</b> Example 2: Estimating mean and variance</a></li>
<li class="chapter" data-level="7.5.3" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#issues-with-metropolis-algorithm"><i class="fa fa-check"></i><b>7.5.3</b> Issues with Metropolis Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#two-coins"><i class="fa fa-check"></i><b>7.6</b> Two coins</a><ul>
<li class="chapter" data-level="7.6.1" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#the-model"><i class="fa fa-check"></i><b>7.6.1</b> The model</a></li>
<li class="chapter" data-level="7.6.2" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#exact-analysis"><i class="fa fa-check"></i><b>7.6.2</b> Exact analysis</a></li>
<li class="chapter" data-level="7.6.3" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#metropolis"><i class="fa fa-check"></i><b>7.6.3</b> Metropolis</a></li>
<li class="chapter" data-level="7.6.4" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#gibbs-sampling"><i class="fa fa-check"></i><b>7.6.4</b> Gibbs sampling</a></li>
<li class="chapter" data-level="7.6.5" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#advantages-and-disadvantages-of-gibbs-vs-metropolis"><i class="fa fa-check"></i><b>7.6.5</b> Advantages and Disadvantages of Gibbs vs Metropolis</a></li>
<li class="chapter" data-level="7.6.6" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#so-what-do-we-learn-about-the-coins"><i class="fa fa-check"></i><b>7.6.6</b> So what do we learn about the coins?</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#mcmc-posterior-sampling-big-picture"><i class="fa fa-check"></i><b>7.7</b> MCMC posterior sampling: Big picture</a><ul>
<li class="chapter" data-level="7.7.1" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#mcmc-markov-chain-monte-carlo"><i class="fa fa-check"></i><b>7.7.1</b> MCMC = Markov chain Monte Carlo</a></li>
<li class="chapter" data-level="7.7.2" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#posterior-sampling-random-walk-through-the-posterior"><i class="fa fa-check"></i><b>7.7.2</b> Posterior sampling: Random walk through the posterior</a></li>
<li class="chapter" data-level="7.7.3" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#where-do-we-go-from-here-1"><i class="fa fa-check"></i><b>7.7.3</b> Where do we go from here?</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#ch07-exercises"><i class="fa fa-check"></i><b>7.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html"><i class="fa fa-check"></i><b>8</b> JAGS – Just Another Gibbs Sampler</a><ul>
<li class="chapter" data-level="8.1" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#what-jags-is"><i class="fa fa-check"></i><b>8.1</b> What JAGS is</a><ul>
<li class="chapter" data-level="8.1.1" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#jags-documentation"><i class="fa fa-check"></i><b>8.1.1</b> JAGS documentation</a></li>
<li class="chapter" data-level="8.1.2" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#updating-c-and-clang"><i class="fa fa-check"></i><b>8.1.2</b> Updating C and CLANG</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#example-1-estimating-a-proportion-1"><i class="fa fa-check"></i><b>8.2</b> Example 1: estimating a proportion</a><ul>
<li class="chapter" data-level="8.2.1" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#the-model-1"><i class="fa fa-check"></i><b>8.2.1</b> The Model</a></li>
<li class="chapter" data-level="8.2.2" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#load-data"><i class="fa fa-check"></i><b>8.2.2</b> Load Data</a></li>
<li class="chapter" data-level="8.2.3" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#specify-the-model"><i class="fa fa-check"></i><b>8.2.3</b> Specify the model</a></li>
<li class="chapter" data-level="8.2.4" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#run-the-model"><i class="fa fa-check"></i><b>8.2.4</b> Run the model</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#extracting-information-from-a-jags-run"><i class="fa fa-check"></i><b>8.3</b> Extracting information from a JAGS run</a><ul>
<li class="chapter" data-level="8.3.1" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#posterior-1"><i class="fa fa-check"></i><b>8.3.1</b> posterior()</a></li>
<li class="chapter" data-level="8.3.2" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#side-note-posterior-sampling-and-the-grid-method"><i class="fa fa-check"></i><b>8.3.2</b> Side note: posterior sampling and the grid method</a></li>
<li class="chapter" data-level="8.3.3" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#using-coda"><i class="fa fa-check"></i><b>8.3.3</b> Using coda</a></li>
<li class="chapter" data-level="8.3.4" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#using-bayesplot"><i class="fa fa-check"></i><b>8.3.4</b> Using bayesplot</a></li>
<li class="chapter" data-level="8.3.5" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#using-kruschkes-functions"><i class="fa fa-check"></i><b>8.3.5</b> Using Kruschke’s functions</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#optional-arguments-to-jags"><i class="fa fa-check"></i><b>8.4</b> Optional arguments to jags()</a><ul>
<li class="chapter" data-level="8.4.1" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#number-and-size-of-chains"><i class="fa fa-check"></i><b>8.4.1</b> Number and size of chains</a></li>
<li class="chapter" data-level="8.4.2" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#starting-point-for-chains"><i class="fa fa-check"></i><b>8.4.2</b> Starting point for chains</a></li>
<li class="chapter" data-level="8.4.3" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#running-chains-in-parallel"><i class="fa fa-check"></i><b>8.4.3</b> Running chains in parallel</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#example-2-comparing-two-proportions"><i class="fa fa-check"></i><b>8.5</b> Example 2: comparing two proportions</a><ul>
<li class="chapter" data-level="8.5.1" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#the-data"><i class="fa fa-check"></i><b>8.5.1</b> The data</a></li>
<li class="chapter" data-level="8.5.2" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#the-model-2"><i class="fa fa-check"></i><b>8.5.2</b> The model</a></li>
<li class="chapter" data-level="8.5.3" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#describing-the-model-to-jags"><i class="fa fa-check"></i><b>8.5.3</b> Describing the model to JAGS</a></li>
<li class="chapter" data-level="8.5.4" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#fitting-the-model"><i class="fa fa-check"></i><b>8.5.4</b> Fitting the model</a></li>
<li class="chapter" data-level="8.5.5" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#inspecting-the-results"><i class="fa fa-check"></i><b>8.5.5</b> Inspecting the results</a></li>
<li class="chapter" data-level="8.5.6" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#difference-in-proportions"><i class="fa fa-check"></i><b>8.5.6</b> Difference in proportions</a></li>
<li class="chapter" data-level="8.5.7" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#sampling-from-the-prior"><i class="fa fa-check"></i><b>8.5.7</b> Sampling from the prior</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#ch08-exercises"><i class="fa fa-check"></i><b>8.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="heierarchical-models.html"><a href="heierarchical-models.html"><i class="fa fa-check"></i><b>9</b> Heierarchical Models</a><ul>
<li class="chapter" data-level="9.1" data-path="heierarchical-models.html"><a href="heierarchical-models.html#gamma-distributions"><i class="fa fa-check"></i><b>9.1</b> Gamma Distributions</a></li>
<li class="chapter" data-level="9.2" data-path="heierarchical-models.html"><a href="heierarchical-models.html#one-coin-from-one-mint"><i class="fa fa-check"></i><b>9.2</b> One coin from one mint</a></li>
<li class="chapter" data-level="9.3" data-path="heierarchical-models.html"><a href="heierarchical-models.html#multiple-coins-from-one-mint"><i class="fa fa-check"></i><b>9.3</b> Multiple coins from one mint</a></li>
<li class="chapter" data-level="9.4" data-path="heierarchical-models.html"><a href="heierarchical-models.html#multiple-coins-from-multiple-mints"><i class="fa fa-check"></i><b>9.4</b> Multiple coins from multiple mints</a></li>
<li class="chapter" data-level="9.5" data-path="heierarchical-models.html"><a href="heierarchical-models.html#therapeutic-touch"><i class="fa fa-check"></i><b>9.5</b> Therapeutic Touch</a><ul>
<li class="chapter" data-level="9.5.1" data-path="heierarchical-models.html"><a href="heierarchical-models.html#abstract"><i class="fa fa-check"></i><b>9.5.1</b> Abstract</a></li>
<li class="chapter" data-level="9.5.2" data-path="heierarchical-models.html"><a href="heierarchical-models.html#data-1"><i class="fa fa-check"></i><b>9.5.2</b> Data</a></li>
<li class="chapter" data-level="9.5.3" data-path="heierarchical-models.html"><a href="heierarchical-models.html#a-heierarchical-model"><i class="fa fa-check"></i><b>9.5.3</b> A heierarchical model</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="heierarchical-models.html"><a href="heierarchical-models.html#other-parameterizations-we-might-have-tried"><i class="fa fa-check"></i><b>9.6</b> Other parameterizations we might have tried</a><ul>
<li class="chapter" data-level="9.6.1" data-path="heierarchical-models.html"><a href="heierarchical-models.html#shape-parameters-for-beta"><i class="fa fa-check"></i><b>9.6.1</b> Shape parameters for Beta</a></li>
<li class="chapter" data-level="9.6.2" data-path="heierarchical-models.html"><a href="heierarchical-models.html#mean-instead-of-mode"><i class="fa fa-check"></i><b>9.6.2</b> Mean instead of mode</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="heierarchical-models.html"><a href="heierarchical-models.html#shrinkage"><i class="fa fa-check"></i><b>9.7</b> Shrinkage</a></li>
<li class="chapter" data-level="9.8" data-path="heierarchical-models.html"><a href="heierarchical-models.html#example-baseball-batting-average"><i class="fa fa-check"></i><b>9.8</b> Example: Baseball Batting Average</a></li>
<li class="chapter" data-level="9.9" data-path="heierarchical-models.html"><a href="heierarchical-models.html#ch09-exercises"><i class="fa fa-check"></i><b>9.9</b> Exerciess</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="model-comparison.html"><a href="model-comparison.html"><i class="fa fa-check"></i><b>10</b> (Model Comparison)</a></li>
<li class="chapter" data-level="11" data-path="nhst.html"><a href="nhst.html"><i class="fa fa-check"></i><b>11</b> (NHST)</a></li>
<li class="chapter" data-level="12" data-path="point-null-hypotheses.html"><a href="point-null-hypotheses.html"><i class="fa fa-check"></i><b>12</b> (Point Null Hypotheses)</a></li>
<li class="chapter" data-level="13" data-path="goals-power-sample-size.html"><a href="goals-power-sample-size.html"><i class="fa fa-check"></i><b>13</b> (Goals, Power, Sample Size)</a></li>
<li class="chapter" data-level="14" data-path="stan.html"><a href="stan.html"><i class="fa fa-check"></i><b>14</b> Stan</a><ul>
<li class="chapter" data-level="14.1" data-path="stan.html"><a href="stan.html#why-stan-might-work-better"><i class="fa fa-check"></i><b>14.1</b> Why Stan might work better</a></li>
<li class="chapter" data-level="14.2" data-path="stan.html"><a href="stan.html#describing-a-model-to-stan"><i class="fa fa-check"></i><b>14.2</b> Describing a model to Stan</a></li>
<li class="chapter" data-level="14.3" data-path="stan.html"><a href="stan.html#samping-from-the-prior"><i class="fa fa-check"></i><b>14.3</b> Samping from the prior</a></li>
<li class="chapter" data-level="14.4" data-path="stan.html"><a href="stan.html#ch14-exercises"><i class="fa fa-check"></i><b>14.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="glm-overview.html"><a href="glm-overview.html"><i class="fa fa-check"></i><b>15</b> GLM Overview</a><ul>
<li class="chapter" data-level="15.1" data-path="glm-overview.html"><a href="glm-overview.html#data-consists-of-observations-of-variables"><i class="fa fa-check"></i><b>15.1</b> Data consists of observations of variables</a><ul>
<li class="chapter" data-level="15.1.1" data-path="glm-overview.html"><a href="glm-overview.html#variable-roles"><i class="fa fa-check"></i><b>15.1.1</b> Variable Roles</a></li>
<li class="chapter" data-level="15.1.2" data-path="glm-overview.html"><a href="glm-overview.html#types-of-variables"><i class="fa fa-check"></i><b>15.1.2</b> Types of Variables</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="glm-overview.html"><a href="glm-overview.html#glm-framework"><i class="fa fa-check"></i><b>15.2</b> GLM Framework</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html"><i class="fa fa-check"></i><b>16</b> Estimating One and Two Means</a><ul>
<li class="chapter" data-level="16.1" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#basic-model-for-two-means"><i class="fa fa-check"></i><b>16.1</b> Basic Model for Two Means</a><ul>
<li class="chapter" data-level="16.1.1" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#data-2"><i class="fa fa-check"></i><b>16.1.1</b> Data</a></li>
<li class="chapter" data-level="16.1.2" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#model"><i class="fa fa-check"></i><b>16.1.2</b> Model</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#an-old-sleep-study"><i class="fa fa-check"></i><b>16.2</b> An Old Sleep Study</a><ul>
<li class="chapter" data-level="16.2.1" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#data-3"><i class="fa fa-check"></i><b>16.2.1</b> Data</a></li>
<li class="chapter" data-level="16.2.2" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#model-1"><i class="fa fa-check"></i><b>16.2.2</b> Model</a></li>
<li class="chapter" data-level="16.2.3" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#separate-standard-deviations-for-each-group"><i class="fa fa-check"></i><b>16.2.3</b> Separate standard deviations for each group</a></li>
<li class="chapter" data-level="16.2.4" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#comparison-to-t-test"><i class="fa fa-check"></i><b>16.2.4</b> Comparison to t-test</a></li>
<li class="chapter" data-level="16.2.5" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#rope-region-of-practical-equivalence"><i class="fa fa-check"></i><b>16.2.5</b> ROPE (Region of Practical Equivalence)</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#variations-on-the-theme"><i class="fa fa-check"></i><b>16.3</b> Variations on the theme</a><ul>
<li class="chapter" data-level="16.3.1" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#other-distributions-for-the-response"><i class="fa fa-check"></i><b>16.3.1</b> Other distributions for the response</a></li>
<li class="chapter" data-level="16.3.2" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#other-priors-for-sigma-or-tau"><i class="fa fa-check"></i><b>16.3.2</b> Other Priors for <span class="math inline">\(\sigma\)</span> (or <span class="math inline">\(\tau\)</span>)</a></li>
<li class="chapter" data-level="16.3.3" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#paired-comparisons"><i class="fa fa-check"></i><b>16.3.3</b> Paired Comparisons</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#how-many-chains-how-long"><i class="fa fa-check"></i><b>16.4</b> How many chains? How long?</a><ul>
<li class="chapter" data-level="16.4.1" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#why-multiple-chains"><i class="fa fa-check"></i><b>16.4.1</b> Why multiple chains?</a></li>
<li class="chapter" data-level="16.4.2" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#what-large-n.eff-does-and-doesnt-do-for-us"><i class="fa fa-check"></i><b>16.4.2</b> What large n.eff does and doesn’t do for us</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#looking-at-likelihood"><i class="fa fa-check"></i><b>16.5</b> Looking at Likelihood</a></li>
<li class="chapter" data-level="16.6" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#ch16-exercises"><i class="fa fa-check"></i><b>16.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>17</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="17.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#the-deluxe-basic-model"><i class="fa fa-check"></i><b>17.1</b> The deluxe basic model</a><ul>
<li class="chapter" data-level="17.1.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#likelihood-1"><i class="fa fa-check"></i><b>17.1.1</b> Likelihood</a></li>
<li class="chapter" data-level="17.1.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#priors"><i class="fa fa-check"></i><b>17.1.2</b> Priors</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#example-galtons-data"><i class="fa fa-check"></i><b>17.2</b> Example: Galton’s Data</a><ul>
<li class="chapter" data-level="17.2.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#describing-the-model-to-jags-1"><i class="fa fa-check"></i><b>17.2.1</b> Describing the model to JAGS</a></li>
<li class="chapter" data-level="17.2.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#problems-and-how-to-fix-them"><i class="fa fa-check"></i><b>17.2.2</b> Problems and how to fix them</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#centering-and-standardizing"><i class="fa fa-check"></i><b>17.3</b> Centering and Standardizing</a><ul>
<li class="chapter" data-level="17.3.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#beta_0-and-beta_1-are-still-correlated"><i class="fa fa-check"></i><b>17.3.1</b> <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are still correlated</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#weve-fit-a-model-now-what"><i class="fa fa-check"></i><b>17.4</b> We’ve fit a model, now what?</a><ul>
<li class="chapter" data-level="17.4.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#estimate-parameters"><i class="fa fa-check"></i><b>17.4.1</b> Estimate parameters</a></li>
<li class="chapter" data-level="17.4.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#make-predictions"><i class="fa fa-check"></i><b>17.4.2</b> Make predictions</a></li>
<li class="chapter" data-level="17.4.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#posterior-predictive-checks"><i class="fa fa-check"></i><b>17.4.3</b> Posterior Predictive Checks</a></li>
<li class="chapter" data-level="17.4.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#posterior-predictive-checks-with-bayesplot"><i class="fa fa-check"></i><b>17.4.4</b> Posterior predictive checks with bayesplot</a></li>
<li class="chapter" data-level="17.4.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#ppc-with-custom-data"><i class="fa fa-check"></i><b>17.4.5</b> PPC with custom data</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#fitting-models-with-stan"><i class="fa fa-check"></i><b>17.5</b> Fitting models with Stan</a></li>
<li class="chapter" data-level="17.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#two-intercepts-model"><i class="fa fa-check"></i><b>17.6</b> Two Intercepts model</a></li>
<li class="chapter" data-level="17.7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#ch17-exercises"><i class="fa fa-check"></i><b>17.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html"><i class="fa fa-check"></i><b>18</b> Multiple Metric Predictors</a><ul>
<li class="chapter" data-level="18.1" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#sat"><i class="fa fa-check"></i><b>18.1</b> SAT</a><ul>
<li class="chapter" data-level="18.1.1" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#sat-vs-expenditure"><i class="fa fa-check"></i><b>18.1.1</b> SAT vs expenditure</a></li>
<li class="chapter" data-level="18.1.2" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#sat-vs-expenditure-and-percent-taking-the-test"><i class="fa fa-check"></i><b>18.1.2</b> SAT vs expenditure and percent taking the test</a></li>
<li class="chapter" data-level="18.1.3" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#whats-wrong-with-this-picture"><i class="fa fa-check"></i><b>18.1.3</b> What’s wrong with this picture?</a></li>
<li class="chapter" data-level="18.1.4" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#multiple-predictors-in-pictures"><i class="fa fa-check"></i><b>18.1.4</b> Multiple predictors in pictures</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#interaction"><i class="fa fa-check"></i><b>18.2</b> Interaction</a><ul>
<li class="chapter" data-level="18.2.1" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#sat-with-interaction-term"><i class="fa fa-check"></i><b>18.2.1</b> SAT with interaction term</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#fitting-a-linear-model-with-brms"><i class="fa fa-check"></i><b>18.3</b> Fitting a linear model with brms</a><ul>
<li class="chapter" data-level="18.3.1" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#adjusting-the-model-with-brm"><i class="fa fa-check"></i><b>18.3.1</b> Adjusting the model with brm()</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#interpretting-a-model-with-an-interaction-term"><i class="fa fa-check"></i><b>18.4</b> Interpretting a model with an interaction term</a><ul>
<li class="chapter" data-level="18.4.1" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#thinking-about-the-noise"><i class="fa fa-check"></i><b>18.4.1</b> Thinking about the noise</a></li>
</ul></li>
<li class="chapter" data-level="18.5" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#ch18-exercises"><i class="fa fa-check"></i><b>18.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="nominal-predictors.html"><a href="nominal-predictors.html"><i class="fa fa-check"></i><b>19</b> Nominal Predictors</a><ul>
<li class="chapter" data-level="19.1" data-path="nominal-predictors.html"><a href="nominal-predictors.html#fruit-flies-study"><i class="fa fa-check"></i><b>19.1</b> Fruit flies Study</a></li>
<li class="chapter" data-level="19.2" data-path="nominal-predictors.html"><a href="nominal-predictors.html#model-1-out-of-the-box"><i class="fa fa-check"></i><b>19.2</b> Model 1: Out-of-the-box</a></li>
<li class="chapter" data-level="19.3" data-path="nominal-predictors.html"><a href="nominal-predictors.html#model-2-custom-priors"><i class="fa fa-check"></i><b>19.3</b> Model 2: Custom Priors</a></li>
<li class="chapter" data-level="19.4" data-path="nominal-predictors.html"><a href="nominal-predictors.html#models-3-and-4-alternate-parameterizations"><i class="fa fa-check"></i><b>19.4</b> Models 3 and 4: alternate parameterizations</a></li>
<li class="chapter" data-level="19.5" data-path="nominal-predictors.html"><a href="nominal-predictors.html#comparing-groups"><i class="fa fa-check"></i><b>19.5</b> Comparing groups</a><ul>
<li class="chapter" data-level="19.5.1" data-path="nominal-predictors.html"><a href="nominal-predictors.html#comparing-to-the-intercept-group"><i class="fa fa-check"></i><b>19.5.1</b> Comparing to the “intercept group”</a></li>
<li class="chapter" data-level="19.5.2" data-path="nominal-predictors.html"><a href="nominal-predictors.html#comparing-others-pairs-of-groups"><i class="fa fa-check"></i><b>19.5.2</b> Comparing others pairs of groups</a></li>
<li class="chapter" data-level="19.5.3" data-path="nominal-predictors.html"><a href="nominal-predictors.html#contrasts-comparing-groups-of-groups"><i class="fa fa-check"></i><b>19.5.3</b> Contrasts: Comparing “groups of groups”</a></li>
</ul></li>
<li class="chapter" data-level="19.6" data-path="nominal-predictors.html"><a href="nominal-predictors.html#more-variations"><i class="fa fa-check"></i><b>19.6</b> More Variations</a></li>
<li class="chapter" data-level="19.7" data-path="nominal-predictors.html"><a href="nominal-predictors.html#ch19-exercises"><i class="fa fa-check"></i><b>19.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html"><i class="fa fa-check"></i><b>20</b> Multiple Nominal Predictors</a><ul>
<li class="chapter" data-level="20.1" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#crop-yield-by-till-method-and-fertilizer"><i class="fa fa-check"></i><b>20.1</b> Crop Yield by Till Method and Fertilizer</a><ul>
<li class="chapter" data-level="20.1.1" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#what-does-sigma-represent"><i class="fa fa-check"></i><b>20.1.1</b> What does <span class="math inline">\(\sigma\)</span> represent?</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#split-plot-design"><i class="fa fa-check"></i><b>20.2</b> Split Plot Design</a></li>
<li class="chapter" data-level="20.3" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#which-model-should-we-use"><i class="fa fa-check"></i><b>20.3</b> Which model should we use?</a><ul>
<li class="chapter" data-level="20.3.1" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#modeling-choices"><i class="fa fa-check"></i><b>20.3.1</b> Modeling Choices</a></li>
<li class="chapter" data-level="20.3.2" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#measuring-a-model-prediction-error"><i class="fa fa-check"></i><b>20.3.2</b> Measuring a Model – Prediction Error</a></li>
<li class="chapter" data-level="20.3.3" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#overfitting-example"><i class="fa fa-check"></i><b>20.3.3</b> Overfitting Example</a></li>
<li class="chapter" data-level="20.3.4" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#measuring-fit-with-r2"><i class="fa fa-check"></i><b>20.3.4</b> Measuring fit with <span class="math inline">\(r^2\)</span></a></li>
<li class="chapter" data-level="20.3.5" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#leave-one-out-analysis"><i class="fa fa-check"></i><b>20.3.5</b> Leave One Out Analysis</a></li>
<li class="chapter" data-level="20.3.6" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#out-of-sample-prediction-error"><i class="fa fa-check"></i><b>20.3.6</b> Out-of-sample prediction error</a></li>
<li class="chapter" data-level="20.3.7" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#approximating-out-of-sample-prediction-error"><i class="fa fa-check"></i><b>20.3.7</b> Approximating out-of-sample prediction error</a></li>
<li class="chapter" data-level="20.3.8" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#the-deviance-scale"><i class="fa fa-check"></i><b>20.3.8</b> The deviance scale</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#using-loo"><i class="fa fa-check"></i><b>20.4</b> Using loo</a></li>
<li class="chapter" data-level="20.5" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#ch20-exercses"><i class="fa fa-check"></i><b>20.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="dichotymous-response.html"><a href="dichotymous-response.html"><i class="fa fa-check"></i><b>21</b> Dichotymous Response</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">(Re)Doing Bayesain Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="stan" class="section level1">
<h1><span class="header-section-number">14</span> Stan</h1>
<div id="why-stan-might-work-better" class="section level2">
<h2><span class="header-section-number">14.1</span> Why Stan might work better</h2>
<p>Stan is sometimes (but not always) better or faster than JAGS. The reason is
that the HMC (Hamilton Markov Chain) algorithm that it uses avoids some of the
potential problems of the Metropolis algorithm and Gibbs sampler.
You can think of HMC as a generlization of the Metropolis algorithm.
Recall that in the Metropolis algorithm</p>
<ul>
<li>There is always a current vector of parameter values (like the
current island in our story)</li>
<li>A new vector of parameter values is proposed</li>
<li>The proposal is accepted or rejected by comparing the ratio
of the likelihoods of the current and proposal vectors.
<ul>
<li>It is important that we only need the ratio because the scaling
constant would be prohibitively expensive to compute.</li>
</ul></li>
</ul>
<p>The main change is in how HMC chooses its proposals. Recall that in
the basic Metropolis algorithm</p>
<ul>
<li>the proposal distribution is symmetric</li>
<li>the proposal distribution is the same no matter where
the current parameter vector is.</li>
</ul>
<p>This has some potential negative consequences</p>
<ul>
<li>When the current position is a region of relatively low posterior density,
the algorithm is as likely to propose moves that go farther from the mode
as toward it. This can be inefficient.</li>
<li>The behavior of the algorithm can be greatly affected by the “step size”
(how likely the proposal is to be close to or far from the current position).</li>
</ul>
<p>HMC addresses these by using a proposal distribution that
* Changes depending on the current position
* Is more likely to make proposals in the direction of the mode</p>
<p>Unlike Gibbs samplers, HMC is not guided by the fixed directions corresponding
to letting only one parameter value change at a time. This makes it easier for
HMC to navigate posteriors that have narrow “ridges” that don’t follow one of
these primary directions, so Stan is less disturbed by correlations in the
posterior distribution than JAGS is.</p>
<p>The basic idea of the HMC sampler in Stan is to turn the log posterior
upsided down so it is bowl-shaped with its mode at the “bottom” and to
imagine a small particle sliding along this surface after receiving a
“flick” to get it moving. If the flick is in the direction of the mode,
the particle will move farther.
If it is away from the mode, it may go
up hill for a while and then turn around.
(The same thing may happen if it travels in the direction of the mode and
overshoots.)
If it is in some other direction,
it will take a curved path that bends toward the mode.
A proposal is generated by specifying
* A direction and “force” for the flick (momentum)
* The amount of “time” to let the particle move.
At the end of the specified amount of time, the particle will be at
the proposal position.
* A level of discretization used to simulate the motion of the particle.</p>
<p>In principle (ie, physics), every proposal can be excepted
(as in the Gibbs sampler).
In practice, because the simulated movement is discretized into a
sequence of small segments, a rule is used that involves both the
ratio of the posterior values and the ratio of the momentums of the
current and proposal values.
If the motion is simulated with many small segments, the proposal will nearly
always be accepted, but it will take longer to do the simulation. On the other
hand, if a cruder approximation is used, the simulation is faster, but the
proposal is more likely to be rejected. “Time” is represented by the product of
the number of steps used and the size of the steps: <code>steps * eps</code> (eps is short
for espilon, but “steps time eps” has a aring to it). The step size (<code>eps</code>) is a
tuning parameter of the algorithm, and things seem to work most efficiently if
roughly 2/3 of proposals are accepted. The value of <code>eps</code> can be adjusted to
attain something close to this goal.</p>
<p>Stan adds an extra bit to this algorithm. To avoid the inefficiency
of overshooting and turning around, it tries to estimate when this will
happen. The result is its No U-Turn Sampler (NUTS). There are a number
of other features that lead to the complexity of Stan including</p>
<ul>
<li>Symbolic differentiation to determine the gradient of the posterior and
momentum.</li>
<li>Simulation techniques for the physics to minimize the inaccuracy
created because of discretization.</li>
<li>Techniques for dealing with parameters with bounded support.</li>
<li>An inital phase that helps set the tuning parameters: step size (<code>eps</code>),
time (<code>steps * eps</code>), and the distribution from which to sample the
initial momentum.</li>
</ul>
<p>Because of all these techinical details, it is easy to see why Stan may be
much slower than JAGS in situations where JAGS works well. The flip-side is
that Stan make work in situations where JAGS fails altogether or takes too
much time to be of practical use. Generally, as models become more complex,
Stan gains the advantage. For simple models, JAGS is often faster.</p>
</div>
<div id="describing-a-model-to-stan" class="section level2">
<h2><span class="header-section-number">14.2</span> Describing a model to Stan</h2>
<p>Coding Stan models is also a bit more complicated, but what we have learned
about JAGS is helpful. RStudio also offers excellent support for Stan, so
we won’t have to use tricks like writing a “function” in R that isn’t really
R code to describe a JAGS model.</p>
<p>To use Stan in R we will load the <code>rstan</code> package and take advantage of
<a href="https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started">RStudio’s Stan chunks</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rstan)
<span class="kw">rstan_options</span>(<span class="dt">auto_write =</span> <span class="ot">TRUE</span>)  <span class="co"># saves some compiling</span></code></pre>
<p>Stan descriptions have several sections (not all of which are required):</p>
<ul>
<li>data – declarations of variables to hold the data</li>
<li>transformed data – transformations of data</li>
<li>parameters – declaration of parameters</li>
<li>transformed parameters – transformations of parameters</li>
<li>model – description of prior and likelihood</li>
<li>generated quantities – used to keep track of additional
values Stan can compute at each step.</li>
</ul>
<p>Here is an example of a simple Stan model:</p>
<pre class="stan"><code>data {
  int&lt;lower=0&gt; N;  // N is a non-negative integer
  int y[N];          // y is a length-N vector of integers
}
parameters {
  real&lt;lower=0,upper=1&gt; theta;  // theta is between 0 and 1
} 
model {
  theta ~ beta (1,1);
  y ~ bernoulli(theta);
}</code></pre>
<p>See if you can figure out what this model is doing.</p>
<p>You will also see that Stan requires some extra stuff compared to
JAGS. In particular, we need to tell Stan which quantities are integers
and which are reals, and also if there is an restriction to their domain.</p>
<p><strong>Note:</strong> running the chunk above takes a little while.
This is when Stan compiles the C code for the model and also works out the
formulas for the gradient (derivatives). The result is a
<strong>dynamic shared object</strong> (<strong>DSO</strong>).</p>
<p>To use this model in RStudio, put the code in a Stan chunk (one of the options
from the insert menu) and set the <code>output.var</code> to the R variable that will store
the results. In this case, we have named it <code>simple_stan</code> using the
argument <code>output.var = &quot;simple_stan&quot;</code>. Behind the scenes, RStudio is
calling <code>stan_code()</code> to pass information between R and Stan and to
get Stan to do the compilation.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">class</span>(simple_stan)   <span class="co"># what kind of thing is this?</span></code></pre>
<pre><code>## [1] &quot;stanmodel&quot;
## attr(,&quot;package&quot;)
## [1] &quot;rstan&quot;</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">simple_stan          <span class="co"># let&#39;s take a look</span></code></pre>
<pre><code>## S4 class stanmodel &#39;83dbe9f99dbf55ff04494fdddf566a3d&#39; coded as follows:
## data {
##   int&lt;lower=0&gt; N;  // N is a non-negative integer
##   int y[N];          // y is a length-N vector of integers
## }
## parameters {
##   real&lt;lower=0,upper=1&gt; theta;  // theta is between 0 and 1
## } 
## model {
##   theta ~ beta (1,1);
##   y ~ bernoulli(theta);
## }</code></pre>
<p>We still need to provide Stan some data and ask Stan to provide us
with some posterior samples. We do this with the <code>sampling()</code>
function. By separating this into a separate step, we can use the same
compiled model with different data sets or different settings
(more iterations, for example) without having to recompile.</p>
<pre class="sourceCode r"><code class="sourceCode r">simple_stanfit &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">sampling</span>(
    simple_stan, 
    <span class="dt">data  =</span> <span class="kw">list</span>(
      <span class="dt">N =</span> <span class="dv">50</span>,
      <span class="dt">y =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">15</span>), <span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">35</span>))
    ),
    <span class="dt">chains =</span> <span class="dv">3</span>,     <span class="co"># default is 4</span>
    <span class="dt">iter =</span> <span class="dv">1000</span>,    <span class="co"># default is 2000</span>
    <span class="dt">warmup =</span> <span class="dv">200</span>    <span class="co"># default is half of iter</span>
  )</code></pre>
<pre><code>## 
## SAMPLING FOR MODEL &#39;83dbe9f99dbf55ff04494fdddf566a3d&#39; NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 2.1e-05 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup)
## Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup)
## Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup)
## Chain 1: Iteration: 201 / 1000 [ 20%]  (Sampling)
## Chain 1: Iteration: 300 / 1000 [ 30%]  (Sampling)
## Chain 1: Iteration: 400 / 1000 [ 40%]  (Sampling)
## Chain 1: Iteration: 500 / 1000 [ 50%]  (Sampling)
## Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling)
## Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling)
## Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling)
## Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling)
## Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.002412 seconds (Warm-up)
## Chain 1:                0.007942 seconds (Sampling)
## Chain 1:                0.010354 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL &#39;83dbe9f99dbf55ff04494fdddf566a3d&#39; NOW (CHAIN 2).
## Chain 2: 
## Chain 2: Gradient evaluation took 5e-06 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:   1 / 1000 [  0%]  (Warmup)
## Chain 2: Iteration: 100 / 1000 [ 10%]  (Warmup)
## Chain 2: Iteration: 200 / 1000 [ 20%]  (Warmup)
## Chain 2: Iteration: 201 / 1000 [ 20%]  (Sampling)
## Chain 2: Iteration: 300 / 1000 [ 30%]  (Sampling)
## Chain 2: Iteration: 400 / 1000 [ 40%]  (Sampling)
## Chain 2: Iteration: 500 / 1000 [ 50%]  (Sampling)
## Chain 2: Iteration: 600 / 1000 [ 60%]  (Sampling)
## Chain 2: Iteration: 700 / 1000 [ 70%]  (Sampling)
## Chain 2: Iteration: 800 / 1000 [ 80%]  (Sampling)
## Chain 2: Iteration: 900 / 1000 [ 90%]  (Sampling)
## Chain 2: Iteration: 1000 / 1000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 0.002665 seconds (Warm-up)
## Chain 2:                0.008474 seconds (Sampling)
## Chain 2:                0.011139 seconds (Total)
## Chain 2: 
## 
## SAMPLING FOR MODEL &#39;83dbe9f99dbf55ff04494fdddf566a3d&#39; NOW (CHAIN 3).
## Chain 3: 
## Chain 3: Gradient evaluation took 6e-06 seconds
## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.06 seconds.
## Chain 3: Adjust your expectations accordingly!
## Chain 3: 
## Chain 3: 
## Chain 3: Iteration:   1 / 1000 [  0%]  (Warmup)
## Chain 3: Iteration: 100 / 1000 [ 10%]  (Warmup)
## Chain 3: Iteration: 200 / 1000 [ 20%]  (Warmup)
## Chain 3: Iteration: 201 / 1000 [ 20%]  (Sampling)
## Chain 3: Iteration: 300 / 1000 [ 30%]  (Sampling)
## Chain 3: Iteration: 400 / 1000 [ 40%]  (Sampling)
## Chain 3: Iteration: 500 / 1000 [ 50%]  (Sampling)
## Chain 3: Iteration: 600 / 1000 [ 60%]  (Sampling)
## Chain 3: Iteration: 700 / 1000 [ 70%]  (Sampling)
## Chain 3: Iteration: 800 / 1000 [ 80%]  (Sampling)
## Chain 3: Iteration: 900 / 1000 [ 90%]  (Sampling)
## Chain 3: Iteration: 1000 / 1000 [100%]  (Sampling)
## Chain 3: 
## Chain 3:  Elapsed Time: 0.002442 seconds (Warm-up)
## Chain 3:                0.00825 seconds (Sampling)
## Chain 3:                0.010692 seconds (Total)
## Chain 3:</code></pre>
<p>The output below looks similar to what we have seen from JAGS.</p>
<pre class="sourceCode r"><code class="sourceCode r">simple_stanfit</code></pre>
<pre><code>## Inference for Stan model: 83dbe9f99dbf55ff04494fdddf566a3d.
## 3 chains, each with iter=1000; warmup=200; thin=1; 
## post-warmup draws per chain=800, total post-warmup draws=2400.
## 
##         mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat
## theta   0.30    0.00 0.06   0.19   0.26   0.30   0.35   0.44   961    1
## lp__  -32.63    0.02 0.75 -34.85 -32.81 -32.35 -32.15 -32.10  1106    1
## 
## Samples were drawn using NUTS(diag_e) at Wed Apr 24 08:13:32 2019.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
<p>There are a number of functions that can extract information from
stanfit objects.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">methods</span>(<span class="dt">class =</span> <span class="st">&quot;stanfit&quot;</span>)</code></pre>
<pre><code>##  [1] as.array           as.data.frame      as.matrix         
##  [4] as.mcmc.list       bridge_sampler     constrain_pars    
##  [7] dim                dimnames           extract           
## [10] get_cppo_mode      get_inits          get_logposterior  
## [13] get_num_upars      get_posterior_mean get_seed          
## [16] get_seeds          get_stancode       get_stanmodel     
## [19] grad_log_prob      is.array           log_posterior     
## [22] log_prob           loo                names             
## [25] names&lt;-            neff_ratio         nuts_params       
## [28] pairs              plot               posterior         
## [31] print              rhat               show              
## [34] stanfit            summary            traceplot         
## [37] unconstrain_pars  
## see &#39;?methods&#39; for accessing help and source code</code></pre>
<p>Unfortunately, some of these have the same names as functions elsewhere (in
the coda package, for example). We generally adopt an approach that
keeps things as similar to what we did with JAGS as possible.</p>
<ul>
<li><p>Use <code>CalvinBayes::posterior()</code> to create a dataframe with posterior
samples. These can be plotted or explored using <code>ggformula</code> or other
familiar tools.</p></li>
<li><p>Use <code>as.matrix()</code> or <code>as.mcmc.list()</code> to create an object that can
be used with <code>bayesplot</code> just as we did when we used JAGS.</p></li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">gf_dens</span>(<span class="op">~</span>theta, <span class="dt">data =</span> <span class="kw">posterior</span>(simple_stanfit))</code></pre>
<p><img src="Redoing_files/figure-html/ch14-simple-stan-plots-1.png" width="65%" /></p>
<pre class="sourceCode r"><code class="sourceCode r">simple_mcmc &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(simple_stanfit)
<span class="kw">mcmc_areas</span>(simple_mcmc, <span class="dt">prob =</span> <span class="fl">0.9</span>, <span class="dt">pars =</span> <span class="st">&quot;theta&quot;</span>)</code></pre>
<p><img src="Redoing_files/figure-html/ch14-simple-stan-plots-2.png" width="65%" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mcmc_areas</span>(<span class="kw">as.mcmc.list</span>(simple_stanfit), <span class="dt">prob =</span> <span class="fl">0.9</span>, <span class="dt">pars =</span> <span class="st">&quot;theta&quot;</span>)</code></pre>
<p><img src="Redoing_files/figure-html/ch14-simple-stan-plots-3.png" width="65%" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">diag_mcmc</span>(<span class="kw">as.mcmc.list</span>(simple_stanfit))</code></pre>
<p><img src="Redoing_files/figure-html/ch14-simple-stan-diagplot-1.png" width="65%" /></p>
</div>
<div id="samping-from-the-prior" class="section level2">
<h2><span class="header-section-number">14.3</span> Samping from the prior</h2>
<p>In JAGS, to sample from the posterior, we just “removed the data”.
For any parameter values, the likelihood of not having any data if
we don’t collect any data is 1. So the posterior is the same as the
prior.</p>
<p>Unlike JAGS, Stan does not allow missing data, so we need a different
way to sample from the posterior. In Stan, we will remove the likelihood.
To understand why this works, let’s think a little bit about how Stan
operates.</p>
<ul>
<li><p>All internal work is done on the log scale.</p>
<p>log prior, log likelihood, log posterior.</p></li>
<li><p>Additive constants on the log scale
(multiplicative constants on the natural scale) don’t matter…</p>
<p>… at least not for generating posterior samples,
so they can be ignored or chosen conveniently.
The distribution functions in Stan are really logs of kernels
with constants chosen to optimize efficiency of computation.</p></li>
<li><p>log(posterior) = log(prior) + log(likelihood) + constant</p>
<p>So if we don’t add in the likelihood part, we just get the prior
again as the posterior.</p></li>
</ul>
<p>A line like</p>
<pre><code>y ~ bernoulli(theta);</code></pre>
<p>Is just telling stan to add the log of the bernoulli pmf for each value
of the data vector <code>y</code> using the current value for <code>theta</code>. If we
comment out that line, no log likelihood will be added.</p>
<pre class="stan"><code>data {
  int&lt;lower=0&gt; N;  // N is a non-negative integer
  int y[N];          // y is a length-N vector of integers
}
parameters {
  real&lt;lower=0,upper=1&gt; theta;  // theta is between 0 and 1
} 
model {
  theta ~ beta (1,1);
  // y ~ bernoulli(theta);     // comment out to remove likelihood
}</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">simple0_stanfit &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">sampling</span>(
    simple0_stan, 
    <span class="dt">data  =</span> <span class="kw">list</span>(
      <span class="dt">N =</span> <span class="dv">50</span>,
      <span class="dt">y =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">15</span>), <span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">35</span>))
    ),
    <span class="dt">chains =</span> <span class="dv">3</span>,     <span class="co"># default is 4</span>
    <span class="dt">iter =</span> <span class="dv">1000</span>,    <span class="co"># default is 2000</span>
    <span class="dt">warmup =</span> <span class="dv">200</span>    <span class="co"># default is half of iter</span>
  )</code></pre>
</div>
<div id="ch14-exercises" class="section level2">
<h2><span class="header-section-number">14.4</span> Exercises</h2>
<!-- Exercise 14.1. [Purpose: Transformed parameters in Stan, and comparison with JAGS.]  -->
<ol style="list-style-type: decimal">
<li><p>Let’s compare Stan and JAGS on the therapeutic touch example from
Chapter 9. (See Figure 9.7 on page 236.) Stan and JAGS code for this example are below. The data are in <code>TherapeuticTouch</code>.</p>
<pre class="stan"><code>data {
  int&lt;lower=1&gt; Nsubj;
  int&lt;lower=1&gt; Ntotal;
  int&lt;lower=0,upper=1&gt; y[Ntotal];
  int&lt;lower=1&gt; s[Ntotal]; // notice Ntotal not Nsubj
}
parameters {
  real&lt;lower=0,upper=1&gt; theta[Nsubj]; // individual prob correct
  real&lt;lower=0,upper=1&gt; omega;        // group mode
  real&lt;lower=0&gt; kappaMinusTwo;        // group concentration minus two
}
transformed parameters {
  real&lt;lower=0&gt; kappa;  
  kappa &lt;- kappaMinusTwo + 2;
}
model {
  omega ~ beta(1, 1);
  kappaMinusTwo ~ gamma(1.105125, 0.1051249 );  // mode=1, sd=10 
  theta ~ beta(omega * (kappa-2) + 1, (1 - omega) * (kappa-2) + 1); 
  for ( i in 1:Ntotal ) {
    y[i] ~ bernoulli(theta[s[i]]);
  }
}</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">jags_model &lt;-<span class="st"> </span><span class="cf">function</span>() {
  <span class="cf">for</span> ( i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>Ntotal ) {
    y[i] <span class="op">~</span><span class="st"> </span><span class="kw">dbern</span>( theta[s[i]] )
  }
  <span class="cf">for</span> (s <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>Nsubj ) {
    theta[s] <span class="op">~</span><span class="st"> </span><span class="kw">dbeta</span>(omega <span class="op">*</span><span class="st"> </span>(kappa<span class="dv">-2</span>) <span class="op">+</span><span class="st"> </span><span class="dv">1</span>, (<span class="dv">1</span><span class="op">-</span>omega) <span class="op">*</span><span class="st"> </span>(kappa<span class="dv">-2</span>) <span class="op">+</span><span class="st"> </span><span class="dv">1</span>) 
  }
  omega <span class="op">~</span><span class="st"> </span><span class="kw">dbeta</span>(<span class="dv">1</span>, <span class="dv">1</span>) 
  kappa &lt;-<span class="st"> </span>kappaMinusTwo <span class="op">+</span><span class="st"> </span><span class="dv">2</span>
  kappaMinusTwo <span class="op">~</span><span class="st"> </span><span class="kw">dgamma</span>(<span class="fl">1.105125</span>, <span class="fl">0.1051249</span>)  <span class="co"># mode=1, sd=10 </span>
}</code></pre>
<p>Now answer the following questions.</p>
<ol style="list-style-type: lower-alpha">
<li>What does the transformed parameters block of the Stan code do?</li>
<li>In the Stan code, there are two lines with <code>~</code> in them. One is
inside a for loop and the other not. Why?</li>
<li>Compile the Stan program, and note how long it takes.</li>
<li>Now generate posterior samples using both the JAGS and Stan versions.
Do the produce the same posterior distribution? How do the effective
sample sizes compare?</li>
<li>Tweak the settings until you get similar effective sample sizes
and rhat values from both Stan and JAGS.
(ESS is the best metric of how much work they have done, and we want to be
sure both algorithms think they are converging to get a fair comparison.)
Once you have done that, compare their speeds.
Which is faster in this example? By how much?
(If you want R to help automate the timing, you can use <code>system.time()</code>.)</li>
</ol></li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="goals-power-sample-size.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="glm-overview.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["Redoing.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
