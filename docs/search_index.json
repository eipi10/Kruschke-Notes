[
["index.html", "(Re)Doing Bayesain Data Analysis 1 What’s in These Notes", " (Re)Doing Bayesain Data Analysis R Pruim 2019-05-08 1 What’s in These Notes This “book” is a companion to Kruschke’s Doing Bayesian Data Analysis. The main reasons for this companion are to use a different style of R code that includes: use of modern packages like tidyverse, R2jags, bayesplot, and ggformula; adherence to a different style guide; less reliance on manually editing scripts and more use of resusable code available in packages; a workflow that takes advantage of RStudio and RMarkdown. This is a work in progress. Please accept my apologies in advance for errors, inconsistencies lack of complete coverage But feel free to post an issue on github if you spot things that require attention or care to make suggestions for improvement. I’ll be teaching from this book in Spring 2019, so I expect rapid development during those months. "],
["credibility-models-and-parameters.html", "2 Credibility, Models, and Parameters 2.1 The Steps of Bayesian Data Analysis 2.2 Example 1: Which coin is it? 2.3 Distributions 2.4 Example 2: Height vs Weight 2.5 Where do we go from here? 2.6 Exercises 2.7 Footnotes", " 2 Credibility, Models, and Parameters 2.1 The Steps of Bayesian Data Analysis In general, Bayesian analysis of data follows these steps: Identify the data relevant to the research questions. What are the measurement scales of the data? Which data variables are to be predicted, and which data variables are supposed to act as predictors? Define a descriptive model for the relevant data. The mathematical form and its parameters should be meaningful and appropriate to the theoretical purposes of the analysis. Specify a prior distribution on the parameters. The prior must pass muster with the audience of the analysis, such as skeptical scientists. Use Bayesian inference to re-allocate credibility across parameter values. Interpret the posterior distribution with respect to theoretically meaningful issues (assuming that the model is a reasonable description of the data; see next step). Check that the posterior predictions mimic the data with reasonable accuracy (i.e., conduct a “posterior predictive check”). If not, then consider a different descriptive model. In this chapter we will focus on two examples so we can get an overview of what Bayesian data analysis looks like. In subsequent chapters we will fill in lots of the missing details. 2.1.1 R code Some of the R code used in this chapter has been hidden, and some of it is visible. In any case the point of this chapter is not to understand the details of the R code. It is there mainly for those of you who are curious, or because you might come back and look at this chapter later in the semester. For those of you new to R, we will be learning it as we go along. For those of you who have used R before, some of this will be familiar to you, but other things likely will not be familiar. 2.1.2 R packages We will make use of a number of R packages as we go along. Here is the code used to load the packages used in this chapter. If you try to mimic the code on your own machine, you will need to use these packages. library(ggformula) # for creating plots theme_set(theme_bw()) # change the default graphics settings library(dplyr) # for data wrangling library(mosaic) # includes the previous 2 (and some other stuff) library(CalvinBayes) # includes BernGrid() library(brms) # used to fit the model in the second exmample, ## Loading required package: Rcpp ## Loading &#39;brms&#39; package (version 2.8.0). Useful instructions ## can be found by typing help(&#39;brms&#39;). A more detailed introduction ## to the package is available through vignette(&#39;brms_overview&#39;). ## ## Attaching package: &#39;brms&#39; ## The following object is masked from &#39;package:rstan&#39;: ## ## loo ## The following object is masked from &#39;package:mosaic&#39;: ## ## mm ## The following objects are masked from &#39;package:CalvinBayes&#39;: ## ## rhat, rstudent_t # but hidden from view here 2.2 Example 1: Which coin is it? As first simple illustration of the big ideas of Bayesian inference, let’s consider a situation where we have a coin that is known to result in heads in either 0, 20, 40, 60, 80, or 100% of tosses. But we don’t know which. Our plan is to gather data by flipping the coin and recording the results. If we let \\(\\theta\\) be the true probability of tossing a head, we can refer to these 5 possibilities as \\(\\theta = 0\\), \\(\\theta = 0.2\\), \\(\\theta = 0.4\\), \\(\\theta = 0.6\\), \\(\\theta = 0.8\\), and \\(\\theta = 1\\). Before collecting our data, if have no other information, we will consider each coin to be equally credible. We could represent that as follows. Now suppose we toss the coin and obtain a head. What does that do to our credibilities? Clearly \\(\\theta = 0\\) is no longer possible. So the credibility of that option becomes 0. The other credibilities are adjusted as well. We will see later just how, but the following should be intuitive: the options with larger values of \\(\\theta\\) should increase in credibility more than those with lower values of \\(\\theta\\). the total credibility of all options should remain 1 (100%). In fact, the adjusted credibility after one head toss looks like this: This updating of credibility of possible values of \\(\\theta\\) is the key idea in Bayesian inference. Bayesians don’t call these distributions of credibility “before” and “after”, however. Instead they use the longer words “prior” and “posterior”, which mean the same thing. Now suppose we toss the coin again and get another head. Once again we can update the credibility, and once again, the larger values of \\(\\theta\\) will see their credibility increase while the smaller values of \\(\\theta\\) will see their credibility decrease. Time for a third toss. This time we obtain a tail. Now the credibility of \\(\\theta = 1\\) drops to 0, and the relative credibilities of the smaller values of \\(\\theta\\) will increase and of the larger values of \\(\\theta\\) will decrease. Finally, we flip one more tail. As expected, the posterior is now symmetric with the two central values of \\(\\theta\\) having the larger credibility. We can keep playing this game as long as we like. Each coin toss provides a bit more information with which to update the posterior, which becomes our new prior for subsequent data. The BernGrid() function in the CalvinBayes package makes it easy to generate plots similar to the ones above.1 BernGrid(&quot;HHTTTHTTT&quot;, # the data steps = TRUE, # show each step p = c(0, 0.2, 0.4, 0.6, 0.8, 1)) # possible probabilities ## Converting data to 1, 1, 0, 0, 0, 1, 0, 0, 0 2.2.1 Freedom of choice In practice, we are usually not given a small number of possible values for the probability (of obtaining heads in our example, but it could be any probability). Instead, the probability could be any value between 0 and 1. But we can do Bayesian updating in essentially the same way. Instead of a bar chart, we will use a line graph (called a density plot) to show how the credibility depends on the parameter value. BernGrid(&quot;HHTTTHTTT&quot;, # the data steps = TRUE) # show each step ## Converting data to 1, 1, 0, 0, 0, 1, 0, 0, 0 2.3 Distributions The (prior and posterior) distributions in the previous plots were calculated numerically using a Bayesian update rule that we will soon learn. Density functions have the properties that * they are never negative, and * the total area under the curve is 1. Where the density curve is taller, values are more likely. So in the last posterior credibility above, we see that values near 1/3 are the most credible while values below 0.015 or above 0.065 are not very credible. In particular, we still can’t discount the possibility that we are dealing with a fair coin since 0.5 lies well within the most credible central portion of the plot. We will also encounter densities with names like “normal”, “beta”, and “t”. The gf_dist() function from ggformula can be used to plot distributions. We just need to provide R’s version of the name for the family and any required parameter values. 2.3.1 Beta distributions The curves in our coins example above look a lot like beta distributions. In fact, we will eventually learn that they are beta distributions, and that each new observed coin toss increases either shape1 or shape2 by 1. gf_dist(&quot;beta&quot;, shape1 = 1, shape2 = 1, color = &quot;gray50&quot;) %&gt;% gf_dist(&quot;beta&quot;, shape1 = 2, shape2 = 1, color = &quot;red&quot;) %&gt;% gf_dist(&quot;beta&quot;, shape1 = 3, shape2 = 1, color = &quot;orange&quot;) %&gt;% gf_dist(&quot;beta&quot;, shape1 = 3, shape2 = 2, color = &quot;forestgreen&quot;) %&gt;% gf_dist(&quot;beta&quot;, shape1 = 3, shape2 = 3, color = &quot;navy&quot;) 2.3.2 Normal distributions Another important family of distributions is the normal family. These are bell-shaped, symmetric distributions centered at the mean (\\(\\mu\\)). A second parameter, the standard deviation (\\(\\sigma\\)) quantifies how spread out the distribution is. To plot a normal distribution with mean 10 and standard deviation 1 or 2, we use gf_dist(&quot;norm&quot;, mean = 10, sd = 1, color = &quot;steelblue&quot;) %&gt;% gf_dist(&quot;norm&quot;, mean = 10, sd = 2, color = &quot;red&quot;) The red curve is “twice as spread out” as the blue one. We can also draw random samples from distributions. Random samples will not exactly follow the shape of the distribution they were drawn from, so it takes some experience to get calibrated to know when things are “close enough” to consider a proposed distribution to be believable, and when they are “different enough” to be skeptical. Generating some random data and comparing to the theoretical distribution can help us calibrate. In the example below, we generate 25 random samples of size 100 and compare their (density) histograms to the theoretical Norm(10, 2) distribution. expand.grid() produces a data frame with two columns containing every combination of the numbers 1 through 100 with the numbers 1 through 25, for a total of 2500 rows. mutate() is used to add a new variable to the data frame. Rdata &lt;- expand.grid( rep = 1:100, sample = 1:25) %&gt;% mutate( x = rnorm(2500, mean = 10, sd = 2) ) head(Rdata) rep sample x 1 1 11.171 2 1 11.419 3 1 9.781 4 1 9.093 5 1 11.212 6 1 6.364 gf_dhistogram( ~ x | sample, data = Rdata, color = &quot;gray30&quot;, alpha = 0.5) %&gt;% gf_dist(&quot;norm&quot;, mean = 10, sd = 2, color = &quot;red&quot;) We will see many other uses of these functions. See the next chapter for in introduction to R functions that will be useful. 2.4 Example 2: Height vs Weight The coins example above is overly simple compared to typical applications. Before getting to the nuts and bolts of doing Bayesian data analysis, let’s look at a somewhat more realistic example. Suppose we want to model the relationship between weight and height in 40-year-old Americans. 2.4.1 Data Here’s a scatter plot of some data from the NHANES study that we will use for this example. (Note: this is not the same data set used in the book. The data here come from the NHANES::NHANES data set.) 2.4.2 Describing a model for the relationship between height and weight A plausible model is that weight is linearly related to height. We will make this model a bit more precise by defining the model parameters and distributions involved. Typically statisticians use Greek letters to represent parameters. This model has three parameters (\\(\\beta_0\\), \\(\\beta_1\\), and \\(\\sigma\\)) and makes two claims The average weight of people with height \\(x\\) is \\(\\beta_0 + \\beta_1 x\\) (some linear function of \\(x\\)). We can express this as \\[ \\mu_{Y|x} = E(Y \\mid x) = \\beta_0 + \\beta_1 x \\] or \\[ \\mu_{\\mbox{weight}|\\mbox{height}} = E(\\mbox{weight} \\mid \\mbox{height}) = \\beta_0 + \\beta_1 \\cdot \\mbox{height} \\] The \\(Y\\) and \\(x\\) notation is useful for general formulas; for specific problems (especially in R code), it is usually better to use descriptive names for the variables. The capital \\(Y\\) indicates that it has a distribution. \\(x\\) is lower case because we are imagining a specific value there. So for each value of \\(x\\), the there is a distribution of \\(Y\\)’s. But not everyone is average. The model used here assumes that the distributions of the heights of people with a given weight are symmetrically distributed around the average weight for that height and that the distribution is normal (bell-shaped). The parameter \\(\\sigma\\) is called the standard deviation and measures the amount of variability. If \\(\\sigma\\) is small, then most people’s weights are very close to the average for their height. If \\(\\sigma\\) is larger, then there is more variability in weights for people who have the same height. We express this as \\[\\begin{align} y \\mid x \\sim {\\sf Norm}(\\mu_{y|x}, \\sigma) \\end{align}\\] Notice the \\(\\sim\\) in this expression. It is read “is distributed as” and describes the distribution (shape) of some quantity. Putting this all together, and being a little bit sloppy we might write it this way: \\[\\begin{align} Y &amp;\\sim {\\sf Norm}(\\mu, \\sigma) \\\\ \\mu &amp; \\sim \\beta_0 + \\beta_1 x \\end{align}\\] In this style the dependence of \\(y\\) on \\(x\\) is implicit (via \\(\\mu\\)’s dependence on \\(x\\)) and we save writing \\(\\mid x\\) in a few places. 2.4.3 Prior A prior distribution describes what is known/believed about the parameters before we use the information from our data. This could be informed by previous data, or it may be a fairly uninformative prior that considers many values of the parameter to be credible. For this example, we use very flat broad priors (centered at 0 for the \\(\\beta\\)’s and extending from 0 to a very large number of \\(\\sigma\\). (We know that \\(\\sigma &gt; 0\\), so our prior should reflect that knowledge.) 2.4.4 Posterior The posterior distribution is calculated by combining the information about the model (via the likelihood function) with the prior. The posterior will provide updated distributions for \\(\\beta_0\\), \\(\\beta_1\\) and \\(\\sigma\\). These distributions will be narrow if our data give a strong evidence about their values and wider if even after considering the data, there is still considerable uncertainty about the parameter values. For now we won’t worry about how the posterior distribution is computed, but we can inspect it visually. (It is called Post in the R code below.) For example, if we are primarily interested in the slope (how much heavier are people on average for each inch they are taller?), we can plot the posterior distribution of \\(\\beta_1\\) or calculate its mean, or the region containing the central 95% of the distribution. Such a region is called a highest density interval (HDI) (sometimes called the highest posterior density interval (HPDI), to emphasize that we are looking at a posterior distribution, but an HDI can be computed for other distributions as well). gf_density( ~ b_height, data = Post, alpha = 0.5) mean(~ b_height, data = Post) ## [1] 7.223 hdi(Post, pars = &quot;b_height&quot;) par lo hi mode prob b_height 5.551 9.045 6.804 0.95 mcmc_areas(as.mcmc(Post), pars = &quot;b_height&quot;, prob = 0.95) Although we don’t get a very precise estimate of \\(\\beta_1\\) from this model/data combination, we can be quite confident that taller people are indeed heavier (on average), somewhere between 5 and 10 pounds heavier per inch taller. Another interesting plot shows lines overlaid on the scatter plot. Each line represents a plausible (according to the posterior distribution) combination of slope and intercept. 100 such lines are included in the plot below. 2.4.5 Posterior Predictive Check Notice that only a few of the dots are covered by the blue lines. That’s because the blue lines represent plausible average weights. But the model takes into account that some people may be quite a bit heavier or lighter than average. A posterior predictive check is a way of checking that the data look like they could have been plausibly generated by our model. We can generate a simulated weight for a given height by randomly selecting values of \\(\\beta_0\\), \\(\\beta_1\\), \\(\\sigma\\) so that the more credible values are more likely to be selected, and using the normal distribution to generate a difference between an individual weight and the average weight (as determined by the parameters \\(\\beta_0\\) and \\(\\beta_1\\). For example, here are the first two rows of our posterior distribution: Post %&gt;% head(2) b_Intercept b_height sigma lp__ -217.0 6.028 40.11 -784.5 -422.1 9.030 48.28 -786.5 To simulate a weight for a height of 65 inches based on the fist row, we could take a random draw from a \\({\\sf Norm}(-217 + 6.028 \\cdot 65, 40.11)\\) distribution. We can do a similar thing for the second row. Post %&gt;% head(2) %&gt;% mutate(pred_y = rnorm(2, mean = b_Intercept + b_height * 65, sd = sigma)) b_Intercept b_height sigma lp__ pred_y -217.0 6.028 40.11 -784.5 185.3 -422.1 9.030 48.28 -786.5 219.4 Those values are quite different. This is because credible values of \\(\\sigma\\) are quite large – an indication that individuals will vary quite substantially from the average weight for their height. gf_density( ~ sigma, data = Post) We should not be surprised to see some (~ 5%) of people who are 85 pounds above or below the average weight for their height. If we do this many times for several height values and plot the central 95% of the weights, we get a plot that looks like this: PPC &lt;- expand.grid( height = seq(56, 76, by = 1), rep = 1:nrow(Post) ) %&gt;% mutate( b_Intercept = Post$b_Intercept[rep], b_height = Post$b_height[rep], sigma = Post$sigma[rep], weight = b_Intercept + b_height * height + rnorm(n = n(), 0, sigma) ) %&gt;% group_by(height) %&gt;% summarise( mean = mean(weight), lo = quantile(weight, prob = 0.025), hi = quantile(weight, prob = 0.975) ) gf_point(weight ~ height, data = NHANES40, shape = 1) %&gt;% gf_pointrange(mean + lo + hi ~ height, data = PPC, alpha = 0.7, color = &quot;steelblue&quot;) Now we see that indeed, most (but not all) of the data points fall within a range that the model believes is credible. If this were not the case, it would be evidence that our model is not well aligned with the data and might lead us to explore other models. Notice that by taking many different credible values of the parameters (including \\(\\sigma\\)), we are taking into account both our uncertainty about the parameter values and the variability that the model describes in the population (even for given parameter values). 2.5 Where do we go from here? Now that we have seen an overview of Bayesian inference at work, you probably have lots of questions. Of time we will improve our answers to each of them. How do we create models? One of the nice things about Bayesian inference is that it is so flexible. That allows us to create all sorts of models. We will begin with models of a proportion (and how that proportion might depend on other variables) because these are the simplest to understand. Then we will move on other important examples. (The back half of our book is a smorgasbord of example situations.) How do we select priors? We will begin with fairly “uninformative” priors that say very little, and we will experiment with different priors to see what affect the choice of prior has on our analysis. Gradually we will learn more about prior selection. How do we update the prior based on data to get the posterior? Here we will learn several approaches, most of them computational. (There are only a limited number of examples where the prior can be computed analytically.) We will start with computational methods that are simple to implement and relatively easy to understand, but are too inefficient to use on large or complex problems. Eventually we will learn how to use two important algorithms (JAGS and Stan) to describe and fit Bayesian models. How do we tell whether the algorithm that generated the posterior worked well? The computainal algorithms that compute posterior distributions can fail. No one algorithm works best on every problem, and sometimes we need to describe our model differently to help the computer. We will learn some diagnostics to help us detect when there may be problems with our computations. What can we do with the posterior once we have it? After all the work of building a model, selectig a prior, fitting the model to obtain a posterior, and convincing ourselves that no disasters have happened along the way, what can we do with the posterior? We will use it both to diagnose the model itself and to see what the model has to say. 2.6 Exercises Consider Figure 2.6 on page 29 of DBDA2E. Two of the data points fall above the vertical bars. Does this mean that the model does not describe the data well? Briefly explain your answer. Run the following examples in R. Compare the plots produced and comment the big idea(s) illustrated by this comparison. library(CalvinBayes) BernGrid(&quot;H&quot;, resolution = 4, prior = triangle::dtriangle) BernGrid(&quot;H&quot;, resolution = 10, prior = triangle::dtriangle) BernGrid(&quot;H&quot;, prior = 1, resolution = 100, geom = geom_col) BernGrid(&quot;H&quot;, resolution = 100, prior = function(p) abs(p - 0.5) &gt; 0.48, geom = geom_col) Run the following examples in R. Compare the plots produced and comment the big idea(s) illustrated by this comparison. library(CalvinBayes) BernGrid(&quot;TTHT&quot;, prior = triangle::dtriangle) BernGrid(&quot;TTHT&quot;, prior = function(x) triangle::dtriangle(x)^0.1) BernGrid(&quot;TTHT&quot;, prior = function(x) triangle::dtriangle(x)^10) Run the following examples in R. Compare the plots produced and comment the big idea(s) illustrated by this comparison. library(CalvinBayes) dfoo &lt;- function(p) { 0.02 * dunif(p) + 0.49 * triangle::dtriangle(p, 0.1, 0.2) + 0.49 * triangle::dtriangle(p, 0.8, 0.9) } BernGrid(c(rep(0,13), rep(1,14)), prior = triangle::dtriangle) BernGrid(c(rep(0,13), rep(1,14)), resolution = 1000, prior = dfoo) Run the following examples in R. Compare the plots produced and comment the big idea(s) illustrated by this comparison. library(CalvinBayes) dfoo &lt;- function(p) { 0.02 * dunif(p) + 0.49 * triangle::dtriangle(p, 0.1, 0.2) + 0.49 * triangle::dtriangle(p, 0.8, 0.9) } BernGrid(c(rep(0, 3), rep(1, 3)), prior = dfoo) BernGrid(c(rep(0, 10), rep(1, 10)), prior = dfoo) BernGrid(c(rep(0, 30), rep(1, 30)), prior = dfoo) BernGrid(c(rep(0, 100), rep(1, 100)), prior = dfoo) Run the following examples in R and compare them to the ones in the previous exercise. What do you observe? library(CalvinBayes) dfoo &lt;- function(p) { 0.02 * dunif(p) + 0.49 * triangle::dtriangle(p, 0.1, 0.2) + 0.49 * triangle::dtriangle(p, 0.8, 0.9) } BernGrid(c(rep(0, 3), rep(1, 4)), prior = dfoo) BernGrid(c(rep(0, 4), rep(1, 3)), prior = dfoo) BernGrid(c(rep(0, 10), rep(1, 11)), prior = dfoo) BernGrid(c(rep(0, 11), rep(1, 10)), prior = dfoo) BernGrid(c(rep(0, 30), rep(1, 31)), prior = dfoo) BernGrid(c(rep(0, 31), rep(1, 30)), prior = dfoo) 2.7 Footnotes You don’t need to know this now, but the name BernGrid() comes from the facts that (a) an random process with two outcomes is called a Bernoulli experiment, and (b) the method used to compute the posterior is called the grid method.↩ "],
["some-useful-bits-of-r.html", "3 Some Useful Bits of R 3.1 You Gotta Have Style 3.2 Vectors, Lists, and Data Frames 3.3 Plotting with ggformula 3.4 Creating data with expand.grid() 3.5 Transforming and summarizing data dplyr and tidyr 3.6 Writing Functions 3.7 Some common error messages 3.8 Exercises 3.9 Footnotes", " 3 Some Useful Bits of R 3.1 You Gotta Have Style Good programming style is incredibly important. It makes your code easier to read and edit. That leads to fewer errors. Here is a brief style guide you are expected to follow for all code in this course: For more detailed see http://adv-r.had.co.nz/Style.html, on which this is based. No long lines. Lines of code should have at most 80 characters. Programming lines should not wrap, you should choose the line breaks yourself. Choose them in natural places. In R markdown, long codes lines don’t wrap, they flow off the page, so the end isn’t visible. (And it makes it obvious that you didn’t look at your own print out.) # Don&#39;t ever use really long lines. Not even in comments. They spill off the page and make people wonder what they are missing. Use your space bar. There is a reason it is the largest key on the keyboard. Use it often. Spaces after commas (always). Spaces around operators (always). Spaces after the comment symbol # (always). Use other spaces judiciously to align similar code chunks to make things easier to read or compare. x&lt;-c(1,2,4)+5 # BAD BAD BAD x &lt;- c(1, 2, 4) + 5 # Ah :^) But don’t go crazy with the space bar. There are a few places you should not use spaces: after open parentheses or before closed parentheses between function names and the parentheses that follow Indent to show the structure of your code. Use 2 spaces to indent (to keep things from drifting right too quickly). Fortunately, this is really easy. Highlight your code and hit &lt;CTRL&gt;-i (PC) or &lt;command&gt;-i (Mac). If the indention looks odd to you, you have most likely messed up commas, quotes, parentheses, or curly braces. Choose names wisely and consistently. Naming things is hard, but take a moment to choose good names, and go back and change them if you come up with a better name later. Here are some helpful hints: Very short names should only be used for a very short time (a couple lines of code). Else we tend to forget what they meant. Avoid names like x, f, etc. unless the use is brief and mimics some common mathematical formula. Break long names visually. Common ways to do this are with a dot (.), an underscore _, or camelCase. There are R coders who prefer all three, but don’t mix and match for similar kinds of things, that just makes it harder to remember what to do the next time. good_name &lt;- 10 good.name &lt;- 10 goodName &lt;- 10 # note alignment via extra space in this line really_terrible.ideaToDo &lt;- -5 The trend in R is toward using underscore (_) and I recommend it. Older code often used dot (.). CamelCase is the least common in R. Recommendation: capitalize data frame names; use lower case for variables inside data frames. This is not a common convention in R, but it can really help to keep things straight. I’ll do this in the data sets I create, but when we use other data sets, they may not follow this convention. Avoid using names that are already in use by R. This can be hard to avoid when you are starting out because you don’t know what all is defined. Here are a few things to avoid. T # abbreviation for TRUE F # abbreviation for FALSE c # used to concetenate vectors and lists df # density function for f distributions dt # density function for t distributions Use comments (#), but use them for the right thing. Comments can be used to clarify names, point out subtlties in code, etc. They should not be used for your analysis or discussion of results. Don’t comment things that are obvious without comment. Comments should add value. x &lt;- 4 # set x to 4 &lt;----------------------- no need for this comment x &lt;- 4 # b/c there are four grade levels in the study &lt;------- useful Exceptions should be exceptional. No style guide works perfectly in all situations. Ocassionally you may need to violate the style guide. But these instances should be rare and should have a good reason. They should not arise form your sloppiness or laziness. 3.1.1 An additional note about homework When you do homework, I want to see your code and the results (and your discussion of those results). Writing in R Markdown makes this all easy to do. But make sure that I can see all the necessary things to evaluate what you are doing. You have access to your code and can investigate variables, etc. But make sure I can see what’s going one in the document. This often means displaying intermediate results. Once common way to do this is with a semi-colon: x &lt;- 57 * 23; x ## [1] 1311 3.2 Vectors, Lists, and Data Frames 3.2.1 Vectors In R, a vector is a homogeneous ordered collection (indexing starts at 1). By homogeneous, we mean that each element is he same kind of thing. Short vectors can be created using c(): x &lt;- c(1, 3, 5) x ## [1] 1 3 5 Evenly spaced sequences can be created using seq(): x &lt;- seq(0, 100, by = 5); x ## [1] 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 y &lt;- seq(0, 1, length.out = 11); y ## [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0:10 # short cut for consecutive integers ## [1] 0 1 2 3 4 5 6 7 8 9 10 Repeated values can be created with rep(): rep(5, 3) ## [1] 5 5 5 rep(c(1, 2, 3), each = 2) ## [1] 1 1 2 2 3 3 rep(c(1, 2, 3), times = 2) ## [1] 1 2 3 1 2 3 rep(c(1, 2, 3), times = c(1, 2, 3)) ## [1] 1 2 2 3 3 3 rep(c(1, 2, 3), each = c(1, 2, 3)) # Ack! see warning message. ## Warning in rep(c(1, 2, 3), each = c(1, 2, 3)): first element used of &#39;each&#39; argument ## [1] 1 2 3 When a function acts on a vector, there are several things that could happen. One result can be computed from the entire vector. x &lt;- c(1, 3, 6, 10) length(x) ## [1] 4 mean(x) ## [1] 5 The function may be applied to each element of the vector and a vector of results returned. (Such functions are called vectorized.) log(x) ## [1] 0.000 1.099 1.792 2.303 2 * x ## [1] 2 6 12 20 x^2 ## [1] 1 9 36 100 The first element of the vector may be used and the others ignored. (Less common but dangerous – be on the lookout. See example above.) Items in a vector can be accessed using []: x &lt;- seq(10, 20, by = 2) x[2] ## [1] 12 x[10] # NA indicates a missing value ## [1] NA x[10] &lt;- 4 x # missing values filled in to make room! ## [1] 10 12 14 16 18 20 NA NA NA 4 is.na(x) ## [1] FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE FALSE In addition to using integer indices, there are two other ways to access elements of a vector: names and logicals. If the items in a vector are named, names are displayed when a vector is displayed, and names can be used to access elements. x &lt;- c(a = 5, b = 3, c = 12, 17, 1) x ## a b c ## 5 3 12 17 1 names(x) ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;&quot; &quot;&quot; x[&quot;b&quot;] ## b ## 3 Logicals (TRUE and FALSE) are very interesting in R. In indexing, they tell us which items to keep and which to discard. x &lt;- (1:10)^2 x &lt; 50 ## [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE FALSE FALSE FALSE x[x &lt; 50] ## [1] 1 4 9 16 25 36 49 x[c(TRUE, FALSE)] # T/F recycled to length 10 ## [1] 1 9 25 49 81 which(x &lt; 50) ## [1] 1 2 3 4 5 6 7 3.2.2 Lists Lists are a lot like vectors, but Create a list with list(). The elements can be different kinds of things (including other lists) Use [[ ]] to access elements. You can also use $ to access named elements If you use [] you will get a list back not an element. # a messy list L &lt;- list(5, list(1, 2, 3), x = TRUE, y = list(5, a = 3, 7)) L ## [[1]] ## [1] 5 ## ## [[2]] ## [[2]][[1]] ## [1] 1 ## ## [[2]][[2]] ## [1] 2 ## ## [[2]][[3]] ## [1] 3 ## ## ## $x ## [1] TRUE ## ## $y ## $y[[1]] ## [1] 5 ## ## $y$a ## [1] 3 ## ## $y[[3]] ## [1] 7 L[[1]] ## [1] 5 L[[2]] ## [[1]] ## [1] 1 ## ## [[2]] ## [1] 2 ## ## [[3]] ## [1] 3 L[1] ## [[1]] ## [1] 5 L$y ## [[1]] ## [1] 5 ## ## $a ## [1] 3 ## ## [[3]] ## [1] 7 L[[&quot;x&quot;]] ## [1] TRUE L[1:3] ## [[1]] ## [1] 5 ## ## [[2]] ## [[2]][[1]] ## [1] 1 ## ## [[2]][[2]] ## [1] 2 ## ## [[2]][[3]] ## [1] 3 ## ## ## $x ## [1] TRUE glimpse(L) ## List of 4 ## $ : num 5 ## $ :List of 3 ## ..$ : num 1 ## ..$ : num 2 ## ..$ : num 3 ## $ x: logi TRUE ## $ y:List of 3 ## ..$ : num 5 ## ..$ a: num 3 ## ..$ : num 7 3.2.3 Data frames for rectangular data Rectangular data is organized in rows and columns (much like an excel spreadsheet). These rows and columns have a particular meaning: Each row represents one observational unit. Observational units go by many others names depending whether they are people, or inanimate objects, our events, etc. Examples include case, subject, item, etc. Regardless, the observational units are the things about which we collect information, and each one gets its own row in rectangular data. Each column represents a variable – one thing that is “measured” and recorded (at least in principle, some measurements might be missing) for each observational unit. Example In a study of nutritional habits of college students, our observational units are the college students in the study. Each student gets her own row in the data frame. The variables might include things like an ID number (or name), sex, height, weight, whether the student lives on campus or off, what type of meal plan they have at the dining hall, etc., etc. Each of these is recorded in a separate column. Data frames are the standard way to store rectangular data in R. Usually variables (elements of the list) are vectors, but this isn’t required, sometimes you will see list variables in data frames. Each element (ie, variable) must have the same length (to keep things rectangular). Here, for example, are the first few rows of a data set called KidsFeet: library(mosaicData) # Load package to make KidsFeet data available head(KidsFeet) # first few rows name birthmonth birthyear length width sex biggerfoot domhand David 5 88 24.4 8.4 B L R Lars 10 87 25.4 8.8 B L L Zach 12 87 24.5 9.7 B R R Josh 1 88 25.2 9.8 B L R Lang 2 88 25.1 8.9 B L R Scotty 3 88 25.7 9.7 B R R 3.2.3.1 Accessing via We can access rows, columns, or individual elements of a data frame using [ ]. This is the more usual way to do things. KidsFeet[, &quot;length&quot;] ## [1] 24.4 25.4 24.5 25.2 25.1 25.7 26.1 23.0 23.6 22.9 27.5 24.8 26.1 27.0 26.0 23.7 24.0 24.7 26.7 ## [20] 25.5 24.0 24.4 24.0 24.5 24.2 27.1 26.1 25.5 24.2 23.9 24.0 22.5 24.5 23.6 24.7 22.9 26.0 21.6 ## [39] 24.6 KidsFeet[, 4] ## [1] 24.4 25.4 24.5 25.2 25.1 25.7 26.1 23.0 23.6 22.9 27.5 24.8 26.1 27.0 26.0 23.7 24.0 24.7 26.7 ## [20] 25.5 24.0 24.4 24.0 24.5 24.2 27.1 26.1 25.5 24.2 23.9 24.0 22.5 24.5 23.6 24.7 22.9 26.0 21.6 ## [39] 24.6 KidsFeet[3, ] name birthmonth birthyear length width sex biggerfoot domhand 3 Zach 12 87 24.5 9.7 B R R KidsFeet[3, 4] ## [1] 24.5 KidsFeet[3, 4, drop = FALSE] # keep it a data frame length 3 24.5 KidsFeet[1:3, 2:3] birthmonth birthyear 5 88 10 87 12 87 By default, Accessing a row returns a 1-row data frame. Accessing a column returns a vector (at least for vector columns) Accessing a element returns that element (technically a vector with one element in it). 3.2.3.2 Accessing columns via $ We can also access individual variables using the $ operator: KidsFeet$length ## [1] 24.4 25.4 24.5 25.2 25.1 25.7 26.1 23.0 23.6 22.9 27.5 24.8 26.1 27.0 26.0 23.7 24.0 24.7 26.7 ## [20] 25.5 24.0 24.4 24.0 24.5 24.2 27.1 26.1 25.5 24.2 23.9 24.0 22.5 24.5 23.6 24.7 22.9 26.0 21.6 ## [39] 24.6 KidsFeet$length[2] ## [1] 25.4 KidsFeet[2, &quot;length&quot;] ## [1] 25.4 KidsFeet[2, &quot;length&quot;, drop = FALSE] # keep it a data frame length 2 25.4 As we will see, there are are other tools that will help us avoid needing to us $ or [ ] for access columns in a data frame. This is especially nice when we are working with several variables all coming from the same data frame. 3.2.3.3 Accessing by number is dangerous Generally speaking, it is safer to access things by name than by number when that is an option. It is easy to miscalculate the row or column number you need, and if rows or columns are added to or deleted from a data frame, the numbering can change. 3.2.3.4 Implementation Data frames are implemented in R as a special type (technically, class) of list. The elements of the list are the columns in the data frame. Each column must have the same length (so that our data frame has coherent rows). Most often the columns are vectors, but this isn’t required. This explains why $ works the way it does – we are just accessing one item in a list. It also means that we can use [[ ]] to access a column: KidsFeet[[&quot;length&quot;]] ## [1] 24.4 25.4 24.5 25.2 25.1 25.7 26.1 23.0 23.6 22.9 27.5 24.8 26.1 27.0 26.0 23.7 24.0 24.7 26.7 ## [20] 25.5 24.0 24.4 24.0 24.5 24.2 27.1 26.1 25.5 24.2 23.9 24.0 22.5 24.5 23.6 24.7 22.9 26.0 21.6 ## [39] 24.6 KidsFeet[[4]] ## [1] 24.4 25.4 24.5 25.2 25.1 25.7 26.1 23.0 23.6 22.9 27.5 24.8 26.1 27.0 26.0 23.7 24.0 24.7 26.7 ## [20] 25.5 24.0 24.4 24.0 24.5 24.2 27.1 26.1 25.5 24.2 23.9 24.0 22.5 24.5 23.6 24.7 22.9 26.0 21.6 ## [39] 24.6 KidsFeet[4] length 24.4 25.4 24.5 25.2 25.1 25.7 26.1 23.0 23.6 22.9 27.5 24.8 26.1 27.0 26.0 23.7 24.0 24.7 26.7 25.5 24.0 24.4 24.0 24.5 24.2 27.1 26.1 25.5 24.2 23.9 24.0 22.5 24.5 23.6 24.7 22.9 26.0 21.6 24.6 3.2.4 Other types of data Some types of data do not work well in a rectangular arrangement of a data frame, and there are many other ways to store data. In R, other types of data commonly get stored in a list of some sort. 3.3 Plotting with ggformula R has several plotting systems. Base graphics is the oldest. lattice and ggplot2 are both built on a system called grid graphics. ggformula is built on ggplot2 to make it easier to use and to bring in some of the advantages of lattice. You can find out about more about ggformula at https://projectmosaic.github.io/ggformula/news/index.html. 3.4 Creating data with expand.grid() We will frequently have need of synthetic data that includes all combinations of some variable values. expand.grid() does this for us: expand.grid( a = 1:3, b = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;)) a b 1 A 2 A 3 A 1 B 2 B 3 B 1 C 2 C 3 C 1 D 2 D 3 D 3.5 Transforming and summarizing data dplyr and tidyr See the tutorial at http://rsconnect.calvin.edu/wrangling-jmm2019 or https://rpruim.shinyapps.io/wrangling-jmm2019 3.6 Writing Functions 3.6.1 Why write functions? There are two main reasons for writing functions. You may want to use a tool that requires a function as input. To use integrate(), for example, you must provide the integrand as a function. To make your own work easier. Functions make it easier to reuse code or to break larger tasks into smaller parts. 3.6.2 Function parts Functions consist of several parts. Most importantly An argument list. A list of named inputs to the function. These may have default values (or not). There is also a special argument ... which gathers up any other arguments provided by the user. Many R functions make use of ... args(ilogit) # one argument, called x, no default value ## function (x) ## NULL The body. This is the code the tells R to do when the function is executed. body(ilogit) ## { ## exp(x)/(1 + exp(x)) ## } An environment where code is executed. Each function has its own “scratch pad” where it can do work without interfering with global computations. But environments in R are nested, so it is possible to reach outside of this narrow environment to access other things (and possible to change them). For the most part we won’t worry about this, but if you use a variable not defined in your function but defined elsewhere, you may see unexpecte results. If you type the name of a function without parenthesis, you will see all three parts listed: ilogit ## function (x) ## { ## exp(x)/(1 + exp(x)) ## } ## &lt;bytecode: 0x7f9fda064e08&gt; ## &lt;environment: namespace:mosaicCore&gt; 3.6.3 The function() function has its function To write a function we use the function() function to specify the arguments and the body. (R will assign an environment for us.) The general outline is my_function_name &lt;- function(arg1 = default1, arg2 = default2, arg3, arg4, ...) { # stuff for my function to do } We may include as many named arguments as we like, and some or all or none of them may have default values. The results of the last line of the function are returned. If we like, we can also use the return() function to make it clear what is being returned when. Let’s write a function that adds. (Redundant, but a useful illustration.) foo &lt;- function(x, y = 5) { x + y # or return(x + y) } foo(3, 5) ## [1] 8 foo(3) ## [1] 8 foo(2, x = 3) # Note: this makes y = 2 ## [1] 5 foo(x = 1:3, y = 100) ## [1] 101 102 103 foo(x = 1:3, y = c(100, 200, 300)) # vectorized! ## [1] 101 202 303 foo(x = 1:3, y = c(100, 200)) # You have been warned! ## Warning in x + y: longer object length is not a multiple of shorter object length ## [1] 101 202 103 Here is a more useful example. Suppose we want to integrate \\(f(x) = x^2 (2-x)\\) on the interval from 0 to 2. Since this is such a simple function, if we are not going to reuse it, we don’t need to bother naming it, we can just create the function inside our call to integrate(). integrate(function(x) { x^2 * (2-x) }, 0, 2) ## 1.333 with absolute error &lt; 1.5e-14 3.7 Some common error messages 3.7.1 object not found If R claims some object is not found, the two most likely causes are a typo – if you spell the name of the object slightly differently, R can’t figure out what you mean blah &lt;- 17 bla ## Error in eval(expr, envir, enclos): object &#39;bla&#39; not found forgetting to load a package – if the object is in a package, that package must be loaded detach(&quot;package:mosaic&quot;, unload = TRUE) detach(&quot;package:ggformula&quot;, unload = TRUE) # without packages, no gf_line() ## Error: package &#39;ggformula&#39; is required by &#39;CalvinBayes&#39; so will not be detached gf_line() ## gf_line() uses ## * a formula with shape y ~ x. ## * geom: line ## * key attributes: alpha, color, fill, group, linetype, size, lineend, linejoin, linemitre, arrow ## ## For more information, try ?gf_line library(ggformula) # reload package; now things work gf_line() ## gf_line() uses ## * a formula with shape y ~ x. ## * geom: line ## * key attributes: alpha, color, fill, group, linetype, size, lineend, linejoin, linemitre, arrow ## ## For more information, try ?gf_line 3.7.1 Package inputenc Error: Unicode char not set up for use with LaTeX. Sometimes if you copy and paste text from a web page or PDF document you will get symbols knitr doesn’t know how to handle. Smart quotes, ligatures, and other special characters are the most likely cause. tools::showNonASCIIfile() can help you locate non-ASCII characters in a file. 3.7.2 Any message mentioning yaml YAML stand for yet another markup language. The first part of an R Markdown file is called the YAML header. If you get a yaml error when you knit a document, most likely you have messed up the YAML header someone. If you don’t see the problem, you can start a new document and copy-and-paste the contents (without the TAML header) into the new document (after its YAML header). 3.8 Exercises Create a function in R that converts Fahrenheit temperatures to Celsius temperatures. [Hint: \\(C = (F-32) \\cdot 5/9\\).] What you turn in should show the code that defines your function. some test cases that show that your function is working. (Show that -40, 32, 98.6, and 212 convert to -40, 0, 37, and 100.) Note: you should be able to test all these cases by calling the function only once. Use c(-40, 32, 98.6, 212) as the input. See if you can predict the output of each line below. Then run in R to see if you are correct. If you are not correct, see if you can figure out why R does what it does (and make a note so you are not surprised the next time). odds &lt;- 1 + 2 * (0:4); odds primes &lt;- c(2, 3, 5, 7, 11, 13) length(odds) length(primes) odds + 1 odds + primes odds * primes odds &gt; 5 sum(odds &gt; 5) sum(primes &lt; 5 | primes &gt; 9) odds[3] odds[10] odds[-3] primes[odds] primes[primes &gt;= 7] sum(primes[primes &gt; 5]) sum(odds[odds &gt; 5]) odds[10] &lt;- 1 + 2 * 9 odds y &lt;- 1:10 y &lt;- 1:10; y (x &lt;- 1:5) The problem uses the KidsFeet data set from the mosaicData package. The hints are suggested functions that might be of use. How many kids are represented in the data set. [Hint: nrow() or dim()] Which of the variables are factors? [Hint: glimpse()] Add a new variable called foot_ratio that is equal to length divided by width. [Hint: mutate()] Add a new variable called biggerfoot2 that has values &quot;dom&quot; (if domhand and biggerfoot are the same) and &quot;nondom&quot; (if domhand and biggerfoot are different). [Hint: mutate(), ==, ifelse()] Create new data set called Boys that contains only the boys. [Hint: filter(), ==] What is the name of the boy with the largest foot_ratio? Show how to find this programmatically, don’t just scan through the whole data set yourself. [Hint: max() or arrange()] 3.9 Footnotes "],
["probability.html", "4 Probability 4.1 Some terminology 4.2 Distributions in R 4.3 Joint, marginal, and conditional distributions 4.4 Exercises 4.5 Footnotes", " 4 Probability 4.1 Some terminology Probability is about quantifying the relative chances of various possible outcomes of a random process. As a very simple example (used to illustrate the terminology below), considering rolling a single 6-sided die. sample space: The set of all possible outcomes of a random process. [{1, 2, 3, 4, 5, 6}] event: a set of outcomes (subset of sample space) [E = {2, 4, 6} is the event that we obtain an even number] probability: a number between 0 and 1 assigned to an event (really a function that assigns numbers to each event). We write this P(E). [P(E) = 1/2 where E = {1, 2, 3}] random variable: a random process that produces a number. [So rolling a die can be considered a random variable.] probability distribution: a description of all possible outcomes and their probabilities. For rolling a die we might do this with a table like this: 1 2 3 4 5 6 1/6 1/6 1/6 1/6 1/6 1/6 support (of a random variable): the set of possible values of a random variable. This is very similar to the sample space. probability mass function (pmf): a function (often denoted with \\(p\\) or \\(f\\)) that takes possible values of a discrete random variable as input and returns the probability of that outcome. If \\(S\\) is the support of the random variable, then \\[ \\sum_{x \\in S} p(x) = 1 \\] and any function with this property is a pmf. Probabilities of events are obtained by adding the probabilities of all outcomes in the event: \\[ \\operatorname{Pr}(E) = \\sum_{x \\in E} p(x) \\] * pmfs can be represented in a table (like the one above) or graphically with a probability histogram or lollipop plot like the ones below. [These are not for the 6-sided die, as we can tell because the probabilities are not the same for each input; the die rolling example would make very boring plots.] Histograms are generally presented on the density scale so the total area of the histogram is 1. (In this example, the bin widths are 1, so this is the same as being on the probability scale.) probability density function (pdf): a function (often denoted with \\(p\\) or \\(f\\)) that takes the possible values of continuous random variable as input and returns the probability density. If \\(S\\) is the support of the random variable, then2 \\[ \\int_{x \\in S} f(x) \\; dx = 1 \\] and any function with this property is a pmf. Probabilities are obtained by integrating (visualized by the area under the density curve): \\[ \\operatorname{Pr}(a \\le X \\le b) = \\int_a^b f(x) \\; dx \\] kernel function: If \\(\\int_{x \\in S} f(x) \\; dx = k\\) for some real number \\(k\\), then \\(f\\) is a kernel function. We can obtain the pdf from the kernel by dividing by \\(k\\). cumulative distribution function (cdf): a function (often denoted with a capital \\(F\\)) that takes a possible value of a random variable as input and returns the probability of obtaining a value less than or equal to the input: \\[ F_X(x) = \\operatorname{Pr}(X \\le x) \\] cdfs can be defined for both discrete and continuous random variables. a family of distributions: is a collection of distributions which share common features but are distinguished by different parameter values. For example, we could have the family of distributions of fair dice random variables. The parameter would tell us how many sides the die has. Statisticians call this family the discrete uniform distributions because all the probabilities are equal (1/6 for 6-sided die, 1/10 for a \\(D_10\\), etc.). We will get to know several important families of distributions, among them the binomial, beta, normal, and t families will be especially useful. You may already be familiar with some or all of these. We will also use distributions that have no name and are only described by a pmf or pdf, or perhaps only by a large number of random samples from which we attempt to estimate the pmf or pdf. 4.2 Distributions in R pmfs, pdfs, and cdfs are available in R for many important families of distributions. You just need to know a few things: each family has a standard abbreviation in R pmf and pdf functions begin with the letter d followed by the family abbreviation cdf functions begin with the letter p followed by the family abbreviation the inverse of the cdf function is called a quantile function, it starts with the letter q functions beginning with r can generate random samples from a distribution help for any of these functions will tell you what R calls the parameters of the family. gf_dist() can be used to make various plots of distributions. 4.2.1 Example: Normal distributions As an example, let’s look the family of normal distributions. If you type dnorm( and then hit TAB or if you type args(dnorm) you can see the arguments for this function. args(dnorm) ## function (x, mean = 0, sd = 1, log = FALSE) ## NULL From this we see that the parameters are called mean and sd and have default value of 0 and 1. These values will be used if we don’t specify something else. As with many of the pmf and pdf functions, there is also an option to get back the log of the pmf or pdf by setting log = TRUE. This turns out to be computationally much more efficient in many contexts, as we will see. Let’s begin with some pictures of a normal distribution with mean 10 and standard deviation 1: gf_dist(&quot;norm&quot;, mean = 10, sd = 2, title = &quot;pdf for Norm(10, 2)&quot;) gf_dist(&quot;norm&quot;, mean = 10, sd = 2, kind = &quot;cdf&quot;, title = &quot;cdf for Norm(10, 2)&quot;) Now some exercises. Assume \\(X \\sim {\\sf Norm}(10, 2)\\). What is \\(\\operatorname{Pr}(X \\le 5)\\)? We can see by inspection that it is less that 0.5. pnorm() will give us the value we are after; xpnorm() will provide more verbose output and a plot as well. pnorm(5, mean = 10, sd = 2) ## [1] 0.00621 xpnorm(5, mean = 10, sd = 2) ## ## If X ~ N(10, 2), then ## P(X &lt;= 5) = P(Z &lt;= -2.5) = 0.00621 ## P(X &gt; 5) = P(Z &gt; -2.5) = 0.9938 ## ## [1] 0.00621 What is \\(\\operatorname{Pr}(5 \\le X \\le 10)\\)? pnorm(10, mean = 10, sd = 2) - pnorm(5, mean = 10, sd = 2) ## [1] 0.4938 How tall is the density function at it’s peak? Normal distributions are symmetric about their means, so we need the value of the pdf at 10. dnorm(10, mean = 10, sd = 2) ## [1] 0.1995 What is the mean of a Norm(10, 2) distribution? Ignoring for the moment that we know the answer is 10, we can compute it. Notice the use of dnorm() in the computation. integrate(function(x) x * dnorm(x, mean = 10, sd = 2), -Inf, Inf) ## 10 with absolute error &lt; 0.0011 What is the variance of a Norm(10, 2) distribution? Again, we know the answer is the square of the standard deviation, so 4. But let’s get R to compute it in a way that would work for other distributions as well. integrate(function(x) (x - 10)^2 * dnorm(x, mean = 10, sd = 2), -Inf, Inf) ## 4 with absolute error &lt; 7.1e-05 Simulate a data set with 50 values drawn from a \\({\\sf Norm}(10, 2)\\) distribution and make a histogram of the results and overlay the normal pdf for comparison. x &lt;- rnorm(50, mean = 10, sd = 2) # be sure to use a density histogram so it is on the same scale as the pdf! gf_dhistogram(~ x, bins = 10) %&gt;% gf_dist(&quot;norm&quot;, mean = 10, sd = 2, color = &quot;red&quot;) 4.2.2 Simulating running proportions library(ggformula) library(dplyr) theme_set(theme_bw()) Flips &lt;- tibble( n = 1:500, flip = rbinom(500, 1, 0.5), running_count = cumsum(flip), running_prop = running_count / n ) gf_line( running_prop ~ n, data = Flips, color = &quot;skyblue&quot;, ylim = c(0, 1.0), xlab = &quot;Flip Number&quot;, ylab = &quot;Proportion Heads&quot;, main = &quot;Running Proportion of Heads&quot;) %&gt;% gf_hline(yintercept = 0.5, linetype = &quot;dotted&quot;) 4.3 Joint, marginal, and conditional distributions Sometimes (most of the time, actually) we are interested joint distributions. A joint distribution is the distribution of multiple random variables that result from the same random process. For example, we might roll a pair of dice and obtain two numbers (one for each die). Or we might collect a random sample of people and record the height for each of them. Or we might randomly select one person, but record multiple facts (height and weight, for example). All of these situations are covered by joint distributions.3 4.3.1 Example: Hair and eye color Kruschke illustrates joint distributions with an example of hair and eye color recorded for a number of people.4 That table below has the proportions for each hair/eye color combination. For example, Hair/Eyes Blue Green Hazel Brown Black 0.034 0.115 0.008 0.025 Blond 0.159 0.012 0.027 0.017 Brown 0.142 0.201 0.049 0.091 Red 0.029 0.044 0.024 0.024 Each value in the table indicates the proportion of people that have a particular hair color and a particular eye color. So the upper left cell says that 3.4% of people have black hair and blue eyes (in this particular sample – the proportions will vary a lot depending on the population of interest). We will denote this as \\[ \\operatorname{Pr}(\\mathrm{Hair} = \\mathrm{black}, \\mathrm{Eyes} = \\mathrm{blue}) = 0.034 \\;. \\] or more succinctly as \\[ p(\\mathrm{black}, \\mathrm{blue}) = 0.034 \\;. \\] This type of probability is called a joint probability because it tells about the probability of both things happening. Use the table above to do the following. What is \\(p(\\mathrm{brown}, \\mathrm{green})\\) and what does that number mean? Add the proportion across each row and down each column. (Record them to the right and along the bottom of the table.) For example, in the first row we get \\[ 0.034 + 0.115 + 0.008 + 0.025 = 0.182 \\;. \\] Explain why \\(p(\\mathrm{black}) = 0.182\\) is good notation for this number. Up to round-off error, the total of all the proportions should be 1. Check that this is true. What proportion of people with black hair have blue eyes? This is called a conditional probability. We denote it as \\(\\operatorname{Pr}(\\mathrm{Eyes} = \\mathrm{blue} \\mid \\mathrm{Hair} = \\mathrm{black})\\). or \\(p(\\mathrm{blue} \\mid \\mathrm{black})\\). Compute some other conditional probabilities. \\(p(\\mathrm{black} \\mid \\mathrm{blue})\\). \\(p(\\mathrm{blue} \\mid \\mathrm{blond})\\). \\(p(\\mathrm{blond} \\mid \\mathrm{blue})\\). \\(p(\\mathrm{brown} \\mid \\mathrm{hazel})\\). \\(p(\\mathrm{hazel} \\mid \\mathrm{brown})\\). There are 32 such conditional probabilities that we can compute from this table. Which is largest? Which is smallest? Write a general formula for computing the conditional probability \\(p(c \\mid r)\\) from the \\(p(r,c)\\) values. (\\(r\\) and \\(c\\) are to remind you of rows and columns.) Write a general formula for computing the conditional probability \\(p(r \\mid c)\\) from the \\(p(r,c)\\) values. If we have continuous random variables, we can do a similar thing. Instead of working with probability, we will work with a pdf. Instead of sums, we will have integrals. Write a general formula for computing each of the following if \\(p(x,y)\\) is a continuous joint pdf. \\(p_X(x) = p(x) =\\) \\(p_Y(y) = p(y) =\\) \\(p_{Y\\mid X}(y\\mid x) = p(y \\mid x) =\\) \\(p_{X\\mid Y}(y\\mid x) = (x \\mid y) =\\) We can expression both versions of conditional probability using a word equation. Fill in the missing numerator and denominator \\[ \\mathrm{conditional} = \\frac{\\phantom{joint}}{\\phantom{marginal}} \\] 4.3.2 Independence If \\(p(x \\mid y) = p(x)\\) (conditional = marginal) for all combinations of \\(x\\) and \\(y\\), we say that \\(X\\) and \\(Y\\) are independent. Use the definitions above to express independence another way. Are hair and eye color independent in our example? True or False. If we randomly select a card from a standard deck (52 cards, 13 denominations, 4 suits), are suit and denomination independent? Create a table for two independent random variables \\(X\\) and \\(Y\\), each of which takes on only 3 possible values. Now create a table for a different pair \\(X\\) and \\(Y\\) that are not independent but have the same marginal probabilities as in the previous exercise. 4.4 Exercises Suppose a random variable has the pdf \\(p(x) = 6x (1-x)\\) on the interval \\([0,1]\\). (That means it is 0 outside of that interval.) Use function() to create a function in R that is equivalent to p(x). Use gf_function() to plot the function on the interval \\([0, 1]\\). Integrate by hand to show that the total area under the pdf is 1 (as it should be for any pdf). Now have R compute that same integral (using integrate()). What is the largest value of \\(p(x)\\)? At what value of \\(x\\) does it occur? Is it a problem that this value is larger than 1? Hint: differentiation might be useful. Recall that \\(\\operatorname{E}(X) = \\int x f(x) \\;dx\\) for a continuous random variable with pdf \\(f\\) and \\(\\operatorname{E}(X) = \\sum x f(x) \\;dx\\) for a discrete random variable with pmf \\(f\\). (The integral or sum is over the support of the random variable.) Compute the expected value for the following random variables. \\(A\\) is discrete with pmf \\(f(x) = x/10\\) for \\(x \\in \\{1, 2, 3, 4\\}\\). \\(B\\) is continuous with kernel \\(f(x) = x^2(1-x)\\) on \\([0, 1]\\). Hint: first figure out what the pdf is. Compute the variance and standard deviation of each of the distributions in the previous problem. In Bayesian inference, we will often need to come up with a distribution that matches certain features that correspond to our knowledge or intuition about a situation. Find a normal distribution with a mean of 10 such that half of the distribution is within 3 of 10 (ie, between 7 and 13). Hint: use qnorm() to determine how many standard deviations are between 10 and 7. School children were surveyed regarding their favorite foods. Of the total sample, 20% were 1st graders, 20% were 6th graders, and 60% were 11th graders. For each grade, the following table shows the proportion of respondents that chose each of three foods as their favorite. From that information, construct a table of joint probabilities of grade and favorite food. Are grade and favorite food independent? Explain how you ascertained the answer. grade Ice cream Fruit French fries 1st 0.3 0.6 0.1 6th 0.6 0.3 0.1 11th 0.3 0.1 0.6 Three cards are placed in a hat. One is black on both sides, one is white on both sides, and the third is white on one side and black on the other. One card is selected at random from the three cards in the hat and placed on the table. The top of the card is black. What is the probability that the bottom is also black? What notation should we use for this probability? The three cards from the previous problem are returned to the hat. Once again a card is pulled and placed on the table, and once again the top is black. This time a second card is drawn and placed on the table. The top side of the second card is white. What is the probability that the bottom side of the first card is black? What is the probability that the bottom side of the second card is black? What is the probability that the bottom side of both cards is black? Pandas. Suppose there are two species of panda, A and B. Without a special blood test, it is not possible to tell them apart. But it is known that half of pandas are of each species and that 10% of births from species A are twins and 20% of births from species B are twins. If a female panda has twins, what is the probability that she is from species A? If the same panda later has another set of twins, what is the probability that she is from species A? A different panda has twins and a year later gives birth to a single panda. What is the probability that this panda is from species A? More Pandas. You get more interested in pandas and learn that at your favorite zoo, 70% of pandas are species A and 30% are species B. You learn that one of the pandas has twins. What is the probability that the panda is species A? The same panda has a single panda the next year. Now what is the probability that the species is A? 4.5 Footnotes Kruschke likes to write his integrals in a different order: \\(\\int dx \\; f(x)\\) instead of \\(\\int f(x) \\; dx\\). Either order means the same thing.↩ Kruschke calls these 2-way distributions, but there can be more than variables involved.↩ The datasets package has a version of this data with a third variable: sex. (It is as a 3d table rather than as a data frame). According to the help for this data set, these data come from “a survey of students at the University of Delaware reported by Snee (1974). The split by Sex was added by Friendly (1992a) for didactic purposes.” It isn’t exactly clear what population this might represent↩ "],
["bayes-rule-and-the-grid-method.html", "5 Bayes’ Rule and the Grid Method 5.1 The Big Bayesian Idea 5.2 Estimating the bias in a coin using the Grid Method 5.3 Working on the log scale 5.4 Discrete Parameters 5.5 Exercises 5.6 Footnotes", " 5 Bayes’ Rule and the Grid Method 5.1 The Big Bayesian Idea Model specifies \\[\\begin{align*} \\mbox{prior: } \\quad &amp; p(\\mbox{parameter values}) \\\\ \\mbox{likelihood: } \\quad &amp; p(\\mbox{data values} \\mid \\mbox{parameter values}) \\end{align*}\\] Bayes rule + data gives \\[\\begin{align*} \\mbox{posterior: } \\quad &amp; p(\\mbox{parameter values} \\mid \\mbox{data values}) \\end{align*}\\] Let’s let \\(D\\) be the data values and \\(\\theta\\) the parameter values. So the prior is \\(p(\\theta)\\), and the posterior is \\(p(\\theta \\mid D)\\). Recall that \\[\\begin{align*} p(D, \\theta) &amp;= p(\\theta) \\cdot p(D \\mid \\theta) \\\\ &amp;= p(D) \\cdot p(\\theta \\mid D) \\\\[3mm] p(D) \\cdot p(\\theta \\mid D) &amp;= p(\\theta) \\cdot p(D \\mid \\theta) \\end{align*}\\] Solving that last equation for \\(p(\\theta \\mid D)\\) gives \\[\\begin{align*} p(\\theta \\mid D) &amp;= \\frac{ p(\\theta) \\cdot p(D \\mid \\theta)}{p(D)} \\\\ &amp;= \\frac{ p(\\theta) \\cdot p(D \\mid \\theta)}{\\sum_{\\theta^*} p(\\theta^*) p(D \\mid \\theta^*)} \\mbox{or} \\frac{ p(\\theta) \\cdot p(D \\mid \\theta)}{\\int p(\\theta^*) p(D \\mid \\theta^*) \\; d\\theta^*} \\\\ \\end{align*}\\] Important facts about the denominator: The denominator sums or integrates over all possible numerators. The denominator depends on \\(D\\) but not on \\(\\theta\\). So it is just a normalizing constant that guarantees that total probability is 1 for the posterior distribution. That is, it converts the kernel into a pdf. If we only need a kernel, we don’t need to compute the denominator. Another way of saying all this is that \\[\\begin{align*} p(\\theta \\mid D) &amp;\\propto p(\\theta) \\cdot p(D \\mid \\theta) \\\\[3mm] \\mbox{posterior} &amp; \\propto \\mbox{prior} \\cdot \\mbox{likelihood} \\\\[3mm] \\mbox{kernel of posterior} &amp;= \\mbox{prior} \\cdot \\mbox{likelihood} \\end{align*}\\] That last line is worth repeating. It’s the most important equation in this course: \\[ \\LARGE \\mbox{(kernel of) posterior} = \\mbox{prior} \\cdot \\mbox{likelihood} \\] 5.1.1 Likelihood For a fixed data set \\(D\\), \\(p(\\theta)\\) and \\(p(\\theta \\mid D)\\) are pdfs (or pmfs) describing the prior and posterior distributions of \\(\\theta\\). The likelihood function is different. If we consider \\(p(D \\mid \\theta)\\) to be a function of \\(D\\), it is not a pdf or pmf, and the total area under the curve for all possible data sets need not be 1. The likelihood function is specified by the model. The model must tell us “how likely a given data set would be” for a specified value of the parameters \\(\\theta\\). 5.1.2 When Bayes is easy If the number of possible values for \\(\\theta\\) is small (so we could just do all the arithmetic by brute force) or if the integrals and sums are easy to compute, then Bayesian updating (computing the posterior) is relatively easy. We’ll start with examples (at least approximately) in those two happy situations and worry about some of the complications a little bit later. 5.2 Estimating the bias in a coin using the Grid Method Big ideas: Discretize the parameter space if it is not already discrete. Compute prior and likelihood at each “grid point” in the (discretized) parameter space. Compute (kernel of) posterior as prior \\(\\cdot\\) likelihood at each “grid point”. Normalize to get posterior, if desired. Below we will see how to perform these four steps in R. 5.2.1 Creating a Grid The parameter is \\(\\theta\\) and we will discretize by selecting 1001 grid points from 0 to 1 by 0.001.5 CoinsGrid &lt;- expand.grid( theta = seq(0, 1, by = 0.001) ) head(CoinsGrid) theta 0.000 0.001 0.002 0.003 0.004 0.005 Now let’s add on a triangle prior with a peak when \\(\\theta = 0.5\\). library(triangle) CoinsGrid &lt;- expand.grid( theta = seq(0, 1, by = 0.001) ) %&gt;% mutate( prior = dtriangle(theta) # triangle distribution ) gf_area(prior ~ theta, data = CoinsGrid) Now the likelihood for a small data set: 1 success out of 4 trials. This is the trickiest part. dbinom(x, size = n, prob = theta) will calculate the probability that we want for a given value of x, n, and theta. We want to do this for each value of theta but using the same values for x and n each time purrr:map_dbl() helps us tell R how to do this. Each value of theta gets plugged in for .x and a vector of numbers (dbl stands for double – computer talk for real number) is returned. library(purrr) x &lt;- 1; n &lt;- 4 CoinsGrid &lt;- expand.grid( theta = seq(0, 1, by = 0.001) ) %&gt;% mutate( prior = dtriangle(theta), # triangle distribution likelihood = map_dbl(theta, ~ dbinom(x = x, size = n, .x)) ) gf_area( prior ~ theta, data = CoinsGrid, alpha = 0.3) %&gt;% gf_area( likelihood ~ theta, data = CoinsGrid, alpha = 0.3, fill = &quot;green&quot;) Note: Likelihoods are NOT pmfs or pdfs, so the total area under a likelihood function is usually not 1. We can make a normalized version for the purpose of plotting. (Recall, we will normalize the posterior at the end anyway, so it is fine if the likelihood is off by a constant multiple at this point in the process.) We do this by dividing by sum of the likelihoods and by the width of the spaces between grid points. library(purrr) x &lt;- 1; n &lt;- 4 CoinsGrid &lt;- expand.grid( theta = seq(0, 1, by = 0.001) ) %&gt;% mutate( prior = dtriangle(theta), # triangle distribution likelihood = map_dbl(theta, ~ dbinom(x = x, size = n, .x)), likelihood1 = likelihood / sum(likelihood) / 0.001 # &quot;normalized&quot; ) gf_area( prior ~ theta, data = CoinsGrid, alpha = 0.3) %&gt;% gf_area( likelihood1 ~ theta, data = CoinsGrid, alpha = 0.3, fill = &quot;green&quot;) The hardest part of the coding (computing the likelihood) is now done. Getting the posterior is as simple as computing a product. library(purrr) x &lt;- 1; n &lt;- 4 CoinsGrid &lt;- expand.grid( theta = seq(0, 1, by = 0.001) ) %&gt;% mutate( prior = dtriangle(theta), # triangle distribution likelihood = map_dbl(theta, ~ dbinom(x = x, size = n, .x)), likelihood1 = likelihood / sum(likelihood) / 0.001, # &quot;normalized&quot; posterior0 = prior * likelihood, # unnormalized posterior = posterior0 / sum(posterior0) / 0.001 # normalized ) gf_area( prior ~ theta, data = CoinsGrid, alpha = 0.3) %&gt;% gf_area( likelihood1 ~ theta, data = CoinsGrid, alpha = 0.3, fill = &quot;green&quot;) %&gt;% gf_area( posterior ~ theta, data = CoinsGrid, alpha = 0.3, fill = &quot;steelblue&quot;) gf_line( prior ~ theta, data = CoinsGrid) %&gt;% gf_line( likelihood1 ~ theta, data = CoinsGrid, color = &quot;green&quot;) %&gt;% gf_line( posterior ~ theta, data = CoinsGrid, color = &quot;steelblue&quot;) 5.2.2 HDI from the grid The CalvinBayes packages includes a function hdi_from_grid() to compute highest density intervals from a grid. The basic idea of the algorithm used is to sort the grid by the posterior values. The mode will be at the end of the list, and the “bottom 95%” will be the HDI (or some other percent if we choose a different level). This method works as long as the posterior is unimodal, increasing to the mode from either side. hdi_from_grid() is slightly more complicated because it handles things like multiple parameters and performs some standardization (so we can work with kernels, for example). It does assume that the grid is uniform (ie, evenly spaced). We simply provide the data frame containing our grid calculations, pars: the name of the parameter (or parameters) for which we want intervals (default is the first column in the grid), prob: the probability we want in covered by our interval (0.95 by default), posterior: the name of the column containing the posterior kernel values (&quot;posterior&quot; by default) library(CalvinBayes) hdi_from_grid(CoinsGrid, pars = &quot;theta&quot;, prob = 0.95) param lo hi prob height mode_height mode theta 0.098 0.681 0.9501 0.4833 2.37 0.4 With this information in hand, we can add a representation of the 95% HDI to our plot. HDICoins &lt;- hdi_from_grid(CoinsGrid, pars = &quot;theta&quot;, prob = 0.95) gf_line(posterior ~ theta, data = CoinsGrid) %&gt;% gf_hline(yintercept = ~height, data = HDICoins, color = &quot;red&quot;, alpha = 0.5) %&gt;% gf_pointrangeh(height ~ mode + lo + hi, data = HDICoins, color = &quot;red&quot;, size = 1) %&gt;% gf_labs(caption = &quot;posterior mode and 95% HPI indicated in red&quot;) 5.2.3 Automating the grid Note: This function is a bit different from CalvinBayes::BernGrid(). MyBernGrid &lt;- function( x, n, # x successes in n tries prior = dunif, resolution = 1000, # number of intervals to use for grid ...) { Grid &lt;- expand.grid( theta = seq(0, 1, length.out = resolution + 1) ) %&gt;% mutate( # saving only the normalized version of each prior = prior(theta, ...), prior = prior / sum(prior) * resolution, likelihood = dbinom(x, n, theta), likelihood = likelihood / sum(likelihood) * resolution, posterior = prior * likelihood, posterior = posterior / sum(posterior) * resolution ) H &lt;- hdi_from_grid(Grid, pars = &quot;theta&quot;, prob = 0.95) gf_line(prior ~ theta, data = Grid, color = ~&quot;prior&quot;, size = 1.15, alpha = 0.8) %&gt;% gf_line(likelihood ~ theta, data = Grid, color = ~&quot;likelihood&quot;, size = 1.15, alpha = 0.7) %&gt;% gf_line(posterior ~ theta, data = Grid, color = ~&quot;posterior&quot;, size = 1.15, alpha = 0.6) %&gt;% gf_pointrangeh( height ~ mode + lo + hi, data = H, color = &quot;red&quot;, size = 1) %&gt;% gf_labs(title = &quot;Prior/Likelihood/Posterior&quot;, subtitle = paste(&quot;Data: n =&quot;, n, &quot;, x =&quot;, x)) %&gt;% gf_refine( scale_color_manual( values = c( &quot;prior&quot; = &quot;forestgreen&quot;, &quot;likelihood&quot; = &quot;blue&quot;, &quot;posterior&quot; = &quot;red&quot;), breaks = c(&quot;prior&quot;, &quot;likelihood&quot;, &quot;posterior&quot;) )) %&gt;% print() invisible(Grid) # return the Grid, but don&#39;t show it } This function let’s us quickly explore several scenarios and compare the results. How does changing the prior affect the posterior? How does changing the data affect the posterior? library(triangle) MyBernGrid(1, 4, prior = dtriangle, a = 0, b = 1, c = 0.5) MyBernGrid(1, 4, prior = dunif) MyBernGrid(10, 40, prior = dtriangle, a = 0, b = 1, c = 0.5) MyBernGrid(10, 40, prior = dunif) MyBernGrid(1, 4, prior = dtriangle, a = 0, b = 1, c = 0.8) MyBernGrid(10, 40, prior = dtriangle, a = 0, b = 1, c = 0.8) MyBernGrid(10, 40, prior = dbeta, shape1 = 25, shape2 = 12) 5.3 Working on the log scale Very often it is numerically better to work on the log scale, computing the logs of the prior, likelihood, and posterior. There are at least two reasons for this: Likelihoods are often very small, especially if there is a lot of data. (Even with the most credible parameter values, the probability of getting exactly the data set that was observed is very low.) Likelihoods often involve products and exponentiation. Take logarithms turns these into sums and products. In fact, we can often compute these logs without first computing the prior, likelihood, or posterior. (It depends on the form of those functions.) Let’s redo our previous example working on the log scale until the very end. x &lt;- 1; n &lt;- 4 CoinsGridLog &lt;- expand.grid( theta = seq(0, 1, by = 0.001) ) %&gt;% mutate( logprior = log(dtriangle(theta, 0, 1)), # triangle distribution loglik = map_dbl(theta, ~ dbinom(x = x, size = n, prob = .x, log = TRUE)), logpost = logprior + loglik, posterior = exp(logpost), posterior1 = posterior / sum(posterior, na.rm = TRUE) ) gf_line(posterior1 ~ theta, data = CoinsGridLog) 5.4 Discrete Parameters Most of the parameters we will encounter will be able to take on all values in some interval. If we have parameter that can only take on a discrete set of values, then the grid method is exact if we make a grid point for each of those values. Usually we think of parameters taking on numerical values, but here is an example where a parameter takes on categorical labels for values. Suppose we have a medical test for a disease and we know the following information. Only 1 person in 1000 has the disease in our population of interest If a person is healthy, the probability that the test will be correct is 97%. (97% = specificity = true negative rate) If a person is diseased, the probability that the test will be correct is 99%. (99% = sensitivity = true positive rate) If a person is tested and the test comes back “positive” (indicating disease), what is the probability that the person actually has the disease? Our parameter that we want to estimate is disease status, which can take on only two possible values: healthy or diseased. Disease_Grid &lt;- tibble( status = c(&quot;healthy&quot;, &quot;sick&quot;), prior = c(999/1000, 1/1000) ) Disease_Grid status prior healthy 0.999 sick 0.001 Now let’s add in the likelihood and posterior information assuming a positive test result. Disease_Grid &lt;- tibble( status = c(&quot;healthy&quot;, &quot;sick&quot;), prior = c(999/1000, 1/1000), likelihood = c(.03, .99), posterior = prior * likelihood, posterior1 = posterior / sum(posterior) ) Disease_Grid status prior likelihood posterior posterior1 healthy 0.999 0.03 0.030 0.968 sick 0.001 0.99 0.001 0.032 So we have updated our belief from a 0.1% chance the person has the disease to a 3.2$ chance that they have the disease. That’s a sizable increase, but the person is still most likely healthy, not diseased. 5.5 Exercises More testing. Suppose that the population consists of 100,000 people. Compute how many people would be expected to fall into each cell of Table 5.4 on page 104 of DBDA2e. (To compute the expected number of people in a cell, just multiply the cell probability by the size of the population.) You should find that out of 100,000 people, only 100 have the disease, while 99,900 do not have the disease. These marginal frequencies instantiate the prior probability that \\(p(\\theta = \\frown) = 0.001\\). Notice also the cell frequencies in the column \\(\\theta = \\frown\\), which indicate that of 100 people with the disease, 99 have a positive test result and 1 has a negative test result. These cell frequencies instantiate the hit rate of 0.99. Your job for this part of the exercise is to fill in the frequencies of the remaining cells of the table. Take a good look at the frequencies in the table you just computed for the previous part. These are the so-called “natural frequencies” of the events, as opposed to the somewhat unintuitive expression in terms of conditional probabilities (Gigerenzer &amp; Hoffrage, 1995). From the cell frequencies alone, determine the proportion of people who have the disease, given that their test result is positive. Your answer should match the result from applying Bayes’ rule to the probabilities. Now we’ll consider a related representation of the probabilities in terms of natural frequencies, which is especially useful when we accumulate more data. This type of representation is called a “Markov” representation by Krauss, Martignon, and Hoffrage (1999). Suppose now we start with a population of \\(N = 10,000,000\\) people. We expect 99.9% of them (i.e., 9,990,000) not to have the disease, and just 0.1% (i.e., 10,000) to have the disease. Now consider how many people we expect to test positive. Of the 10,000 people who have the disease, 99%, (i.e., 9,900) will be expected to test positive. Of the 9,990,000 people who do not have the disease, 5% (i.e., 499,500) will be expected to test positive. Now consider re-testing everyone who has tested positive on the first test. How many of them are expected to show a negative result on the re-test? What proportion of people who test positive at first and then negative on retest, actually have the disease? In other words, of the total number of people at the bottom of the diagram in the previous part (those are the people who tested positive then negative), what proportion of them are in the left branch of the tree? How does the result compare with your answer to Exercise 5.1? Suppose we have a test with a 97% specificity and a 99% sensitivity just like in Section 5.4. Now suppose that a random person is selected, has a first test that is positive, then is retested and has a second test that is negative. Taking into account both tests, and assuming the results of the two tests are independent, what is the probability that the person has the disease? Hint: We can use the the posterior after the first test as a prior for the second test. Be sure to keep as many decimal digits as possible (use R and don’t round intermediate results). Note: In this problem we are assuming the the results of the two tests are independent, which might not be the case for some medical tests. Consider again the disease and diagnostic test of the previous exercise and Section 5.4. Suppose that a person selected at random from the population gets the test and it comes back negative. Compute the probability that the person has the disease. The person then gets re-tested, and on the second test the result is positive. Compute the probability that the person has the disease. How does the result compare with your answer in the previous exercise? Modify MyBernGrid() so that it takes an argument specifying the probability for the HDI. Use it to create a plot showing 50% HDI for theta using a symmetric triangle prior and data consisting of 3 success and 5 failures. Let’s try the grid method for a model with two parameters. Suppose we want to estimate the mean and standard deviation of the heights of 21-year-old American men or women (your choice which group). First, lets get some data. library(NHANES) Men &lt;- NHANES %&gt;% filter(Gender == &quot;male&quot;, Age == 21) Women &lt;- NHANES %&gt;% filter(Gender == &quot;female&quot;, Age == 21) Likelihood Our model is that heights are normally distributed with mean \\(\\mu\\) and standard deviation \\(\\sigma\\): Prior. For our prior, let’s use something informed just a little bit by what we know about people (we could do better with other priors, but that’s not our goal at the moment): the mean height is somewhere between 5 and 7 feet (let’s use 150 and 200 cm which are close to that) the standard deviation is positive, but no more than 20 cm (so 95% of people are within 40 cm (~ 16 inches) of average – that seems like a pretty safe bet). we will use a uniform prior over these ranges (even though you probably believe that some parts of the ranges are much more credible than others). So our model is \\[\\begin{align*} \\mathrm{Height} &amp; \\sim {\\sf Norm}(\\mu, \\sigma) \\\\ \\mu &amp; \\sim {\\sf Unif}(150, 200) \\\\ \\sigma &amp; \\sim {\\sf Unif}(0, 20) \\end{align*}\\] Grid. Use a grid that has 200-500 values for each parameter. Fill in the ?? below to create and update your grid. Notes: It is more numerically stable to work on the log-scale as much as possible, You may normalize if you want to, but it isn’t necessary for this problem. library(purrr) Height_Grid &lt;- expand.grid( mu = seq(??, ??, ?? = ??), sigma = seq(??, ??, ?? = ??) ) %&gt;% filter(sigma != 0) %&gt;% # remove sigma = 0 mutate( prior = ??, logprior = ??, loglik = map2_dbl(mu, sigma, ~ ?? ) # use .x for mu and .y for sigma logpost = logprior + loglik, posterior = exp(logpost) ) Once you have created and updated your grid, you can visualize your posterior using a command like this (use gf_lims() if you want to zoom in a bit): gf_tile(posterior ~ mu + sigma, data = Height_Grid) %&gt;% gf_contour(posterior ~ mu+ sigma, data = Height_Grid, color = &quot;yellow&quot;) Now answer the following questions. Using the picture you just created, what would you say are credible values for \\(\\mu\\) and for \\(\\sigma\\)? Now use hdi_from_grid() to compute a 90% highest density (posterior) intervals for each parameter. Do those make sense when you compare to the picture? Create a plot showing the posterior distribution for \\(\\mu\\) and a 90% HDI for \\(\\mu\\). [Hint: how can you get a grid for the marginal distribution of \\(\\mu\\) from the grid for \\(\\mu\\) and \\(\\sigma\\)?] Redo the previous problem using a triangle prior for each parameter. You may choose where to put the peak of the triangle. Bob plays basketball. He shoots 70% of his shots from 2-point range and makes 48% of these shots. He shoots 30% of his shots from 3-point range and makes 32% of these shots. Joe just made a shot. What is the probability that it was a 3-point shot? Do this problem twice. The first time, use probability rules, carefully denoting the probabilities involved. (For any number that appears, I should be able to tell from your notation where it came from.) The second time, use the “grid method”. Alice has 3 hats labeled with the letters H, A, and T. In each hat are marbles of various colors. Hat White marbles Red marbles Yellow marbles H 4 10 6 A 6 12 2 T 5 3 2 Alice randomly selects a hat by flipping two coins. If both are heads, she chooses hat H. If both are tails, she chooses hat T. If there is one head and one tail, she chooses hat A. Once that hat is selected, she draws out two marbles. If the two marbles are both white, what is the probability that the hat was hat A? If there is one red marble and one yellow marble, what is the probability that the hat was hat A? If the two marbles are the same color, what is the probability that the hat was hat A? 5.6 Footnotes There are other ways to do this, but expand.grid() will work when we have more than one parameter, so we’ll start using it already in the simpler case of a single parameter.↩ "],
["inferring-a-binomial-probability-via-exact-mathematical-analysis.html", "6 Inferring a Binomial Probability via Exact Mathematical Analysis 6.1 Beta distributions 6.2 Beta and Bayes 6.3 Getting to know the Beta distributions 6.4 What if the prior isn’t a beta distribution? 6.5 Exercises", " 6 Inferring a Binomial Probability via Exact Mathematical Analysis 6.1 Beta distributions A few important facts about beta distributions two parameters: \\(\\alpha = a =\\) shape1; \\(\\beta = b =\\) shape2. kernel: \\(x^{\\alpha - 1} (1-x)^{\\beta -1}\\) on \\([0, 1]\\) area under the kernel: \\(B(a, b)\\) [\\(B()\\) is the beta function, beta() in R] scaling contant: \\(1 / B(a, b)\\) We can use gf_dist() to see what a beta distribution looks like. gf_dist(&quot;beta&quot;, shape1 = 5, shape2 = 3, color = ~ &quot;Beta(5, 3)&quot;) %&gt;% gf_dist(&quot;beta&quot;, shape1 = 3, shape2 = 5, color = ~ &quot;Beta(3, 5)&quot;) %&gt;% gf_dist(&quot;beta&quot;, shape1 = 0.9, shape2 = 0.9, color = ~ &quot;Beta(0.9, 0.9)&quot;) %&gt;% gf_dist(&quot;beta&quot;, shape1 = 0.9, shape2 = 1.1, color = ~ &quot;Beta(0.9, 1.1)&quot;) %&gt;% gf_labs(title = &quot;Some Beta distributions&quot;, color = &quot;distribution&quot;) 6.2 Beta and Bayes Suppose we want to estimate a proportion \\(\\theta\\) by repeating some random process (like a coin toss) \\(N\\) times. We will code each result using a 0 (failure) or a 1 (success): \\(Y_1, Y_2, \\dots, Y_N\\). Here’s our model. The prior, to be determined shortly, is indicated as ??? for the moment. \\[\\begin{align*} Y_i &amp; \\sim {\\sf Bern}(\\theta) \\\\ \\theta &amp; \\sim{} ??? \\end{align*}\\] 6.2.1 The Bernoulli likelihood function The first line turns into the following likelihood function – the probability of observing \\(y_i\\) for a give parameter value \\(\\theta\\): \\[\\begin{align*} Pr{Pr}(Y_i = y_i \\mid \\theta) = p(y_i \\mid \\theta) &amp;= \\begin{cases} \\theta &amp; y_i = 1 \\\\ (1-\\theta) &amp; y_i = 0 \\end{cases} \\\\ &amp;= \\theta^{y_i} (1-\\theta)^{y_i} \\end{align*}\\] The likelihood for the entire data set is then \\[\\begin{align*} p(\\langle y_1, y_2, \\dots, y_N \\rangle \\mid \\theta) &amp;= \\prod_{i = 1}^N \\theta^{y_i} (1-\\theta)^{y_i} \\\\ &amp;= \\theta^{x} (1-\\theta)^{N - x} \\end{align*}\\] where \\(x\\) is the number of “successes” and \\(N\\) is the number of trials. Since the likelihood only depends on \\(x\\) and \\(N\\), not the particular order in which the 0’s and 1’s are observed, we will write the likelihood as \\[\\begin{align*} p(x, N \\mid \\theta) &amp;= \\theta^{x} (1-\\theta)^{N - x} \\end{align*}\\] Reminder: If we think of this expression as a function of \\(\\theta\\) for fixed data (rather than as a function of the data for fixed \\(\\theta\\)), we see that it is the kernel of a \\({\\sf Beta}(x + 1, N - x + 1)\\) distribution. But even thought of this way, the likelihood need not be a PDF – the total sum or integral need not be 1. But we will sometimes normalize likelihood functions if we want to display them on plots with priors and posteriors. 6.2.2 A convenient prior Now let think about our posterior: \\[\\begin{align*} p(\\theta \\mid x, N) &amp; = \\overbrace{p(x, N \\mid \\theta)}^{\\mathrm{likelihood}} \\cdot \\overbrace{p(\\theta)}^{\\mathrm{prior}} / p(x, N) \\\\ &amp; = {\\theta^x (1-\\theta)^{N - x}} \\cdot {p(\\theta)} / p(x, N) \\end{align*}\\] If we let \\(p(\\theta) = \\theta^a (1-\\theta^b)\\), the product is epsecially easy to evaluate: \\[\\begin{align*} p(\\theta \\mid x, N) &amp; = \\overbrace{p(x, N \\mid \\theta)}^{\\mathrm{likelihood}} \\cdot \\overbrace{p(\\theta)}^{\\mathrm{prior}} / p(x, N) \\\\ &amp; = {\\theta^x (1-\\theta)^{N - x}} \\cdot {\\theta^a (1-\\theta)^b)} / p(x, N) \\\\ &amp; = {\\theta^{x+a} (1-\\theta)^{N - x + b}} / p(x, N) \\end{align*}\\] In this happy situation, when mutlipying the likelihood and the prior leads to a posterior with same form as the prior, we say that the prior is a conjugate prior (for that particular likelihood function). So beta priors are conjugate priors for the Bernoulli likelihood, and if we use a beta prior, we will get a beta posterior and it is easy to calculate which one: prior data posterior \\(\\sf{Beta}(a, b)\\) \\(x, N\\) \\({\\sf Beta}(x + a, N - x + b)\\) 6.2.3 Pros and Cons of conjugate priors Pros: Easy and fast calculation; can reason about the relationship between prior, likelihood, and posterior based on a known distributions. Cons: We are restricted to using a conjugate prior, and that isn’t always the prior we want; many situations don’t have natural conjugate priors available; the computations are often not as simple as in our current example. 6.3 Getting to know the Beta distributions 6.3.1 Important facts You can often look up this sort of information on the Wikipedia page for a family of distributions. If you go to https://en.wikipedia.org/wiki/Beta_distribution you will find, among other things, the following: Notation Beta(\\(\\alpha, \\beta\\)) Parameters \\(\\alpha &gt; 0\\) shape (real) \\(\\beta &gt; 0\\) shape (real) Support \\(\\displaystyle x\\in [0,1]\\) or \\(\\displaystyle x\\in (0,1)\\) PDF \\(\\displaystyle \\frac{x^{\\alpha -1}(1-x)^{\\beta -1}}{\\mathrm{B}(\\alpha, \\beta )}\\) Mean \\(\\displaystyle \\frac{\\alpha }{\\alpha +\\beta }\\) Mode \\(\\displaystyle {\\frac{\\alpha -1}{\\alpha +\\beta -2}}\\) for \\(\\alpha, \\beta &gt; 1\\) 0 for \\(\\alpha = 1, \\beta &gt; 1\\) 1 for \\(\\alpha &gt; 1, \\beta = 1\\) Variance \\(\\displaystyle \\frac{\\alpha \\beta}{(\\alpha +\\beta )^{2}(\\alpha +\\beta +1)}\\) Concentration \\(\\displaystyle \\kappa =\\alpha +\\beta\\) 6.3.2 Alternative parameterizations of Beta distributions There are several different parameterizations of the beta distributions that can be helpful in selecting a prior or interpreting a posterior. 6.3.2.1 Mode and concentration Let the concentration be defined as \\(\\kappa =\\alpha +\\beta\\). Since the mode (\\(\\omega\\)) is \\(\\displaystyle {\\frac{\\alpha -1}{\\alpha +\\beta -2}}\\) for \\(\\alpha, \\beta &gt; 1\\), we can solve for \\(\\alpha\\) and \\(\\beta\\) to get \\[\\begin{align} \\alpha &amp;= \\omega (\\kappa - 2) + 1\\\\ \\beta &amp;= (1-\\omega)(\\kappa -2) + 1 \\end{align}\\] 6.3.2.2 Mean and concentration The beta distribution may also be reparameterized in terms of its mean \\(\\mu\\) and the concentration \\(\\kappa\\). If we solve for \\(\\alpha\\) and \\(\\beta\\), we get \\[\\begin{align} \\alpha &amp;= \\mu \\kappa \\\\ \\beta &amp;= (1 - \\mu) \\kappa \\end{align}\\] 6.3.2.3 Mean and variance (or standard deviation) We can also parameterize with the mean \\(\\mu\\) and variance \\(\\sigma^2\\). Solving the system of equations for mean and variance given in the table above, we get \\[\\begin{align} \\kappa &amp;=\\alpha +\\beta = \\frac{\\mu (1-\\mu )}{\\sigma^2} - 1 \\\\ \\alpha &amp;=\\mu \\kappa = \\mu \\left({\\frac{\\mu (1-\\mu )}{\\sigma^2}}-1\\right) \\\\ \\beta &amp;= (1-\\mu )\\kappa = (1-\\mu ) \\left({\\frac{\\mu (1-\\mu)} {\\sigma^2}} -1 \\right), \\end{align}\\] provided \\(\\sigma^2 &lt; \\mu (1-\\mu)\\). 6.3.3 beta_params() CalvinBayes::beta_params() will compute several summaries of a beta distribution given any of these 2-parameter summaries. This can be very handy for converting from one type of information about a beta distribution to another. For example. Suppose you want a beta distribution with mean 0.3 and standard deviation 0.1. Which beta distribution is it? library(CalvinBayes) beta_params(mean = 0.3, sd = 0.1) shape1 shape2 mean mode sd concentration 6 14 0.3 0.2778 0.1 20 We can do a similar thing with other combinations. bind_rows( beta_params(mean = 0.3, concentration = 10), beta_params(mode = 0.3, concentration = 10), beta_params(mean = 0.3, sd = 0.2), beta_params(shape1 = 5, shape2 = 10), ) shape1 shape2 mean mode sd concentration 3.000 7.000 0.3000 0.2500 0.1382 10.00 3.400 6.600 0.3400 0.3000 0.1428 10.00 1.275 2.975 0.3000 0.1222 0.2000 4.25 5.000 10.000 0.3333 0.3077 0.1179 15.00 6.3.4 Automating Bayesian updates for a proportion (beta prior) Since we have formulas for this case, we can write a function handle any beta prior and any data set very simply. (Much simpler than doing the grid method each time). quick_bern_beta &lt;- function( x, n, # data, successes and trials ... # see clever trick below ) { pars &lt;- beta_params(...) a &lt;- pars$shape1 b &lt;- pars$shape2 theta_hat &lt;- x / n # value that makes likelihood largest posterior_mode &lt;- (a + x - 1) / (a + b + n - 2) # scale likelihood to be as tall as the posterior likelihood &lt;- function(theta) { dbinom(x, n, theta) / dbinom(x, n, theta_hat) * dbeta(posterior_mode, a + x, b + n - x) # posterior height at mode } gf_dist(&quot;beta&quot;, shape1 = a, shape2 = b, color = ~ &quot;prior&quot;, alpha = 0.5, xlim = c(0,1), size = 1.2) %&gt;% gf_function(likelihood, color = ~ &quot;likelihood&quot;, alpha = 0.5, size = 1.2) %&gt;% gf_dist(&quot;beta&quot;, shape1 = a + x, shape2 = b + n - x, color = ~ &quot;posterior&quot;, alpha = 0.5, size = 1.6) %&gt;% gf_labs( color = &quot;function&quot;, title = paste0(&quot;posterior: Beta(&quot;, a + x, &quot;, &quot;, b + n - x, &quot;)&quot;) ) %&gt;% gf_refine( scale_color_manual( values = c(&quot;prior&quot; = &quot;gray50&quot;, &quot;likelihood&quot; = &quot;forestgreen&quot;, &quot;posterior&quot; = &quot;steelblue&quot;))) } With such a function in hand, we can explore examples very quickly. Here are three examples from DBDA2e (pp. 134-135). quick_bern_beta(17, 20, mode = 0.5, k = 500) quick_bern_beta(17, 20, mode = 0.75, k = 25) quick_bern_beta(17, 20, a = 1, b = 1) 6.4 What if the prior isn’t a beta distribution? Unless it is some other distribution where we can work things out mathematically, we are back to the grid method. Here’s an example like the one on page 136. dtwopeaks &lt;- function(x) { 0.48 * triangle::dtriangle(x, 0.2, 0.3) + 0.48 * triangle::dtriangle(x, 0.7, 0.8) + 0.04 * dunif(x) } BernGrid(data = c(rep(0, 13), rep(1, 14)), prior = dtwopeaks) %&gt;% gf_function(function(theta) 0.3 * dbinom(13, 27, theta), color = &quot;forestgreen&quot;) 6.5 Exercises Show that if \\(\\alpha, \\beta &gt; 1\\), then the mode of a Beta(\\(\\alpha\\), \\(\\beta\\)) distribution is \\(\\displaystyle {\\frac{\\alpha -1}{\\alpha +\\beta -2}}\\). Hint: What would you do if you were in Calculus I? Suppose we have a coin that we know comes from a magic-trick store, and therefore we believe that the coin is strongly biased either usually to come up heads or usually to come up tails, but we don’t know which. Express this belief as a beta prior. That is, find shape parameters that lead to a beta distribution that corresponds to this belief. Now we flip the coin 5 times and it comes up heads in 4 of the 5 flips. What is the posterior distribution? Use quick_bern_beta() or a similar function of your own creation to show the prior and posterior graphically. Suppose we estimate a proprtion \\(\\theta\\) using a \\({\\sf Beta}(10, 10)\\) prior and a observe 26 successes and 48 failures. What is the posterior distribution? What is the mean of the posterior distribution? What is the mode of the posterior distribution? Compute a 90% HDI for \\(\\theta\\). [Hint: qbeta()] Suppose a state-wide election is approaching, and you are interested in knowing whether the general population prefers the democrat or the republican. There is a just-published poll in the newspaper, which states that of 100 randomly sampled people, 58 preferred the republican and the remainder preferred the democrat. Suppose that before the newspaper poll, your prior belief was a uniform distribution. What is the 95% HDI on your beliefs after learning of the newspaper poll results? Based on what you know about elections, why is a uniform prior not a great choice? Repeat part (a) with a prior the conforms better to what you know about elections. How much does the change of prior affect the 95% HDI? You find another poll conducted by a different news organization In this second poll, 56 of 100 people preferred the republican. Assuming that peoples’ opinions have not changed between polls, what is the 95% HDI on the posterior taking both polls into account. Make it clear which prior you are using. Based on this data (and your choice of prior, and assuming public opinion doesn’t change between the time of the polls and election day), what is the probability that the republican will win the election. "],
["markov-chain-monte-carlo-mcmc.html", "7 Markov Chain Monte Carlo (MCMC) 7.1 King Markov and Adviser Metropolis 7.2 Quick Intro to Markov Chains 7.3 Back to King Markov 7.4 How well does the Metropolis Algorithm work? 7.5 Markov Chains and Posterior Sampling 7.6 Two coins 7.7 MCMC posterior sampling: Big picture 7.8 Exercises", " 7 Markov Chain Monte Carlo (MCMC) 7.1 King Markov and Adviser Metropolis King Markov is king of a chain of 5 islands. Rather than live in a palace, he lives in a royal boat. Each night the royal boat anchors in the harbor of one of the islands. The law declares that the king must harbor at each island in proportion to the population of the island. Question 1: If the populations of the islands are 100, 200, 300, 400, and 500 people, how often must King Markov harbor at each island? King Markov has some personality quirks: He can’t stand record keeping. So he doesn’t know the populations on his islands and doesn’t keep track of which islands he has visited when. He can’t stand routine (variety is the spice of his life), so he doesn’t want to know each night where he will be the next night. He asks Adviser Metropolis to devise a way for him to obey the law but that randomly picks which island to stay at each night, doesn’t require him to remember where he has been in the past, and doesn’t require him to remember the populations of all the islands. He can ask the clerk on any island what the island’s population is whenever he needs to know. But it takes half a day to sail from one island to another, so he is limited in how much information he can obtain this way each day. Metropolis devises the following scheme: Each morning, have breakfast with the island clerk and inquire about the population of the current island. Then randomly pick one of the 4 other islands (a proposal island) and travel there in the morning Let \\(J(b \\mid a)\\) be the conditional probability of selecting island \\(b\\) as the candidate if \\(a\\) is the current island. \\(J\\) does not depend on the populations of the islands (since the King can’t remember them). Over lunch at the proposal island, inquire about its population. If the proposal island has more people, stay at the proposal island for the night (since the king should prefer more populated islands). If the proposal island has fewer people, stay at the proposal island with probability \\(A\\), else return to the “current” island (ie, last night’s island). Metropolis is convinced that for the right choices of \\(J\\) and \\(A\\), this will satisfy the law. He quickly determines that \\(A\\) cannot be 0 and cannot be 1: Question 2. What happens if \\(A = 0\\)? What happens if \\(A = 1\\)? It seems like \\(A\\) might need to depend on the populations of the current and proposal islands. When we want to emphasize that, we’ll denote it as \\(A = A(b \\mid a)\\). But how? If \\(A\\) is too large, the king will visit small islands too often. If \\(A\\) is too small, he will visit large islands too often. Fortunately, Metropolis knows about Markov Chains. Unfortunately, some of you may not. So let’s learn a little bit about Markov Chains and then figure out how Metropolis should choose \\(J\\) and \\(A\\). 7.2 Quick Intro to Markov Chains 7.2.1 More info, please This is going to be very quick. You can learn more, if you are interested, by going to https://www.dartmouth.edu/~chance/teaching_aids/books_articles/probability_book/Chapter11.pdf 7.2.2 Definition Consider a random process that proceeds in discrete steps (often referred to as time). Let \\(X_t\\) represent the “state” of the process at time \\(t\\). Since this is a random process, \\(X_t\\) is random, and we can ask probability questions like ``What is the probability of being in state ____ at time ____?&quot;, ie, What is \\(\\mathrm{Pr}(X_t = x)\\)? If \\[ \\mathrm{Pr}(X_{t+1} = x \\mid X_t = x_t, X_{t-1} = x_{t-1}, \\dots , X_0 = x_0) = \\mathrm{Pr}(X_{t+1} \\mid X_{t} = x_t) \\] then we say that the process is a Markov Chain. The intuition is that (the probabilities of) what happens next depends only on the current state and not on previous history. 7.2.3 Time-Homogeneous Markov Chains The simplest version of a Markov Chain is one that is time-homogeneous: \\[ \\mathrm{Pr}(X_{t+1} = b \\mid X_t = a) = p_{ab} \\] That is, the (conditional) probability of moving from state \\(a\\) to state \\(b\\) in one step is the same at every time. 7.2.4 Matrix representation A time-homogeneous Markov Chain can be represented by a square matrix \\(M\\) with \\[ M_{ij} = p_{ij} = \\mbox{probability of transition from state $i$ to state $j$ in one step} \\] (This will be an infinite matrix if the state space in infinite, but we’ll start with simple examples with small, finite state spaces.) \\(M_{ij}\\) is the probability of moving in one step from state \\(i\\) to state \\(j\\). More generally, we will write \\(M^{(k)}_{ij}\\) for the probability of moving from state \\(i\\) to state \\(j\\) in \\(k\\) steps. Small Example: M &lt;- rbind( c(0, 0.5, 0.5), c(0.25, 0.25, 0.5), c(0.5, 0.3, 0.2)) M 0.00 0.50 0.5 0.25 0.25 0.5 0.50 0.30 0.2 Question 3: How many states does this process have? What is the probability of moving from state 1 to state 3 in 1 step? What is the probability of moving from state 1 to state 3 in 2 steps? (Hint: what are the possible stopping points along the way?) How do we obtain \\(M^{(2)}\\) from \\(M\\)? How do we obtain \\(M^{(k)}\\) from \\(M\\)? Question 4: The Metropolis Algorithm as a Markov process What are the states of the Metropolis algorithm? If King Markov is on island 2, what is the probability of moving to Island 3? If King Markov is on island 3, what is the probability of moving to Island 2? What is the general formula for the probability of moving from island \\(a\\) to island \\(b\\) (in one step)? (\\(\\mathrm{Pr}(X_{t+1}=b \\mid X_t = a)\\)) 7.2.5 Regular Markov Chains A time-homogeneous Markov Chain, is called regular if there is a number \\(k\\) such that every state is reachable from every other state with non-zero probability in \\(k\\) steps Question 5a Is our small example regular? If so, how many steps are required? Question 5b Under what conditions is the Metropolis algorithm regular? Regular Markov Chains have a very nice property: \\[ \\lim_{k \\to \\infty} M^{(k)} = W \\] where every row of \\(W\\) is the same. This says that, no matter where you start the process, the long-run probability of being in each state will be the same. In our small example above, convergence is quite rapid: M %^% 20 0.2769 0.3385 0.3846 0.2769 0.3385 0.3846 0.2769 0.3385 0.3846 M %^% 21 0.2769 0.3385 0.3846 0.2769 0.3385 0.3846 0.2769 0.3385 0.3846 Note: If we apply the matrix \\(M\\) to the limiting probability (\\(w\\), one row of \\(W\\)), we just get \\(w\\) back again: \\[w M = w\\] W &lt;- M %^% 30 W[1,] ## [1] 0.2769 0.3385 0.3846 W[1,] %*% M 0.2769 0.3385 0.3846 In fact, this is a necessary and sufficient condition for the limiting probability. So, here’s what Metropolis needs to do: Choose \\(J\\) and \\(A\\) so that his algorithm is a regular Markov Chain with matrix \\(M\\) If \\(w = \\langle p(1), p(2), p(3), p(4), p(5) \\rangle\\) is the law-prescribed probabilities for island harboring, then \\(w M = w\\). 7.3 Back to King Markov If \\(A\\) is between 0 and 1, and the jumping rule allows us to get to all the islands (eventually), then the Markov Chain will be regular, so there will be a limiting distribution. But the limiting distribution must be the one the law requires. It suffices to show that if the law is satisfied at time \\(t\\) it is satisfied at time \\(t+1\\) (\\(wM = w\\)): \\[ \\mathrm{Pr}(X_t = a) = p(a) \\mbox{ for all $a$ } \\Rightarrow \\mathrm{Pr}(X_{t+1} = a) = p(a) \\mbox{ for all $a$} \\] Here’s the trick: We will choose \\(J\\) and \\(A\\) so that the following two unconditional probabilities are equal. \\[ \\mathrm{Pr}(a \\to_t b) = \\mathrm{Pr}(b \\to_t a) \\] where \\(\\mathrm{Pr}(a \\to_t b) = \\mathrm{Pr}(X_t = a \\ \\&amp; \\ X_{t+1} = b)\\). Why does this work? Suppose \\(\\mathrm{Pr}(X_t = a) = p(a)\\) as the law prescribes. \\(\\mathrm{Pr}(a \\to_t b) = \\mathrm{Pr}(b \\to_t a)\\) makes the joint distribution symmetric: For any \\(a\\) and any \\(b\\). \\[\\mathrm{Pr}(X_{t} = a \\ \\&amp; \\ X_{t+1} = b) = \\mathrm{Pr}(X_{t} = b \\ \\&amp; \\ X_{t+1} = a)\\] This means that both marginals are the same, so for any \\(a\\): \\[\\mathrm{Pr}(X_t = a) = \\mathrm{Pr}(X_{t+1} = a)\\] In other words, the probability of the current island will be the same as the probability of the next island: \\(w M = w\\). Time for some algebra (and probability)! How do we choose \\(J\\) and \\(A\\)? Recall the ingredients: \\(P(a)\\) be the population of island \\(a\\) \\(p(a)\\) be the proportion of the total population living on island \\(a\\): \\(p(a) = \\frac{p(a)}{\\sum_x p(x)}\\) \\(J(b \\mid a)\\) is the conditional probability of selecting island \\(b\\) as the candidate when \\(a\\) is the current island. (J for Jump probability) \\(A(b \\mid a)\\) is the probability of accepting proposal island \\(b\\) if it is proposed from island \\(a\\). Question 6: Consider two islands – \\(a\\) and \\(b\\) – with \\(P(b) &gt; P(a)\\). Assume that probability of being on island \\(x\\) is \\(p(x)\\). Calculate the following probabilities (in terms of things like \\(p\\), \\(J\\), and \\(A\\)). (Unconditional) probability of moving from \\(a\\) to \\(b = \\mathrm{Pr}(a \\to_t b) =\\) (Unconditional) probability of moving from \\(b\\) to \\(a = \\mathrm{Pr}(b \\to_t a) =\\) Question 7: How do we choose J and A to make these probabilities equal? \\[ A(a \\mid b) = \\phantom{\\frac{p(a) J(b \\mid a)}{p(b) J(a \\mid b)}} \\] Question 8: Symmetric jump rules. Is it possible to do this with symmetric jump rules? That is, can we require \\(J(b \\mid a) = J(a \\mid b)\\)? (Remember, the king doesn’t like to remember stuff, and this means half as much stuff to remember about the jump rules). Does using a symmetric jump rule make the acceptance rule \\(A\\) any simpler or more complicated? (The king won’t be so happy if the simpler jump rule makes the acceptance rule a lot more complicated.) Question 9: Constant jump rules. Is it possible to do this if we require that \\(J(y \\mid x) = J(y&#39; \\mid x&#39;)\\) for all \\(y \\neq x\\) and \\(y&#39; \\neq x&#39;\\)? (This would make life even easier for the king.) For King Markov, what would \\(J\\) be if we did it this way? The original Metropolis algorithm used symmetric jump rules. The later generalization (Metropolis-Hastings) employed non-symmetric jump rules to get better performance of the Markov Chain. 7.4 How well does the Metropolis Algorithm work? Let’s let the computer simulate this algorithm. And since the computer is doing all the work, let’s make a general function so we can experiment a bit. KingMarkov &lt;- function( num_steps = 1e5, population = 1:5, island_names = 1:length(population), start = 1, J = function(a, b) {1 / (length(population) - 1)} ) { num_islands &lt;- length(population) island_seq &lt;- rep(NA, num_steps) # trick to pre-alocate memory proposal_seq &lt;- rep(NA, num_steps) # trick to pre-alocate memory current &lt;- start proposal &lt;- NA for (i in 1:num_steps) { # record current island island_seq[i] &lt;- current proposal_seq[i] &lt;- proposal # propose one of the other islands other_islands &lt;- setdiff(1:num_islands, current) proposal &lt;- sample(other_islands, 1, prob = purrr::map(other_islands, ~ J(current, .x))) # move? prob_move &lt;- population[proposal] / population[current] # new current island (either current current or proposal) current &lt;- ifelse(runif(1) &lt; prob_move, proposal, current) } tibble( step = 1:num_steps, island = island_names[island_seq], proposal = island_names[proposal_seq] ) } Question 10: Look at the code above and answer the following. What are the default populations of the islands? What is the default jump rule? Explain what each of the following bits of code are doing: other_islands &lt;- setdiff(1:num_islands, current) prob = purrr::map(other_islands, ~ J(current, .x)) the call to sample() prob_move &lt;- population[proposal] / population[current] current &lt;- ifelse(runif(1) &lt; prob_move, proposal, current) the call to tibble() 7.4.1 Jumping to any island Now let’s simulate the first 5000 nights of King Markov’s reign. Tour &lt;- KingMarkov(5000) Target &lt;- tibble(island = 1:5, prop = (1:5)/ sum(1:5)) gf_line(island ~ step, data = Tour %&gt;% filter(step &lt;= 200)) %&gt;% gf_point(proposal ~ step, data = Tour %&gt;% filter(step &lt;= 200), color = &quot;red&quot;, alpha = 0.4) %&gt;% gf_refine(scale_y_continuous(breaks = 1:10)) ## Warning: Removed 1 rows containing missing values (geom_point). gf_dhistogram( ~ island, data = Tour, binwidth = 1, color = &quot;black&quot;) %&gt;% gf_point(prop ~ island, data = Target, color = &quot;red&quot;) %&gt;% gf_refine(scale_x_continuous(breaks = 1:10)) Question 11: Look at the first plot. It shows where the king stayed each of the first 200 nights. Did the king ever stay two consecutive nights on the same island? (How can you tell from the plot?) Did the king ever stay two consecutive nights on the smallest island? (How can you answer this without looking at the plot?) 7.4.2 Jumping only to neighbor islands What if we only allow jumping to neighboring islands? (Imagine the islands are arranged in a circle and we only sail clockwise or counterclockwise around the circle to the nearest island.) neighbor &lt;- function(a, b) as.numeric(abs(a-b) %in% c(1,4)) Tour &lt;- KingMarkov(10000, population = 1:5, J = neighbor) Target &lt;- tibble(island = 1:5, prop = (1:5)/ sum(1:5)) gf_line(island ~ step, data = Tour %&gt;% filter(step &lt;= 200)) %&gt;% gf_refine(scale_y_continuous(breaks = 1:10)) gf_dhistogram( ~ island, data = Tour, binwidth = 1) %&gt;% gf_point(prop ~ island, data = Target, color = &quot;red&quot;) %&gt;% gf_refine(scale_x_continuous(breaks = 1:10)) The effect of visiting only neighbors is more dramatic with more islands. neighbor &lt;- function(a, b) as.numeric(abs(a-b) %in% c(1,9)) Tour &lt;- KingMarkov(10000, population = 1:10, J = neighbor) Target &lt;- tibble(island = 1:10, prop = (1:10)/ sum(1:10)) gf_line(island ~ step, data = Tour %&gt;% filter(step &lt;= 200)) %&gt;% gf_refine(scale_y_continuous(breaks = 1:10)) gf_dhistogram( ~ island, data = Tour, binwidth = 1) %&gt;% gf_point(prop ~ island, data = Target, color = &quot;red&quot;) %&gt;% gf_refine(scale_x_continuous(breaks = 1:10)) 7.5 Markov Chains and Posterior Sampling That was a nice story, and some nice probability theory. But what does it have to do with Bayesian computation? Regular Markov Chains (and some generalizations of them) can be used to sample from a posterior distribution: state = island = set of parameter values in typical applications, this will be an infinite state space population = prior * likelihood importantly, we do not need to normalize the posterior; that would typically be a very computationally expensive thing to do start in any island = start at any parameter values convergence may be faster from some starting states than from others, but in principle, any state will do randomly choose a proposal island = randomly select a proposal set of parameter values if the posterior is greater there, move if the posterior is smaller, move anyway with probability \\[A = \\frac{\\mbox{proposal `posterior&#39;}}{\\mbox{current `posterior&#39;}}\\] Metropolis-Hastings variation: More choices for \\(J()\\) (need not be symmetric) gives more opportunity to tune for convergence Other variations: Can allow \\(M\\) to change over the course of the algorithm. (No longer time-homogeneous.) 7.5.1 Example 1: Estimating a proportion To see how this works in practice, let’s consider our familiar model that has a Bernoulli likelihood and a beta prior: \\(Y_i \\sim {\\sf Bern}(\\theta)\\) \\(\\theta \\sim {\\sf Beta}(a, b)\\) Since we are already familiar with situation, we know that the posterior should be a beta distribution when the prior is a beta distribution. We can use this information to see how well the algorithm works in that situation. Let’s code up our Metropolis algorithm for this situation. There is a new wrinkle, however: The state space for the parameter is a continuous interval [0,1]. So we need a new kind of jump rule Instead of sampling from a finite state space, we use rnorm() The standard deviation of the normal distribution (called size in the code below) controls how large a step we take (on average). This number has nothing to do with the model, it is a tuning parameter of the algorithm. metro_bern &lt;- function( x, n, # x = successes, n = trials size = 0.01, # sd of jump distribution start = 0.5, # value of theta to start at num_steps = 1e4, # number of steps to run the algorithm prior = dunif, # function describing prior ... # additional arguments for prior ) { theta &lt;- rep(NA, num_steps) # trick to pre-alocate memory proposed_theta &lt;- rep(NA, num_steps) # trick to pre-alocate memory move &lt;- rep(NA, num_steps) # trick to pre-alocate memory theta[1] &lt;- start for (i in 1:(num_steps-1)) { # head to new &quot;island&quot; proposed_theta[i + 1] &lt;- rnorm(1, theta[i], size) if (proposed_theta[i + 1] &lt;= 0 || proposed_theta[i + 1] &gt;= 1) { prob_move &lt;- 0 # because prior is 0 } else { current_prior &lt;- prior(theta[i], ...) current_likelihood &lt;- dbinom(x, n, theta[i]) current_posterior &lt;- current_prior * current_likelihood proposed_prior &lt;- prior(proposed_theta[i+1], ...) proposed_likelihood &lt;- dbinom(x, n, proposed_theta[i+1]) proposed_posterior &lt;- proposed_prior * proposed_likelihood prob_move &lt;- proposed_posterior / current_posterior } # sometimes we &quot;sail back&quot; if (runif(1) &gt; prob_move) { # sail back move[i + 1] &lt;- FALSE theta[i + 1] &lt;- theta[i] } else { # stay move[i + 1] &lt;- TRUE theta[i + 1] &lt;- proposed_theta[i + 1] } } tibble( step = 1:num_steps, theta = theta, proposed_theta = proposed_theta, move = move, size = size ) } Question 12: What happens if the proposed value for \\(\\theta\\) is not in the interval \\([0,1]\\)? Why? Question 13: What do proposed_posterior and current_posterior correspond to in the story of King Markov? Question 14: Notice that we are using the unnormalized posterior. Why don’t we need to normalize the posterior? Why is it important that we don’t have to normalize the posterior? 7.5.1.1 Looking at posterior samples The purpose of all this was to get samples from the posterior distribution. We can use histograms or density plots to see what our MCMC algorithm shows us for the posterior distribution. When using MCMC algorithms, we won’t typically have ways of knowing the “right answer”. But in this case, we know the posterior is Beta(6, 11), so we can compare our posterior samples to that distribution to see how well things worked. Let’s try a nice small step size like 0.2%. set.seed(341) Tour &lt;- metro_bern(5, 15, size = 0.002) gf_dhistogram(~ theta, data = Tour, bins = 100) %&gt;% gf_dens(~ theta, data = Tour) %&gt;% gf_dist(&quot;beta&quot;, shape1 = 6, shape2 = 11, color = &quot;red&quot;) Hmm. That’s not too good. Let’s see if we can figure out why. 7.5.1.2 Trace Plots A trace plot shows the “tour of King Markov’s ship” – the sequence of parameter values sampled (in order). gf_line(theta ~ step, data = Tour) %&gt;% gf_hline(yintercept = 5/15, color = &quot;red&quot;) Question 15: Why does the trace plot begin at a height of 0.5? Question 16: What features of this trace plot indicate that our posterior sampling isn’t working well? Would making the step size larger or smaller be more likely to help? Question 17: Since we know that the posterior distribution is Beta(6, 11), how could we use R to show us what an ideal trace plot would look like? 7.5.1.3 Comparing step sizes Let’s see how our choice of step affects the sampling. Size 0 is sampling from a true Beta(6, 11) distribution. set.seed(341) Tours &lt;- bind_rows( metro_bern(5, 15, size = 0.02), metro_bern(5, 15, size = 0.2), metro_bern(5, 15, size = 0.002), tibble(theta = rbeta(1e4, 6, 11), size = 0, step = 1:1e4) ) gf_dhistogram( ~ theta | size ~ ., data = Tours, bins = 100) %&gt;% gf_dist(&quot;beta&quot;, shape1 = 6, shape2 = 11, color = &quot;red&quot;) Sizes 0.2 and 0.02 look much better than 0.002. Looking at the trace plots, we see that the samples using a step size of 0.02 are still highly auto-correlated (neighboring values are similar to each other). Thus the “effective sample size” is not nearly as big as the number of posterior samples we have generated. With a step size of 0.2, the amount of auto-correlation is substantially reduced, but not eliminated. gf_line(theta ~ step, data = Tours) %&gt;% gf_hline(yintercept = 5/14, color = &quot;red&quot;) %&gt;% gf_facet_grid(size ~ .) %&gt;% gf_lims(x = c(0,1000)) ## Warning: Removed 9000 rows containing missing values (geom_path). 7.5.1.4 Auto-correlation and Thinning One way to reduce the auto-correlation in posterior samples is by thinning. This auto-correlation plot suggests that keeping every 7th or 8th value when size is 0.2 should give us a posterior sample that is nearly independent. acf(Tours %&gt;% filter(size == 0.2) %&gt;% pull(theta)) gf_line(theta ~ step, data = Tours %&gt;% filter(step %% 8 == 0)) %&gt;% gf_hline(yintercept = 5/14, color = &quot;red&quot;) %&gt;% gf_facet_grid(size ~ .) %&gt;% gf_lims(x = c(0,1000)) ## Warning: Removed 1125 rows containing missing values (geom_path). Now the idealized trace plot and the trace plot for step = 0.2 are quite similar looking. So the effective sample size for that step size is approximately 1/8 the number of posterior samples generated. For step=0.02 we must thin even more, which would require generating many more posterior samples to begin with: ACF &lt;- broom::tidy(acf(Tours %&gt;% filter(size == 0.02, step &gt; 1000) %&gt;% pull(theta), plot = FALSE, lag.max = 50)) gf_col(acf ~ lag, data = ACF, width = 0.2) 7.5.2 Example 2: Estimating mean and variance Consider the following simple model: \\(Y_i \\sim {\\sf Norm}(\\mu, \\sigma)\\) \\(\\mu \\sim {\\sf Norm}(0, 1)\\) \\(\\log(\\sigma) \\sim {\\sf Norm}(0,1)\\) In this case the posterior distribution for \\(\\mu\\) can be worked out exactly and should be normal. Let’s code up our Metropolis algorithm for this situation. New stuff: we have two parameters, so we’ll use separate jumps for each and combine we could use a jump rule based on both values together, but we’ll keep this simple the state space for each parameter is infinite, so we need a new kind of jump rule instead of sampling from a finite state space, we use rnorm() the standard deviation controls how large a step we take (on average) example below uses same standard deviation for both parameters, but we should select them individually if the parameters are on different scales metro_norm &lt;- function( y, # data vector num_steps = 1e5, size = 1, # sd&#39;s of jump distributions start = list(mu = 0, log_sigma = 0) ) { size &lt;- rep(size, 2)[1:2] # make sure exactly two values mu &lt;- rep(NA, num_steps) # trick to pre-alocate memory log_sigma &lt;- rep(NA, num_steps) # trick to pre-alocate memory move &lt;- rep(NA, num_steps) # trick to pre-alocate memory mu[1] &lt;- start$mu log_sigma[1] &lt;- start$log_sigma move[1] &lt;- TRUE for (i in 1:(num_steps - 1)) { # head to new &quot;island&quot; mu[i + 1] &lt;- rnorm(1, mu[i], size[1]) log_sigma[i + 1] &lt;- rnorm(1, log_sigma[i], size[2]) move[i + 1] &lt;- TRUE log_post_current &lt;- dnorm(mu[i], 0, 1, log = TRUE) + dnorm(log_sigma[i], 0, 1, log = TRUE) + sum(dnorm(y, mu[i], exp(log_sigma[i]), log = TRUE)) log_post_proposal &lt;- dnorm(mu[i + 1], 0, 1, log = TRUE) + dnorm(log_sigma[i + 1], 0, 1, log = TRUE) + sum(dnorm(y, mu[i + 1], exp(log_sigma[i+1]), log = TRUE)) prob_move &lt;- exp(log_post_proposal - log_post_current) # sometimes we &quot;sail back&quot; if (runif(1) &gt; prob_move) { move[i + 1] &lt;- FALSE mu[i + 1] &lt;- mu[i] log_sigma[i + 1] &lt;- log_sigma[i] } } tibble( step = 1:num_steps, mu = mu, log_sigma = log_sigma, move = move, size = paste(size, collapse = &quot;, &quot;) ) } Let’s use the algorithm with three different size values and compare results. set.seed(341) y &lt;- rnorm(25, 1, 2) # sample of 25 from Norm(1, 2) Tour1 &lt;- metro_norm(y = y, num_steps = 5000, size = 1) Tour0.1 &lt;- metro_norm(y = y, num_steps = 5000, size = 0.1) Tour0.01 &lt;- metro_norm(y = y, num_steps = 5000, size = 0.01) Norm_Tours &lt;- bind_rows(Tour1, Tour0.1, Tour0.01) df_stats(~ move | size, data = Norm_Tours, props) size prop_FALSE prop_TRUE 0.01, 0.01 0.0422 0.9578 0.1, 0.1 0.2380 0.7620 1, 1 0.9134 0.0866 7.5.2.1 Density plots gf_dhistogram( ~ mu | size ~ ., data = Norm_Tours, bins = 100) gf_dhistogram( ~ exp(log_sigma) | size ~ ., data = Norm_Tours, bins = 100) 7.5.2.2 Trace plots gf_line(mu ~ step | size ~ ., data = Norm_Tours) gf_line(log_sigma ~ step | size ~ ., data = Norm_Tours) 7.5.2.3 Comparing Multiple Chains If we run multiple chains with different starting points and different random choices, we hope to see similar trace plots. After all, we don’t want our analysis to be an analysis of starting points or of random choices. Tour1a &lt;- metro_norm(y = y, num_steps = 5000, size = 1) %&gt;% mutate(chain = &quot;A&quot;) Tour1b &lt;- metro_norm(y = y, num_steps = 5000, size = 1) %&gt;% mutate(chain = &quot;B&quot;) Tour1c &lt;- metro_norm(y = y, num_steps = 5000, size = 1, start = list(mu = 10, log_sigma = 5)) %&gt;% mutate(chain = &quot;C&quot;) Tour1d &lt;- metro_norm(y = y, num_steps = 5000, size = 1, start = list(mu = 10, log_sigma = 5)) %&gt;% mutate(chain = &quot;D&quot;) Tours1 &lt;- bind_rows(Tour1a, Tour1b, Tour1c, Tour1d) gf_line(mu ~ step, color = ~chain, alpha = 0.5, data = Tours1) gf_line(mu ~ step, color = ~chain, alpha = 0.5, data = Tours1) %&gt;% gf_facet_grid( chain ~ .) 7.5.2.4 Comparing Chains to an Ideal Chain Not all posteriors are normal, but here’s what a chain would look like if the posterior is normal and there is no correlation between draws. Ideal &lt;- tibble(step = 1:5000, mu = rnorm(5000, 1, .3), size = &quot;ideal&quot;) gf_line(mu ~ step | size, data = Norm_Tours %&gt;% bind_rows(Ideal)) If the draws are correlated, then we might get more ideal behavior if we selected only a subset – every 20th or every 30th value, for example. This is the idea behind “effective sample size”. The effective sample size of a correlated chain is the length of an ideal chain that contains as much independent information as the correlated chain. acf(Norm_Tours %&gt;% filter(size == &quot;1, 1&quot;) %&gt;% pull(mu)) gf_line(mu ~ step | size ~ ., data = bind_rows(Norm_Tours, Ideal) %&gt;% filter(step %% 20 == 0)) %&gt;% gf_labs(title = &quot;Every 20th draw&quot;) gf_line(mu ~ step | size ~ ., data = bind_rows(Norm_Tours, Ideal) %&gt;% filter(step %% 30 == 0)) %&gt;% gf_labs(title = &quot;Every 30th draw&quot;) If we thin to every 20th value, our chains with size = 1 and size = 0.1 look quite similar to the ideal chain. The chain with size = 0.01 still moves too slowly through the parameter space. So tuning parameters will affect the effective sample size. 7.5.2.5 Discarding the first portion of a chain The first portion of a chain may not work as well. This portion is typically removed from the analysis since it is more an indication of the starting values used than the long-run sampling from the posterior. gf_line(log_sigma ~ step | size ~ ., data = Norm_Tours) gf_path(log_sigma ~ mu | size ~ (step &gt; 500), data = Norm_Tours, alpha = 0.5) %&gt;% gf_density2d(log_sigma ~ mu, data = Norm_Tours) gf_histogram( ~ mu | size ~ (step &gt; 500) , data = Norm_Tours, binwidth = 0.1) gf_histogram( ~ log_sigma | size ~ (step &gt; 500), data = Norm_Tours, binwidth = 0.1) 7.5.3 Issues with Metropolis Algorithm These are really issues with all MCMC algorithms, not just the Metropolis version: First portion of a chain might not be very good, need to discard it Tuning can affect performance – how do we tune? Samples are correlated – although the long-run probabilities are right, the next stop is not independent of the current one so our effective posterior sample size isn’t as big as it appears 7.6 Two coins 7.6.1 The model Suppose we have two coins and want to compare the proportion of heads each coin generates. Parameters: \\(\\theta_1\\), \\(\\theta_2\\) Data: \\(N_1\\) flips of coin 1 and \\(N_2\\) flips of coin 2. (Results: \\(z_1\\) and \\(z_2\\) heads, respectivly.) Likelihood: indepdendent Bernoulli (each flip independent of the other flips, each coin independent of the other coin) Prior: Independent Beta distributions for each \\(\\theta_i\\) That is, \\(y_{1i} \\sim {\\sf Bern}(\\theta_1), y_{2i} \\sim {\\sf Bern}(\\theta_2)\\) \\(\\theta_1 \\sim {\\sf Beta(a_1, b_1)}, \\theta_2 \\sim {\\sf Beta(a_2, b_2)}\\) (independent) For the examples below we will use data showing that 6 of 8 tosses of the first coin were heads and only 2 of 7 tosses of the second coin. But the methods work equally well with other data sets. While comparing a small number of coin tosses like this is not so interesting, the method can be used for a wide range of practical things, liking testing whether two treatments for a condition are equally effective, etc. 7.6.2 Exact analysis From this we can work out the posterior as usual. (Pay attention to the important parts of the kernel, that is, the numerators.) \\[\\begin{align*} p(\\theta_1, \\theta_2 \\mid D) &amp;= p(D \\mid \\theta_1, \\theta_2) p(\\theta_1, \\theta_2) / p(D) \\\\[3mm] &amp;= \\theta_1^{z_1} (1 − \\theta_1)^{N_1−z_1} \\theta_1^{z_2} (1 − \\theta_2)^{N_2−z_2} p(\\theta_1, \\theta_2) / p(D) \\\\[3mm] &amp;= \\frac{ \\theta_1^{z_1} (1 − \\theta_1)^{N_1 − z_1} \\theta_1^{z_2} (1 − \\theta_2)^{N_2 − z_2} \\theta_1^{a_1−1}(1 − \\theta_1)^{b_1 - 1} \\theta_2^{a_2−1}(1 − \\theta_2)^{b_2 - 1}} {p(D)B(a_1, b_1)B(a_2, b_2)} \\\\[3mm] &amp;= \\frac{ \\theta_1^{z_1 + a_1 − 1}(1 − \\theta_1)^{N_1 − z_1 + b_1 − 1} \\theta_2^{z_2 + a_2 − 1}(1 − \\theta_2)^{N_2 − z_2 + b_2 − 1} }{p(D)B(a_1, b_1)B(a_2, b_2)} \\end{align*}\\] So the posterior distribution of \\(\\langle \\theta_1, \\theta_2 \\rangle\\) is two independent Beta distributions: \\({\\sf Beta}(z_1 + a, N_1 - z_1 + b_1)\\) and \\({\\sf Beta}(z_2 + a, N_2 - z_2 + b_2)\\). Some nice images of these distributions appear on page 167. 7.6.3 Metropolis metro_2coins &lt;- function( z1, n1, # z = successes, n = trials z2, n2, # z = successes, n = trials size = c(0.1, 0.1), # sds of jump distribution start = c(0.5, 0.5), # value of thetas to start at num_steps = 5e4, # number of steps to run the algorithm prior1 = dbeta, # function describing prior prior2 = dbeta, # function describing prior args1 = list(), # additional args for prior1 args2 = list() # additional args for prior2 ) { theta1 &lt;- rep(NA, num_steps) # trick to pre-alocate memory theta2 &lt;- rep(NA, num_steps) # trick to pre-alocate memory proposed_theta1 &lt;- rep(NA, num_steps) # trick to pre-alocate memory proposed_theta2 &lt;- rep(NA, num_steps) # trick to pre-alocate memory move &lt;- rep(NA, num_steps) # trick to pre-alocate memory theta1[1] &lt;- start[1] theta2[1] &lt;- start[2] size1 &lt;- size[1] size2 &lt;- size[2] for (i in 1:(num_steps-1)) { # head to new &quot;island&quot; proposed_theta1[i + 1] &lt;- rnorm(1, theta1[i], size1) proposed_theta2[i + 1] &lt;- rnorm(1, theta2[i], size2) if (proposed_theta1[i + 1] &lt;= 0 || proposed_theta1[i + 1] &gt;= 1 || proposed_theta2[i + 1] &lt;= 0 || proposed_theta2[i + 1] &gt;= 1) { proposed_posterior &lt;- 0 # because prior is 0 } else { current_prior &lt;- do.call(prior1, c(list(theta1[i]), args1)) * do.call(prior2, c(list(theta2[i]), args2)) current_likelihood &lt;- dbinom(z1, n1, theta1[i]) * dbinom(z2, n2, theta2[i]) current_posterior &lt;- current_prior * current_likelihood proposed_prior &lt;- do.call(prior1, c(list(proposed_theta1[i+1]), args1)) * do.call(prior2, c(list(proposed_theta2[i+1]), args2)) proposed_likelihood &lt;- dbinom(z1, n1, proposed_theta1[i+1]) * dbinom(z2, n2, proposed_theta2[i+1]) proposed_posterior &lt;- proposed_prior * proposed_likelihood } prob_move &lt;- proposed_posterior / current_posterior # sometimes we &quot;sail back&quot; if (runif(1) &gt; prob_move) { # sail back move[i + 1] &lt;- FALSE theta1[i + 1] &lt;- theta1[i] theta2[i + 1] &lt;- theta2[i] } else { # stay move[i + 1] &lt;- TRUE theta1[i + 1] &lt;- proposed_theta1[i + 1] theta2[i + 1] &lt;- proposed_theta2[i + 1] } } tibble( step = 1:num_steps, theta1 = theta1, theta2 = theta2, proposed_theta1 = proposed_theta1, proposed_theta2 = proposed_theta2, move = move, size1 = size1, size2 = size2 ) } Metro_2coinsA &lt;- metro_2coins( z1 = 6, n1 = 8, z2 = 2, n2 = 7, size = c(0.02, 0.02), args1 = list(shape1 = 2, shape2 = 2), args2 = list(shape1 = 2, shape2 = 2) ) Metro_2coinsA %&gt;% gf_density2d(theta2 ~ theta1) Metro_2coinsA %&gt;% gf_density(~ (theta2 - theta1)) # effective sample size is much smaller than apparent sample size due to auto-correlation acf(Metro_2coinsA$theta2 - Metro_2coinsA$theta1) Metro_2coinsA %&gt;% filter(step &lt; 500) %&gt;% gf_path(theta2 ~ theta1, color = ~ step, alpha = 0.5) %&gt;% gf_point(theta2 ~ theta1, color = ~ step, alpha = 0.5) Metro_2coinsB &lt;- metro_2coins( z1 = 6, n1 = 8, z2 = 2, n2 = 7, size = c(0.2, 0.2), args1 = list(shape1 = 2, shape2 = 2), args2 = list(shape1 = 2, shape2 = 2) ) Metro_2coinsB %&gt;% gf_density2d(theta2 ~ theta1) Metro_2coinsB %&gt;% gf_density(~ (theta2 - theta1)) # effective sample size is better but still quite a bit # smaller than apparent sample size due to auto-correlation acf(Metro_2coinsB$theta2 - Metro_2coinsB$theta1) Metro_2coinsB %&gt;% filter(step &lt; 500) %&gt;% gf_path(theta2 ~ theta1, color = ~ step, alpha = 0.5) %&gt;% gf_point(theta2 ~ theta1, color = ~ step, alpha = 0.5) 7.6.4 Gibbs sampling Gibbs sampling provides an attempt to improve on the efficiency of the standard Metropolis algorithm by using a different method to propose new parameter values. The idea is this: Pick one of the parameter values: \\(\\theta_i\\) Determine the posterior distribution of \\(\\theta_i\\) using current estimates of the other parameters \\(\\{\\theta_j \\mid j \\neq i\\}\\) This won’t be exactly right, because those estimates are not exactly right, but it should be good when the parameters estimates are close to correct. Sample from the posterior distribution for \\(\\theta_i\\) to get a new proposed value for \\(\\theta_i\\). Always accept this proposal, since it is being sampled from a distribution that already makes more likely values more likely to be proposed. Keep cycling through all the parameters, each time updating one using the current estimates for the others. It takes some work to show that this also converges, and in practice it is often more efficient than the basic Metropolis algorithm. But it is limited to situations where the marginal posterior can be be sampled from. In our example, we can work out the marginal posterior fairly easily: \\[\\begin{align*} p(\\theta_1|\\theta_2, D) &amp;= p(\\theta_1, \\theta_2|D)/p(\\theta_2|D) \\\\ &amp;= p(\\theta_1, \\theta_2|D) \\int d\\theta_1 p(\\theta_1, \\theta_2|D) \\\\ &amp;= \\frac{\\mathrm{dbeta}(\\theta_1, z_1 + a_1, N_1 −z_1 + b_1) \\cdot \\mathrm{dbeta}(\\theta_2, z_2 + a_2, N_2 −z_2 + b_2)} {\\int d\\theta_1 \\mathrm{dbeta}(\\theta_1, z_1 + a_1, N_1 −z_1 +b_1) \\cdot \\mathrm{dbeta}(\\theta_2 \\mid z_2 +a_2, N_2 −z_2 +b_2)} \\\\ &amp;= \\frac{\\mathrm{dbeta}(\\theta_1, z_1 + a_1, N_1 − z_1 + b_1) \\cdot \\mathrm{dbeta}(\\theta_2, z_2 + a_2, N_2 − z_2 + b_2)} {\\mathrm{dbeta}(\\theta_2 \\mid z_2 + a_2, N_2 −z_2 +b_2) \\int d\\theta_1 \\mathrm{dbeta}(\\theta_1, z_1 + a_1, N_1 − z_1 + b_1)} \\\\ &amp;= \\frac{\\mathrm{dbeta}(\\theta_1, z_1 + a_1, N_1 − z_1 + b_1)} {\\int d\\theta_1 \\mathrm{dbeta}(\\theta_1, z_1 + a_1, N_1 − z_1 + b_1)} \\\\ &amp;= \\mathrm{dbeta}(\\theta_1, z_1 + a_1, N_1 − z_1 + b_1) \\end{align*}\\] In other words, \\(p(\\theta_1 \\mid \\theta_2, D) = p(\\theta_1, D)\\), which isn’t surprising since we already know that the posterior distributions \\(\\theta_1\\) and \\(\\theta_2\\) are independent. (In more complicated models, the marginal posterior may depend on all of the parameters, so the calculation above might not be so simple.) Of course, the analogous statement holds for \\(\\theta_2\\) in this model. This examples shows off Gibbs sampling in a situation where it shines: when the posterior distribution is a collection of independent marginals. gibbs_2coins &lt;- function( z1, n1, # z = successes, n = trials z2, n2, # z = successes, n = trials start = c(0.5, 0.5), # value of thetas to start at num_steps = 1e4, # number of steps to run the algorithm a1, b1, # params for prior for theta1 a2, b2 # params for prior for theta2 ) { theta1 &lt;- rep(NA, num_steps) # trick to pre-alocate memory theta2 &lt;- rep(NA, num_steps) # trick to pre-alocate memory theta1[1] &lt;- start[1] theta2[1] &lt;- start[2] for (i in 1:(num_steps-1)) { if (i %% 2 == 1) { # update theta1 theta1[i+1] &lt;- rbeta(1, z1 + a1, n1 - z1 + b1) theta2[i+1] &lt;- theta2[i] } else { # update theta2 theta1[i+1] &lt;- theta1[i] theta2[i+1] &lt;- rbeta(1, z2 + a2, n2 - z2 + b2) } } tibble( step = 1:num_steps, theta1 = theta1, theta2 = theta2, ) } Gibbs &lt;- gibbs_2coins(z1 = 6, n1 = 8, z2 = 2, n2 = 7, a1 = 2, b1 = 2, a2 = 2, b2 = 2) Gibbs %&gt;% gf_density2d(theta2 ~ theta1) Gibbs %&gt;% gf_dens( ~ theta1) acf(Gibbs$theta1) Gibbs %&gt;% filter(step &lt; 500) %&gt;% gf_path(theta2 ~ theta1, color = ~ step, alpha = 0.5) %&gt;% gf_point(theta2 ~ theta1, color = ~ step, alpha = 0.5) Note: Software like JAGS only records results each time it makes a complete cycle through the parameters. We could do that by keeping every other row: Gibbs %&gt;% filter(step %% 2 == 0) %&gt;% gf_density2d(theta2 ~ theta1) Gibbs %&gt;% filter(step %% 2 == 0) %&gt;% gf_density( ~ (theta2 - theta1)) Gibbs %&gt;% filter(step %% 2 == 0) %&gt;% mutate(difference = theta2 - theta1) %&gt;% pull(difference) %&gt;% acf() Gibbs %&gt;% filter(step &lt; 500, step %% 2 == 0) %&gt;% gf_path(theta2 ~ theta1, color = ~ step, alpha = 0.5) %&gt;% gf_point(theta2 ~ theta1, color = ~ step, alpha = 0.5) 7.6.5 Advantages and Disadvantages of Gibbs vs Metropolis Advantages No need to tune. The preformance of the Metropolis algorithm depends on the jump rule used. Gibbs “auto-tunes” by using the marginal posteriors. Gibbs sampling has the potential to sample much more efficiently than Metropolis. It doesn’t propose updates only to reject them, and doesn’t suffer from poor tuning that can make Metropolis search very slowly through the posterior space. Disadvantages Less general: We need to be able to sample from the marginal posterior. Gibbs sampling can be slow if the posterior has highly correlated parameters since given all but one of them, the algorithm with be very certain about the remaining one and adjust it only a very small amount. It is hard for Gibbs samplers to quickly move along “diagonal ridges” in the posterior. The good news is that other people have done the hard work of coding up Gibbs sampling for us, we just need to learn how to describe the model in a way that works with their code. We will be using JAGS (just another Gibbs Sampler) and later Stan (which generalizes the metropolis algorithm in a different way) to fit more interesting models that would be too time consuming to custom code on our own. The examples in the chapter are to help us understand better how these algorithms work so we can interpret the results we obtian when using them. 7.6.6 So what do we learn about the coins? We have seen that we can fit this model a number of different ways now, but we haven’t actually looked at the results. Are the coins different? How much different? Since the Gibbs sampler is more efficient than the Metropolis algorithm for this situation, we’ll use the posterior samples from the Gibbs sampler to answer. We are interested in \\(\\theta_2 - \\theta_1\\), the difference in the biases of the two coins. To learn about that, we simply investigate the distribution of that quantity in our posterior samples. (Note: You cannot learn about this difference by only considering \\(\\theta_1\\) and \\(\\theta_2\\) sepearately.) gf_dhistogram(~(theta2 - theta1), data = Gibbs) %&gt;% gf_dens() hdi(Gibbs %&gt;% mutate(difference = theta2 - theta1), pars = &quot;difference&quot;) par lo hi mode prob difference -0.6623 0.057 -0.2591 0.95 mosaic::prop(~(theta2 - theta1 &gt; 0), data = Gibbs) ## prop_TRUE ## 0.0601 We don’t have much data, so the posterior distribution of the difference in biases is pretty wide. 0 is within the 95% HDI for \\(\\theta_2 - \\theta_1\\), so we don’t have compelling evidence that the two biases are different based on this small data set. 7.7 MCMC posterior sampling: Big picture 7.7.1 MCMC = Markov chain Monte Carlo Markov chain because the process is a Markov process with probabilities of transitioning from one state to another Monte Carlo because it inovles randomness. (Monte Carlo is a famous casino location.) We will refer to one random walk starting from a pariticular starting value as a chain. 7.7.2 Posterior sampling: Random walk through the posterior Our goal, whether we use Metropolis, Gibbs sampling, Stan, or some other MCMC posterior samping method, is to generate random values from the posterior distribution. Ideally these samples should be representative of the posterior and not of other artifacts like the starting location of the chain, or tuning parameters used to generate the walk. accurate to the posterior. If we run the algorithm multiple times, we would like the results to be similar from run to run. (They won’t match exactly, but if they are all giving good approximations to the same thing, then they should all close to each other.) efficient. The theory says that all of these methods converge to the correct posterior distribution, but in practice, we can only do a finite run. If the sampling is not efficient enough, our finite run might give us a distorted picture (that would eventually have been corrected had we run things long enough). If we are convinced that the posterior sampling is of high enough quality, we can use the posterior samples to answer all sorts of questions relatively easily. 7.7.3 Where do we go from here? Learn to design more interesting models to answer more interesting questions. Learn to describe these models and hand them to JAGS or Stan for posterior sampling. Learn to diagnose posterior samples to detect potential problems with the posterior sampling. Learn how to interpret the results. 7.8 Exercises In this exercise, you will see how the Metropolis algorithm operates with a multimodal prior. Define the function \\(p(\\theta) = (cos(4 \\pi \\theta) + 1)^2/1.5\\) in R. Use gf_function() to plot \\(p(\\theta)\\) on the interval from 0 to 1. [Hint: Use the xlim argument.] Use integrate() to confirm that \\(p\\) is a pdf. Run metro_bern() with \\(p\\) as your prior, with no data (x = 0, n = 0), and with size = 0.2. Plot the posterior distribution of \\(\\theta\\) and explain why it looks the way it does. Now create a posterior histogram or density plot using x = 2, n = 3. Do the results look reasonable? Explain. Now create a posterior histogram or density plot with x = 1, n = 3, and size = 0.02. Comment on how this compares to plot you made in the previous item. Repeat the previous two items but with start = 0.15 and start = 0.95. How does this help explain what is happening? Why is it good practice to run MCMC algorithms with several different starting values as part of the diagnositc process? How would looking at trace plots from multiple starting points help you detect this problem? (What would the trace plots look like when things are good? What would they look like when things are bad?) "],
["jags-just-another-gibbs-sampler.html", "8 JAGS – Just Another Gibbs Sampler 8.1 What JAGS is 8.2 Example 1: estimating a proportion 8.3 Extracting information from a JAGS run 8.4 Optional arguments to jags() 8.5 Example 2: comparing two proportions 8.6 Exercises", " 8 JAGS – Just Another Gibbs Sampler This chapter focuses on a very simple model – one for which JAGS is overkill. This allows us to get familiar with JAGS and the various tools to investigate JAGS models in a simple setting before moving on to more interesting models soon. 8.1 What JAGS is JAGS (Just Another Gibbs Sampler) is an implementation of an MCMC algorithm called Gibbs sampling to sample the posterior distribution of a Bayesian model. We will interact with JAGS from within R using the following packages: R2jags – interface between R and JAGS coda – general tools for analyzing and graphing MCMC algorithms bayesplot – a number of useful plots using ggplot2 CalvinBayes – includes some of the functions from Kruschke’s text and other things to make our lives better. 8.1.1 JAGS documentation You can find JAGS documentation at http://people.stat.sc.edu/hansont/stat740/jags_user_manual.pdf. This can be useful if you need to find out particulars about things like the distributions that are availble in JAGS. 8.1.2 Updating C and CLANG Based on limited testing, it appears that things are good to go and you should not need to do this. To use the newest versions of JAGS, Stan, and the R packages that accompany them, we need to use a newer version of some software than is standard for &lt;rstudio.calvin.edu&gt;. I have taken care of this at the system level, and that may suffice, but if things don’t work in your account, take the following steps: Open a terminal with Tools &gt; Terminal &gt; New Terminal Copy-and-paste this into the terminal window. echo &quot;source scl_source enable devtoolset-7 llvm-toolset-7&quot; &gt;&gt; ~/.bashrc This tells the server to use a newer version of C++ and CLANG. Close the terminal Restart R with Session &gt; Restart R You should only need to go through these steps once. 8.2 Example 1: estimating a proportion 8.2.1 The Model That is \\[\\begin{align*} Y_i &amp;\\sim {\\sf Bern}(\\theta) \\\\ \\theta &amp;\\sim {\\sf Beta}(a, b) \\end{align*}\\] 8.2.2 Load Data The data sets provided as csv files by Kruschke also live in the CalvinBayes package, so you can read this file with library(CalvinBayes) data(&quot;z15N50&quot;) glimpse(z15N50) ## Observations: 50 ## Variables: 1 ## $ y &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, … We see that the data are coded as 50 0’s and 1’s in a variable named y. (You should use better names when creating your own data sets.) 8.2.3 Specify the model There are at least three R packages that provide an interface to JAGS: rjags, R2jags, and runjags. We will primarily use R2jags. Kruschke primarily uses rjags. The main advantage of R2jags is that we can specify the model by creating a special kind of function.6 The avoids the need to create temporary files (as rjags requires) and keeps things tidier in our R markdown documents. The main part of the model description is the same in either style, but notice that the using the function style, we do not need to include model{ ... } in our description. Here’s how we describe our simple model. bern_model &lt;- function() { for (i in 1:N) { y[i] ~ dbern(theta) # each response is Bernoulli with fixed parameter theta } theta ~ dbeta(1, 1) # prior for theta } Some things to note: dbern() and dbeta() are JAGS functions. The JAGS distribution functions are similar to, but not identical to the ones in R. (R doesn’t have Bernoulli at all, for example.) Sometimes the parameterization are different. Importantly, JAGS doesn’t have named arguments, so the arguments must go in the order JAGS requires. Notice that we are only giving the distribution name and its parameters. (So the first argument that R requires is not part of this in JAGS.) JAGS is also not vectorized the way R is, so we will need to write some explicit for loops to say “do this to every that”. In the example above, the for loops says that for each row of the data (i in 1:N), the response (y[i]) is Bernoulli with paramter \\(\\theta\\) (dbern(theta)). 8.2.4 Run the model R2jags::jags() can be used to run our JAGS model. We need to specify three things: (1) the model we are using (as defined above), (2) the data we are using, (3) the parameters we want saved in the posterior sampling. (theta is the only parameter in this model, but in larger models, we might choose to save only some of the parameters). The data do not need to be in a data frame, and this usually means a bit more work on our part to tell JAGS things like how much data there is. We will prepare all the information JAGS needs about the data in a list using list(). There are some additional, optional things we might want to control as well. More on those later. For now, let’s fit the model using the default values for everything else. # Load the R2jags package library(R2jags) # Make the same &quot;random&quot; choices each time this is run. # This makes the Rmd file stable so you can comment on specific results. set.seed(123) # Fit the model bern_jags &lt;- jags( data = list(y = z15N50$y, N = nrow(z15N50)), model.file = bern_model, parameters.to.save = c(&quot;theta&quot;) ) ## module glm loaded ## Compiling model graph ## Resolving undeclared variables ## Allocating nodes ## Graph information: ## Observed stochastic nodes: 50 ## Unobserved stochastic nodes: 1 ## Total graph size: 53 ## ## Initializing model Let’s take a quick look at what we have. bern_jags ## Inference for Bugs model at &quot;/var/folders/py/txwd26jx5rq83f4nn0f5fmmm0000gn/T//RtmpTihjvE/model25213925a6d3.txt&quot;, fit using jags, ## 3 chains, each with 2000 iterations (first 1000 discarded) ## n.sims = 3000 iterations saved ## mu.vect sd.vect 2.5% 25% 50% 75% 97.5% Rhat n.eff ## theta 0.308 0.064 0.191 0.261 0.306 0.351 0.435 1.001 3000 ## deviance 62.089 1.395 61.087 61.186 61.571 62.459 65.770 1.001 3000 ## ## For each parameter, n.eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor (at convergence, Rhat=1). ## ## DIC info (using the rule, pD = var(deviance)/2) ## pD = 1.0 and DIC = 63.1 ## DIC is an estimate of expected predictive error (lower deviance is better). Some notes on the output above: 3 chains: The Gibbs sampler was run 3 times with 3 different starting values. Each chain ran for 2000 steps, but only the last 1000 steps were saved. n.sims = 3000 (1000 in each of 3 chains). mu.vect: We see that the average value of theta in our posterior sample is 0.308. n.eff = 3000 is the number of effective samples. In this case, JAGS is being very efficient, as we would expect since it is just sampling directly from the posterior distribution. Rhat = 1: This is a check for possible convergence problems. If an MCMC sampler has converged, Rhat will be 1. So if the value we see is not very close to 1, that is a sign of problems. Any value greater than 1.1 is a cause for concern. We’ll talk more about deviance later. 8.3 Extracting information from a JAGS run 8.3.1 posterior() We can plot the posterior distribution, using posterior() to extract the posterior samples as a data frame. Since we know the posterior distribution should be Beta(16, 36), we’ll add that to our plot as a reference to see how well our posterior sample is doing. library(CalvinBayes) head(posterior(bern_jags)) deviance theta chain iter 61.65 0.2528 chain:1 1 61.11 0.2895 chain:1 2 62.74 0.3871 chain:1 3 61.29 0.3296 chain:1 4 61.09 0.3052 chain:1 5 63.67 0.4098 chain:1 6 gf_dhistogram(~theta, data = posterior(bern_jags), bins = 50) %&gt;% gf_dens(~theta, size = 1.5, alpha = 0.8) %&gt;% gf_dist(&quot;beta&quot;, shape1 = 16, shape2 = 36, color = &quot;red&quot;) 8.3.2 Side note: posterior sampling and the grid method It is also possible to generate posterior samples when we use the grid method. The mosaic package include the resample() function that will sample rows of a data frame with replacement using specified probabilities (given by the posterior, for example). Here’s how that works. Grid &lt;- expand.grid( theta = seq(0, 1, by = 0.001) ) %&gt;% mutate( prior = dbeta(theta, 1, 1), likelihood = dbinom(15, 50, theta), posterior = prior * likelihood, posterior = posterior / sum(posterior) / 0.001 ) Posterior &lt;- resample(Grid, size = 5000, prob = Grid$posterior) gf_dhistogram(~ theta, data = Posterior, bins = 50) %&gt;% gf_dens(~theta, size = 1.5, alpha = 0.8) %&gt;% gf_dist(&quot;beta&quot;, shape1 = 16, shape2 = 36, color = &quot;red&quot;) 8.3.3 Using coda The coda package provides output analysis and diagnostics for MCMC algorithms. In order to use it, we must convert our JAGS object into something coda recognizes. We do with with the as.mcmc() function. bern_mcmc &lt;- as.mcmc(bern_jags) plot(bern_mcmc) Note: Kruschke uses rjags without R2jags, so he does this step using rjags::coda.samples() instead of as.mcmc(). Both functions result in the same thing – posterior samples in a format that coda expects, but they have different starting points. 8.3.4 Using bayesplot The mcmc object we extracted with as.mcmc() can be used by the utilities in the bayesplot(). Here, for example is the bayesplot plot of the posterior distribution for theta. By default, a vertical line segment is drawn at the median of the posterior distribution. library(bayesplot) mcmc_areas( bern_mcmc, pars = c(&quot;theta&quot;), # make a plot for the theta parameter prob = 0.90) # shade the central 90% One advantage of bayesplot is that the plots use the ggplot2 system and so interoperate well with ggformula. mcmc_trace(bern_mcmc, pars = &quot;theta&quot;) # spearate the chains using facets and modify the color scheme mcmc_trace(bern_mcmc, pars = &quot;theta&quot;) %&gt;% gf_facet_grid(Chain ~ .) %&gt;% gf_refine(scale_color_viridis_d()) ## Scale for &#39;colour&#39; is already present. Adding another scale for &#39;colour&#39;, which will replace the ## existing scale. We will encounter additional plots from bayesplot as we go along. 8.3.5 Using Kruschke’s functions I have put (modified versions of) some of functions from Kruschke’s book into the CalvinBayes package so that you don’t have to source his files to use them. diag_mcmc() [diagMCMC()] diag_mcmc(bern_mcmc, par = &quot;theta&quot;) plot_post() [plotPost()] The plot_post() function takes as its first argument a vector of posterior sampled values for one of the parameters. We can extract such a vector a couple different ways: ## # these produce the same output plot_post(bern_mcmc[, &quot;theta&quot;], main = &quot;theta&quot;, xlab = expression(theta)) ## $posterior ## ESS mean median mode ## var1 3000 0.3075 0.3056 0.2982 ## ## $hdi ## prob lo hi ## 1 0.95 0.1896 0.4342 ## plot_post(posterior(bern_jags)$theta, main = &quot;theta&quot;, xlab = expression(theta)) There are a number of options that allow you to add some additional information to the plot. Specifying quietly = TRUE will turn off the numerical display that plot_post() generates along with the plot. Here is an example.[^08-2] plot_post(bern_mcmc[, &quot;theta&quot;], main = &quot;theta&quot;, xlab = expression(theta), cenTend = &quot;median&quot;, compVal = 0.5, ROPE = c(0.45, 0.55), credMass = 0.90, quietly = TRUE) 8.4 Optional arguments to jags() 8.4.1 Number and size of chains Sometimes we want to use more or longer chains (or fewer or shorter chains if we are doing a quick preliminary check before running longer chains later). jags() has three arguments for this: n.chains: number of chains n.iter: number of iterations per chain n.burnin: number of burn in steps per chain n.thin: keep one sample per n.thin. The default value of n.thin is set to save about 1000 values per chain. So in the example below, we end up with only 4000 samples (1000 per chain) rather than the 16000 you might have expected. set.seed(76543) bern_jags2 &lt;- jags( data = list(y = z15N50$y, N = nrow(z15N50)), model.file = bern_model, parameters.to.save = c(&quot;theta&quot;), n.chains = 4, n.iter = 5000, n.burnin = 1000, ) bern_jags2 Setting n.thin = 1 will save them all. set.seed(76543) bern_jags2a &lt;- jags( data = list(y = z15N50$y, N = nrow(z15N50)), model.file = bern_model, parameters.to.save = c(&quot;theta&quot;), n.chains = 4, n.iter = 5000, n.burnin = 1000, n.thin = 1 ) bern_jags2a 8.4.2 Starting point for chains We can also control the starting point for the chains. Starting different chains and quite different parameter values can help verify that the MCMC algorithm is not overly sensitive to where we are starting from, and ensure that the MCMC algorithm has explored the posterior distribution sufficiently. On the other hand, if we start a chain too far from the peak of the posterior distribution, the chain may have trouble converging. We can provide either specific starting points for each chain or a function that generates random starting points. gf_dist(&quot;beta&quot;, shape1 = 3, shape2 = 3) set.seed(2345) bern_jags3 &lt;- jags( data = list(y = z15N50$y, N = nrow(z15N50)), model.file = bern_model, parameters.to.save = c(&quot;theta&quot;), # start each chain by sampling from the prior inits = function() list(theta = rbeta(1, 3, 3)) ) bern_jags4 &lt;- jags( data = list(y = z15N50$y, N = nrow(z15N50)), model.file = bern_model, parameters.to.save = c(&quot;theta&quot;), # choose specific starting point for each chain inits = list( list(theta = 0.5), list(theta = 0.7), list(theta = 0.9) ) ) mcmc_trace(as.mcmc(bern_jags4), pars = &quot;theta&quot;) It is a good sign that our three traces look very similar and overlap a lot. This indicates that the chains are mixing well and not overly affected by their starting point. 8.4.3 Running chains in parallel Although this model runs very quickly, others models may take considerably longer. We can use jags.parallel() in place of jags() to take advantage of multiple cores to run more than one chain at a time. jags.seed can be used to set the seed for the parallel random number generator used. (Note: set.seed() does not work when using jags.parallel() and jags.seed has no effect when using jags().) library(R2jags) bern_jags5 &lt;- jags.parallel( data = list(y = z15N50$y, N = nrow(z15N50)), model.file = bern_model, parameters.to.save = c(&quot;theta&quot;), n.chains = 4, n.iter = 5000, n.burnin = 1000, jags.seed = 12345 ) 8.5 Example 2: comparing two proportions We have seen this situation before when we compared two coins. This time we’ll be a little more personal and compare two people. We will also work with a data set in a slightly different form. But the main point will be to see how we describe this familiar model to JAGS. 8.5.1 The data Suppose we want to compare Reginald and Tony’s abilities to hit a target (with a dart, perhaps). For each attempt, we record two pieces of information: the person making the attempt (the subject) and whether the attempt succeeded (0 or 1). Kruschke’s provides a data frame for this, but the names he uses are not good practice, so let’s remanme them to be more like what you might see in a real data set. library(mosaic) head(z6N8z2N7) y s 1 Reginald 0 Reginald 1 Reginald 1 Reginald 1 Reginald 1 Reginald # Let&#39;s do some renaming Target &lt;- z6N8z2N7 %&gt;% rename(hit = y, subject = s) df_stats(hit ~ subject, data = Target, props, attempts = length) subject prop_0 prop_1 attempts Reginald 0.2500 0.7500 8 Tony 0.7143 0.2857 7 Reginald was more successful than Tony, but neither had very many attempts. 8.5.2 The model Now our model is that each person has his own success rate – we have two \\(\\theta\\)’s, one for Reginald and one for Tony. We express this as \\[\\begin{align*} Y_i|s &amp;\\sim {\\sf Bern}(\\theta_{s}) \\\\ \\theta_s &amp;\\sim {\\sf Beta}(a, b) \\end{align*}\\] 8.5.3 Describing the model to JAGS bern2_model &lt;- function() { for (i in 1:Nobs) { # each response is Bernoulli with the appropriate theta hit[i] ~ dbern(theta[subject[i]]) } for (s in 1:Nsub) { theta[s] ~ dbeta(2, 2) # prior for each theta } } JAGS will also need access to four pieces of information from our data set: a vector of hit values a vector of subject values – coded as integers 1 and 2 (so that subject[i] makes sense to JAGS. (In general, JAGS is much less fluid in handling data than R is, so we often need to do some manual data conversion for JAGS.) Nobs – the total number of observations Nsub – the number of subjects We will prepare these as a list. TargetList &lt;- list( Nobs = nrow(Target), Nsub = 2, hit = Target$hit, subject = as.numeric(as.factor(Target$subject)) ) TargetList ## $Nobs ## [1] 15 ## ## $Nsub ## [1] 2 ## ## $hit ## [1] 1 0 1 1 1 1 1 0 0 0 1 0 0 1 0 ## ## $subject ## [1] 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 8.5.4 Fitting the model bern2_jags &lt;- jags( data = TargetList, model = bern2_model, parameters.to.save = &quot;theta&quot;) 8.5.5 Inspecting the results bern2_mcmc &lt;- as.mcmc(bern2_jags) # Kruschke diagnostic plots diag_mcmc(bern2_mcmc) # bayesplot plots mcmc_acf(bern2_mcmc) mcmc_acf_bar(bern2_mcmc) mcmc_pairs(bern2_mcmc, pars = c(&quot;theta[1]&quot;, &quot;theta[2]&quot;)) mcmc_combo(bern2_mcmc) mcmc_combo(bern2_mcmc, combo = c(&quot;dens&quot;, &quot;dens_overlay&quot;, &quot;trace&quot;, &quot;scatter&quot;), pars = c(&quot;theta[1]&quot;, &quot;theta[2]&quot;)) Here is a list of mcmc_ functions available: apropos(&quot;^mcmc_&quot;) ## [1] &quot;mcmc_acf&quot; &quot;mcmc_acf_bar&quot; &quot;mcmc_areas&quot; ## [4] &quot;mcmc_areas_data&quot; &quot;mcmc_areas_ridges&quot; &quot;mcmc_areas_ridges_data&quot; ## [7] &quot;mcmc_combo&quot; &quot;mcmc_dens&quot; &quot;mcmc_dens_chains&quot; ## [10] &quot;mcmc_dens_chains_data&quot; &quot;mcmc_dens_overlay&quot; &quot;mcmc_hex&quot; ## [13] &quot;mcmc_hist&quot; &quot;mcmc_hist_by_chain&quot; &quot;mcmc_intervals&quot; ## [16] &quot;mcmc_intervals_data&quot; &quot;mcmc_neff&quot; &quot;mcmc_neff_data&quot; ## [19] &quot;mcmc_neff_hist&quot; &quot;mcmc_nuts_acceptance&quot; &quot;mcmc_nuts_divergence&quot; ## [22] &quot;mcmc_nuts_energy&quot; &quot;mcmc_nuts_stepsize&quot; &quot;mcmc_nuts_treedepth&quot; ## [25] &quot;mcmc_pairs&quot; &quot;mcmc_parcoord&quot; &quot;mcmc_parcoord_data&quot; ## [28] &quot;mcmc_recover_hist&quot; &quot;mcmc_recover_intervals&quot; &quot;mcmc_recover_scatter&quot; ## [31] &quot;mcmc_rhat&quot; &quot;mcmc_rhat_data&quot; &quot;mcmc_rhat_hist&quot; ## [34] &quot;mcmc_scatter&quot; &quot;mcmc_trace&quot; &quot;mcmc_trace_highlight&quot; ## [37] &quot;mcmc_violin&quot; The functions ending in _data() return the data used to make the corresponding plot. This can be useful if you want to display that same information in a different way or if you just want to inspect the data to make sure you understand the plot. 8.5.6 Difference in proportions If we are primarily interested in the difference between Reginald and Tony, we can plot the difference in their theta values. head(posterior(bern2_jags)) deviance theta.1 theta.2 chain iter 19.88 0.5540 0.4877 chain:1 1 18.18 0.6395 0.3935 chain:1 2 19.09 0.7375 0.5295 chain:1 3 19.55 0.5836 0.1285 chain:1 4 22.69 0.7354 0.7078 chain:1 5 17.53 0.7893 0.2377 chain:1 6 gf_density( ~(theta.1 - theta.2), data = posterior(bern2_jags)) 8.5.7 Sampling from the prior To sample from the prior, we must do the following: remove the response variable from our data list change Nobs to 0 set DIC = FALSE in the call to jags(). This will run the model without any data, which means the posterior will be the same as the prior. # make a copy of our data list TargetList0 &lt;- list( Nobs = 0, Nsub = 2, subject = as.numeric(as.factor(Target$subject)) ) bern2_jags0 &lt;- jags( data = TargetList0, model.file = bern2_model, parameters.to.save = c(&quot;theta&quot;), n.chains = 2, n.iter = 5000, n.burnin = 1000, DIC = FALSE) ## Compiling model graph ## Resolving undeclared variables ## Allocating nodes ## Graph information: ## Observed stochastic nodes: 0 ## Unobserved stochastic nodes: 2 ## Total graph size: 20 ## ## Initializing model 8.5.7.1 Note about : in JAGS and in R From the JAGS documentation: The sequence operator : can only produce increasing sequences. If n &lt; m then m:n produces a vector of length zero and when this is used in a for loop index expression the contents of loop inside the curly brackets are skipped. Note that this behavior is different from the sequence operator in R, where m:n will produce a decreasing sequence if n &lt; m. So in our JAGS model, 1:0 correctly represents no data (and no trips through the for loop). 8.5.7.2 What good is it to generate samples from the prior? Our model set priors for \\(\\theta_1\\) and \\(\\theta_2\\), but this implies a distribution for \\(\\theta_1 - \\theta_2\\), and we might like to see what that distribution looks like. gf_density( ~(theta.1 - theta.2), data = posterior(bern2_jags0)) 8.6 Exercises Sampling from priors. You want to know who is the better free throw shooter, Alice or Bob. You decide to have each shoot a number of shots and record their makes and misses. You are primarily interested in the difference between their free throw shooting proportions (\\(\\theta_2 - \\theta_1\\)), and you are curious to know how your choice of priors for \\(\\theta_1\\) and \\(\\theta_2\\) affects the prior for \\(\\theta_2 - \\theta_1\\). For each situation below, use JAGS to sample from the prior distribution for \\(\\theta_2 - \\theta_1\\) and create a density plot. (In each case, assume the priors for \\(\\theta_1\\) and \\(\\theta_2\\) are independent.) Both priors are uniform. What distribution do you think the prior for \\(\\theta_2 - \\theta_1\\) is? Both priors are \\({\\sf Beta}(0.2, 0.2)\\). Explain why the prior for \\(\\theta_2 - \\theta_1\\) looks the way it does. Hint: Don’t forget to set DIC = FALSE when sampling from the prior. Now suppose that Alice makes 25 out of 30 shots and Bob makes 18 out of 32. Is this enough evidence to conclude that Alice is the better shooter? Do this two ways. In each case, use a \\({\\sf Beta}(4, 2)\\) prior for both \\(\\theta_1\\) and \\(\\theta_2\\). Create data and use a model like the one used elsewhere in this chapter. [Hint: rep() is handy for creating a bunch of values that are the same.] Instead of using dbern(), use dbin() (JAGS version of the binomial distribution). This should allow you to get by with simpler data that consists only of the numbers 25, 30, 18, and 32. Note: the order of arguments for dbin() is probability first, then number of trials. This is reversed from the order in R. In the previous problem, what does this prior say about the beliefs about Alice and Bob’s shooting before gathering data? Let’s think about Alice and Bob some more. We don’t know how to do this yet, but explain why if you knew very little about basketball, you might like to have a prior for \\(\\theta_1\\) and \\(\\theta_2\\) that was not indpendent. How might the priors for \\(\\theta_1\\) and \\(\\theta_2\\) be related? Consider the model below. Create a plot of the prior distribution of theat1 and theta2. A scatter plot with overlayed density plot works well. How does this prior compare to the priors in problem 1. (Hint: Don’t forget to use DIC = FALSE when sampling from the prior.) Fit the model to the Alice and Bob data. How does this choice of prior change things? diff_model &lt;- function() { z1 ~ dbin(theta1, n1) z2 ~ dbin(theta2, n2) theta2 &lt;- theta1 + delta theta1 ~ dbeta(4, 2) delta ~ dnorm(0, 400) # Normal with mean 0 and sd = 0.05 } diff_jags &lt;- jags.parallel( model = diff_model, data = list(n1 = 30, z1 = 25, n2 = 32, z2 = 18), parameters.to.save = c(&quot;theta1&quot;, &quot;theta2&quot;, &quot;delta&quot;), n.iter = 5000, n.chains = 4 ) Redo problem 5 using the grid method. This is a bit of a trick that R2jags uses. The function created is never run. The code is inspected and taken as the description of the model. If you were to run the funtion, all it would do is create R formulas.↩ "],
["heierarchical-models.html", "9 Heierarchical Models 9.1 Gamma Distributions 9.2 One coin from one mint 9.3 Multiple coins from one mint 9.4 Multiple coins from multiple mints 9.5 Therapeutic Touch 9.6 Other parameterizations we might have tried 9.7 Shrinkage 9.8 Example: Baseball Batting Average 9.9 Exerciess", " 9 Heierarchical Models 9.1 Gamma Distributions We will use gamma distributions for some of our priors in this chapter. Gamma distributions have support \\((0,\\infty)\\) and are skewed to the right. Both R and JAGS paramterize the gamma distributions with two parameters called shape and rate. gf_dist(&quot;gamma&quot;, shape = 2, rate = 3, color = ~&quot;Gamma(2, 3)&quot;) %&gt;% gf_dist(&quot;gamma&quot;, shape = 4, rate = 3, color = ~&quot;Gamma(4, 3)&quot;) %&gt;% gf_dist(&quot;gamma&quot;, shape = 2, rate = 6, color = ~&quot;Gamma(2, 6)&quot;) %&gt;% gf_dist(&quot;gamma&quot;, shape = 4, rate = 6, color = ~&quot;Gamma(4, 6)&quot;) %&gt;% gf_labs(title = &quot;Some Gamma distributions&quot;) The mean, mode, standard deviation can be calcuated from the shape \\(s\\) and rate \\(r\\) as follows: \\[\\begin{align*} \\mu &amp;= \\frac{s}{r} \\\\ \\omega &amp;= \\frac{s−1}{r} \\qquad (s &gt; 1) \\\\ \\sigma &amp; = \\frac{\\sqrt{s}}{r} \\end{align*}\\] In addition, the scale parameter (1/rate) is sometimes used in place of the rate parameter. The gamma_params() function will automate conversion between various parameterizations. It works just like beta_params() that we have seen before. gamma_params(mode = 15, sd = 10, plot = TRUE) shape rate scale mode mean sd 4 0.2 5 15 20 10 As the shape parameter gets larger and larger, the gamma distribution becomes less and less skewed (and more and more like a normal distribution): gf_dist(&quot;gamma&quot;, shape = 25, rate = 5, color = ~&quot;Gamma(25, 5)&quot;) %&gt;% gf_dist(&quot;norm&quot;, mean = 5, sd = 1, color = ~&quot;Norm(5, 1)&quot;) gf_dist(&quot;gamma&quot;, shape = 100, rate = 5, color = ~&quot;Gamma(25, 5)&quot;) %&gt;% gf_dist(&quot;norm&quot;, mean = 20, sd = 2, color = ~&quot;Norm(5, 1)&quot;) 9.2 One coin from one mint 9.3 Multiple coins from one mint 9.4 Multiple coins from multiple mints 9.5 Therapeutic Touch The study is described in the text. The article reporting on the study can be found at https://jamanetwork.com/journals/jama/fullarticle/187390. Here’s the abstract: 9.5.1 Abstract Context.— Therapeutic Touch (TT) is a widely used nursing practice rooted in mysticism but alleged to have a scientific basis. Practitioners of TT claim to treat many medical conditions by using their hands to manipulate a “human energy field” perceptible above the patient’s skin. Objective.— To investigate whether TT practitioners can actually perceive a “human energy field.” Design.— Twenty-one practitioners with TT experience for from 1 to 27 years were tested under blinded conditions to determine whether they could correctly identify which of their hands was closest to the investigator’s hand. Placement of the investigator’s hand was determined by flipping a coin. Fourteen practitioners were tested 10 times each, and 7 practitioners were tested 20 times each. Main Outcome Measure.— Practitioners of TT were asked to state whether the investigator’s unseen hand hovered above their right hand or their left hand. To show the validity of TT theory, the practitioners should have been able to locate the investigator’s hand 100% of the time. A score of 50% would be expected through chance alone. Results.— Practitioners of TT identified the correct hand in only 123 (44%) of 280 trials, which is close to what would be expected for random chance. There was no significant correlation between the practitioner’s score and length of experience (r=0.23). The statistical power of this experiment was sufficient to conclude that if TT practitioners could reliably detect a human energy field, the study would have demonstrated this. Conclusions.— Twenty-one experienced TT practitioners were unable to detect the investigator’s “energy field.” Their failure to substantiate TT’s most fundamental claim is unrefuted evidence that the claims of TT are groundless and that further professional use is unjustified. 9.5.2 Data library(mosaic) head(TherapeuticTouch, 3) y s 1 S01 0 S01 0 S01 gf_barh(s ~ ., data = TherapeuticTouch, fill = ~ factor(y)) 9.5.3 A heierarchical model Big ideas: The ten trials for each subject are a sample from the many trials that could have been done. distribution of results: \\({\\sf Bern}(\\theta_s)\\) – each subject has a potentially different \\(\\theta_s\\). The subjects themselves are just a sample from all of the TT practitioners that could have been in the study. So the \\(\\theta_s\\) values are a sample from a distribution of \\(\\theta\\) values for all TT practititioners and tell us something about that distribution. We will assume a beta distribution for this, where the parameters are unknown and estimated from the data. Use the data to estimate both the individual level \\(\\theta_s\\) values and the group level parameters of the beta distribution. Parameterization of the beta distribution for \\(\\theta_s\\). We are primarily interested in the mean or mode of this distribution (typical value of \\(\\theta\\) for TT practitioner). Many combinations of shape parameters give the same mean (or mode), and they are highly correlated. For example, \\({\\sf Beta}(2,4)\\), \\({\\sf Beta}(20,40)\\), and \\({\\sf Beta}(200,400)\\) all have a mean of 1/3. We will parameterize this Beta distribution with mode (\\(\\omega\\)), and concentration (\\(\\kappa\\)) We will need to convert mode and concentration into the two shape parameters, since JAGS and R use the two shape parameters. \\[\\begin{align} \\alpha &amp;= \\omega (\\kappa - 2) + 1\\\\ \\beta &amp;= (1 - \\omega) (\\kappa - 2) + 1) \\end{align}\\] \\(\\omega\\) and \\(\\kappa\\) will need priors \\(\\omega\\): Beta \\(\\kappa - 2\\): Gamma (because \\(\\kappa &gt;2\\)) Putting this altogether we have the following picture: Now we code it up for JAGS. gamma_params(mean = 1, sd = 10) shape rate scale mode mean sd 0.01 0.01 100 NA 1 10 touch_model &lt;- function() { for (i in 1:Ntotal) { y[i] ~ dbern(theta[s[i]]) } for (s in 1:Nsubj) { theta[s] ~ dbeta(omega * (kappa - 2) + 1, (1 - omega) * (kappa - 2) + 1) } omega ~ dbeta(1, 1) kappa &lt;- kappaMinusTwo + 2 kappaMinusTwo ~ dgamma(0.01, 0.01) # mean = 1, sd = 10 } set.seed(1234) TouchData &lt;- list( Ntotal = nrow(TherapeuticTouch), Nsubj = length(unique(TherapeuticTouch$s)), y = TherapeuticTouch$y, # must convert subjects to sequence 1:Nsubj s = as.numeric(factor(TherapeuticTouch$s)) ) touch_jags &lt;- jags( data = TouchData, model = touch_model, parameters.to.save = c(&quot;theta&quot;, &quot;kappa&quot;, &quot;omega&quot;), ) touch_jags ## Inference for Bugs model at &quot;/var/folders/py/txwd26jx5rq83f4nn0f5fmmm0000gn/T//RtmpTihjvE/model2521eb17d5d.txt&quot;, fit using jags, ## 3 chains, each with 2000 iterations (first 1000 discarded) ## n.sims = 3000 iterations saved ## mu.vect sd.vect 2.5% 25% 50% 75% 97.5% Rhat n.eff ## kappa 52.286 54.028 8.932 20.025 34.399 65.489 210.966 1.056 44 ## omega 0.439 0.035 0.367 0.416 0.439 0.462 0.508 1.004 1100 ## theta[1] 0.363 0.088 0.175 0.305 0.369 0.426 0.517 1.016 210 ## theta[2] 0.384 0.084 0.208 0.331 0.389 0.444 0.536 1.015 190 ## theta[3] 0.409 0.081 0.241 0.358 0.414 0.463 0.564 1.005 970 ## theta[4] 0.411 0.083 0.236 0.357 0.415 0.467 0.564 1.020 270 ## theta[5] 0.409 0.080 0.244 0.358 0.411 0.461 0.563 1.010 500 ## theta[6] 0.410 0.082 0.235 0.359 0.414 0.464 0.562 1.006 1100 ## theta[7] 0.409 0.080 0.244 0.359 0.412 0.461 0.560 1.019 180 ## theta[8] 0.410 0.080 0.243 0.360 0.413 0.462 0.565 1.012 510 ## theta[9] 0.407 0.080 0.247 0.356 0.410 0.459 0.561 1.008 650 ## theta[10] 0.409 0.081 0.238 0.358 0.413 0.463 0.559 1.008 710 ## theta[11] 0.433 0.077 0.276 0.384 0.433 0.483 0.588 1.004 1700 ## theta[12] 0.433 0.081 0.278 0.383 0.434 0.485 0.593 1.005 710 ## theta[13] 0.434 0.078 0.280 0.385 0.434 0.484 0.587 1.002 3000 ## theta[14] 0.432 0.080 0.272 0.380 0.432 0.482 0.593 1.001 3000 ## theta[15] 0.433 0.080 0.275 0.381 0.434 0.484 0.590 1.004 3000 ## theta[16] 0.457 0.080 0.300 0.408 0.454 0.504 0.624 1.002 3000 ## theta[17] 0.456 0.079 0.295 0.406 0.453 0.506 0.621 1.002 1600 ## theta[18] 0.454 0.081 0.295 0.401 0.453 0.504 0.626 1.003 3000 ## theta[19] 0.457 0.078 0.313 0.407 0.454 0.505 0.618 1.001 3000 ## theta[20] 0.455 0.080 0.298 0.403 0.452 0.508 0.612 1.003 3000 ## theta[21] 0.457 0.082 0.296 0.404 0.455 0.510 0.621 1.005 1000 ## theta[22] 0.457 0.079 0.311 0.405 0.454 0.507 0.625 1.003 1800 ## theta[23] 0.480 0.083 0.328 0.425 0.474 0.529 0.658 1.008 510 ## theta[24] 0.482 0.083 0.327 0.427 0.476 0.531 0.660 1.003 1300 ## theta[25] 0.506 0.088 0.351 0.446 0.497 0.562 0.691 1.008 260 ## theta[26] 0.507 0.088 0.354 0.446 0.498 0.560 0.700 1.003 680 ## theta[27] 0.505 0.087 0.355 0.445 0.495 0.559 0.695 1.008 250 ## theta[28] 0.527 0.093 0.374 0.460 0.517 0.581 0.735 1.008 300 ## deviance 378.963 5.156 368.591 375.437 379.284 382.411 388.755 1.010 220 ## ## For each parameter, n.eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor (at convergence, Rhat=1). ## ## DIC info (using the rule, pD = var(deviance)/2) ## pD = 13.2 and DIC = 392.1 ## DIC is an estimate of expected predictive error (lower deviance is better). What do we learn from a quick look at this output? The Rhat values look good The autocorrelation varies from parameter to parameter. For some parameters, it looks like it will take a much longer run to get a large effective sample size. So let’s do a larger run. touch_jags &lt;- jags.parallel( data = TouchData, model = touch_model, parameters.to.save = c(&quot;theta&quot;, &quot;kappa&quot;, &quot;omega&quot;), n.burnin = 1000, n.iter = 41000, n.chains = 5, n.thin = 10, jags.seed = 54321 ) touch_jags ## Inference for Bugs model at &quot;touch_model&quot;, fit using jags, ## 5 chains, each with 41000 iterations (first 1000 discarded), n.thin = 10 ## n.sims = 20000 iterations saved ## mu.vect sd.vect 2.5% 25% 50% 75% 97.5% Rhat n.eff ## kappa 55.710 55.745 8.632 21.295 37.091 68.780 210.357 1.001 8100 ## omega 0.435 0.037 0.362 0.412 0.436 0.460 0.508 1.001 8900 ## theta[1] 0.360 0.087 0.169 0.305 0.367 0.422 0.513 1.001 19000 ## theta[2] 0.384 0.084 0.206 0.332 0.389 0.441 0.536 1.001 20000 ## theta[3] 0.407 0.080 0.240 0.357 0.410 0.460 0.560 1.001 20000 ## theta[4] 0.407 0.080 0.239 0.357 0.410 0.461 0.560 1.001 19000 ## theta[5] 0.408 0.080 0.240 0.359 0.411 0.460 0.561 1.001 8400 ## theta[6] 0.407 0.080 0.240 0.357 0.410 0.459 0.561 1.001 20000 ## theta[7] 0.407 0.080 0.241 0.358 0.410 0.459 0.559 1.001 8100 ## theta[8] 0.407 0.080 0.238 0.357 0.411 0.459 0.560 1.001 12000 ## theta[9] 0.408 0.080 0.241 0.358 0.411 0.460 0.563 1.001 6900 ## theta[10] 0.408 0.080 0.242 0.358 0.411 0.460 0.563 1.001 13000 ## theta[11] 0.431 0.079 0.274 0.382 0.431 0.481 0.591 1.001 20000 ## theta[12] 0.430 0.079 0.271 0.380 0.430 0.480 0.588 1.001 20000 ## theta[13] 0.431 0.079 0.272 0.381 0.430 0.481 0.588 1.001 10000 ## theta[14] 0.430 0.078 0.276 0.380 0.430 0.479 0.590 1.001 20000 ## theta[15] 0.431 0.078 0.274 0.382 0.432 0.481 0.590 1.001 20000 ## theta[16] 0.454 0.080 0.300 0.402 0.451 0.503 0.622 1.001 20000 ## theta[17] 0.454 0.080 0.303 0.402 0.451 0.503 0.624 1.001 20000 ## theta[18] 0.455 0.080 0.301 0.403 0.451 0.505 0.624 1.001 20000 ## theta[19] 0.454 0.080 0.301 0.402 0.452 0.502 0.626 1.001 20000 ## theta[20] 0.454 0.079 0.300 0.403 0.452 0.502 0.620 1.001 20000 ## theta[21] 0.455 0.080 0.303 0.403 0.452 0.504 0.621 1.001 20000 ## theta[22] 0.455 0.080 0.302 0.402 0.451 0.504 0.622 1.001 18000 ## theta[23] 0.477 0.083 0.327 0.422 0.471 0.527 0.659 1.001 12000 ## theta[24] 0.476 0.082 0.328 0.422 0.470 0.526 0.657 1.001 15000 ## theta[25] 0.501 0.087 0.349 0.441 0.492 0.553 0.691 1.001 9700 ## theta[26] 0.500 0.086 0.351 0.441 0.493 0.551 0.691 1.001 20000 ## theta[27] 0.500 0.086 0.350 0.441 0.493 0.553 0.691 1.001 9900 ## theta[28] 0.525 0.093 0.370 0.460 0.514 0.581 0.733 1.001 20000 ## deviance 379.089 5.187 368.486 375.671 379.322 382.640 388.787 1.001 20000 ## ## For each parameter, n.eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor (at convergence, Rhat=1). ## ## DIC info (using the rule, pD = var(deviance)/2) ## pD = 13.5 and DIC = 392.5 ## DIC is an estimate of expected predictive error (lower deviance is better). touch_mcmc &lt;- as.mcmc(touch_jags) plot_post(touch_mcmc[, &quot;omega&quot;], comparison_value = 0.5) ## $posterior ## ESS mean median mode ## var1 14724 0.4354 0.4357 0.4379 ## ## $hdi ## prob lo hi ## 1 0.95 0.3638 0.5091 ## ## $comparison ## value P(&lt; comp. val.) P(&gt; comp. val.) ## 1 0.5 0.9597 0.04025 diag_mcmc(touch_mcmc, par = &quot;omega&quot;) diag_mcmc(touch_mcmc, par = &quot;kappa&quot;) diag_mcmc(touch_mcmc, par = &quot;theta[1]&quot;) mcmc_pairs(touch_mcmc, pars = c(&quot;omega&quot;, &quot;kappa&quot;)) GGally::ggpairs(posterior(touch_jags) %&gt;% select(omega, kappa)) gf_point(kappa ~ omega, data = posterior(touch_jags), alpha = 0.05) %&gt;% gf_density2d(kappa ~ omega, data = posterior(touch_jags)) 9.6 Other parameterizations we might have tried 9.6.1 Shape parameters for Beta Suppose we decided to parameterize the beta distribution with shape parameters like this? touch_model2 &lt;- function() { for (i in 1:Ntotal) { y[i] ~ dbern(theta[s[i]]) } for (s in 1:Nsubj) { theta[s] ~ dbeta(alpha, beta) } kappa &lt;- alpha + beta mu &lt;- alpha / (alpha + beta) alpha &lt;- alphaMinusOne + 1 beta &lt;- betaMinusOne + 1 alphaMinusOne ~ dgamma(0.01, 0.01) betaMinusOne ~ dgamma(0.01, 0.01) } We’ll run it with the same options we used above to faciliate easy comparisons. touch_jags2 &lt;- jags.parallel( data = TouchData, model = touch_model2, parameters.to.save = c(&quot;theta&quot;, &quot;alpha&quot;, &quot;beta&quot;, &quot;mu&quot;, &quot;omega&quot;, &quot;kappa&quot;), n.burnin = 1000, n.iter = 41000, n.chains = 5, n.thin = 10, jags.seed = 54321 ) The resuls are disasterous: Rhat values well above 1 and effective sample sizes that are much smaller than before. touch_jags2 ## Inference for Bugs model at &quot;touch_model2&quot;, fit using jags, ## 5 chains, each with 41000 iterations (first 1000 discarded), n.thin = 10 ## n.sims = 20000 iterations saved ## mu.vect sd.vect 2.5% 25% 50% 75% 97.5% Rhat n.eff ## alpha 19.586 23.261 1.000 4.833 12.099 24.854 89.225 2.300 7 ## beta 24.922 29.869 1.000 6.200 15.476 31.857 110.226 2.411 7 ## kappa 44.508 52.940 2.000 11.184 27.621 56.852 197.948 2.369 7 ## mu 0.448 0.040 0.369 0.420 0.447 0.482 0.506 1.157 27 ## theta[1] 0.322 0.120 0.056 0.247 0.344 0.409 0.509 1.708 10 ## theta[2] 0.355 0.107 0.112 0.292 0.370 0.431 0.532 1.435 14 ## theta[3] 0.391 0.098 0.172 0.333 0.399 0.455 0.567 1.210 30 ## theta[4] 0.391 0.097 0.175 0.335 0.400 0.455 0.570 1.205 30 ## theta[5] 0.392 0.098 0.176 0.335 0.401 0.457 0.571 1.196 31 ## theta[6] 0.391 0.098 0.170 0.334 0.400 0.456 0.570 1.213 30 ## theta[7] 0.392 0.097 0.176 0.335 0.399 0.455 0.571 1.188 33 ## theta[8] 0.391 0.097 0.174 0.334 0.399 0.456 0.567 1.204 30 ## theta[9] 0.391 0.098 0.171 0.333 0.400 0.455 0.568 1.212 29 ## theta[10] 0.391 0.098 0.175 0.333 0.399 0.455 0.568 1.205 31 ## theta[11] 0.427 0.094 0.233 0.370 0.428 0.484 0.621 1.066 250 ## theta[12] 0.427 0.094 0.233 0.371 0.429 0.485 0.619 1.064 260 ## theta[13] 0.427 0.094 0.231 0.370 0.428 0.484 0.619 1.073 180 ## theta[14] 0.428 0.094 0.229 0.371 0.429 0.485 0.619 1.071 220 ## theta[15] 0.427 0.094 0.230 0.370 0.429 0.483 0.616 1.070 190 ## theta[16] 0.463 0.096 0.286 0.402 0.456 0.517 0.679 1.046 260 ## theta[17] 0.463 0.096 0.285 0.403 0.456 0.517 0.676 1.044 330 ## theta[18] 0.464 0.096 0.286 0.403 0.457 0.518 0.682 1.048 270 ## theta[19] 0.462 0.096 0.282 0.401 0.456 0.517 0.678 1.049 280 ## theta[20] 0.463 0.095 0.288 0.402 0.457 0.517 0.677 1.047 260 ## theta[21] 0.462 0.097 0.283 0.401 0.456 0.516 0.682 1.045 290 ## theta[22] 0.463 0.096 0.287 0.401 0.456 0.518 0.680 1.048 280 ## theta[23] 0.499 0.104 0.325 0.429 0.485 0.554 0.747 1.134 35 ## theta[24] 0.500 0.104 0.325 0.430 0.486 0.555 0.747 1.135 35 ## theta[25] 0.533 0.117 0.353 0.452 0.512 0.597 0.814 1.280 17 ## theta[26] 0.533 0.117 0.354 0.450 0.513 0.597 0.812 1.282 17 ## theta[27] 0.533 0.118 0.353 0.451 0.512 0.597 0.819 1.289 16 ## theta[28] 0.569 0.133 0.373 0.471 0.540 0.644 0.880 1.459 12 ## deviance 378.572 5.644 367.282 374.715 378.780 382.457 389.202 1.034 120 ## ## For each parameter, n.eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor (at convergence, Rhat=1). ## ## DIC info (using the rule, pD = var(deviance)/2) ## pD = 15.4 and DIC = 394.0 ## DIC is an estimate of expected predictive error (lower deviance is better). 9.6.2 Mean instead of mode This change seems less dramatic. Let’s see how using mean and concentraion compares to using mode and concentration. touch_model3 &lt;- function() { for (i in 1:Ntotal) { y[i] ~ dbern(theta[s[i]]) } for (s in 1:Nsubj) { theta[s] ~ dbeta(mu * kappa, (1 - mu) * kappa) } mu ~ dbeta(2, 2) kappa &lt;- kappaMinusTwo + 2 kappaMinusTwo ~ dgamma(0.01, 0.01) } touch_jags3 &lt;- jags.parallel( data = TouchData, model = touch_model3, parameters.to.save = c(&quot;theta&quot;, &quot;mu&quot;, &quot;kappa&quot;), n.burnin = 1000, n.iter = 41000, n.chains = 5, n.thin = 10, jags.seed = 54321 ) This model seems to perform reasonably well. touch_jags3 ## Inference for Bugs model at &quot;touch_model3&quot;, fit using jags, ## 5 chains, each with 41000 iterations (first 1000 discarded), n.thin = 10 ## n.sims = 20000 iterations saved ## mu.vect sd.vect 2.5% 25% 50% 75% 97.5% Rhat n.eff ## kappa 58.519 58.419 9.258 22.258 39.046 72.852 222.144 1.001 16000 ## mu 0.441 0.033 0.377 0.419 0.441 0.463 0.507 1.001 8700 ## theta[1] 0.364 0.087 0.174 0.310 0.373 0.425 0.514 1.001 18000 ## theta[2] 0.387 0.082 0.213 0.337 0.392 0.443 0.536 1.001 20000 ## theta[3] 0.409 0.078 0.248 0.360 0.412 0.460 0.558 1.001 17000 ## theta[4] 0.409 0.078 0.244 0.361 0.412 0.461 0.559 1.001 15000 ## theta[5] 0.409 0.079 0.241 0.360 0.412 0.461 0.557 1.001 19000 ## theta[6] 0.409 0.080 0.243 0.360 0.412 0.462 0.561 1.001 20000 ## theta[7] 0.409 0.079 0.242 0.360 0.412 0.461 0.560 1.001 12000 ## theta[8] 0.408 0.079 0.242 0.359 0.411 0.460 0.559 1.001 11000 ## theta[9] 0.409 0.079 0.244 0.360 0.413 0.461 0.562 1.001 20000 ## theta[10] 0.410 0.079 0.243 0.361 0.412 0.462 0.559 1.001 20000 ## theta[11] 0.432 0.078 0.276 0.382 0.432 0.481 0.589 1.001 13000 ## theta[12] 0.433 0.078 0.276 0.383 0.433 0.482 0.588 1.001 9900 ## theta[13] 0.431 0.077 0.274 0.382 0.432 0.480 0.584 1.001 12000 ## theta[14] 0.431 0.078 0.274 0.382 0.432 0.481 0.586 1.001 20000 ## theta[15] 0.431 0.078 0.276 0.383 0.431 0.480 0.590 1.001 20000 ## theta[16] 0.454 0.078 0.306 0.403 0.451 0.503 0.619 1.001 13000 ## theta[17] 0.455 0.078 0.307 0.404 0.452 0.503 0.619 1.001 20000 ## theta[18] 0.454 0.079 0.302 0.403 0.451 0.503 0.618 1.001 18000 ## theta[19] 0.455 0.077 0.309 0.405 0.452 0.503 0.617 1.001 20000 ## theta[20] 0.454 0.079 0.302 0.402 0.451 0.503 0.619 1.001 15000 ## theta[21] 0.454 0.078 0.300 0.404 0.452 0.502 0.616 1.001 6200 ## theta[22] 0.455 0.079 0.303 0.404 0.452 0.503 0.622 1.001 17000 ## theta[23] 0.477 0.082 0.329 0.422 0.471 0.526 0.657 1.001 20000 ## theta[24] 0.477 0.081 0.329 0.423 0.472 0.526 0.655 1.001 20000 ## theta[25] 0.500 0.086 0.352 0.441 0.491 0.551 0.692 1.001 20000 ## theta[26] 0.499 0.085 0.353 0.441 0.491 0.549 0.690 1.001 20000 ## theta[27] 0.498 0.084 0.350 0.441 0.491 0.549 0.685 1.001 20000 ## theta[28] 0.522 0.091 0.368 0.458 0.512 0.577 0.725 1.001 12000 ## deviance 379.246 5.135 368.618 375.817 379.516 382.831 388.728 1.001 20000 ## ## For each parameter, n.eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor (at convergence, Rhat=1). ## ## DIC info (using the rule, pD = var(deviance)/2) ## pD = 13.2 and DIC = 392.4 ## DIC is an estimate of expected predictive error (lower deviance is better). TouchData0 &lt;- list( Ntotal = 0, Nsubj = length(unique(TherapeuticTouch$s)), # y = TherapeuticTouch$y, # must convert subjects to sequence 1:Nsubj s = as.numeric(factor(TherapeuticTouch$s)) ) So why do we prefer the mode to the mean? Let’s take a look at the prior distribution on one of the \\(\\theta\\)s. touch_jags_prior &lt;- jags.parallel( data = TouchData0, model = touch_model, parameters.to.save = c(&quot;theta&quot;, &quot;kappa&quot;, &quot;omega&quot;), n.burnin = 1000, n.iter = 41000, n.chains = 5, n.thin = 10, DIC = FALSE, jags.seed = 54321 ) touch_jags_prior3 &lt;- jags.parallel( data = TouchData0, model = touch_model3, parameters.to.save = c(&quot;theta&quot;, &quot;kappa&quot;, &quot;mu&quot;), n.burnin = 1000, n.iter = 41000, n.chains = 5, n.thin = 10, DIC = FALSE, jags.seed = 54321 ) gf_dens( ~ theta.1, data = posterior(touch_jags_prior), color = ~&quot;mode&quot;) %&gt;% gf_dens( ~ theta.1, data = posterior(touch_jags_prior3), color = ~&quot;mean&quot;) Using the mean rather than mode corresponds to an unfortunate prior on \\(\\theta_i\\). 9.7 Shrinkage 9.8 Example: Baseball Batting Average 9.9 Exerciess "],
["model-comparison.html", "10 (Model Comparison)", " 10 (Model Comparison) "],
["nhst.html", "11 (NHST)", " 11 (NHST) "],
["point-null-hypotheses.html", "12 (Point Null Hypotheses)", " 12 (Point Null Hypotheses) "],
["goals-power-sample-size.html", "13 Goals, Power, Sample Size 13.1 Intro 13.2 Power 13.3 Calculating Power: 3 step process 13.4 Power Examples", " 13 Goals, Power, Sample Size 13.1 Intro 13.1.1 Goals Kruschke (bold added): Any goal of research can be formally expressed in various ways. In this chapter I will focus on the following goals formalized in terms of the highest density interval (HDI): Goal: Reject a null value of a parameter. Formal expression: Show that a region of practical equivalence (ROPE) around the null value excludes the posterior 95% HDI. Goal: Affirm a predicted value of a parameter. Formal expression: Show that a ROPE around the predicted value includes the posterior 95% HDI. Goal: Achieve precision in the estimate of a parameter. Formal expression: Show that the posterior 95% HDI has width less than a specified maximum. 13.1.2 Obstacles The crucial obstacle to the goals of research is that a random sample is only a probabilistic representation of the population from which it came. Even if a coin is actually fair, a random sample of flips will rarely show exactly 50% heads. And even if a coin is not fair, it might come up heads 5 times in 10 flips. Drugs that actually work no better than a placebo might happen to cure more patients in a particular random sample. And drugs that truly are effective might happen to show little difference from a placebo in another particular random sample of patients. Thus, a random sample is a fickle indicator of the true state of the underlying world. Whether the goal is showing that a suspected value is or isn’t credible, or achieving a desired degree of precision, random variation is the researcher’s bane. Noise is the nemesis. 13.2 Power Because of random noise, the goal of a study can be achieved only probabilistically. The probability of achieving the goal, given the hypothetical state of the world and the sampling plan, is called the power of the planned research. 13.2.1 Three ways to increase power Reduce measurement noise as much as possible. We can avoid sources of variability by controlling them (keep them constant for all observational units) or by including them as co-variates inour model. “Reduction of noise and control of other influences is the primary reason for conducting experiments in the lab instead of in the maelstrom of the real world.” (But with the downside that lab conditions might not accurately reflect the conditions of the situation we are actually interested in.) Amplify the underlying magnitude of the effect if we possibly can. Exmples: In a study of methods to improve reading performance, we might select participants who are reading below grade level and so have the most room to improve. When administering a drug, a larger dose is likely to show a larger effect (within reason – we don’t want undo side effects). Increase sample size. In principle, more data means more information and less variability. In practice, more data means more costs (time, money, etc.). 13.3 Calculating Power: 3 step process We can calculate the power of our study by repeating the following three steps many times: Sample parameters from a hypothetical distribution of parameter values. These are chosen to reflect some situation we are interested in. Our main question will be “How likely are we to attain our goals in this situation.” Given the sampled parameter values, simulate a data set (using the data collection method proposed for the study). Using the data set, compute the posterior HDI (or some other measure related to our goal). Each HDI can be classified as achieving or not achieving the goal. The proportion of simulated data sets that achieve the goal is our estimate of power, given the hypothesized distribution of parameter values. 13.4 Power Examples 13.4.1 Example: Catching an unfair coin Let’s go through these steps to estimate the power of detecting a coin that comes up heads 65% of the time using a ROPE of (0.49, 0.51). Our goal in this case is an HDI that is either below 0.49 or above 0.51. 13.4.1.1 Sample parameters In this case, this is pretty boring since our hypothetical situation is that the proportion is exactly 0.65. But for the sake of what is to come, we will create a little function to compute 0.65 for us. To improve output formatting, and so things generalize later, we will return that value as a named vector. (A data frame or list would also work.) We can test it out by “doing” it 3 times. library(mosaic) # mosaic contains the do() function draw_theta &lt;- function() { c(theta = 0.65) } do(3) * draw_theta() theta 0.65 0.65 0.65 13.4.1.2 Simulate data For a given parameter value, we need to simulate data, in this case a number of heads and a number of flips. In our example, the number of flips is always the same, but we could design the study differently so that the number of flips was not always the same, for example by flipping until we see a certain number of heads (or tails, or both). We will make this an argument to our function so we can explore different sample sizes later. simulate_data &lt;- function(theta, n) { x &lt;- rbinom(1, n, theta) data.frame(theta = theta, heads = x, flips = n) } do(3) * simulate_data(0.60, 100) theta heads flips .row .index 0.6 58 100 1 1 0.6 61 100 1 2 0.6 56 100 1 3 13.4.1.3 Compute the HDI From our simulated data, we need to compute and HDI. To avoid needing to simulate, we will use what we know about beta distributions to compute the posterior distribution analytically. To keep the code simple, we will use a central 95% interval that is not an HDI, but it should be close. The default prior is uniform (\\({\\sf Beta}(1,1)\\)), but we will allow arguments to the function that let us experiment with different priors as well. compute_hdi &lt;- function(data, prior = list(a = 1, b = 1)) { # posterior post &lt;- data.frame(a = prior$a + data$heads, b = prior$b + data$flips - data$heads) # not quite the HDI data.frame( theta = data$theta, x = data$heads, n = data$flips, lo = qbeta(0.025, post$a, post$b), hi = qbeta(0.975, post$a, post$b) ) } draw_theta() %&gt;% simulate_data(n = 100) %&gt;% compute_hdi() theta x n lo hi 0.65 61 100 0.5118 0.6999 13.4.1.4 Lather, rinse, repeat Now we repeat these three steps many times. do(5) * { draw_theta() %&gt;% simulate_data(n = 100) %&gt;% compute_hdi() } theta x n lo hi .row .index 0.65 69 100 0.5934 0.7722 1 1 0.65 70 100 0.6039 0.7810 1 2 0.65 64 100 0.5421 0.7273 1 3 0.65 59 100 0.4918 0.6814 1 4 0.65 67 100 0.5728 0.7544 1 5 Sims100 &lt;- do(5000) * { draw_theta() %&gt;% simulate_data(n = 100) %&gt;% compute_hdi() } Sims100 &lt;- Sims100 %&gt;% mutate(reject = (hi &lt; 0.49) | (lo &gt; 0.51)) df_stats(~reject, data = Sims100, props, counts) prop_FALSE prop_TRUE n_FALSE n_TRUE 0.169 0.831 845 4155 The power increases if we incrase the sample size. Sims200 &lt;- do(5000) * { draw_theta() %&gt;% simulate_data(n = 200) %&gt;% compute_hdi() } Sims200 &lt;- Sims200 %&gt;% mutate(reject = (hi &lt; 0.49) | (lo &gt; 0.51)) df_stats(~reject, data = Sims200, props, counts) prop_FALSE prop_TRUE n_FALSE n_TRUE 0.0166 0.9834 83 4917 13.4.2 Example: Estimating a Proportion Suppose we would like to estimate a proportion within \\(\\pm 2\\)%. Further suppose we have no idea what that proportion is. So now we will draw values of \\(\\theta\\) from a uniform distribution. 13.4.2.1 draw_theta_unif &lt;- function(a = 0, b = 1) { c(theta = runif(1, a, b)) } do(3) * draw_theta_unif() theta 0.7242 0.9703 0.8775 Sims200p &lt;- do(5000) * { draw_theta_unif() %&gt;% simulate_data(n = 200) %&gt;% compute_hdi() } Sims200p &lt;- Sims200p %&gt;% mutate( width = hi - lo, success = width &lt; 0.02) df_stats(~ success, data = Sims200p, props, counts) prop_FALSE prop_TRUE n_FALSE n_TRUE 0.9878 0.0122 4939 61 So a sample of size 200 isn’t going to do it (at least not very often). Let’s try 2000. Sims2000p &lt;- do(5000) * { draw_theta_unif() %&gt;% simulate_data(n = 2000) %&gt;% compute_hdi() } Sims2000p &lt;- Sims2000p %&gt;% mutate( width = (hi - lo), center = lo + width / 2, success = width &lt; 0.02) df_stats( ~ success, data = Sims2000p, props, counts) prop_FALSE prop_TRUE n_FALSE n_TRUE 0.8888 0.1112 4444 556 Better, but we’re still hitting our target only 10% of the time. Sims8kp &lt;- do(5000) * { draw_theta_unif() %&gt;% simulate_data(n = 8000) %&gt;% compute_hdi() } Sims8kp &lt;- Sims8kp %&gt;% mutate( width = (hi - lo), center = lo + width / 2, success = width &lt; 0.02) df_stats( ~ success, data = Sims8kp, props, counts) prop_FALSE prop_TRUE n_FALSE n_TRUE 0.4062 0.5938 2031 2969 We can find out a bit more about what is going on here by comparing the width of the interval to the simulate value of \\(\\theta\\). gf_point(width ~ theta, data = Sims8kp, shape = 21) %&gt;% gf_hline(yintercept = 0.02, color = &quot;red&quot;) As we see, the width of the interval is wider when \\(\\theta\\) is near 0.5. This means we can get by with a smaller sample size if we have good reason to expect that \\(\\theta\\) is near 0 or 1. And we will need a larger sample size if we expect \\(\\theta\\) is near 0.5. Sims_small_theta &lt;- do(5000) * { draw_theta_unif(0,0.2) %&gt;% simulate_data(n = 3000) %&gt;% compute_hdi() } Sims_small_theta &lt;- Sims_small_theta %&gt;% mutate( width = hi - lo, success = width &lt; 0.02 ) df_stats(~success, data = Sims_small_theta, props, counts) prop_FALSE prop_TRUE n_FALSE n_TRUE 0.5712 0.4288 2856 2144 gf_histogram(~ width, data = Sims_small_theta, bins = 40) gf_point(width ~ theta, data = Sims_small_theta, shape = 21) 13.4.3 More Complex Example The one proportion example is as simple as it gets only one parameter (the proportion) simple distribution (Bernoulli) relatively easy to come up with hypothetical distributions easy calculation of the posterior distribution In a typical situation, none of these special aspects will hold. Let’s try something just one step more complex: a simple linear model. draw_theta_slr &lt;- function() { data.frame(intercept = runif(1, 10, 12), slope = runif(1, 3, 4), sigma = runif(1, 4, 5) ) } do(3) * draw_theta_slr() intercept slope sigma .row .index 11.47 3.508 4.108 1 1 10.77 3.732 4.790 1 2 10.72 3.047 4.114 1 3 simulate_data_slr &lt;- function(theta = list(slope = 1, intercept = 0, sigma = 1), n = 40, xlim = c(0,1)) { tibble( x = runif(n, xlim[1], xlim[2]), y = theta$intercept + theta$slope * x + rnorm(n, 0, theta$sigma) ) } gf_point(y ~ x, data = simulate_data_slr()) gf_point(y ~ x, data = simulate_data_slr( xlim = c(0,10), theta = list(slope = 2, intercept = 10, sigma = 0.5)) ) gf_point(y ~ x, data = simulate_data_slr( xlim = c(0,10), theta = list(slope = 2, intercept = 10, sigma = 2.5)) ) slr_model &lt;- brm( y ~ x, data = simulate_data_slr()) ## Compiling the C++ model ## Start sampling compute_hdi_slr &lt;- function(data) { model &lt;- update(slr_model, newdata = data) model %&gt;% posterior() %&gt;% hdi() } draw_theta_slr() %&gt;% simulate_data_slr() %&gt;% compute_hdi_slr() ## Start sampling Let’s do 100 simulations. This is going to require posterior sampling from 100 models, so we want to be confident things are working properly before we simulate thousands of these. The use of update() will make this run much faster. Sims_slr &lt;- do(100) * { draw_theta_slr() %&gt;% simulate_data_slr() %&gt;% compute_hdi_slr() } ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Warning: There were 1 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 10. See ## http://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded ## Warning: Examine the pairs() plot to diagnose sampling problems ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Warning: There were 1 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 10. See ## http://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded ## Warning: Examine the pairs() plot to diagnose sampling problems ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling Here is a plot showing the simulated HDIs. For any particular goal, it would now be easy to compute how often the goal is attained. gf_pointrange( mode + lo + hi ~ .index, data = Sims_slr) %&gt;% gf_facet_wrap( ~ par, scales = &quot;free&quot;) "],
["stan.html", "14 Stan 14.1 Why Stan might work better 14.2 Describing a model to Stan 14.3 Samping from the prior 14.4 Exercises", " 14 Stan 14.1 Why Stan might work better Stan is sometimes (but not always) better or faster than JAGS. The reason is that the HMC (Hamilton Markov Chain) algorithm that it uses avoids some of the potential problems of the Metropolis algorithm and Gibbs sampler. You can think of HMC as a generlization of the Metropolis algorithm. Recall that in the Metropolis algorithm There is always a current vector of parameter values (like the current island in our story) A new vector of parameter values is proposed The proposal is accepted or rejected by comparing the ratio of the likelihoods of the current and proposal vectors. It is important that we only need the ratio because the scaling constant would be prohibitively expensive to compute. The main change is in how HMC chooses its proposals. Recall that in the basic Metropolis algorithm the proposal distribution is symmetric the proposal distribution is the same no matter where the current parameter vector is. This has some potential negative consequences When the current position is a region of relatively low posterior density, the algorithm is as likely to propose moves that go farther from the mode as toward it. This can be inefficient. The behavior of the algorithm can be greatly affected by the “step size” (how likely the proposal is to be close to or far from the current position). HMC addresses these by using a proposal distribution that * Changes depending on the current position * Is more likely to make proposals in the direction of the mode Unlike Gibbs samplers, HMC is not guided by the fixed directions corresponding to letting only one parameter value change at a time. This makes it easier for HMC to navigate posteriors that have narrow “ridges” that don’t follow one of these primary directions, so Stan is less disturbed by correlations in the posterior distribution than JAGS is. The basic idea of the HMC sampler in Stan is to turn the log posterior upsided down so it is bowl-shaped with its mode at the “bottom” and to imagine a small particle sliding along this surface after receiving a “flick” to get it moving. If the flick is in the direction of the mode, the particle will move farther. If it is away from the mode, it may go up hill for a while and then turn around. (The same thing may happen if it travels in the direction of the mode and overshoots.) If it is in some other direction, it will take a curved path that bends toward the mode. A proposal is generated by specifying * A direction and “force” for the flick (momentum) * The amount of “time” to let the particle move. At the end of the specified amount of time, the particle will be at the proposal position. * A level of discretization used to simulate the motion of the particle. In principle (ie, physics), every proposal can be excepted (as in the Gibbs sampler). In practice, because the simulated movement is discretized into a sequence of small segments, a rule is used that involves both the ratio of the posterior values and the ratio of the momentums of the current and proposal values. If the motion is simulated with many small segments, the proposal will nearly always be accepted, but it will take longer to do the simulation. On the other hand, if a cruder approximation is used, the simulation is faster, but the proposal is more likely to be rejected. “Time” is represented by the product of the number of steps used and the size of the steps: steps * eps (eps is short for espilon, but “steps time eps” has a aring to it). The step size (eps) is a tuning parameter of the algorithm, and things seem to work most efficiently if roughly 2/3 of proposals are accepted. The value of eps can be adjusted to attain something close to this goal. Stan adds an extra bit to this algorithm. To avoid the inefficiency of overshooting and turning around, it tries to estimate when this will happen. The result is its No U-Turn Sampler (NUTS). There are a number of other features that lead to the complexity of Stan including Symbolic differentiation to determine the gradient of the posterior and momentum. Simulation techniques for the physics to minimize the inaccuracy created because of discretization. Techniques for dealing with parameters with bounded support. An inital phase that helps set the tuning parameters: step size (eps), time (steps * eps), and the distribution from which to sample the initial momentum. Because of all these techinical details, it is easy to see why Stan may be much slower than JAGS in situations where JAGS works well. The flip-side is that Stan make work in situations where JAGS fails altogether or takes too much time to be of practical use. Generally, as models become more complex, Stan gains the advantage. For simple models, JAGS is often faster. 14.2 Describing a model to Stan Coding Stan models is also a bit more complicated, but what we have learned about JAGS is helpful. RStudio also offers excellent support for Stan, so we won’t have to use tricks like writing a “function” in R that isn’t really R code to describe a JAGS model. To use Stan in R we will load the rstan package and take advantage of RStudio’s Stan chunks. library(rstan) rstan_options(auto_write = TRUE) # saves some compiling Stan descriptions have several sections (not all of which are required): data – declarations of variables to hold the data transformed data – transformations of data parameters – declaration of parameters transformed parameters – transformations of parameters model – description of prior and likelihood generated quantities – used to keep track of additional values Stan can compute at each step. Here is an example of a simple Stan model: data { int&lt;lower=0&gt; N; // N is a non-negative integer int y[N]; // y is a length-N vector of integers } parameters { real&lt;lower=0,upper=1&gt; theta; // theta is between 0 and 1 } model { theta ~ beta (1,1); y ~ bernoulli(theta); } See if you can figure out what this model is doing. You will also see that Stan requires some extra stuff compared to JAGS. In particular, we need to tell Stan which quantities are integers and which are reals, and also if there is an restriction to their domain. Note: running the chunk above takes a little while. This is when Stan compiles the C code for the model and also works out the formulas for the gradient (derivatives). The result is a dynamic shared object (DSO). To use this model in RStudio, put the code in a Stan chunk (one of the options from the insert menu) and set the output.var to the R variable that will store the results. In this case, we have named it simple_stan using the argument output.var = &quot;simple_stan&quot;. Behind the scenes, RStudio is calling stan_code() to pass information between R and Stan and to get Stan to do the compilation. class(simple_stan) # what kind of thing is this? ## [1] &quot;stanmodel&quot; ## attr(,&quot;package&quot;) ## [1] &quot;rstan&quot; simple_stan # let&#39;s take a look ## S4 class stanmodel &#39;83dbe9f99dbf55ff04494fdddf566a3d&#39; coded as follows: ## data { ## int&lt;lower=0&gt; N; // N is a non-negative integer ## int y[N]; // y is a length-N vector of integers ## } ## parameters { ## real&lt;lower=0,upper=1&gt; theta; // theta is between 0 and 1 ## } ## model { ## theta ~ beta (1,1); ## y ~ bernoulli(theta); ## } We still need to provide Stan some data and ask Stan to provide us with some posterior samples. We do this with the sampling() function. By separating this into a separate step, we can use the same compiled model with different data sets or different settings (more iterations, for example) without having to recompile. simple_stanfit &lt;- sampling( simple_stan, data = list( N = 50, y = c(rep(1, 15), rep(0, 35)) ), chains = 3, # default is 4 iter = 1000, # default is 2000 warmup = 200 # default is half of iter ) ## ## SAMPLING FOR MODEL &#39;83dbe9f99dbf55ff04494fdddf566a3d&#39; NOW (CHAIN 1). ## Chain 1: ## Chain 1: Gradient evaluation took 2.1e-05 seconds ## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.21 seconds. ## Chain 1: Adjust your expectations accordingly! ## Chain 1: ## Chain 1: ## Chain 1: Iteration: 1 / 1000 [ 0%] (Warmup) ## Chain 1: Iteration: 100 / 1000 [ 10%] (Warmup) ## Chain 1: Iteration: 200 / 1000 [ 20%] (Warmup) ## Chain 1: Iteration: 201 / 1000 [ 20%] (Sampling) ## Chain 1: Iteration: 300 / 1000 [ 30%] (Sampling) ## Chain 1: Iteration: 400 / 1000 [ 40%] (Sampling) ## Chain 1: Iteration: 500 / 1000 [ 50%] (Sampling) ## Chain 1: Iteration: 600 / 1000 [ 60%] (Sampling) ## Chain 1: Iteration: 700 / 1000 [ 70%] (Sampling) ## Chain 1: Iteration: 800 / 1000 [ 80%] (Sampling) ## Chain 1: Iteration: 900 / 1000 [ 90%] (Sampling) ## Chain 1: Iteration: 1000 / 1000 [100%] (Sampling) ## Chain 1: ## Chain 1: Elapsed Time: 0.002491 seconds (Warm-up) ## Chain 1: 0.008107 seconds (Sampling) ## Chain 1: 0.010598 seconds (Total) ## Chain 1: ## ## SAMPLING FOR MODEL &#39;83dbe9f99dbf55ff04494fdddf566a3d&#39; NOW (CHAIN 2). ## Chain 2: ## Chain 2: Gradient evaluation took 7e-06 seconds ## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds. ## Chain 2: Adjust your expectations accordingly! ## Chain 2: ## Chain 2: ## Chain 2: Iteration: 1 / 1000 [ 0%] (Warmup) ## Chain 2: Iteration: 100 / 1000 [ 10%] (Warmup) ## Chain 2: Iteration: 200 / 1000 [ 20%] (Warmup) ## Chain 2: Iteration: 201 / 1000 [ 20%] (Sampling) ## Chain 2: Iteration: 300 / 1000 [ 30%] (Sampling) ## Chain 2: Iteration: 400 / 1000 [ 40%] (Sampling) ## Chain 2: Iteration: 500 / 1000 [ 50%] (Sampling) ## Chain 2: Iteration: 600 / 1000 [ 60%] (Sampling) ## Chain 2: Iteration: 700 / 1000 [ 70%] (Sampling) ## Chain 2: Iteration: 800 / 1000 [ 80%] (Sampling) ## Chain 2: Iteration: 900 / 1000 [ 90%] (Sampling) ## Chain 2: Iteration: 1000 / 1000 [100%] (Sampling) ## Chain 2: ## Chain 2: Elapsed Time: 0.003295 seconds (Warm-up) ## Chain 2: 0.008936 seconds (Sampling) ## Chain 2: 0.012231 seconds (Total) ## Chain 2: ## ## SAMPLING FOR MODEL &#39;83dbe9f99dbf55ff04494fdddf566a3d&#39; NOW (CHAIN 3). ## Chain 3: ## Chain 3: Gradient evaluation took 5e-06 seconds ## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds. ## Chain 3: Adjust your expectations accordingly! ## Chain 3: ## Chain 3: ## Chain 3: Iteration: 1 / 1000 [ 0%] (Warmup) ## Chain 3: Iteration: 100 / 1000 [ 10%] (Warmup) ## Chain 3: Iteration: 200 / 1000 [ 20%] (Warmup) ## Chain 3: Iteration: 201 / 1000 [ 20%] (Sampling) ## Chain 3: Iteration: 300 / 1000 [ 30%] (Sampling) ## Chain 3: Iteration: 400 / 1000 [ 40%] (Sampling) ## Chain 3: Iteration: 500 / 1000 [ 50%] (Sampling) ## Chain 3: Iteration: 600 / 1000 [ 60%] (Sampling) ## Chain 3: Iteration: 700 / 1000 [ 70%] (Sampling) ## Chain 3: Iteration: 800 / 1000 [ 80%] (Sampling) ## Chain 3: Iteration: 900 / 1000 [ 90%] (Sampling) ## Chain 3: Iteration: 1000 / 1000 [100%] (Sampling) ## Chain 3: ## Chain 3: Elapsed Time: 0.002517 seconds (Warm-up) ## Chain 3: 0.008281 seconds (Sampling) ## Chain 3: 0.010798 seconds (Total) ## Chain 3: The output below looks similar to what we have seen from JAGS. simple_stanfit ## Inference for Stan model: 83dbe9f99dbf55ff04494fdddf566a3d. ## 3 chains, each with iter=1000; warmup=200; thin=1; ## post-warmup draws per chain=800, total post-warmup draws=2400. ## ## mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat ## theta 0.30 0.00 0.06 0.19 0.26 0.30 0.35 0.44 961 1 ## lp__ -32.63 0.02 0.75 -34.85 -32.81 -32.35 -32.15 -32.10 1106 1 ## ## Samples were drawn using NUTS(diag_e) at Wed May 8 14:54:55 2019. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split chains (at ## convergence, Rhat=1). There are a number of functions that can extract information from stanfit objects. methods(class = &quot;stanfit&quot;) ## [1] as.array as.data.frame as.matrix as.mcmc.list bridge_sampler ## [6] constrain_pars dim dimnames extract get_cppo_mode ## [11] get_inits get_logposterior get_num_upars get_posterior_mean get_seed ## [16] get_seeds get_stancode get_stanmodel grad_log_prob is.array ## [21] log_posterior log_prob loo names names&lt;- ## [26] neff_ratio nuts_params pairs plot posterior ## [31] print rhat show stanfit summary ## [36] traceplot unconstrain_pars ## see &#39;?methods&#39; for accessing help and source code Unfortunately, some of these have the same names as functions elsewhere (in the coda package, for example). We generally adopt an approach that keeps things as similar to what we did with JAGS as possible. Use CalvinBayes::posterior() to create a dataframe with posterior samples. These can be plotted or explored using ggformula or other familiar tools. Use as.matrix() or as.mcmc.list() to create an object that can be used with bayesplot just as we did when we used JAGS. gf_dens(~theta, data = posterior(simple_stanfit)) simple_mcmc &lt;- as.matrix(simple_stanfit) mcmc_areas(simple_mcmc, prob = 0.9, pars = &quot;theta&quot;) mcmc_areas(as.mcmc.list(simple_stanfit), prob = 0.9, pars = &quot;theta&quot;) diag_mcmc(as.mcmc.list(simple_stanfit)) 14.3 Samping from the prior In JAGS, to sample from the posterior, we just “removed the data”. For any parameter values, the likelihood of not having any data if we don’t collect any data is 1. So the posterior is the same as the prior. Unlike JAGS, Stan does not allow missing data, so we need a different way to sample from the posterior. In Stan, we will remove the likelihood. To understand why this works, let’s think a little bit about how Stan operates. All internal work is done on the log scale. log prior, log likelihood, log posterior. Additive constants on the log scale (multiplicative constants on the natural scale) don’t matter… … at least not for generating posterior samples, so they can be ignored or chosen conveniently. The distribution functions in Stan are really logs of kernels with constants chosen to optimize efficiency of computation. log(posterior) = log(prior) + log(likelihood) + constant So if we don’t add in the likelihood part, we just get the prior again as the posterior. A line like y ~ bernoulli(theta); Is just telling stan to add the log of the bernoulli pmf for each value of the data vector y using the current value for theta. If we comment out that line, no log likelihood will be added. data { int&lt;lower=0&gt; N; // N is a non-negative integer int y[N]; // y is a length-N vector of integers } parameters { real&lt;lower=0,upper=1&gt; theta; // theta is between 0 and 1 } model { theta ~ beta (1,1); // y ~ bernoulli(theta); // comment out to remove likelihood } simple0_stanfit &lt;- sampling( simple0_stan, data = list( N = 50, y = c(rep(1, 15), rep(0, 35)) ), chains = 3, # default is 4 iter = 1000, # default is 2000 warmup = 200 # default is half of iter ) 14.4 Exercises Let’s compare Stan and JAGS on the therapeutic touch example from Chapter 9. (See Figure 9.7 on page 236.) Stan and JAGS code for this example are below. The data are in TherapeuticTouch. data { int&lt;lower=1&gt; Nsubj; int&lt;lower=1&gt; Ntotal; int&lt;lower=0,upper=1&gt; y[Ntotal]; int&lt;lower=1&gt; s[Ntotal]; // notice Ntotal not Nsubj } parameters { real&lt;lower=0,upper=1&gt; theta[Nsubj]; // individual prob correct real&lt;lower=0,upper=1&gt; omega; // group mode real&lt;lower=0&gt; kappaMinusTwo; // group concentration minus two } transformed parameters { real&lt;lower=0&gt; kappa; kappa &lt;- kappaMinusTwo + 2; } model { omega ~ beta(1, 1); kappaMinusTwo ~ gamma(1.105125, 0.1051249 ); // mode=1, sd=10 theta ~ beta(omega * (kappa-2) + 1, (1 - omega) * (kappa-2) + 1); for ( i in 1:Ntotal ) { y[i] ~ bernoulli(theta[s[i]]); } } jags_model &lt;- function() { for ( i in 1:Ntotal ) { y[i] ~ dbern( theta[s[i]] ) } for (s in 1:Nsubj ) { theta[s] ~ dbeta(omega * (kappa-2) + 1, (1-omega) * (kappa-2) + 1) } omega ~ dbeta(1, 1) kappa &lt;- kappaMinusTwo + 2 kappaMinusTwo ~ dgamma(1.105125, 0.1051249) # mode=1, sd=10 } Now answer the following questions. What does the transformed parameters block of the Stan code do? In the Stan code, there are two lines with ~ in them. One is inside a for loop and the other not. Why? Compile the Stan program, and note how long it takes. Now generate posterior samples using both the JAGS and Stan versions. Do the produce the same posterior distribution? How do the effective sample sizes compare? Tweak the settings until you get similar effective sample sizes and rhat values from both Stan and JAGS. (ESS is the best metric of how much work they have done, and we want to be sure both algorithms think they are converging to get a fair comparison.) Once you have done that, compare their speeds. Which is faster in this example? By how much? (If you want R to help automate the timing, you can use system.time().) "],
["glm-overview.html", "15 GLM Overview 15.1 Data consists of observations of variables 15.2 GLM Framework", " 15 GLM Overview 15.1 Data consists of observations of variables Rectangular format: rows: one per observation/observational unit (person, thing observed) columns: one per variable (measurement made/recorded) 15.1.1 Variable Roles Often we will divid up variables into predictor or explanatory varaibles and predicted or response variables. This indicates that we want to use our model to help us predict the values of some variables given the values of other variables. Example: How does a college predict success based on high school GPA and SAT/ACT scores? 15.1.2 Types of Variables scale metric? continuous/discrete ratio M C interval M C count M D ordinal - D nominal - D dichotymous variables are variables that only take on two values. They are a bit of a special case (which we have already dealt with) because (a) they are simpler, and (b) the ordinal/nominal distinction doesn’t really matter. More the most part, we will treat ratio and interval variables the same way, the important distinctions for us become metric, count, dichotymous, ordinal, nominal We also have the option of not having a predictor variable. That gives us \\(6 \\cdots 5 = 30\\) combinations of predictor and predicted variables types – so 30 types of models that have a single predictor and a single predicted variable. (Using 1 to represent no predictor – ie, all observations are in one group – we can denote these as follows dichotymous ~ 1 dichotymous ~ dichotymous metric ~ 1 metric ~ dichotyous metric ~ metric metric ~ ordinal etc, etc, etc. We have already handled the first two (one coin and two coins examples). Over the rest of the semester will continue down the list adding new cobminations of predictor and predicted. Multiple predictors can be handled (for the most part) by combining ideas from the 2-variable models. 15.2 GLM Framework First try: \\(y = h(x_1, x_2, \\dots, x_k)\\) but we don’t expect the predictors to exactly determine the response, so this is doomed to fail. Second try: \\(y \\sim h(x_1, x_2, \\dots, x_k)\\) predictors determine a distribution for response. this is essientially what we will do, but we will refine things a bit this isn’t always the easiest way to think about things it’s awkward to have \\(h\\) return a distribution some features of the distribution will be determined outside of \\(h\\) so \\(h\\) will tell us something about the distribution, but maybe not everything we have already seen this in action: Alice and Bob shooting free throws (or Reginald and Tony throwing at a target). predictor: the subject (Alice or Bob) [dichotymous] response: hit or miss [dichotymous] distribution: Bernoulli with \\(\\theta\\) determined by the subject. \\(h(Alice) = \\theta_1\\); \\(h(Bob) = \\theta_2\\) (Generalized) Linear models restrict the form of \\(h\\): one predictor variable: \\(h(x) = \\beta_0 + \\beta_1 x\\). multiple predictor variables: \\(h(x) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots \\beta_k x_k\\). \\(x = \\langle x_1, x_2, \\dots, x_k \\rangle\\). If you are familiar with linear algebra, \\(\\beta_1 x_1 + \\beta_2 x_2 + \\cdots \\beta_k x_k = \\beta \\cdot x\\) is just the dot product of a vector of \\(\\beta\\)’s with a vector of \\(x\\)’s. to emphasize that \\(h()\\) is a linear function, we will also denote it \\(\\mathrm{lin}()\\) to indicate that it is “some linear function of the precictor(s).” transformed predictors: Since expression like \\(x^2\\) or \\(\\log x\\) are just new variables, the system easily accomodates transformations of the predictors link (and inverse link) functions expand the model pallette by adding transformations of \\(y\\) \\[\\begin{align*} f(y) &amp;= \\mathrm{lin}(x)\\\\ y &amp;= g(\\mathrm{lin}(x)) \\end{align*}\\] \\(f\\) is called the link function because it links \\(y\\) to a linear funciton. \\(g\\) is called the inverse link function. Kruschke sometimes just calls them both the link function since they come in pairs and it is usually clear which of \\(f\\) and \\(g\\) is meant. Nonlinear models use an \\(h()\\) that is not linear. It is not harder to work with nonlinear models than with linear models in JAGS or Stan, although they may be more difficult to interpret depending on the form of \\(h()\\). "],
["estimating-one-and-two-means.html", "16 Estimating One and Two Means 16.1 Basic Model for Two Means 16.2 An Old Sleep Study 16.3 Variations on the theme 16.4 How many chains? How long? 16.5 Looking at Likelihood 16.6 Exercises", " 16 Estimating One and Two Means 16.1 Basic Model for Two Means 16.1.1 Data Two variables: metric ~ dichotymous metric response dichotomous explanatory 16.1.2 Model The traditional starting point for modeling means is to assume that the each group is sampled from a normal distribution with unknown mean and a common standard deviation. (We’ll see that is no harder to have different standard deviations.) So for two groups our model has three parameters: two means (\\(\\mu_1\\) and \\(\\mu_2\\)) and one standard deviation \\(\\sigma\\). Of course, we also need priors for these parameters. A common prior for the means is a normal distribution. We will start with a uniform prior for the standard deviation, but discuss better alternatives shortly. That gives the following template for our model: \\[\\begin{align*} Y_{i|g} &amp; \\sim {\\sf Norm}(\\mu_g, \\sigma) \\\\ \\mu_g &amp; \\sim {\\sf Norm}(?, ?) \\\\ \\sigma &amp; \\sim {\\sf Unif}(?, ?) \\end{align*}\\] The questions marks will be filled in based on considerations of the scale (order of magnitude of the data) and the amount of regularizing we want to do. 16.2 An Old Sleep Study Cushny, A. R. and Peebles, A. R. (1905) “The action of optical isomers: II hyoscines.” The Journal of Physiology 32, 501–510. Design: Subjects sleep habits were compared without a sleep inducing drug and then with to see how two different drugs affected sleep. 16.2.1 Data Let’s look at the data. (extra = additional sleep on drug; group should really be drug, so let’s rename it.) library(ggformula) library(dplyr) sleep &lt;- datasets::sleep %&gt;% rename(drug = group) gf_boxplot(extra ~ drug, data = sleep) df_stats(extra ~ drug, data = sleep) drug min Q1 median Q3 max mean sd n missing 1 -1.6 -0.175 0.35 1.70 3.7 0.75 1.789 10 0 2 -0.1 0.875 1.75 4.15 5.5 2.33 2.002 10 0 16.2.2 Model It is simple enough to convert the model description above into a JAGS model, but we need to fill in those question marks. Let’s try this: mean for prior on \\(\\mu_g\\): 0 corresponds to the drug having no impact on sleep allows drug to increase or decrease sleep without prejudice any other number would require more justification will tend to pull estimates toward 0 (shrinkage) – we are requiring evidence to convince us that the drug does something to sleep. sd for prior on \\(\\mu_g\\): 3 Says we are 95% certain that the average impact of a drug will be between -6 and 6 additional hours of sleep and that it is very unlikely the drug will change sleep by 9 or more hours. This is fairly week prior (6 extra hours of sleep would be a lot). This might be chosen in consultation with scientists who are more familiar with what is reasonable. range for \\(\\sigma\\): One crude way to set the prior is to give a ball mark estimate for the the standard deviation of the amount of sleep change in each treatment group and then make sure we cover a range 3 orders of magnitude in each direction. We can experiment with different priors to see how the impact results. library(R2jags) sleep_model &lt;- function() { for (i in 1:Nobs) { extra[i] ~ dnorm(mu[drug[i]], 1 / sigma^2) } for (d in 1:Ndrugs) { mu[d] ~ dnorm(0, 1/3^2) # sd = 3 } sigma ~ dunif(2/1000, 2 * 1000) # 3 orders of mag each way of 2 delta_mu &lt;- mu[2] - mu[1] tau &lt;- 1 / sigma^2 } sleep_jags &lt;- jags( model = sleep_model, parameters.to.save = c(&quot;mu&quot;, &quot;sigma&quot;, &quot;delta_mu&quot;), data = list( extra = sleep$extra, drug = sleep$drug, Nobs = nrow(sleep), Ndrugs = 2 ), DIC = FALSE # because we haven&#39;t discussed deviance yet ) library(CalvinBayes) library(bayesplot) summary(sleep_jags) ## fit using jags ## 3 chains, each with 2000 iterations (first 1000 discarded) ## n.sims = 3000 iterations saved ## mu.vect sd.vect 2.5% 25% 50% 75% 97.5% Rhat n.eff ## delta_mu 1.505 0.896 -0.309 0.933 1.523 2.075 3.269 1.001 3000 ## mu[1] 0.717 0.622 -0.518 0.315 0.723 1.131 1.962 1.001 3000 ## mu[2] 2.221 0.642 0.894 1.814 2.243 2.638 3.455 1.001 3000 ## sigma 2.035 0.379 1.455 1.772 1.980 2.237 2.905 1.003 820 sleep_mcmc &lt;- as.mcmc(sleep_jags) mcmc_areas(sleep_mcmc, prob = 0.95, regex_pars = &quot;mu&quot;) mcmc_areas(sleep_mcmc, prob = 0.95, regex_pars = &quot;sigma&quot;) mcmc_pairs(sleep_mcmc) mosaic::prop( ~(delta_mu &gt; 0), data = posterior(sleep_jags)) ## prop_TRUE ## 0.952 16.2.3 Separate standard deviations for each group sleep_model2 &lt;- function() { for (i in 1:Nobs) { extra[i] ~ dnorm(mu[drug[i]], 1/sigma[drug[i]]^2) } for (d in 1:Ndrugs) { mu[d] ~ dnorm(0, 1/3^2) sigma[d] ~ dunif(2/1000, 2 * 1000) tau[d] &lt;- 1 / sigma[d]^2 } delta_mu &lt;- mu[2] - mu[1] delta_sigma &lt;- sigma[2] - sigma[1] } sleep_jags2 &lt;- jags( model = sleep_model2, parameters.to.save = c(&quot;mu&quot;, &quot;sigma&quot;, &quot;delta_mu&quot;, &quot;delta_sigma&quot;, &quot;tau&quot;), data = list( extra = sleep$extra, drug = sleep$drug, Nobs = nrow(sleep), Ndrugs = 2 ), DIC = FALSE ) library(bayesplot) library(CalvinBayes) summary(sleep_jags2) ## fit using jags ## 3 chains, each with 2000 iterations (first 1000 discarded) ## n.sims = 3000 iterations saved ## mu.vect sd.vect 2.5% 25% 50% 75% 97.5% Rhat n.eff ## delta_mu 1.491 1.002 -0.523 0.853 1.513 2.140 3.451 1.001 3000 ## delta_sigma 0.254 0.935 -1.562 -0.298 0.223 0.783 2.170 1.001 3000 ## mu[1] 0.712 0.672 -0.586 0.286 0.701 1.136 2.061 1.001 3000 ## mu[2] 2.203 0.736 0.758 1.747 2.229 2.667 3.592 1.001 2600 ## sigma[1] 2.103 0.611 1.272 1.679 1.994 2.373 3.627 1.001 3000 ## sigma[2] 2.357 0.695 1.412 1.883 2.230 2.666 4.112 1.001 3000 ## tau[1] 0.278 0.140 0.076 0.178 0.251 0.355 0.618 1.001 3000 ## tau[2] 0.222 0.114 0.059 0.141 0.201 0.282 0.501 1.001 3000 sleep_mcmc2 &lt;- as.mcmc(sleep_jags2) mcmc_areas(sleep_mcmc2, prob = 0.95, regex_pars = &quot;mu&quot;) mcmc_areas(sleep_mcmc2, prob = 0.95, regex_pars = &quot;sigma&quot;) mosaic::prop( ~(delta_mu &gt; 0), data = posterior(sleep_jags2)) ## prop_TRUE ## 0.9303 mosaic::prop( ~(delta_sigma &gt; 0), data = posterior(sleep_jags2)) ## prop_TRUE ## 0.62 hdi(sleep_jags2, pars = c(&quot;delta&quot;)) par lo hi prob chain hdi(sleep_jags2) par lo hi prob chain delta_mu -0.5231 3.2463 0.95 1 delta_mu -0.4663 3.3997 0.95 2 delta_mu -0.5670 3.6046 0.95 3 delta_sigma -1.7227 2.1318 0.95 1 delta_sigma -1.4971 2.1057 0.95 2 delta_sigma -1.4255 2.2211 0.95 3 mu[1] -0.5609 1.9123 0.95 1 mu[1] -0.6925 1.9083 0.95 2 mu[1] -0.5055 2.2318 0.95 3 mu[2] 0.7860 3.5920 0.95 1 mu[2] 0.7949 3.5497 0.95 2 mu[2] 0.6776 3.6541 0.95 3 sigma[1] 1.1026 3.3793 0.95 1 sigma[1] 1.1953 3.1850 0.95 2 sigma[1] 1.1495 3.3457 0.95 3 sigma[2] 1.2549 3.6323 0.95 1 sigma[2] 1.3421 3.7643 0.95 2 sigma[2] 1.2385 3.7057 0.95 3 tau[1] 0.0485 0.5655 0.95 1 tau[1] 0.0605 0.5789 0.95 2 tau[1] 0.0601 0.5433 0.95 3 tau[2] 0.0345 0.4542 0.95 1 tau[2] 0.0460 0.4268 0.95 2 tau[2] 0.0494 0.4590 0.95 3 16.2.4 Comparison to t-test For those who know about 2-sample t tests: t.test(extra ~ drug, data = sleep) ## ## Welch Two Sample t-test ## ## data: extra by drug ## t = -1.9, df = 18, p-value = 0.08 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -3.3655 0.2055 ## sample estimates: ## mean in group 1 mean in group 2 ## 0.75 2.33 mosaic::prop( ~(delta_mu &lt; 0), data = posterior(sleep_jags2)) ## prop_TRUE ## 0.06967 16.2.5 ROPE (Region of Practical Equivalence) Just knowing that two things are not the same is not of much practical use if the difference is small. One way to quantify this is to specify a region of practical equivalence (ROPE). We could decide, for example, that we are not interested in differences of less than 10 minutes (1/6 hours). Our ROPE (for the difference in means) would then be the interval \\((-1/6, 1/6)\\) and we could ask if there is evidence that the true difference lies outside that interval. This could be checked by seeing if an HDI lies completely outside the ROPE. plot_post(posterior(sleep_jags2)$delta_mu, ROPE = c(-1/6, 1/6), hdi_prob = 0.9) ## $posterior ## ESS mean median mode ## var1 3000 1.491 1.513 1.51 ## ## $hdi ## prob lo hi ## 1 0.9 -0.1725 3.078 ## ## $ROPE ## lo hi P(&lt; ROPE) P(in ROPE) P(&gt; ROPE) ## 1 -0.1667 0.1667 0.05067 0.04033 0.909 Note: you don’t really need a fancy plot like this. All you need to know is the boundaries of your ROPE and the boundaries of your HDI. 16.3 Variations on the theme 16.3.1 Other distributions for the response While the normal distributions are commonly used to describe metric response variables, and many things are normally distributed, not everything is. Skewed distributions. If we have reason to believe that the shape of the response distribution (for a given combination of explanatory variables) is skewed (not symmetrical), then we have two options: a. Transform the response variable. Perhaps $log(y)$ or some other transformation of why is better described by a normal distribution than $y$ itself. b. Choose a skewed distribution. Althernatively, we could choose a skewed distribution as part of the model. Distributions with heavier tails. Values that are quite far from the mean can have a large impact on what values of the man and standard deviation we find credible. If we suspect that the response distribution is likely to heavier tails, we can choose a family of distributions with heavier tails. This also makes our model more robust against outliers so that if the underlying distribution is normal but our data has an unusually large or small observation, the overall fit of the model is less disturbed. The most commonly used family for this is the family of “student” t-distributions. If you have seen these before, you probably learned that the student t-distributions have one parameter, called degrees of freedom (usually denoted \\(\\nu\\) – that’s the Greek letter \\(\\nu\\)). This is a shape parameter, and as \\(\\nu \\to \\infty\\), the t-distributions become more and more like the standard normal distribution. For this reason, we also may refer to \\(\\nu\\) as the normality parameter. the student t-distributions are symmetric about 0. the mean, standard deviation, variance, precision are given by quantity expression valid when mean 0 \\(\\nu &gt; 1\\) standard deviation \\(\\sqrt{\\frac{\\nu}{\\nu -2}}\\) \\(\\nu &gt; 2\\) variance \\(\\frac{\\nu}{\\nu -2}\\) \\(\\nu &gt; 2\\) standard deviation \\(\\frac{\\nu - 2}{\\nu}\\) \\(\\nu &gt; 2\\) (These can fail to exist when the integral involved fail to converge.) We can combine this information to form a more general family of t-distributions by shifting and scaling the student t-distributions. If \\(T \\sim {\\sf T}(\\nu)\\), then \\[ T&#39; = \\mu + \\frac{1}{\\tau} T \\sim {\\sf T}(\\mu, \\tau, \\nu)\\] will have mean: \\(\\mu\\) (provided \\(\\nu &gt; 1\\)); standard deviation: \\(\\sigma \\sqrt{\\frac{\\nu}{\\nu - 2}}\\) (provided \\(\\nu &gt; 2\\)) where \\(\\sigma = \\sqrt{\\frac{1}{\\tau}}\\) precision: \\(\\tau \\frac{\\nu -2}{\\nu}\\) This is how JAGS defines the family of t-distributions. Note that \\(\\tau\\) is not exactly \\(\\frac{1}{\\sigma^2}\\), but it is close when \\(\\nu\\) is large. We can use this more general version of a t-distribution in place of a normal distribution by adding one additional prior – a prior for \\(\\nu\\). We want \\(\\nu &gt;1\\), so we will use our add and subtract trick to shift it to a distribution that is always positive. One choice would be a shifted exponential distribution (Gamma distribution with shape parameter 1). These distributions are heavily skewed, but this is appropriate since all the action is for small values of \\(\\nu\\). If \\(\\nu &gt; 30\\), the t distributions are hardly distinguishable from normal distributions. If we select a distribution with mean 30, then the distribution will be roughly evenly split between “basically normal” and “more spread out than a normal distribution”. # 29 because we will shift by 1 gamma_params(shape = 1, mean = 29, plot = TRUE) shape rate scale mode mean sd 1 0.0345 29 0 29 29 pexp(29, rate = 1/29) ## [1] 0.6321 sleep_model3 &lt;- function() { for (i in 1:Nobs) { extra[i] ~ dt(mu[drug[i]], 1 / sigma[drug[i]]^2, nu[drug[i]]) } for (d in 1:Ndrugs) { mu[d] ~ dnorm(0, 1/3^2) sigma[d] ~ dunif(2/1000, 2 * 1000) nuMinusOne[d] ~ dexp(1/29) nu[d] &lt;- nuMinusOne[d] + 1 } delta_mu &lt;- mu[2] - mu[1] delta_sigma &lt;- sigma[2] - sigma[1] } sleep_jags3 &lt;- jags( model = sleep_model3, parameters.to.save = c(&quot;mu&quot;, &quot;sigma&quot;, &quot;delta_mu&quot;, &quot;delta_sigma&quot;, &quot;nu&quot;), data = list( extra = sleep$extra, drug = sleep$drug, Nobs = nrow(sleep), Ndrugs = 2, n.iter = 5000 ), DIC = FALSE ) ## Warning in jags.model(model.file, data = data, inits = init.values, n.chains = n.chains, : Unused ## variable &quot;n.iter&quot; in data ## Compiling model graph ## Resolving undeclared variables ## Allocating nodes ## Graph information: ## Observed stochastic nodes: 20 ## Unobserved stochastic nodes: 6 ## Total graph size: 67 ## ## Initializing model library(bayesplot) library(CalvinBayes) summary(sleep_jags3) ## fit using jags ## 3 chains, each with 2000 iterations (first 1000 discarded) ## n.sims = 3000 iterations saved ## mu.vect sd.vect 2.5% 25% 50% 75% 97.5% Rhat n.eff ## delta_mu 1.464 0.992 -0.480 0.822 1.464 2.120 3.358 1.001 3000 ## delta_sigma 0.274 0.871 -1.400 -0.255 0.259 0.805 2.069 1.003 1000 ## mu[1] 0.691 0.641 -0.594 0.292 0.704 1.082 1.958 1.001 3000 ## mu[2] 2.155 0.751 0.714 1.666 2.167 2.631 3.606 1.001 3000 ## nu[1] 32.871 29.880 2.850 12.373 23.856 43.915 115.671 1.003 810 ## nu[2] 33.855 29.672 3.043 12.434 25.551 46.011 111.424 1.001 3000 ## sigma[1] 2.009 0.585 1.150 1.592 1.908 2.330 3.349 1.002 1500 ## sigma[2] 2.282 0.666 1.308 1.831 2.156 2.604 3.985 1.002 2100 sleep_mcmc3 &lt;- as.mcmc(sleep_jags3) mcmc_areas(sleep_mcmc3, prob = 0.95, regex_pars = &quot;mu&quot;) mcmc_areas(sleep_mcmc2, prob = 0.95, regex_pars = &quot;mu&quot;) mcmc_areas(sleep_mcmc3, prob = 0.95, regex_pars = &quot;sigma&quot;) mcmc_areas(sleep_mcmc3, prob = 0.95, regex_pars = &quot;nu&quot;) mosaic::prop( ~(delta_mu &gt; 0), data = posterior(sleep_jags3)) ## prop_TRUE ## 0.9257 hdi(sleep_jags3) %&gt;% arrange(chain) par lo hi prob chain delta_mu -0.5194 3.268 0.95 1 delta_sigma -1.4178 1.780 0.95 1 mu[1] -0.5883 1.883 0.95 1 mu[2] 0.8141 3.509 0.95 1 nu[1] 1.0686 96.255 0.95 1 nu[2] 1.0618 102.388 0.95 1 sigma[1] 1.0717 3.119 0.95 1 sigma[2] 1.2284 3.468 0.95 1 delta_mu -0.3966 3.281 0.95 2 delta_sigma -1.4576 2.037 0.95 2 mu[1] -0.5978 2.056 0.95 2 mu[2] 0.7858 3.641 0.95 2 nu[1] 1.0433 89.376 0.95 2 nu[2] 1.0743 87.933 0.95 2 sigma[1] 1.0600 3.280 0.95 2 sigma[2] 1.2132 3.553 0.95 2 delta_mu -0.6552 3.348 0.95 3 delta_sigma -1.5312 2.035 0.95 3 mu[1] -0.4334 2.054 0.95 3 mu[2] 0.5713 3.646 0.95 3 nu[1] 1.1046 81.929 0.95 3 nu[2] 1.1033 87.768 0.95 3 sigma[1] 1.0988 3.240 0.95 3 sigma[2] 1.1617 3.901 0.95 3 In this model we see that protecting our selves with a t distribution rather than a normal distribution doesn’t seem to affect our estimates of delta much at all. bind_rows( hdi(sleep_jags3, pars = &quot;delta&quot;) %&gt;% mutate(model = 3), hdi(sleep_jags2, pars = &quot;delta&quot;) %&gt;% mutate(model = 2) ) %&gt;% arrange (chain, model) ## Warning in bind_rows_(x, .id): Unequal factor levels: coercing to character ## Warning in bind_rows_(x, .id): binding character and factor vector, coercing into character vector ## Warning in bind_rows_(x, .id): binding character and factor vector, coercing into character vector par lo hi prob chain model 16.3.2 Other Priors for \\(\\sigma\\) (or \\(\\tau\\)) Andrew Gelman has an entire paper devoted to the topic of choosing priors for standard deviation in Bayesian models. We won’t delve into all the details or reasons to prefer (or avoid) some priors. But we will mention some of the alternatives available and make a few comments. \\({\\sf Unif}(a/1000, 1000a)\\) for some suitable \\(a\\) based on what we know about the scale of the data. We have already seen this above. It relisted here for completeness. Notes from Gelman’s paper: Gelman mentions using \\({\\sf Unif}(0, A)\\), which is similar, but doesn’t avoid the really small values near 0. Gelman claims that this prior often works reasonably well in practice and is at least a good starting point, especially when the number of groups is small, as it is in our example. Improper Uniform prior – \\({\\sf Unif}(0 ,\\infty)\\) Imagine we wanted to have a uniform prior in the interval \\((0, \\infty)\\). A little thought shows that there is no such pdf (how tall would it need to be?) Nevertheless, some models can be fit with an improper prior – a function that has infinite area beneath it and so cannot be a kernel of a distribution. In this case, we could choose a constant function. If when multiplied by the likelihood we end up with something is a kernel, then we end up with a legitimate posterior, even though we used an improper prior. But generally speaking, improper priors are not the way to go. They can cause trouble for numerical algorithms (if they allow it at all), and there are usually better choices for priors.7 A proper prior with support \\((0, \\infty)\\). Gamma The only family we know with support \\((0, \\infty)\\) is the Gamma family. But we won’t typically use it for this purpose. (But see below for its connection to \\(\\tau\\).) Half-Distributions If we take the positive half of any distribution that is symmetric about 0, we get a “half-distibution”. Half-normal and half-t distributions are frequently used as priors for the standard deviation. In particular, a half t distrubtion with 1 degree of freedom is called a half-Cauchy distribution. This distribution is so braod that it has not mean, so it functions somewhat like a proper substitute for the improper uniform prior. JAGS is clever enough to create the half distribution for us if we code things as if we are using a prior for \\(\\sigma\\) that is symmetric around 0 – no need to say “half”. Dealing with precision (\\(\\tau\\)) directly. Instead of coming up with a prior for \\(\\sigma\\), we could instead come up with a prior for the variance (\\(\\sigma^2\\)) or the precision (\\(\\tau\\)) instead. A gamma distribuiton is frequently used here because it happens to also be a conjugate prior in many situations involving normal distributions. The only tricky part here is choosing parameters for the gamma prior that correspond to our intitution since we are less familiar with precision than with standard deviation. Side note: The reason JAGS uses precision for normal distributions rather than standard deviation or variance is because Gamma distributions are a conjugate prior for precision in simple models based on the normal distribution, and BUGS (which predated JAGS) took advantage of conjugate priors to make sampling more efficient. 16.3.3 Paired Comparisons The data actually contain another variable: ID. As it turns out, the same ten people were tested with each drug. If we are primarily interested in comparing the two drugs, we might take the difference between the extra sleep with one drug and with the other drug for each person. This is referred to as a paired design. A paired comparison of means is really just looking at one mean – the mean difference. We can do this a couple of different ways: Compute the difference before giving data to JAGS Build the differences into the JAGS code. We will use option 1 here and convert our data so that each row corresponds to one person and there are separate columns for the extra sleep produced by each drug. This is sometimes referred to as converting from long format (more rows, fewer columns) to wide format (fewer rows, more columns). The tidyr::spread() function is useful for this. (And tidyr::gather() can be used to convert in the opposite direction.) library(tidyr) sleep_wide &lt;- datasets::sleep %&gt;% rename(drug = group) %&gt;% mutate(drug = paste0(&quot;drug&quot;, drug)) %&gt;% spread(key = drug, value = extra) sleep_wide ID drug1 drug2 1 0.7 1.9 2 -1.6 0.8 3 -0.2 1.1 4 -1.2 0.1 5 -0.1 -0.1 6 3.4 4.4 7 3.7 5.5 8 0.8 1.6 9 0.0 4.6 10 2.0 3.4 sleep_wide &lt;- sleep_wide %&gt;% mutate(delta = drug2 - drug1) sleep_wide ID drug1 drug2 delta 1 0.7 1.9 1.2 2 -1.6 0.8 2.4 3 -0.2 1.1 1.3 4 -1.2 0.1 1.3 5 -0.1 -0.1 0.0 6 3.4 4.4 1.0 7 3.7 5.5 1.8 8 0.8 1.6 0.8 9 0.0 4.6 4.6 10 2.0 3.4 1.4 gf_boxplot(~ delta, data = sleep_wide) sleep_model4 &lt;- function() { for (i in 1:Nsubj) { delta[i] ~ dt(mu, 1 / sigma^2, nu) } mu ~ dnorm(0, 2) sigma ~ dunif(2/1000, 2 * 1000) nuMinusOne ~ dexp(1/29) nu &lt;- nuMinusOne + 1 tau &lt;- 1 / sigma^2 } sleep_jags4 &lt;- jags( model = sleep_model4, parameters.to.save = c(&quot;mu&quot;, &quot;sigma&quot;, &quot;nu&quot;), data = list( delta = sleep_wide$delta, Nsubj = nrow(sleep_wide) ), n.iter = 5000, DIC = FALSE) ## Compiling model graph ## Resolving undeclared variables ## Allocating nodes ## Graph information: ## Observed stochastic nodes: 10 ## Unobserved stochastic nodes: 3 ## Total graph size: 25 ## ## Initializing model library(bayesplot) library(CalvinBayes) summary(sleep_jags4) ## fit using jags ## 3 chains, each with 5000 iterations (first 2500 discarded), n.thin = 2 ## n.sims = 3750 iterations saved ## mu.vect sd.vect 2.5% 25% 50% 75% 97.5% Rhat n.eff ## mu 1.092 0.379 0.252 0.886 1.129 1.334 1.743 1.002 3100 ## nu 21.375 25.137 1.335 4.314 11.899 29.283 93.348 1.001 3100 ## sigma 1.183 0.505 0.371 0.841 1.130 1.462 2.350 1.001 3800 sleep_mcmc4 &lt;- as.mcmc(sleep_jags4) mcmc_areas(sleep_mcmc4, prob = 0.95, pars = &quot;mu&quot;) mcmc_areas(sleep_mcmc4, prob = 0.95, pars = &quot;nu&quot;) mcmc_pairs(sleep_mcmc4) mosaic::prop( ~(mu &gt; 0), data = posterior(sleep_jags4)) ## prop_TRUE ## 0.9896 hdi(sleep_jags4, pars = c(&quot;mu&quot;)) par lo hi prob chain mu 0.2277 1.779 0.95 1 mu 0.3854 1.771 0.95 2 mu 0.2863 1.744 0.95 3 hdi(sleep_jags4) par lo hi prob chain mu 0.2277 1.779 0.95 1 mu 0.3854 1.771 0.95 2 mu 0.2863 1.744 0.95 3 nu 1.0013 73.264 0.95 1 nu 1.0067 65.680 0.95 2 nu 1.0194 77.905 0.95 3 sigma 0.2741 2.206 0.95 1 sigma 0.2526 2.074 0.95 2 sigma 0.3152 2.133 0.95 3 16.4 How many chains? How long? 16.4.1 Why multiple chains? Multiple chains are primarily for diagnostics. Once we are sure things are behaving as they should, we could go back and run one really long chain if we wanted. 16.4.2 What large n.eff does and doesn’t do for us A large value of n.eff makes our estimates more stable. If we run them again, or compare multiple chains, the HDIs for parameters with larger n.eff will change the least. For important work, we will run with a modest n.iter until we are sure things are working well. Then we can increase the number of iterations for final analysis to make sure that our estimates are stable. A large value of n.eff does not make our estimates “better” or make the posterior more concentrated. 16.5 Looking at Likelihood likelihood &lt;- function(mu1, sigma1, mu2 = mu1, sigma2 = sigma1, x, y = c(), log = FALSE) { D &lt;- tibble( group = c(rep(&quot;1&quot;, length(x)), rep(&quot;2&quot;, length(y))), l = c( dnorm(x, mu1, sigma1, log = log), dnorm(y, mu2, sigma2, log = log)), x = c(x, y) ) if (log) { logL &lt;- sum(D$l) L &lt;- exp(logL) } else { L &lt;- prod(D$l) logL &lt;- log(L) } T &lt;- tibble(x = mean(x), logL = logL, height = 1.2 * dnorm(0, 0, 1, log = log)) cat(paste0(&quot;log likelihood: &quot;, format(logL)), &quot;; mu: &quot;, format(mu1), &quot;, &quot;, format(mu2), &quot;; sigma: &quot;, format(sigma1), &quot;, &quot;, format(sigma2), &quot;\\n&quot;) gf_segment(0 + l ~ x + x, data = D, color = ~ group) %&gt;% gf_point(0 ~ x, data = D, color = ~ group) %&gt;% gf_function(function(x) dnorm(x, mu1, sigma1, log = log), color = ~&quot;1&quot;) %&gt;% gf_function(function(x) dnorm(x, mu2, sigma2, log = log), color = ~&quot;2&quot;) } library(manipulate) manipulate( likelihood(MU1, SIGMA1, MU2, SIGMA2, x = c(8, 12), y = c(11, 13), log = LOG) %&gt;% gf_lims(x = c(0, 20), y = c(NA, 0.5)), MU1 = slider(5, 15, 10, step = 0.2), MU2 = slider(5, 15, 10, step = 0.2), SIGMA1 = slider(1, 10, 2, step = 0.2), SIGMA2 = slider(1, 10, 2, step = 0.2), LOG = checkbox(FALSE, &quot;log likelihood&quot;) ) 16.6 Exercises Using the 30-year-olds in the NHANES data set (in the NHANES package), fit a model that compares the mean height for men and women (allowing for different standard deviations). Then and answer the following questions about your model. Explain your choice of priors. Does this sample provide enough evidence to conclude that men are taller (on average)? Does this sample provide enough evidence to conclude that the standard deviation of height differs between men and women? Thirty &lt;- NHANES::NHANES %&gt;% filter(Age == 30) df_stats(Height ~ Gender, data = Thirty) Gender min Q1 median Q3 max mean sd n missing female 152.4 159.0 163.9 168.6 181.3 164.3 6.731 73 3 male 153.0 171.7 176.2 181.1 186.8 175.7 7.082 90 0 gf_dens( ~ Height, color = ~ Gender, data = Thirty, binwidth = 1) ## Warning: Removed 3 rows containing non-finite values (stat_density). Repeat exercise 1, but compare pulse instead of height. The typical lifespan of a laboratory rat that eats ad lib is approximately 700 days. When rats are placed on a restricted diet, their longevity can increase, but there is a lot of variability in lifespans across different individual rats. Restricting the diet might not only affect the typical lifespan, but restricting the diet might also affect the variance of the lifespan across rats. We consider data from R. L. Berger, Boos, and Guess (1988), as reported in Hand, Daly, Lunn, McConway, and Ostrowski (1994, data set #242), and which are available as CalvinBayes::RatLives. Run the two-group analysis on the rat longevity data using a t distribution for the response variable. Do the groups appear to differ in their central tendencies and variances? Does the value of the normality parameter suggest that the distribution of lifetimes has heavier tails than a normal distribution? Did you plot the data before doing part a? It’s a good idea to do that. Create a plot that compares the distributions of rat life for the two groups of rats in the data. Your plot should have revealed that within each group the data appear to be skewed to the left. That is, within each group, there are many rats that died relatively young, but there are fewer rats who lived especially long. We could try to implement a skewed noise distribution, or we could try to transform the data so they are approximately symmetric within each group after transformation. We will try the latter approach here. To get rid of leftward skew, we need a transformation that expands larger values more than the smaller values. We will try squaring the data. (You an use mutate() to add a new variable containing the square of the lifetimes of the rats to the original data or you can take care of this inside the list that you pass to JAGS). Do the groups appear to differ in their central tendencies and variances with this model? What does the value of the normality parameter suggest about the distribution of the transformed lifetimes? To compare the results of the two models, it is useful to back-transform to the natural scale. Give a 90% posterior HDI for the difference in mean lifetime based on each model. These should both be in units of days. Did you use ROPEs in any of your answers above? If not, go back and do so. (You will need to decide how wide the ROPE should be and if/how it changes when you apply the transformation.) In the previous problem, how do the priors for the difference in mean lifetimes compare? Sample from the prior to find out. Be sure to deal appropriately with the transformation so that you are doing an apples to apples comparison. Shohat-Ophir et al. (2012) were interested in alcohol preferences of sexually deprived male flies. The procedure is illustrated in Figure 16.13, and was described as follows: One cohort, rejected-isolated, was subjected to courtship conditioning; they experienced 1-h sessions of sexual rejection by mated females, three times a day, for 4 days. …Flies in the mated-grouped cohort experienced 6-h sessions of mating with multiple receptive virgin females (ratio 1:5) for 4 days. Flies from each cohort were then tested in a two-choice preference assay, in which they voluntarily choose to consume food with or without 15% ethanol supplementation. (Shohat-Ophir et al., 2012, p. 1351, citations and figure reference removed) For each fly, the amount of each type of food consumed was converted to a preference ratio: the amount of ethanol-supplemented food minus the amount of regular food divided by the total of both. 3-day summary preference scores for each individual fruit fly were computed by summing the consumption of ethanol and non-ethanol across days 6–8. The amounts of food consumed and the preference ratios are in CalvinBayes::ShohatOphirKAMH2012dataReduced. How big are differences between groups relative to the uncertainty of the estimate? What do you conclude? (Answer this by computing what Kruschke calls the effect size. But note: effect size is not well defined; there are many things that go by that name. See, for example, the Wikipedia article on effect size.) Instead of focusing on the relative amounts of ethanol and regular food consumed, we might also be interested in the absolute total amount of food consumed. Run the analysis on the total consumption data, which has column name GrandTotal in the data set. What do you conclude? Redo problem 3 in Stan. You only need to do one model (transformed or untransformed, whichever works better). Note: The t distribution in Stan is parameterized differently. The normality paramter comes first, then mean, then standard deviation (not precision). A related issue is an improper posterior. Some combinations of prior and likelihood can lead to a posterior with infinite “area/volume”.↩ "],
["simple-linear-regression.html", "17 Simple Linear Regression 17.1 The deluxe basic model 17.2 Example: Galton’s Data 17.3 Centering and Standardizing 17.4 We’ve fit a model, now what? 17.5 Fitting models with Stan 17.6 Two Intercepts model 17.7 Exercises", " 17 Simple Linear Regression Situation: Metric response Matric predictor 17.1 The deluxe basic model 17.1.1 Likelihood \\[\\begin{align*} y_{i} &amp;\\sim {\\sf Norm}(\\mu_i, \\sigma) \\\\ \\mu_i &amp;\\sim \\beta_0 + \\beta_1 x_i \\end{align*}\\] Some variations: Replace normal distribution with something else (t is common). Allow standard deviations to vary with \\(x\\) as well as the mean. Use a different functional relationship between explanatory and response (non-linear regression) Each of these is relatively easy to do. The first variation is sometimes called robust regression becuase it is more robust to unusual observations. Since it is no harder to work with t distributions than with normal distributions, that will become our go-to simple linear regression model. \\[\\begin{align*} y_{i} &amp;\\sim {\\sf T}(\\mu_i, \\sigma, \\nu) \\\\ \\mu_i &amp;\\sim \\beta_0 + \\beta_1 x_i \\end{align*}\\] 17.1.2 Priors We need priors for \\(\\beta_0\\), \\(\\beta_1\\), \\(\\sigma\\), and \\(\\nu\\). \\(\\nu\\): We’ve already seend that a shifted Gamma with mean around 30 works well as a generic prior giving the data room to stear us away from normality if warranted. \\(\\beta_1\\): The MLE for \\(\\beta_1\\) is \\[ \\hat\\beta_1 = r \\frac{SD_y}{SD_x}\\] so it makes sense to have a prior broadly covers the interval \\((- \\frac{SD_y}{SD_x}, \\frac{SD_y}{SD_x})\\). \\(\\beta_0\\): The MLE for \\(\\beta_0\\) is \\[ \\hat\\beta_0 \\; = \\; \\overline{y} - \\hat \\beta_1 \\overline{x} \\; = \\; \\overline{y} - r \\frac{SD_y}{SD_x} \\cdot \\overline{x}\\] so we can pick a prior that broadly covers the interval \\((\\overline{y} - \\frac{SD_y}{SD_x} \\cdot \\overline{x}, \\overline{y} - \\frac{SD_y}{SD_x} \\cdot \\overline{x})\\) \\(\\sigma\\) measures the amount of variability in responses for a fixed value of \\(x\\) (and is assumed to be the same for each \\(x\\) in the simple version of the model). A weakly informative prior should cover the range of reasonable values of \\(\\sigma\\) with plenty of room to spare. (Our 2-or-3-orders-of-magnititude-either-way uniform distribution might be a reasonable starting point.) Here’s the big picture: 17.2 Example: Galton’s Data Since we are looking at regression, let’s use an historical data set that was part of the origins of the regression story: Galton’s data on height. Galton collected data on the heights of adults and their parents. head(mosaicData::Galton) family father mother sex height nkids 1 78.5 67.0 M 73.2 4 1 78.5 67.0 F 69.2 4 1 78.5 67.0 F 69.0 4 1 78.5 67.0 F 69.0 4 2 75.5 66.5 M 73.5 4 2 75.5 66.5 M 72.5 4 To keep things simpler for the moment, let’s consider only women, and only one sibling per family. set.seed(54321) library(dplyr) GaltonW &lt;- mosaicData::Galton %&gt;% filter(sex == &quot;F&quot;) %&gt;% group_by(family) %&gt;% sample_n(1) Galton was interested in how people’s heights are related to their parents’ heights. He compbined the parents’ heights into the “mid-parent height”, which was the average of the two. GaltonW &lt;- GaltonW %&gt;% mutate(midparent = (father + mother) / 2) gf_point(height ~ midparent, data = GaltonW, alpha = 0.5) 17.2.1 Describing the model to JAGS galton_model &lt;- function() { for (i in 1:length(y)) { y[i] ~ dt(mu[i], 1/sigma^2, nu) mu[i] &lt;- beta0 + beta1 * x[i] } sigma ~ dunif(6/100, 6 * 100) nuMinusOne ~ dexp(1/29) nu &lt;- nuMinusOne + 1 beta0 ~ dnorm(0, 1/100^2) # 100 is order of magnitude of data beta1 ~ dnorm(0, 1/4^2) # expect roughly 1-1 slope } library(R2jags) library(mosaic) galton_jags &lt;- jags( model = galton_model, data = list(y = GaltonW$height, x = GaltonW$midparent), parameters.to.save = c(&quot;beta0&quot;, &quot;beta1&quot;, &quot;sigma&quot;, &quot;nu&quot;), n.iter = 5000, n.burnin = 2000, n.chains = 4, n.thin = 1 ) library(bayesplot) library(CalvinBayes) summary(galton_jags) ## fit using jags ## 4 chains, each with 5000 iterations (first 2000 discarded) ## n.sims = 12000 iterations saved ## mu.vect sd.vect 2.5% 25% 50% 75% 97.5% Rhat n.eff ## beta0 10.695 8.008 -4.072 5.664 11.532 17.189 24.534 4.376 4 ## beta1 0.800 0.120 0.593 0.702 0.787 0.877 1.020 4.071 4 ## nu 33.016 27.311 6.134 14.178 24.807 42.854 106.351 1.002 1600 ## sigma 1.849 0.130 1.594 1.761 1.849 1.935 2.102 1.020 140 ## deviance 699.315 4.276 694.765 696.069 697.727 701.525 709.475 2.312 6 ## ## DIC info (using the rule, pD = var(deviance)/2) ## pD = 3.3 and DIC = 702.6 mcmc_combo(as.mcmc(galton_jags)) 17.2.2 Problems and how to fix them Clearly something is not working the way we would like with this model! Here’s a clue as to the problem: posterior(galton_jags) %&gt;% gf_point(beta0 ~ beta1, color = ~ chain, alpha = 0.2, size = 0.4) %&gt;% gf_density2d(alpha = 0.5) posterior(galton_jags) %&gt;% filter(iter &lt;= 250, chain == &quot;chain:1&quot;) %&gt;% gf_step(beta0 ~ beta1, alpha = 0.8, color = ~iter) %&gt;% gf_density2d(alpha = 0.2) %&gt;% gf_refine(scale_color_viridis_c()) %&gt;% gf_facet_wrap(~chain) #, scales = &quot;free&quot;) The correlation of the parameters in the posterior distribution produces a long, narrow, diagonal ridge that the Gibbs sampler samples only very slowly because it keeps bumping into edge of the cliff. (Remember, the Gibbs sampler only moves in “primary” directions.) So how do we fix this? This is supposed to be the simple linear model after all. There are two ways we could hope to fix our problem. Reparameterize the model so that the correlation between parameters (in the posterior distribution) is reduced or eliminated. Use a different algorithm for posterior sampling. The problem is not with our model per se, rather it is with the method we are using (Gibbs) to sample from the posterior. Perhaps another algorithm will work better. 17.3 Centering and Standardizing Reparameterization 1: centering We can express this model as \\[\\begin{align*} y_{i} &amp;\\sim {\\sf T}(\\mu_i, \\sigma, \\nu) \\\\ \\mu_i &amp;= \\alpha_0 + \\alpha_1 (x_i - \\overline{x}) \\end{align*}\\] Since \\[\\begin{align*} \\alpha_0 + \\alpha_1 (x_i - \\overline{x}) &amp;= (\\alpha_0 - \\alpha_1 \\overline{x}) + \\alpha_1 x_i \\end{align*}\\] We see that \\(\\beta_0 = \\alpha_0 - \\alpha_1 \\overline{x}\\) and \\(\\beta_1 = \\alpha_1\\). So we can easily recover the original parameters if we like. (And if we are primarily interested in \\(\\beta_1\\), no translation is required.) This reparameterization maintains the natural scale of the data, and both \\(\\alpha_0\\) and \\(\\alpha_1\\) are easily interpreted: \\(\\alpha_0\\) is the mean response when the predictor is the average of the predictor values in the data. Reparameterization 2: standardization We can also express our model as \\[\\begin{align*} z_{y_{i}} &amp;\\sim {\\sf T}(\\mu_i, \\sigma, \\nu) \\\\[3mm] \\mu_i &amp;= \\alpha_0 + \\alpha_1 z_{x_i} \\\\[5mm] z_{x_i} &amp;= \\frac{x_i - \\overline{x}}{SD_x} \\\\[3mm] z_{y_i} &amp;= \\frac{y_i - \\overline{y}}{SD_y} \\\\[3mm] \\end{align*}\\] Here the change in the model is due to a transformation of the data. Subtracting the mean and dividing by the standard deviation is called standardization, and the values produced are sometimes called z-scores. The resulting distributions of \\(zy\\) and \\(zx\\) will have mean 0 and standard deviation 1. So in addition to breaking the correlation pattern, we have now put things on a standard scale, regardless of what the original units were. This can be useful for picking constants in priors (we won’t have to estimate the scale of the data involved). In addition, some algorithms work better if all the variables involved have roughly the same scale. The downside is that we usually need to convert back to the original scales of \\(x\\) and \\(y\\) in order to interpret the results. But this is only a matter of a little easy algebra: \\[\\begin{align*} \\hat{z}_{y_i} &amp;= \\alpha_0 + \\alpha_1 z{x_i} \\\\ \\frac{\\hat{y}_i - \\overline{y}}{SD_y} &amp;= \\alpha_0 + \\alpha_1 \\frac{x_i - \\overline{x}}{SD_x} \\\\ \\hat{y}_i &amp;= \\overline{y} + \\alpha_0 SD_y + \\alpha_1 SD_y \\frac{x_i - \\overline{x}}{SD_x} \\\\ \\hat{y}_i &amp;= \\underbrace{\\left[\\overline{y} + \\alpha_0 SD_y - \\alpha_1\\frac{SD_y}{SD_x} \\overline{x} \\right]}_{\\beta_0} + \\underbrace{\\left[\\alpha_1 \\frac{SD_y}{SD_x}\\right]}_{\\beta_1} x_i \\end{align*}\\] Since Kruscske demonstrates standardization, we’ll do centering here. galtonC_model &lt;- function() { for (i in 1:length(y)) { y[i] ~ dt(mu[i], 1/sigma^2, nu) mu[i] &lt;- alpha0 + alpha1 * (x[i] - mean(x)) } sigma ~ dunif(6/100, 6 * 100) nuMinusOne ~ dexp(1/29) nu &lt;- nuMinusOne + 1 alpha0 ~ dnorm(0, 1/100^2) # 100 is order of magnitude of data alpha1 ~ dnorm(0, 1/4^2) # expect roughly 1-1 slope beta0 = alpha0 - alpha1 * mean(x) beta1 = alpha1 # not necessary, but gives us both names } galtonC_jags &lt;- jags( model = galtonC_model, data = list(y = GaltonW$height, x = GaltonW$midparent), parameters.to.save = c(&quot;beta0&quot;, &quot;beta1&quot;, &quot;alpha0&quot;, &quot;alpha1&quot;, &quot;sigma&quot;, &quot;nu&quot;), n.iter = 5000, n.burnin = 2000, n.chains = 4, n.thin = 1 ) summary(galtonC_jags) ## fit using jags ## 4 chains, each with 5000 iterations (first 2000 discarded) ## n.sims = 12000 iterations saved ## mu.vect sd.vect 2.5% 25% 50% 75% 97.5% Rhat n.eff ## alpha0 64.105 0.149 63.812 64.004 64.106 64.208 64.390 1.001 12000 ## alpha1 0.740 0.081 0.577 0.687 0.740 0.795 0.900 1.001 12000 ## beta0 14.686 5.428 4.008 11.050 14.655 18.253 25.540 1.001 12000 ## beta1 0.740 0.081 0.577 0.687 0.740 0.795 0.900 1.001 12000 ## nu 32.250 24.769 6.281 14.368 24.592 42.701 98.596 1.001 8600 ## sigma 1.841 0.128 1.585 1.757 1.842 1.926 2.091 1.001 5300 ## deviance 697.587 2.496 694.651 695.740 696.961 698.787 704.017 1.001 12000 ## ## DIC info (using the rule, pD = var(deviance)/2) ## pD = 3.1 and DIC = 700.7 mcmc_combo(as.mcmc(galtonC_jags)) Ah! That looks much better than before. 17.3.1 \\(\\beta_0\\) and \\(\\beta_1\\) are still correlated Reparameterization has not changed our model, only the way it is described. In particular, \\(\\beta_0\\) and \\(\\beta_1\\) remain correlated in the posterior. But \\(\\alpha_0\\) and \\(\\alpha_1\\) are not correlated, and these are the parameters JAGS is using to sample. gf_point(beta1 ~ beta0, data = posterior(galtonC_jags), alpha = 0.1) gf_point(alpha1 ~ alpha0, data = posterior(galtonC_jags), alpha = 0.1) 17.4 We’ve fit a model, now what? After centering or standardizing, JAGS works much better. We can now sample from our posterior distribution. But what do we do with our posterior samples? 17.4.1 Estimate parameters If we are primarily interested in a regression parameter (usually the slope parameter is much more interesting than the intercept parameter), we can use an HDI to express our estimate. hdi(posterior(galtonC_jags), pars = &quot;beta1&quot;) par lo hi mode prob beta1 0.5825 0.9044 0.7278 0.95 mcmc_areas(as.mcmc(galtonC_jags), pars = &quot;beta1&quot;, prob = 0.95) Galton noticed what we see here: that the slope is less than 1. This means that children of taller than average parents tend to be shorter than their parents and children of below average parents tend to be taller than their parents. He referred to this in his paper as “regression towards mediocrity”. As it turns out, this was not a special feature of the heridity of heights but a general feature of linear models. Find out more in this Wikipedia artilce. 17.4.2 Make predictions Suppse we know the heights of a father and mother, from which we compute ther mid-parent height \\(x\\). How tall would we predict their daughters will be as adults? Each posterior sample provides an answer by describing a t distribution with nu degrees of freedom, mean \\(\\beta_0 + \\beta_1 x\\), and standard deviation \\(\\sigma\\). The posterior distribution of the average hieght of daughters born to parents with midparent height \\(x = 70\\) is shown below, along with an HDI. posterior(galtonC_jags) %&gt;% mutate(mean_daughter = beta0 + beta1 * 70) %&gt;% gf_dens(~mean_daughter) Galton_hdi &lt;- posterior(galtonC_jags) %&gt;% mutate(mean_daughter = beta0 + beta1 * 70) %&gt;% hdi(pars = &quot;mean_daughter&quot;) Galton_hdi par lo hi mode prob mean_daughter 65.89 67.07 66.5 0.95 So on average, we would predict the daughters to be about 66 or 67 inches tall. We can visualize this by drawing a line for each posterior sample. The HDI should span the middle 95% of these. gf_abline(intercept = ~beta0, slope = ~beta1, alpha = 0.01, color = &quot;steelblue&quot;, data = posterior(galtonC_jags) %&gt;% sample_n(2000)) %&gt;% gf_point(height ~ midparent, data = GaltonW, inherit = FALSE, alpha = 0.5) %&gt;% gf_errorbar(lo + hi ~ 70, data = Galton_hdi, color = &quot;skyblue&quot;, width = 0.2, size = 1.2, inherit = FALSE) But this may not be the sort of prediction we want. Notice that most daughters’ heights are not in the blue band in the picture. That band tells about the mean but doesn’t take into account how much individuals vary about that mean. We can add that information in by taking our estimate for \\(\\sigma\\) into account. Here we generate heights by adding noise to the estimate given by values of \\(\\beta_0\\) and \\(\\beta_1\\). posterior(galtonC_jags) %&gt;% mutate(new_ht = beta0 + beta1 * 70 + rt(1200, df = nu) * sigma) %&gt;% gf_point(new_ht ~ 70, alpha = 0.01, size = 0.7, color = &quot;steelblue&quot;) %&gt;% gf_point(height ~ midparent, data = GaltonW, inherit = FALSE, alpha = 0.5) Galton_hdi2 &lt;- posterior(galtonC_jags) %&gt;% mutate(new_ht = beta0 + beta1 * 70 + rt(1200, df = nu) * sigma) %&gt;% hdi(regex_pars = &quot;new&quot;) Galton_hdi2 par lo hi mode prob new_ht 62.38 70.53 66.46 0.95 So our model expects that most daughters whose parents have a midparent height of 70 inches are between 62.4 and 70.5 inches tall. Notice that this interval is taking into account both the uncertainty in our estimates of the parameters \\(\\beta_0\\), \\(\\beta_1\\), \\(\\sigma\\), and \\(\\nu\\) and the variability in heights that \\(\\sigma\\) and \\(\\nu\\) indicate. 17.4.3 Posterior Predictive Checks With a little more work, we can create intervals like this at several different midparent heights. Post_galtonC &lt;- posterior(galtonC_jags) Grid &lt;- expand.grid(midparent = 60:75, iter = 1:nrow(Post_galtonC)) posterior(galtonC_jags) %&gt;% mutate(noise = rt(12000, df = nu) * sigma) %&gt;% left_join(Grid) %&gt;% mutate(height = beta0 + beta1 * midparent + noise) %&gt;% group_by(midparent) %&gt;% do(hdi(., pars = &quot;height&quot;)) ## Joining, by = &quot;iter&quot; ## # A tibble: 16 x 6 ## # Groups: midparent [16] ## midparent par lo hi mode prob ## &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 60 height 55.2 63.2 58.6 0.95 ## 2 61 height 55.9 63.9 59.3 0.95 ## 3 62 height 56.7 64.6 60.4 0.95 ## 4 63 height 57.4 65.3 61.4 0.95 ## 5 64 height 58.3 66.1 61.8 0.95 ## 6 65 height 59.1 66.8 62.4 0.95 ## 7 66 height 59.7 67.4 62.9 0.95 ## 8 67 height 60.5 68.2 64.6 0.95 ## 9 68 height 61.2 69.0 65.0 0.95 ## 10 69 height 61.9 69.6 66.1 0.95 ## 11 70 height 62.6 70.4 66.6 0.95 ## 12 71 height 63.1 70.9 67.9 0.95 ## 13 72 height 63.9 71.8 68.2 0.95 ## 14 73 height 64.7 72.5 69.1 0.95 ## 15 74 height 65.4 73.3 68.7 0.95 ## 16 75 height 66.0 74.1 69.7 0.95 posterior(galtonC_jags) %&gt;% mutate(noise = rt(12000, df = nu) * sigma) %&gt;% left_join(Grid) %&gt;% mutate(avg_height = beta0 + beta1 * midparent, height = avg_height + noise) %&gt;% group_by(midparent) %&gt;% do(hdi(., pars = &quot;height&quot;)) %&gt;% gf_ribbon(lo + hi ~ midparent, fill = &quot;steelblue&quot;, alpha = 0.2) %&gt;% gf_errorbar(lo + hi ~ midparent, width = 0.2, color = &quot;steelblue&quot;, size = 1.2) %&gt;% gf_point(height ~ midparent, data = GaltonW, inherit = FALSE, alpha = 0.5) ## Joining, by = &quot;iter&quot; Comparing the data to the posterior predictions of the model is called a posterior predictive check; we are checking to see whether the data are consistent with what our posterior distribution would predict. In this case, things look good: most, but not all of the data is falling inside the band where our models predicts 95% of new observations would fall. If the posterior predictive check indicates systematic problems with our model, it may lead us to propose another (we hope better) model. 17.4.4 Posterior predictive checks with bayesplot It takes a bit of work to construct the data needed for the plot above. The bayesplot package provides a number of posterior predicitive check (ppc) plots. These functions require two important inputs: y: a vector of response values – usually the values from the original data set. yrep: a matrix of simulated y values. Each row corresponds to one posterior sample. There is one column for each value of y. So the rows of yrep can be compared with y to see if the model is behaving well. Side note: We can compute our simulated \\(y\\) values using predictor values that are just like in our data or using other predictor values of our choosing. The second options lets on consider counterfactual situations. To distinguish these, some people use \\(y_rep\\) for the former and \\(\\tilde{y}\\) for the latter. Now all the work is in creating the yrep matrix. To simplify that, we will use CalvinBayes::posterior_calc(). We will do this two ways, once for average values of height and once for individual values of height (taking into account the variability from person to person as quantified by \\(\\nu\\), and \\(\\sigma\\). y_avg &lt;- posterior_calc( galtonC_jags, height ~ beta0 + beta1 * midparent, data = GaltonW) y_ind &lt;- posterior_calc( galtonC_jags, height ~ beta0 + beta1 * midparent + rt(nrow(GaltonW), df = nu) * sigma, data = GaltonW) The various posterior predictive check plots begin ppc_. Here is an example: ppc_intervals(GaltonW$height, y_avg, x = GaltonW$midparent) ppc_intervals(GaltonW$height, y_ind, x = GaltonW$midparent) If we want a ribbon, like in our plot above, we can almost get it, but ppc_ribbon() connects the dots in a way that isn’t useful for this model. ppc_ribbon(GaltonW$height, y_ind, x = GaltonW$midparent) Fortunately, we can request the data used to create the plot and make our own plot however we like. plot_data &lt;- ppc_ribbon_data(GaltonW$height, y_ind, x = GaltonW$midparent) glimpse(plot_data) ## Observations: 168 ## Variables: 10 ## $ y_id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22… ## $ y_obs &lt;dbl&gt; 69.0, 65.5, 65.0, 61.0, 64.5, 63.0, 66.5, 65.5, 64.0, 64.5, 68.0, 63.5, 67.5,… ## $ x &lt;dbl&gt; 72.75, 69.75, 67.50, 67.75, 68.00, 67.75, 67.75, 67.50, 67.00, 67.00, 68.00, … ## $ outer_width &lt;dbl&gt; 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.… ## $ inner_width &lt;dbl&gt; 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.… ## $ ll &lt;dbl&gt; 65.28, 63.12, 61.52, 61.55, 61.79, 61.59, 61.71, 61.51, 61.09, 61.01, 61.84, … ## $ l &lt;dbl&gt; 67.22, 65.02, 63.41, 63.52, 63.72, 63.51, 63.57, 63.39, 63.01, 62.98, 63.74, … ## $ m &lt;dbl&gt; 68.51, 66.32, 64.64, 64.78, 65.01, 64.79, 64.85, 64.63, 64.27, 64.26, 65.03, … ## $ h &lt;dbl&gt; 69.83, 67.62, 65.91, 66.07, 66.24, 66.07, 66.08, 65.89, 65.55, 65.55, 66.28, … ## $ hh &lt;dbl&gt; 71.79, 69.48, 67.85, 68.01, 68.18, 68.03, 68.04, 67.76, 67.44, 67.44, 68.18, … plot_data %&gt;% gf_ribbon(ll + hh ~ x, fill = &quot;steelblue&quot;) %&gt;% gf_ribbon(l + h ~ x, fill = &quot;steelblue&quot;) %&gt;% gf_line(m ~ x, color = &quot;steelblue&quot;) %&gt;% gf_point(y_obs ~ x, alpha = 0.5) plot_data %&gt;% gf_smooth(ll ~ x, color = &quot;steelblue&quot;) %&gt;% gf_smooth(hh ~ x, color= &quot;steelblue&quot;) %&gt;% gf_smooth(m ~ x, color= &quot;steelblue&quot;) %&gt;% gf_point(y_obs ~ x, alpha = 0.5) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; There are quite a number of these, but most only work for certain types of models. apropos(&quot;^ppc_&quot;) ## [1] &quot;ppc_bars&quot; &quot;ppc_bars_grouped&quot; &quot;ppc_boxplot&quot; ## [4] &quot;ppc_data&quot; &quot;ppc_dens&quot; &quot;ppc_dens_overlay&quot; ## [7] &quot;ppc_ecdf_overlay&quot; &quot;ppc_error_binned&quot; &quot;ppc_error_hist&quot; ## [10] &quot;ppc_error_hist_grouped&quot; &quot;ppc_error_scatter&quot; &quot;ppc_error_scatter_avg&quot; ## [13] &quot;ppc_error_scatter_avg_vs_x&quot; &quot;ppc_freqpoly&quot; &quot;ppc_freqpoly_grouped&quot; ## [16] &quot;ppc_hist&quot; &quot;ppc_intervals&quot; &quot;ppc_intervals_data&quot; ## [19] &quot;ppc_intervals_grouped&quot; &quot;ppc_loo_intervals&quot; &quot;ppc_loo_pit&quot; ## [22] &quot;ppc_loo_pit_overlay&quot; &quot;ppc_loo_pit_qq&quot; &quot;ppc_loo_ribbon&quot; ## [25] &quot;ppc_ribbon&quot; &quot;ppc_ribbon_data&quot; &quot;ppc_ribbon_grouped&quot; ## [28] &quot;ppc_rootogram&quot; &quot;ppc_scatter&quot; &quot;ppc_scatter_avg&quot; ## [31] &quot;ppc_scatter_avg_grouped&quot; &quot;ppc_stat&quot; &quot;ppc_stat_2d&quot; ## [34] &quot;ppc_stat_freqpoly_grouped&quot; &quot;ppc_stat_grouped&quot; &quot;ppc_violin_grouped&quot; 17.4.5 PPC with custom data We are not required to use the original data, we can make other data anyway we like. Since the only value from the data that we used was midparent, we can simply create a data frame with the midparent values that interest us. We might do this to see what the model things about some counterfactual situation or simply to have a less cluttered plot. Unfortunately, the ppc_ functions require y-values. We can trick them by supplying Inf. (NA does not work.) NewData &lt;- tibble( midparent = seq(60, 75, by = 1), height = Inf ) y_avg2 &lt;- posterior_calc( galtonC_jags, height ~ beta0 + beta1 * midparent, data = NewData) y_ind2 &lt;- posterior_calc( galtonC_jags, height ~ beta0 + beta1 * midparent + rt(1, df = nu) * sigma, data = NewData) ppc_intervals(NewData$height, y_avg2, x = NewData$midparent) %&gt;% gf_point(height ~ midparent, data = GaltonW, inherit = FALSE) ppc_intervals(NewData$height, y_ind2, x = NewData$midparent) %&gt;% gf_point(height ~ midparent, data = GaltonW, inherit = FALSE) ppc_ribbon(NewData$height, y_ind2, x = NewData$midparent) %&gt;% gf_point(height ~ midparent, data = GaltonW, inherit = FALSE) 17.5 Fitting models with Stan Centering (or standardizing) is sufficient to make JAGS efficient enough to use. But we can also use Stan, and since Stan is not bothered by correlation in the posterior the way JAGS is, Stan works well even without reparamterizing the model. Here is the Stan equivalent to our original JAGS model. data { int&lt;lower=0&gt; N; // N is a non-negative integer vector[N] y; // y is a length-N vector of reals vector[N] x; // x is a length-N vector of reals } parameters { real beta0; real beta1; real&lt;lower=0&gt; sigma; real&lt;lower=0&gt; nuMinusOne; } transformed parameters{ real&lt;lower=0&gt; nu; nu = nuMinusOne + 1; } model { // we could use a for loop like this: // for (i in 1:N) { // y[i] ~ student_t(nu, beta0 + beta1 * x[i], sigma); //} // but vectorization makes things terser: y ~ student_t(nu, beta0 + beta1 * x, sigma); beta0 ~ normal(0, 100); beta1 ~ normal(0, 4); sigma ~ uniform(6.0 / 100.0, 6.0 * 100.0); nuMinusOne ~ exponential(1/29.0); } library(rstan) galton_stanfit &lt;- sampling( galton_stan, data = list( N = nrow(GaltonW), x = GaltonW$midparent, y = GaltonW$height ), chains = 4, iter = 2000, warmup = 1000 ) Note that the slope and intercept parameters remain correlated in the posterior, but this doesn’t bother Stan the way it bothers JAGS. galton_stanfit ## Inference for Stan model: 210145742d5cefe996c77a84ec632eb5. ## 4 chains, each with iter=2000; warmup=1000; thin=1; ## post-warmup draws per chain=1000, total post-warmup draws=4000. ## ## mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat ## beta0 14.67 0.15 5.38 3.96 11.06 14.68 18.13 25.29 1312 1 ## beta1 0.74 0.00 0.08 0.58 0.69 0.74 0.79 0.90 1305 1 ## sigma 1.84 0.00 0.13 1.59 1.75 1.84 1.92 2.09 1611 1 ## nuMinusOne 32.15 0.72 27.52 5.28 13.47 23.59 41.91 105.11 1460 1 ## nu 33.15 0.72 27.52 6.28 14.47 24.59 42.91 106.11 1460 1 ## lp__ -250.00 0.04 1.40 -253.72 -250.68 -249.66 -248.99 -248.32 1420 1 ## ## Samples were drawn using NUTS(diag_e) at Wed May 8 14:56:18 2019. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split chains (at ## convergence, Rhat=1). gf_point(beta1 ~ beta0, data = posterior(galton_stanfit), alpha = 0.5) mcmc_combo(as.mcmc.list(galton_stanfit), pars = c(&quot;beta0&quot;, &quot;beta1&quot;, &quot;sigma&quot;, &quot;nu&quot;)) 17.6 Two Intercepts model In the example above we have been dealing with the women alone, but we can build a model that handles men and women at the same time. One such model is the “mutliple intercpets” model. In this model, both groups (men and women) will have the same slope, but the intercepts are allowed to differ. Note: Because the distribution of nu is skewed, we are computing \\(log_{10}(\\nu)\\) in this model. \\(\\log_{10}(30) \\approx 1.5\\). data { int&lt;lower=0&gt; N; // N is a non-negative integer vector[N] y; // y is a length-N vector of reals vector[N] x; // x is a length-N vector of reals int&lt;lower=0&gt; g[N]; // g is a length-N vector of integers (for groups) } parameters { real beta0; real beta1; real beta2; real&lt;lower=0&gt; sigma; real&lt;lower=0&gt; nuMinusOne; } transformed parameters{ real&lt;lower=0&gt; log10nu; real&lt;lower=0&gt; nu; nu = nuMinusOne + 1; log10nu = log10(nu); } model { for (i in 1:N) { y[i] ~ student_t(nu, beta0 + beta1 * x[i] + beta2 * g[i], sigma); } beta0 ~ normal(0, 100); beta1 ~ normal(0, 4); beta2 ~ normal(0, 4); sigma ~ uniform(6.0 / 100.0, 6.0 * 100.0); nuMinusOne ~ exponential(1/29.0); } library(rstan) set.seed(12345) GaltonBoth &lt;- mosaicData::Galton %&gt;% mutate(midparent = (father + mother)/2, group = as.numeric(factor(sex)) - 1) %&gt;% # 0s and 1s group_by(family) %&gt;% sample_n(1) galton2_stanfit &lt;- sampling( galton2_stan, data = list( N = nrow(GaltonBoth), x = GaltonBoth$midparent, y = GaltonBoth$height, g = GaltonBoth$group # 0s and 1s ), chains = 4, iter = 2000, warmup = 1000 ) galton2_stanfit ## Inference for Stan model: 867602e844da9001ddd6fca37724a70c. ## 4 chains, each with iter=2000; warmup=1000; thin=1; ## post-warmup draws per chain=1000, total post-warmup draws=4000. ## ## mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat ## beta0 23.72 0.15 5.83 12.07 20.03 23.72 27.65 35.03 1441 1 ## beta1 0.60 0.00 0.09 0.44 0.55 0.60 0.66 0.78 1447 1 ## beta2 5.23 0.01 0.32 4.59 5.02 5.24 5.46 5.84 2289 1 ## sigma 2.09 0.00 0.13 1.84 2.00 2.09 2.18 2.34 2240 1 ## nuMinusOne 36.01 0.57 27.62 6.79 16.18 28.16 47.52 107.40 2352 1 ## log10nu 1.46 0.01 0.31 0.89 1.24 1.46 1.69 2.04 2141 1 ## nu 37.01 0.57 27.62 7.79 17.18 29.16 48.52 108.40 2352 1 ## lp__ -317.92 0.04 1.59 -321.86 -318.77 -317.57 -316.76 -315.82 1470 1 ## ## Samples were drawn using NUTS(diag_e) at Sat Apr 13 13:42:54 2019. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split chains (at ## convergence, Rhat=1). galton2_mcmc &lt;- as.mcmc.list(galton2_stanfit) Post_galton2 &lt;- posterior(galton2_stanfit) mcmc_combo(galton2_mcmc, regex_pars = c(&quot;beta&quot;, &quot;sigma&quot;, &quot;log10nu&quot;)) plot_post(Post_galton2$beta2, xlab = &quot;beta2&quot;, hdi_prob = 0.95) ## $posterior ## ESS mean median mode ## var1 2342 5.234 5.238 5.228 ## ## $hdi ## prob lo hi ## 1 0.95 4.582 5.825 mcmc_pairs(galton2_mcmc, regex_pars = &quot;beta&quot;, off_diag_fun = &quot;hex&quot;) mcmc_areas(galton2_mcmc, regex_pars = &quot;beta2&quot;, prob = 0.95) mcmc_areas(galton2_mcmc, regex_pars = &quot;log10nu&quot;, prob = 0.95) head(GaltonBoth, 3) ## # A tibble: 3 x 8 ## # Groups: family [3] ## family father mother sex height nkids midparent group ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 78.5 67 F 69 4 72.8 0 ## 2 10 74 65.5 F 65.5 1 69.8 0 ## 3 100 69 66 M 70 3 67.5 1 yind &lt;- posterior_calc( galton2_stanfit, yind ~ beta0 + beta1 * midparent + beta2 * group + rt(nrow(GaltonBoth), df = nu) * sigma, data = GaltonBoth ) ppc_intervals_grouped( GaltonBoth$height, yind, group = GaltonBoth$sex, x = GaltonBoth$midparent) ppc_data &lt;- ppc_intervals_data( GaltonBoth$height, yind, group = GaltonBoth$sex, x = GaltonBoth$midparent) glimpse(ppc_data) ## Observations: 197 ## Variables: 11 ## $ y_id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22… ## $ y_obs &lt;dbl&gt; 69.0, 65.5, 70.0, 66.0, 68.0, 73.0, 67.5, 66.0, 65.5, 64.0, 70.0, 68.0, 66.0,… ## $ group &lt;fct&gt; F, F, M, M, M, M, M, F, F, F, M, M, F, M, F, M, M, M, M, F, M, M, F, F, F, M,… ## $ x &lt;dbl&gt; 72.75, 69.75, 67.50, 67.85, 67.50, 67.75, 68.00, 67.75, 67.75, 67.50, 67.00, … ## $ outer_width &lt;dbl&gt; 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.… ## $ inner_width &lt;dbl&gt; 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.… ## $ ll &lt;dbl&gt; 64.00, 62.39, 66.05, 66.41, 66.09, 66.26, 66.27, 61.05, 61.01, 61.05, 65.83, … ## $ l &lt;dbl&gt; 66.28, 64.49, 68.36, 68.57, 68.32, 68.46, 68.56, 63.21, 63.23, 63.23, 68.01, … ## $ m &lt;dbl&gt; 67.75, 65.89, 69.83, 69.95, 69.76, 69.92, 70.02, 64.67, 64.66, 64.63, 69.47, … ## $ h &lt;dbl&gt; 69.22, 67.32, 71.24, 71.40, 71.09, 71.43, 71.56, 66.16, 66.08, 66.01, 70.92, … ## $ hh &lt;dbl&gt; 71.52, 69.44, 73.52, 73.60, 73.27, 73.54, 73.68, 68.35, 68.31, 68.16, 73.12, … gf_ribbon(ll + hh ~ x, fill = ~ group, data = ppc_data) %&gt;% gf_ribbon(l + h ~ x, fill = ~ group, data = ppc_data) %&gt;% gf_point(y_obs ~ x, color = ~ group, data = ppc_data) %&gt;% gf_facet_grid(group ~ .) So what do we learn from all of the ouput above? Diagnostics suggest that the model is converging appropriately. Posterior predicitive checks don’t show any major disagreements between the model and the data. (So our restriction that the slopes of the lines be the same for men and women seems OK.) The “noise distribution” seems well approximated with a normal distribution (The majoritiy of the posterior distibution for \\(\\log_{10}(\\nu)\\) is above 1.5.) hdi(posterior(galton2_stanfit), regex_pars = &quot;nu&quot;, prob = 0.90) par lo hi mode prob nuMinusOne 4.1442 73.403 11.744 0.9 log10nu 0.9737 1.958 1.566 0.9 nu 5.1442 74.403 12.744 0.9 * *Note: HDIs are not transformation invariant because typically the transformation alterns the shape of the posterior.* The new feature of this model is \\(\\beta_2\\), which quantifies the difference in average heights of men and women whose parents have the same heights. Here’s the 95% HPDI for \\(\\beta_2\\) (along with the slope and intercept): hdi(posterior(galton2_stanfit), regex_pars = &quot;beta&quot;) par lo hi mode prob beta0 12.5363 35.456 22.1604 0.95 beta1 0.4333 0.774 0.5954 0.95 beta2 4.5819 5.825 5.1697 0.95 We could let other things differ accross groups as well: slopes, sigmas, nu, etc. 17.7 Exercises Use Galton’s data on the men to estimate The average of height of men whose parents are 65 and 72 inches tall. The middle 50% of heights of men whose parents are 65 and 72 inches tall. You may use either JAGS or Stan. When centering, why did we center x but not y? "],
["multiple-metric-predictors.html", "18 Multiple Metric Predictors 18.1 SAT 18.2 Interaction 18.3 Fitting a linear model with brms 18.4 Interpretting a model with an interaction term 18.5 Exercises", " 18 Multiple Metric Predictors 18.1 SAT 18.1.1 SAT vs expenditure Does spending more on education result in higher SAT scores? Data from 1999 (published in a paper by Gruber) can be used to explore this question. Among other things, the data includes average total SAT score (on a 400-1600 scale) and the amount of money spent on education (in 1000s of dollars per student) in each state. As a first attempt, we could fit a linear model (sat ~ expend). Using centering, the core of the model looks like this: for (i in 1:length(y)) { y[i] ~ dt(mu[i], 1/sigma^2, nu) mu[i] &lt;- alpha0 + alpha1 * (x[i] - mean(x)) } alpha1 measures how much better SAT performance is for each $1000 spent on education in a state. To fit the model, we need priors on our four parameters: nu: We can use our usual shifted exponential. sigma: {Unif}(?, ?) alpha0: {Norm}(?, ?) alpha1: {Norm}(0, ?) The question marks depend on the scale of our variables. If we build those into our model, and provide the answers as part of our data, we can use the same model for multiple data sets, even if they are at different scales. sat_model &lt;- function() { for (i in 1:length(y)) { y[i] ~ dt(mu[i], 1/sigma^2, nu) mu[i] &lt;- alpha0 + alpha1 * (x[i] - mean(x)) } nuMinusOne ~ dexp(1/29.0) nu &lt;- nuMinusOne + 1 alpha0 ~ dnorm(alpha0mean, 1 / alpha0sd^2) alpha1 ~ dnorm(0, 1 / alpha1sd^2) sigma ~ dunif(sigma_lo, sigma_hi * 1000) log10nu &lt;- log(nu) / log(10) # log10(nu) beta0 &lt;- alpha0 - mean(x) * alpha1 # true intercept } So how do we fill in the question marks for this data set? sigma: {Unif}(?,?) This quantifies the amount of variation from state to state among states that have the same per student expenditure. The scale of the SAT ranges from 400 to 1600. Statewide averages will not be near the extremes of this scale. A 6-order of maginitude window around 1 gives {Unif}(0.001, 1000), both ends of which are plenty far from what we think is reasonable. alpha0: {Norm}(?, ?) alpha0 measures the average SAT score for states that spend an average amount. Since average SATs are around 1000, something like {Norm}(1000, 100) seems reasable. alpha1: {Norm}(0, ?) This is the trickiest one. The slope of a regression line can’t be much more than \\(\\frac{SD_y}{SD_x}\\), so we can either estimate that ratio or compute it from our data to guide our choice of prior. library(R2jags) sat_jags &lt;- jags( model = sat_model, data = list( y = SAT$sat, x = SAT$expend, alpha0mean = 1000, # SAT scores are roughly 500 + 500 alpha0sd = 100, # broad prior on scale of 400 - 1600 alpha1sd = 4 * sd(SAT$sat) / sd(SAT$expend), sigma_lo = 0.001, # 3 o.m. less than 1 sigma_hi = 1000 # 3 o.m. greater than 1 ), parameters.to.save = c(&quot;nu&quot;, &quot;log10nu&quot;, &quot;alpha0&quot;, &quot;beta0&quot;, &quot;alpha1&quot;, &quot;sigma&quot;), n.iter = 4000, n.burnin = 1000, n.chains = 3 ) sat_jags ## Inference for Bugs model at &quot;/var/folders/py/txwd26jx5rq83f4nn0f5fmmm0000gn/T//RtmpTihjvE/model25213bcb904b.txt&quot;, fit using jags, ## 3 chains, each with 4000 iterations (first 1000 discarded), n.thin = 3 ## n.sims = 3000 iterations saved ## mu.vect sd.vect 2.5% 25% 50% 75% 97.5% Rhat n.eff ## alpha0 966.30 10.477 945.217 959.654 966.396 973.052 987.086 1.001 3000 ## alpha1 -21.40 7.370 -36.165 -26.181 -21.389 -16.622 -6.772 1.001 2700 ## beta0 1092.68 45.112 1003.147 1063.878 1092.556 1121.854 1182.939 1.001 2100 ## log10nu 1.51 0.328 0.823 1.295 1.524 1.744 2.105 1.001 3000 ## nu 42.31 32.618 6.659 19.731 33.425 55.419 127.370 1.001 3000 ## sigma 69.95 7.860 56.467 64.621 69.186 74.728 87.222 1.001 3000 ## deviance 568.53 2.742 565.260 566.512 567.872 569.868 575.345 1.002 2700 ## ## For each parameter, n.eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor (at convergence, Rhat=1). ## ## DIC info (using the rule, pD = var(deviance)/2) ## pD = 3.8 and DIC = 572.3 ## DIC is an estimate of expected predictive error (lower deviance is better). diag_mcmc(as.mcmc(sat_jags)) mcmc_combo(as.mcmc(sat_jags)) Our primary interest is alpha1. summary_df(sat_jags) %&gt;% filter(param == &quot;alpha1&quot;) param mean sd 2.5% 25% 50% 75% 97.5% Rhat n.eff alpha1 -21.4 7.37 -36.16 -26.18 -21.39 -16.62 -6.772 1.001 2700 plot_post(posterior(sat_jags)$alpha1, xlab = &quot;alpha1&quot;, ROPE = c(-5, 5)) ## $posterior ## ESS mean median mode ## var1 3000 -21.4 -21.39 -21.16 ## ## $hdi ## prob lo hi ## 1 0.95 -36.24 -6.892 ## ## $ROPE ## lo hi P(&lt; ROPE) P(in ROPE) P(&gt; ROPE) ## 1 -5 5 0.986 0.01367 0.0003333 hdi(posterior(sat_jags), pars = &quot;alpha1&quot;, prob = 0.95) par lo hi mode prob alpha1 -36.24 -6.892 -20.56 0.95 This seems odd: Nearly all the credible values for alpha1 are negative? Can we really raise SAT scores by cutting funding to schools? Maybe we should look at the raw data with our model overlaid. gf_point(sat ~ expend, data = SAT) %&gt;% gf_abline(slope = ~ alpha1, intercept = ~ beta0, data = posterior(sat_jags) %&gt;% sample_n(2000), alpha = 0.01, color = &quot;steelblue&quot;) That’s a lot of scatter, and the negative trend is heavily influenced by the 4 states that spend the most (and have relatively low SAT scores). We could do a bit more with this model, for exapmle we could * fit without those 4 states to see how much they are driving the negative trend; * do some PPC to see if the model is reasonable. But instead will will explore another model, one that has two predictors. 18.1.2 SAT vs expenditure and percent taking the test We have some additional data about each state. Let’s fit a model with two predictors: expend and frac. SAT %&gt;% head(4) state expend ratio salary frac verbal math sat Alabama 4.405 17.2 31.14 8 491 538 1029 Alaska 8.963 17.6 47.95 47 445 489 934 Arizona 4.778 19.3 32.17 27 448 496 944 Arkansas 4.459 17.1 28.93 6 482 523 1005 Here’s our model for (robust) multiple linear regression: 18.1.2.1 JAGS Coding it in JAGS requires adding in the additional predictor: sat_model2 &lt;- function() { for (i in 1:length(y)) { y[i] ~ dt(mu[i], 1/sigma^2, nu) mu[i] &lt;- alpha0 + alpha1 * (x1[i] - mean(x1)) + alpha2 * (x2[i] - mean(x2)) } nuMinusOne ~ dexp(1/29.0) nu &lt;- nuMinusOne + 1 alpha0 ~ dnorm(alpha0mean, 1 / alpha0sd^2) alpha1 ~ dnorm(0, 1 / alpha1sd^2) alpha2 ~ dnorm(0, 1 / alpha2sd^2) sigma ~ dunif(sigma_lo, sigma_hi * 1000) beta0 &lt;- alpha0 - mean(x1) * alpha1 - mean(x2) * alpha2 log10nu &lt;- log(nu) / log(10) } library(R2jags) sat2_jags &lt;- jags( model = sat_model2, data = list( y = SAT$sat, x1 = SAT$expend, x2 = SAT$frac, alpha0mean = 1000, # SAT scores are roughly 500 + 500 alpha0sd = 100, # broad prior on scale of 400 - 1600 alpha1sd = 4 * sd(SAT$sat) / sd(SAT$expend), alpha2sd = 4 * sd(SAT$sat) / sd(SAT$frac), sigma_lo = 0.001, sigma_hi = 1000 ), parameters.to.save = c(&quot;log10nu&quot;, &quot;alpha0&quot;, &quot;alpha1&quot;, &quot;alpha2&quot;, &quot;beta0&quot;,&quot;sigma&quot;), n.iter = 4000, n.burnin = 1000, n.chains = 3 ) sat2_jags ## Inference for Bugs model at &quot;/var/folders/py/txwd26jx5rq83f4nn0f5fmmm0000gn/T//RtmpTihjvE/model252169ba9137.txt&quot;, fit using jags, ## 3 chains, each with 4000 iterations (first 1000 discarded), n.thin = 3 ## n.sims = 3000 iterations saved ## mu.vect sd.vect 2.5% 25% 50% 75% 97.5% Rhat n.eff ## alpha0 965.801 4.754 956.565 962.669 965.735 968.869 975.316 1.001 3000 ## alpha1 12.906 4.345 4.138 10.061 12.994 15.709 21.563 1.001 3000 ## alpha2 -2.885 0.225 -3.318 -3.039 -2.885 -2.734 -2.441 1.001 2000 ## beta0 991.250 22.164 947.709 976.934 990.995 1006.116 1035.153 1.001 3000 ## log10nu 1.379 0.367 0.661 1.118 1.393 1.642 2.048 1.001 2600 ## sigma 31.586 3.807 24.563 28.947 31.409 34.047 39.761 1.001 3000 ## deviance 491.060 3.010 487.234 488.830 490.421 492.588 498.706 1.001 2100 ## ## For each parameter, n.eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor (at convergence, Rhat=1). ## ## DIC info (using the rule, pD = var(deviance)/2) ## pD = 4.5 and DIC = 495.6 ## DIC is an estimate of expected predictive error (lower deviance is better). diag_mcmc(as.mcmc(sat2_jags)) mcmc_combo(as.mcmc(sat2_jags)) summary_df(sat2_jags) %&gt;% filter(param == &quot;alpha1&quot;) param mean sd 2.5% 25% 50% 75% 97.5% Rhat n.eff alpha1 12.91 4.345 4.138 10.06 12.99 15.71 21.56 1.001 3000 plot_post(posterior(sat2_jags)$alpha1, xlab = &quot;alpha1&quot;, ROPE = c(-5, 5)) ## $posterior ## ESS mean median mode ## var1 2662 12.91 12.99 13.58 ## ## $hdi ## prob lo hi ## 1 0.95 3.742 21.12 ## ## $ROPE ## lo hi P(&lt; ROPE) P(in ROPE) P(&gt; ROPE) ## 1 -5 5 0 0.03733 0.9627 hdi(posterior(sat2_jags), pars = &quot;alpha1&quot;, prob = 0.95) par lo hi mode prob alpha1 3.742 21.12 12.97 0.95 summary_df(sat2_jags) %&gt;% filter(param == &quot;alpha2&quot;) param mean sd 2.5% 25% 50% 75% 97.5% Rhat n.eff alpha2 -2.885 0.225 -3.317 -3.039 -2.885 -2.734 -2.441 1.002 2000 plot_post(posterior(sat2_jags)$alpha2, xlab = &quot;alpha2&quot;) ## $posterior ## ESS mean median mode ## var1 2504 -2.885 -2.885 -2.88 ## ## $hdi ## prob lo hi ## 1 0.95 -3.329 -2.465 hdi(posterior(sat2_jags), pars = &quot;alpha2&quot;, prob = 0.95) par lo hi mode prob alpha2 -3.329 -2.465 -2.921 0.95 18.1.3 What’s wrong with this picture? gf_point(sat ~ expend, data = SAT) %&gt;% gf_abline(slope = ~ alpha1, intercept = ~ beta0, data = posterior(sat2_jags) %&gt;% sample_n(2000), alpha = 0.01, color = &quot;steelblue&quot;) 18.1.4 Multiple predictors in pictures Interpretting coefficients in a model with multiple predictors is less straightforward that it is in a model with one predictor if those predictors happen to be correlated, as they are in the case of the SAT example above: gf_point(expend ~ frac, data = SAT) 18.1.4.1 If the predictors are uncorrelated Let’s start with the easier case when the predictors are not correlated. 18.1.4.2 Correlated predictors 18.1.4.3 SAT model 18.1.4.4 So how do we interpret? Interpreting the parameters of a multiple regression model is a bit more subtle than it was for simple linear regression where \\(\\beta_0\\) and \\(\\beta_1\\) could be interpreted as the intercept and slope of a linear relationship between the response and the predictor. It is tempting to interpret \\(\\beta_i\\) as how much the response increases (on average) if \\(x_i\\) is increased by \\(1\\) , but this does not correctly take into account the other variables in the regression. Tukey described the coefficients of a multiple regression model this way: \\(\\beta_i\\) tells how the response (\\(Y\\)) responds to change in \\(x_i\\) after adjusting for simultaneous linear change in the other predictors in the data at hand&quot; (Tukey, 1970, Chapter 23). More recently, Hoaglin (Hoaglin, 2016) has written about the perils of theall other predictors held constant&quot; misunderstanding of coefficients in multiple regression. We will continue to refine the interpretation of multiple regression coefficients as we see examples, but we can already give some reasons why the ``all other variables being held constant&quot; interpretation fails. In many situations, it really isn’t possible to adjust one predictor without other predictors simultaneously changing. Imagine, for example, an economic model that includes predictors like inflation rate, interest rates, unemployment rates, etc. A government can take action to affect a variable like interest rates, but that may result in changes to the other predictors as well. When predictor variables are correlated, interpretation can become subtle. For example, if \\(x_1\\) and \\(x_2\\) are negatively correlated and \\(\\beta_1\\) and \\(\\beta_2\\) are both positive, it is possible that an increase \\(x_1\\) could be associated with a in \\(Y\\) because as \\(x_1\\) increases, \\(x_2\\) will tend to decrease, and the negative influence on \\(Y\\) from the decrease in \\(x_2\\) could be larger than the positive influence on \\(Y\\) from the increase in \\(x_1\\). In this situation, \\(\\beta_1 &gt; 0\\) indicates that (which in this example are associated with a decrease in \\(Y\\)), \\(Y\\) tends to increase as \\(x_1\\) increases. 18.1.4.4.1 Flights example In his 2016 eCOTS presentation , Andrew Gelman discussed a paper that used models with several predictors to study the causes of air rage (upset passengers on commercial airlines). Among the regressors were things like the presence of first class seats, whether passengers boarded from the front, size of the aircraft, length of the flight, whether the flight was international, physical characteristics of economy and first class seats, and several others. Among the conclusions of the paper were these: ``Physical inequality on airplanes – that is, the presence of a first class cabin – is associated with more frequent air rage incidents in economy class. Situational inequality – boarding from the front (requiring walking through the first class cabin) versus the middle of the plane – also significantly increases the odds of air rage in both economy and first class. We show that physical design that highlights inequality can trigger antisocial behavior on airplanes.&quot; But since front-boarding planes with first class compartments tend to be larger, and take longer flights, one must be very careful to avoid a ``while holding all other variables fixed&quot; interpretation. 18.2 Interaction The model above could be called a ``parallel slopes&quot; model since we can rewrite \\[\\begin{align*} y &amp;= \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\mathrm{noise} \\\\ y &amp;= (\\beta_0 + \\beta_1 x_1) + \\beta_2 x_2 + \\mathrm{noise} \\\\ y &amp;= (\\beta_0 + \\beta_2 x_2) + \\beta_1 x_1 + \\mathrm{noise} \\end{align*}\\] So the slope of \\(y\\) with respect to \\(x_i\\) is constant, no matter what value the other predictor has. (The intercept changes as we change the other predictor, however.) If we want a model that allows the slopes to also change with the other predictor, we can add in an interaction term: \\[\\begin{align*} y &amp;= \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_1 x_2 \\mathrm{noise} \\\\ y &amp;= (\\beta_0 + \\beta_1 x_1) + (\\beta_2 + \\beta_3 x_1) x_2 + \\mathrm{noise} \\\\ y &amp;= (\\beta_0 + \\beta_2 x_2) + (\\beta_1 + \\beta_3 x_2) x_1\\mathrm{noise} \\end{align*}\\] 18.2.1 SAT with interaction term sat_model3 &lt;- function() { for (i in 1:length(y)) { y[i] ~ dt(mu[i], 1/sigma^2, nu) mu[i] &lt;- alpha0 + alpha1 * (x1[i] - mean(x1)) + alpha2 * (x2[i] - mean(x2)) + alpha3 * (x3[i] - mean(x3)) } nuMinusOne ~ dexp(1/29.0) nu &lt;- nuMinusOne + 1 alpha0 ~ dnorm(alpha0mean, 1 / alpha0sd^2) alpha1 ~ dnorm(0, 1 / alpha1sd^2) alpha2 ~ dnorm(0, 1 / alpha2sd^2) alpha3 ~ dnorm(0, 1 / alpha3sd^2) sigma ~ dunif(sigma_lo, sigma_hi) beta0 &lt;- alpha0 - mean(x1) * alpha1 - mean(x2) * alpha2 log10nu &lt;- log(nu) / log(10) } 18.2.1.1 JAGS library(R2jags) sat3_jags &lt;- jags( model = sat_model3, data = list( y = SAT$sat, x1 = SAT$expend, x2 = SAT$frac, x3 = SAT$frac * SAT$expend, alpha0mean = 1000, # SAT scores are roughly 500 + 500 alpha0sd = 100, # broad prior on scale of 400 - 1600 alpha1sd = 4 * sd(SAT$sat) / sd(SAT$expend), alpha2sd = 4 * sd(SAT$sat) / sd(SAT$frac), alpha3sd = 4 * sd(SAT$sat) / sd(SAT$frac * SAT$expend), sigma_lo = 0.001, sigma_hi = 1000 ), parameters.to.save = c(&quot;log10nu&quot;, &quot;alpha0&quot;, &quot;alpha1&quot;, &quot;alpha2&quot;, &quot;alpha3&quot;, &quot;beta0&quot;,&quot;sigma&quot;), n.iter = 20000, n.burnin = 1000, n.chains = 3 ) sat3_jags ## Inference for Bugs model at &quot;/var/folders/py/txwd26jx5rq83f4nn0f5fmmm0000gn/T//RtmpTihjvE/model25213744f65b.txt&quot;, fit using jags, ## 3 chains, each with 20000 iterations (first 1000 discarded), n.thin = 19 ## n.sims = 3000 iterations saved ## mu.vect sd.vect 2.5% 25% 50% 75% 97.5% Rhat n.eff ## alpha0 965.850 4.619 956.619 962.852 965.816 968.980 974.627 1.002 2000 ## alpha1 1.800 8.261 -14.382 -3.641 1.797 7.296 18.418 1.001 3000 ## alpha2 -4.194 0.845 -5.885 -4.740 -4.196 -3.636 -2.569 1.001 3000 ## alpha3 0.225 0.140 -0.046 0.135 0.225 0.315 0.508 1.001 3000 ## beta0 1103.008 73.409 956.184 1055.468 1102.679 1150.494 1248.924 1.001 3000 ## log10nu 1.400 0.364 0.672 1.155 1.417 1.662 2.063 1.001 3000 ## sigma 31.154 3.736 24.399 28.571 31.000 33.527 39.057 1.002 1400 ## deviance 489.127 3.440 484.564 486.603 488.454 490.832 497.655 1.003 1200 ## ## For each parameter, n.eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor (at convergence, Rhat=1). ## ## DIC info (using the rule, pD = var(deviance)/2) ## pD = 5.9 and DIC = 495.0 ## DIC is an estimate of expected predictive error (lower deviance is better). diag_mcmc(as.mcmc(sat3_jags)) mcmc_combo(as.mcmc(sat3_jags)) mcmc_pairs(as.mcmc(sat3_jags), regex_pars = &quot;alpha&quot;) 18.3 Fitting a linear model with brms The brms package provides a simplified way of describing generalized linear models and fitting them with Stan. The brm() function turns a terse description of the model into Stan code, compiles it, and runs it. Here’s a linear model with sat as response, and expend, frac, and an interaction as predictors. (The * means include the interaction term. If we used + instead, we would not get the interaction term.) library(brms) sat3_brm &lt;- brm(sat ~ expend * frac, data = SAT) ## Compiling the C++ model ## Start sampling sat3_stan &lt;- stanfit(sat3_brm) Stan handles the correlated parameters a bit better than JAGS (but also takes a bit longer to compile and run for simple models). sat3_stan ## Inference for Stan model: cdbc2f76b7d44b10135d8d5c2b383017. ## 4 chains, each with iter=2000; warmup=1000; thin=1; ## post-warmup draws per chain=1000, total post-warmup draws=4000. ## ## mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat ## b_Intercept 1057.00 1.15 43.89 971.81 1027.22 1056.75 1086.88 1144.36 1454 1 ## b_expend 0.64 0.21 8.15 -15.75 -4.81 0.67 6.20 16.23 1523 1 ## b_frac -4.25 0.02 0.85 -5.89 -4.81 -4.23 -3.66 -2.61 1420 1 ## b_expend:frac 0.24 0.00 0.14 -0.03 0.14 0.24 0.33 0.51 1337 1 ## sigma 32.56 0.08 3.56 26.60 30.04 32.22 34.80 40.31 2144 1 ## lp__ -251.39 0.05 1.69 -255.58 -252.27 -251.06 -250.17 -249.13 1316 1 ## ## Samples were drawn using NUTS(diag_e) at Sat Apr 13 13:44:48 2019. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split chains (at ## convergence, Rhat=1). mcmc_combo(as.mcmc.list(sat3_stan)) We can use stancode() to extract the Stan code used to fit the model. brms::stancode(sat3_brm) ## // generated with brms 2.7.0 ## functions { ## } ## data { ## int&lt;lower=1&gt; N; // total number of observations ## vector[N] Y; // response variable ## int&lt;lower=1&gt; K; // number of population-level effects ## matrix[N, K] X; // population-level design matrix ## int prior_only; // should the likelihood be ignored? ## } ## transformed data { ## int Kc = K - 1; ## matrix[N, K - 1] Xc; // centered version of X ## vector[K - 1] means_X; // column means of X before centering ## for (i in 2:K) { ## means_X[i - 1] = mean(X[, i]); ## Xc[, i - 1] = X[, i] - means_X[i - 1]; ## } ## } ## parameters { ## vector[Kc] b; // population-level effects ## real temp_Intercept; // temporary intercept ## real&lt;lower=0&gt; sigma; // residual SD ## } ## transformed parameters { ## } ## model { ## vector[N] mu = temp_Intercept + Xc * b; ## // priors including all constants ## target += student_t_lpdf(temp_Intercept | 3, 946, 85); ## target += student_t_lpdf(sigma | 3, 0, 85) ## - 1 * student_t_lccdf(0 | 3, 0, 85); ## // likelihood including all constants ## if (!prior_only) { ## target += normal_lpdf(Y | mu, sigma); ## } ## } ## generated quantities { ## // actual population-level intercept ## real b_Intercept = temp_Intercept - dot_product(means_X, b); ## } Some comments on the code data { int&lt;lower=1&gt; N; // total number of observations vector[N] Y; // response variable int&lt;lower=1&gt; K; // number of population-level effects matrix[N, K] X; // population-level design matrix int prior_only; // should the likelihood be ignored? } transformed data { int Kc = K - 1; matrix[N, K - 1] Xc; // centered version of X vector[K - 1] means_X; // column means of X before centering for (i in 2:K) { means_X[i - 1] = mean(X[, i]); Xc[, i - 1] = X[, i] - means_X[i - 1]; } } The design matrix X has a column of 1’s followed by a column for each predictor. K is the number of coluns in the design matrix. Xc omits the column of 1’s and centers the other predictors by subtracting their means. Kc is the number of columns in this matrix (so it is one less than K) the compuation of Xc happens in the for loop, which starts at 2 to omit that first column of 1’s. We can use standata() to show the data brm() passes to Stan. standata(sat3_brm) %&gt;% lapply(head) # truncte the output to save some space ## $N ## [1] 50 ## ## $Y ## [1] 1029 934 944 1005 902 980 ## ## $K ## [1] 4 ## ## $X ## Intercept expend frac expend:frac ## 1 1 4.405 8 35.24 ## 2 1 8.963 47 421.26 ## 3 1 4.778 27 129.01 ## 4 1 4.459 6 26.75 ## 5 1 4.992 45 224.64 ## 6 1 5.443 29 157.85 ## ## $prior_only ## [1] 0 parameters { vector[Kc] b; // population-level effects real temp_Intercept; // temporary intercept real&lt;lower=0&gt; sigma; // residual SD } b is equivalent to \\(\\langle \\alpha_1, \\alpha_2, \\alpha_3 \\rangle\\) (which is the same as \\(\\langle \\beta_1, \\beta_2, \\beta_3 \\rangle\\)). temp_Intercept is equivalent to \\(\\alpha_0\\). sigma is just as it has been in our previous models. model { vector[N] mu = temp_Intercept + Xc * b; // priors including all constants target += student_t_lpdf(temp_Intercept | 3, 946, 85); target += student_t_lpdf(sigma | 3, 0, 85) - 1 * student_t_lccdf(0 | 3, 0, 85); // likelihood including all constants if (!prior_only) { target += normal_lpdf(Y | mu, sigma); } } target is the main thing being calculated – typically the log of the posterior, but there is an option to compute the log of the prior instead by setting prior_only to true. You can see that setting prior_only true omits the likelihood portion. The parts of the log posterior are added together using +=. This is equivalent to multiplying on the non-log scale. The first two lines handle the prior; the third line, the likelihood. student_t_lpdf() is the log of the pdf of a t distribution. (Notice how this function uses | to separate its main input from the parameters). The priors for temp_Intercept and sigma are t distributions with 3 degrees of freedom. (The brm() wrapper function must be using the data to suggest \\(\\mu\\) and \\(\\sigma\\) where needed. This is much like the order of magnitude reasoning we have been doing.) It appears that there are components of the prior for temp_Intercept and for sigma, but not for b. This means that the log-prior for b is 0, so the prior is 1. That is, the default in brms is to use an improper flat prior (1 everywhere). We’ll see how to adjust that momentarily. - 1 * student_t_lccdf(0 | 3, 0, 85) is adding a normalizing constant to the prior (and hence to the posterior). normal_lpdf() indicates that this model is using normal noise. generated quantities { real b_Intercept = temp_Intercept - dot_product(means_X, b); } This recovers the ``actual&quot; intercept. It is equivalent to \\[\\begin{align*} \\beta_0 &amp;= \\alpha_0 - \\langle \\overline{x}_{1}, \\overline{x}_{2}, \\overline{x}_{3} \\rangle \\cdot \\langle \\alpha_1, \\alpha_2, \\alpha_3 \\rangle \\\\ &amp;= \\alpha_0 - \\alpha_1 \\overline{x}_1 - \\alpha_2 \\overline{x}_2 - \\alpha_3 \\overline{x}_3 \\end{align*}\\] So this is similar to, but not exactly the same as our previous model. Differences include The priors for \\(\\alpha_0\\) and \\(\\sigma\\) are t distributions with 3 degrees of freedom rather than normal distributions. These are flatter (so less informative) than the corresponding normal priors would be. The prirs for \\(\\alpha_i\\) when \\(i \\ge 1\\) are improper “uniform” priors. Again, this is even less informative than the priors we have been using. The likelihood is based on normal noise rather than t-distributed noise. 18.3.1 Adjusting the model with brm() Suppose we want to construct a model that has the same prior and likelihood as our JAGS model. Here are some values we will need. 4 * sd(SAT$sat) / sd(SAT$expend) ## [1] 219.6 4 * sd(SAT$sat) / sd(SAT$frac) ## [1] 11.18 4 * sd(SAT$sat) / sd(SAT$frac * SAT$expend) ## [1] 1.452 To use a t distribution for the response, we use family = student(). To set the priors, it is handy to know what the parameter names will be and what the default priors would be if we do noting. (If no prior is listed, a flat improper prior will be used.) get_prior( sat ~ expend * frac, data = SAT, family = student() # distribution for response variable ) prior class coef group resp dpar nlpar bound b b expend b expend:frac b frac student_t(3, 946, 85) Intercept gamma(2, 0.1) nu student_t(3, 0, 85) sigma We can communicate the priors to brm() as follows (notice the use of coef or class based on the output above. (class = b could be used to set a common prior for all coefficients in the b class, if that’s what we wanted.) sat3a_brm &lt;- brm( sat ~ expend * frac, data = SAT, family = student(), prior = c( set_prior(&quot;normal(0,220)&quot;, coef = &quot;expend&quot;), set_prior(&quot;normal(0,11)&quot;, coef = &quot;frac&quot;), set_prior(&quot;normal(0,1.5)&quot;, coef = &quot;expend:frac&quot;), set_prior(&quot;normal(1000, 100)&quot;, class = &quot;Intercept&quot;), set_prior(&quot;exponential(1/30.0)&quot;, class = &quot;nu&quot;), set_prior(&quot;uniform(0.001,1000)&quot;, class = &quot;sigma&quot;) ) ) ## Compiling the C++ model ## Start sampling sat3a_stan &lt;- stanfit(sat3a_brm) sat3a_stan ## Inference for Stan model: 336210773a023f629f18d50263dd2a7f. ## 4 chains, each with iter=2000; warmup=1000; thin=1; ## post-warmup draws per chain=1000, total post-warmup draws=4000. ## ## mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat ## b_Intercept 1051.35 1.03 42.61 965.03 1023.29 1051.65 1079.86 1133.24 1715 1 ## b_expend 1.82 0.19 7.96 -13.80 -3.64 1.87 7.09 17.88 1740 1 ## b_frac -4.17 0.02 0.83 -5.75 -4.74 -4.18 -3.60 -2.55 1761 1 ## b_expend:frac 0.22 0.00 0.14 -0.05 0.13 0.22 0.31 0.49 1650 1 ## sigma 31.07 0.08 3.67 24.67 28.43 30.93 33.30 39.02 2273 1 ## nu 35.54 0.54 30.17 4.71 14.38 27.18 47.13 116.23 3098 1 ## lp__ -265.96 0.05 1.73 -270.18 -266.88 -265.66 -264.69 -263.57 1451 1 ## ## Samples were drawn using NUTS(diag_e) at Sat Apr 13 13:45:39 2019. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split chains (at ## convergence, Rhat=1). mcmc_combo(as.mcmc.list(sat3a_stan)) stancode(sat3a_brm) ## // generated with brms 2.7.0 ## functions { ## ## /* compute the logm1 link ## * Args: ## * p: a positive scalar ## * Returns: ## * a scalar in (-Inf, Inf) ## */ ## real logm1(real y) { ## return log(y - 1); ## } ## /* compute the inverse of the logm1 link ## * Args: ## * y: a scalar in (-Inf, Inf) ## * Returns: ## * a positive scalar ## */ ## real expp1(real y) { ## return exp(y) + 1; ## } ## } ## data { ## int&lt;lower=1&gt; N; // total number of observations ## vector[N] Y; // response variable ## int&lt;lower=1&gt; K; // number of population-level effects ## matrix[N, K] X; // population-level design matrix ## int prior_only; // should the likelihood be ignored? ## } ## transformed data { ## int Kc = K - 1; ## matrix[N, K - 1] Xc; // centered version of X ## vector[K - 1] means_X; // column means of X before centering ## for (i in 2:K) { ## means_X[i - 1] = mean(X[, i]); ## Xc[, i - 1] = X[, i] - means_X[i - 1]; ## } ## } ## parameters { ## vector[Kc] b; // population-level effects ## real temp_Intercept; // temporary intercept ## real&lt;lower=0&gt; sigma; // residual SD ## real&lt;lower=1&gt; nu; // degrees of freedom or shape ## } ## transformed parameters { ## } ## model { ## vector[N] mu = temp_Intercept + Xc * b; ## // priors including all constants ## target += normal_lpdf(b[1] | 0,220); ## target += normal_lpdf(b[2] | 0,11); ## target += normal_lpdf(b[3] | 0,1.5); ## target += normal_lpdf(temp_Intercept | 1000, 100); ## target += uniform_lpdf(sigma | 0.001,1000) ## - 1 * uniform_lccdf(0 | 0.001,1000); ## target += exponential_lpdf(nu | 1/30.0) ## - 1 * exponential_lccdf(1 | 1/30.0); ## // likelihood including all constants ## if (!prior_only) { ## target += student_t_lpdf(Y | nu, mu, sigma); ## } ## } ## generated quantities { ## // actual population-level intercept ## real b_Intercept = temp_Intercept - dot_product(means_X, b); ## } 18.4 Interpretting a model with an interaction term If the coefficient on the interation term is not 0, then how \\(y\\) depends on \\(x_i\\) depends on the other predictors in the model. This makes it difficult to talk about ``the effect of \\(x_i\\) on \\(y\\)&quot;. The best we can do is talk about general patterns or about the effect of \\(x_i\\) on \\(y\\) for particular values of the other preditors. In the SAT model, a substantial portion (but not 95%) of the posterior distribution indicates that there is an interaction, so we need to at least be concerned that this is a possibility. mcmc_areas(as.mcmc.list(sat3a_stan), pars = &quot;b_expend:frac&quot;, prob = .90) bind_rows( hdi(posterior(sat3a_stan), pars = &quot;b_expend:frac&quot;, prob = .90), hdi(posterior(sat3a_stan), pars = &quot;b_expend:frac&quot;, prob = .95) ) par lo hi mode prob b_expend:frac -0.0061 0.4445 0.1964 0.90 b_expend:frac -0.0596 0.4807 0.1964 0.95 If we are primarily interested in how expenditures are related to SAT performance, one way to deal with this is to think about the slope of the regression line for various values of the frac variable. By definition, frac is between 0 and 100, and in the data it spans nearly that full range. posterior(sat3a_stan) %&gt;% mutate( slope20 = b_expend + `b_expend:frac` * 20, slope40 = b_expend + `b_expend:frac` * 40, slope60 = b_expend + `b_expend:frac` * 60, slope80 = b_expend + `b_expend:frac` * 80 ) %&gt;% gf_density(~slope20, fill = ~&quot;frac = 20&quot;) %&gt;% gf_density(~slope40, fill = ~&quot;frac = 40&quot;) %&gt;% gf_density(~slope60, fill = ~&quot;frac = 60&quot;) %&gt;% gf_density(~slope80, fill = ~&quot;frac = 80&quot;) %&gt;% gf_labs(x = &quot;b_frac&quot;) According to this mode, spending more money is definitely associated with higher SAT scores when many students take the SAT, but might actually be associated with a small decrease in SAT scores when very few students take the test. The model provides the sharpest estimates of this effect when the fraction of students taking the test is near 50%. Here’s another way to present this sort of comparison using 95% HDIs instead of density plots. We can create our own version of these plot like this NewData &lt;- tibble( sat = Inf, # trick to get ppc_intervals() to almost ignore frac = seq(0, 100, by = 4)) y_slope &lt;- posterior_calc( sat3a_stan, slope_expend ~ b_expend + `b_expend:frac` * frac, # note required back ticks! data = NewData ) ppc_intervals(NewData$sat, y_slope, x = NewData$frac) %&gt;% gf_labs(x = &quot;value of frac&quot;, y = &quot;slope on expend&quot;) %&gt;% gf_hline(yintercept = 0, color = &quot;red&quot;, alpha = 0.5, linetype = &quot;dashed&quot;) 18.4.1 Thinking about the noise The noise parameter (\\(\\sigma\\)) appears to be at least 25, so there is substantial variability in average SAT scores, even among states with the same expenditures and fraction of students taking the test. mcmc_areas(as.mcmc.list(sat3a_stan), pars = &quot;sigma&quot;, prob = .9, prob_outer = 0.95) hdi(posterior(sat3a_stan), pars = &quot;sigma&quot;) par lo hi mode prob sigma 24.3 38.48 29.54 0.95 18.5 Exercises Fit a model that predicts student-teacher ratio (ratio) from ependiture (expend). Is spending a good predictor of student-teacher ratio? Fit a model that predicts SAT scores from student-teacher ratio (ratio) and the fraction of students who take the SAT (frac). How does this model compare with the model that uses expend and ratio as predictors? CalvinBayes::MultLinRegrPlotUnif contains a synthetic data set with variables x1, x2, and y. glimpse(MultLinRegrPlotUnif) ## Observations: 400 ## Variables: 3 ## $ x1 &lt;dbl&gt; 6.2482, 0.5470, 6.2820, 0.5085, 2.8241, 4.7502, 5.1439, 5.7114, 8.3594, 2.3522, 4.4224… ## $ x2 &lt;dbl&gt; 6.4130, 6.0560, 8.8629, 4.9334, 2.2763, 7.1172, 5.8876, 3.6913, 7.8148, 0.9905, 3.9044… ## $ y &lt;dbl&gt; 27.73, 22.44, 33.69, 22.53, 17.64, 25.87, 25.98, 25.56, 32.55, 11.50, 22.49, 18.57, 28… inspect(MultLinRegrPlotUnif) ## ## quantitative variables: ## name class min Q1 median Q3 max mean sd n missing ## 1 x1 numeric 0.011432 2.482 5.236 7.692 9.996 5.129 2.983 400 0 ## 2 x2 numeric 0.003215 2.433 5.342 7.463 9.985 5.044 2.887 400 0 ## 3 y numeric 4.774219 20.371 25.270 30.435 41.955 25.122 6.808 400 0 This is the same data used to make the plots on page 511. The claim there is that the data were randomly created using the formula n &lt;- length(x_1) y &lt;- 10 + x_1 + 2 * x_2 + rnorm(n, 0, 2) Run a regression model using x1 and x2 as predictors for y (no interaction). Use “normal noise” for your model, and \\({\\sf Norm}(0,20)\\) priors for the slope and intercept parameters. How do the posterior distributions compare to the formula used to generate the data? (In a real data analysis situation, we won’t know the “true” relationship like we do here when we simulate the data using a relationship of our own devisig.) Now run a regression model using only x1 as a predictor for y. How do the results compare (to the previous model and to the formula used to generate the data)? Explain why the posterior distribution for sigma changes the way it does. (You might like to look at the pictures on page 511.) Now add an interaction term to the model with two predictors. How does that change the resulting posterior? "],
["nominal-predictors.html", "19 Nominal Predictors 19.1 Fruit flies Study 19.2 Model 1: Out-of-the-box 19.3 Model 2: Custom Priors 19.4 Models 3 and 4: alternate parameterizations 19.5 Comparing groups 19.6 More Variations 19.7 Exercises", " 19 Nominal Predictors 19.1 Fruit flies Study A study of fruit flies (Hanley &amp; Shapiro, 1994) considered whether the female companions (none, 1 pregnant, 8 pregnant, 1 virgin, or 8 virgin) is associated with differences in longevity of males (measured in days). gf_violin(longevity ~ group, data = FruitflyReduced) %&gt;% gf_jitter(width = 0.2, height = 0, alpha = 0.5) %&gt;% gf_point(stat = &quot;summary&quot;, color = &quot;red&quot;, size = 3, alpha = 0.5, fun = mean) ## No summary function supplied, defaulting to `mean_se() 19.2 Model 1: Out-of-the-box It is easy enough to ask brm() to fit a model for us. Let’s just give it our explanatory and response variables and see what happens. flies_brm &lt;- brm(longevity ~ group, data = FruitflyReduced) ## Compiling the C++ model ## Start sampling flies_stan &lt;- stanfit(flies_brm) flies_stan ## Inference for Stan model: 2838b68e72ce876b17fbd0e486bccf49. ## 4 chains, each with iter=2000; warmup=1000; thin=1; ## post-warmup draws per chain=1000, total post-warmup draws=4000. ## ## mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat ## b_Intercept 63.48 0.06 3.00 57.73 61.39 63.54 65.52 69.24 2711 1 ## b_groupPregnant1 1.46 0.07 4.20 -6.58 -1.27 1.39 4.25 9.77 3259 1 ## b_groupPregnant8 -0.09 0.08 4.30 -8.65 -2.95 -0.06 2.81 8.21 3018 1 ## b_groupVirgin1 -6.72 0.07 4.24 -14.90 -9.59 -6.73 -3.91 1.70 3278 1 ## b_groupVirgin8 -24.71 0.08 4.21 -32.86 -27.54 -24.69 -21.79 -16.52 3059 1 ## sigma 14.92 0.02 0.95 13.20 14.26 14.85 15.53 16.92 3996 1 ## lp__ -519.59 0.04 1.73 -523.63 -520.54 -519.29 -518.30 -517.10 1711 1 ## ## Samples were drawn using NUTS(diag_e) at Wed May 1 22:34:15 2019. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split chains (at ## convergence, Rhat=1). mcmc_combo(as.mcmc.list(flies_stan)) mcmc_areas_ridges(as.mcmc.list(flies_stan), regex_pars = &quot;b_g&quot;) But what just happened? Why do we have 5 parameters starting with b_? Our first clue comes from looking at the data that get sent to Stan. standata(flies_brm) %&gt;% lapply(head) ## $N ## [1] 125 ## ## $Y ## [1] 35 37 49 46 63 39 ## ## $K ## [1] 5 ## ## $X ## Intercept groupPregnant1 groupPregnant8 groupVirgin1 groupVirgin8 ## 1 1 0 1 0 0 ## 2 1 0 1 0 0 ## 3 1 0 1 0 0 ## 4 1 0 1 0 0 ## 5 1 0 1 0 0 ## 6 1 0 1 0 0 ## ## $prior_only ## [1] 0 Our group variable has been turned into 4 (really 5, if you count the intercept, which is all 1’s) new 0/1 variables. So our model is \\[\\begin{align*} \\mathrm{longevity} &amp;= \\beta_0 \\cdot 1 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\beta_4 x_4 + \\mathrm{noise} \\\\ &amp; = \\beta_0 \\cdot 1 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\beta_4 x_4 + {\\sf Norm}(0, \\sigma) \\end{align*}\\] where, for example, \\[\\begin{align*} x_1 &amp;= [\\![ \\mbox{group} = \\mbox{Pregnant1} ]\\!] \\\\ &amp;= \\begin{cases} 1 &amp; \\mbox{if group} = \\mbox{Pregnant1} \\\\ 0 &amp; \\mbox{if group} \\neq \\mbox{Pregnant1} \\end{cases} \\end{align*}\\] In other words the distribution of longevity is \\({\\sf Norm}(\\beta_0, \\sigma)\\) for the None0 group \\({\\sf Norm}(\\beta_0 + \\beta_1, \\sigma)\\) for the Pregnant1 group \\({\\sf Norm}(\\beta_0 + \\beta_2, \\sigma)\\) for the Pregnant2 group \\({\\sf Norm}(\\beta_0 + \\beta_3, \\sigma)\\) for the Virgin1 group \\({\\sf Norm}(\\beta_0 + \\beta_4, \\sigma)\\) for the Virgin2 group Here are the default priors. prior_summary(flies_brm) prior class coef group resp dpar nlpar bound b b groupPregnant1 b groupPregnant8 b groupVirgin1 b groupVirgin8 student_t(3, 58, 18) Intercept student_t(3, 0, 18) sigma Flat improper priors for the b_ parameters. t-distribution with 3 degrees of freedom for the intercept (heavier tails than a normal distribution) Note: This is really a prior for \\(\\alpha_0\\), not \\(\\beta_0\\) since it is usually easier to specify a prior for \\(\\alpha_0\\). If for some reason we wanted to specify a prior for \\(\\beta_0\\) instead, there is a little trick: use the formula longevity ~ 0 + intercept + group. If you are curious where 58 and 18 came from, here’s a good guess: df_stats(~ longevity, data = FruitflyReduced, mean, sd) mean_longevity sd_longevity 57.44 17.56 That is, the prior says that the mean response at the mean value of the predictor (in the data) should be roughly the mean value of the responsss in the data, and our uncertainty is on the scale of the variability in responses in the data. “T” for sigma. (This is really a “half t”, since Stan knows the parameter must be positive.) 19.3 Model 2: Custom Priors The out-of-the-box model above differs from the basic model in DBDA. We can get closer to the DBDA model using this: flies2_brm &lt;- brm(longevity ~ group, data = FruitflyReduced, prior = c( set_prior(class = &quot;Intercept&quot;, &quot;normal(60, 100)&quot;), # 100 = 5 * 20 set_prior(class = &quot;b&quot;, &quot;normal(0, 10)&quot;), # group = &quot;b&quot; is default; could be omitted set_prior(class = &quot;sigma&quot;, &quot;uniform(20.0/1000.0, 20.0 * 1000.0)&quot;) ) ) ## Compiling the C++ model ## Start sampling prior_summary(flies2_brm) stancode(flies2_brm) This still isn’t exactly the same as the model used by Kruschke. It turns out that there are multiple ways to code the \\(\\beta\\)s. The model we just fit and one more are easy to do with brm(). A third is used by Kruschke and takes a bit more work to fit using brm(). 19.4 Models 3 and 4: alternate parameterizations If we remove the intercept in the brm() model, we get a model with a \\(\\beta_i\\) for each group mean rather than \\(\\beta_0\\) for the first group and \\(\\beta_i\\) for the difference in group means when \\(i &gt; 0\\): flies3_brm &lt;- brm( longevity ~ 0 + group, data = FruitflyReduced, prior = c( set_prior(class = &quot;b&quot;, &quot;normal(60, 10)&quot;), # group = &quot;b&quot; is default; could be omitted set_prior(class = &quot;sigma&quot;, &quot;uniform(20.0/1000.0, 20.0 * 1000.0)&quot;) ), sample_prior = TRUE ) ## Compiling the C++ model ## Start sampling prior_summary(flies3_brm) stancode(flies3_brm) This is equivalent to \\[\\begin{align*} \\mathrm{longevity} &amp;= \\beta_0 x_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\beta_4 x_4 + \\mathrm{noise} \\\\ &amp; = \\beta_0 x_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\beta_4 x_4 + {\\sf Norm}(0, \\sigma) \\end{align*}\\] where, for example, \\[\\begin{align*} x_1 &amp;= [\\![ \\mbox{group} = \\mbox{Pregnant1} ]\\!] \\\\ &amp;= \\begin{cases} 1 &amp; \\mbox{if group} = \\mbox{Pregnant1} \\\\ 0 &amp; \\mbox{if group} \\neq \\mbox{Pregnant1} \\end{cases} \\end{align*}\\] In other words the distribution of longevity is \\({\\sf Norm}(\\beta_0, \\sigma)\\) for the None0 group \\({\\sf Norm}(\\beta_1, \\sigma)\\) for the Pregnant1 group \\({\\sf Norm}(\\beta_2, \\sigma)\\) for the Pregnant2 group \\({\\sf Norm}(\\beta_3, \\sigma)\\) for the Virgin1 group \\({\\sf Norm}(\\beta_4, \\sigma)\\) for the Virgin2 group Kruschke uses an overspecified model that has 6 parameters: an intercept and 5 “offsets”. An extra step has to be included to properly specify the model. His model is designed so that \\(\\beta_0\\) is an overall average and the other \\(\\beta_i\\)’s give differences to that overall average. I haven’t figured out if there is an easy way to do this with brm(). But with a little work, we can force it. The key to doing this is the use of stanvar() to create additional lines of code that are injected into the Stan code. We use scode to give the desired code (as a string) and block to say which Stan block to put it in. FruitflyReduced &lt;- FruitflyReduced %&gt;% mutate(one = 1) flies4_brm &lt;- brm( longevity ~ 0 + one + group, data = FruitflyReduced, prior = c( set_prior(coef = &quot;one&quot;, &quot;normal(60,10)&quot;), set_prior(class = &quot;b&quot;, &quot;normal(0, 10)&quot;), # group = &quot;b&quot; is default; could be omitted set_prior(class = &quot;sigma&quot;, &quot;uniform(20.0/1000.0, 20.0 * 1000.0)&quot;) ), sample_prior = TRUE, stanvars = c( # compute the average average stanvar(scode = &quot; real a_one = mean(b[2:K]) + b[1];&quot;, block = &quot;genquant&quot;), # compute the offsets to the average average stanvar(scode = &quot; vector[K - 1] a = b[1] + b[2:K] - a_one;&quot;, block = &quot;genquant&quot;) ) ) ## Compiling the C++ model ## Start sampling prior_summary(flies4_brm) stancode(flies4_brm) mcmc_areas(as.mcmc.list(stanfit(flies4_brm)), regex_pars = c(&quot;a_one&quot;, &quot;a\\\\[&quot;, &quot;^b_&quot;)) As we can see, the modes of the posteriors for the a and b parameters are similar (because the prior on b_one kept b_one from drifting too far from where a_one is centered), but the posteriors for the a parameters are significantly narrower, so the conversion from b’s to a’s is important. 19.5 Comparing groups 19.5.1 Comparing to the “intercept group” Let’s return to model 2. stanfit(flies2_brm) ## Inference for Stan model: bf639a104df81234b81629296b75e83c. ## 4 chains, each with iter=2000; warmup=1000; thin=1; ## post-warmup draws per chain=1000, total post-warmup draws=4000. ## ## mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat ## b_Intercept 61.68 0.05 2.63 56.43 59.92 61.73 63.50 66.60 3156 1 ## b_groupPregnant1 2.87 0.06 3.79 -4.29 0.34 2.77 5.40 10.54 3613 1 ## b_groupPregnant8 1.57 0.06 3.83 -5.87 -0.95 1.54 4.19 9.17 3713 1 ## b_groupVirgin1 -4.46 0.06 3.84 -11.81 -7.05 -4.53 -1.93 3.24 3657 1 ## b_groupVirgin8 -21.10 0.06 3.79 -28.37 -23.70 -21.09 -18.56 -13.59 3683 1 ## sigma 14.97 0.01 0.98 13.19 14.29 14.92 15.58 17.07 4315 1 ## lp__ -543.27 0.04 1.78 -547.62 -544.18 -542.92 -541.98 -540.81 1770 1 ## ## Samples were drawn using NUTS(diag_e) at Wed May 1 22:35:06 2019. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split chains (at ## convergence, Rhat=1). In this model, one group corresponds to the intercept of the model, and comparisons of other groups to this group is a matter of investigating the posterior distribution of one of the other \\(\\beta\\)’s. flies_post &lt;- posterior(flies_stan) names(flies_post) ## [1] &quot;b_Intercept&quot; &quot;b_groupPregnant1&quot; &quot;b_groupPregnant8&quot; &quot;b_groupVirgin1&quot; &quot;b_groupVirgin8&quot; ## [6] &quot;sigma&quot; &quot;lp__&quot; &quot;chain&quot; &quot;iter&quot; plot_post(flies_post$b_groupPregnant1) ## $posterior ## ESS mean median mode ## var1 3226 1.46 1.395 0.4242 ## ## $hdi ## prob lo hi ## 1 0.95 -6.641 9.727 hdi(flies_post$b_groupPregnant1) par lo hi mode prob var1 -6.641 9.727 2.438 0.95 plot_post(flies_post$b_groupVirgin1) ## $posterior ## ESS mean median mode ## var1 3173 -6.719 -6.728 -6.163 ## ## $hdi ## prob lo hi ## 1 0.95 -14.72 1.874 mcmc_areas(as.mcmc.list(flies_stan), pars = &quot;b_groupVirgin1&quot;, prob = 0.95) hdi(flies_post$b_groupVirgin1) par lo hi mode prob var1 -14.72 1.874 -6.802 0.95 19.5.2 Comparing others pairs of groups What if we want to compare the Virgin1 and Virgin8 groups? We can use the identity \\(\\beta_0 + \\beta_i - (\\beta_0 + \\beta_j) = \\beta_i - \\beta_j\\) to simplify the algebra and do it this way. (The same would work in model 3 or 4 as well.) flies_post &lt;- flies_post %&gt;% mutate(dVirgin = b_groupVirgin8 - b_groupVirgin1) plot_post(flies_post$dVirgin, xlab = &quot;Virgin8 - Virgin1&quot;) ## $posterior ## ESS mean median mode ## var1 6589 -17.99 -17.94 -17.73 ## ## $hdi ## prob lo hi ## 1 0.95 -26.48 -9.564 19.5.3 Contrasts: Comparing “groups of groups” What if we want to compare the two virgin groups to the 3 other groups? This is a bit simpler to do using the model without an intercept term. flies3_post &lt;- posterior(flies3_brm) names(flies3_post) ## [1] &quot;b_groupNone0&quot; &quot;b_groupPregnant1&quot; &quot;b_groupPregnant8&quot; &quot;b_groupVirgin1&quot; &quot;b_groupVirgin8&quot; ## [6] &quot;sigma&quot; &quot;prior_b&quot; &quot;prior_sigma&quot; &quot;lp__&quot; flies3_post &lt;- flies3_post %&gt;% mutate( contrast = (b_groupVirgin8 + b_groupVirgin1)/2 - (b_groupPregnant1 + b_groupPregnant8 + b_groupNone0) / 3 ) plot_post(flies3_post$contrast, xlab = &quot;Virgin vs non-virgin groups&quot;) ## $posterior ## ESS mean median mode ## var1 5755 -14.87 -14.89 -14.7 ## ## $hdi ## prob lo hi ## 1 0.95 -20.23 -9.784 The expression \\[\\begin{align*} \\frac{\\mu_3 + \\mu_4}{2} - \\frac{\\mu_0 + \\mu_1 + \\mu_2}{3} &amp;= -\\frac13 \\mu_0 -\\frac13 \\mu_1 -\\frac13 \\mu_2 + \\frac12 \\mu_3 + \\frac12 \\mu_4 \\end{align*}\\] is an example of a contrast. A contrast is simply a linear combination of the group means such that the sum of the coefficients is 0. Many interesting relationships can be investigated using contrasts, and the brms package includes the hypothesis() function to help us do this. (Note: because we included sample_prior = TRUE in the call to brm() for this model, the plot below shows both prior and posterior distributions for the contrast.) h &lt;- hypothesis( flies3_brm, &quot;(groupVirgin8 + groupVirgin1) / 2 &lt; (groupPregnant1 + groupPregnant8 + groupNone0) / 3&quot; ) h ## Hypothesis Tests for class b: ## Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 ((groupVirgin8+gr... &lt; 0 -14.87 2.65 -Inf -10.43 Inf 1 * ## --- ## &#39;*&#39;: The expected value under the hypothesis lies outside the 95%-CI. ## Posterior probabilities of point hypotheses assume equal prior probabilities. plot(h) 19.5.3.1 Multiple Hypotheses at once We can even test multiple hypotheses at once. h2 &lt;- hypothesis( flies3_brm, c(&quot;groupVirgin1 &lt; (groupPregnant1 + groupPregnant8 + groupNone0) / 3&quot;, &quot;groupVirgin8 &lt; (groupPregnant1 + groupPregnant8 + groupNone0) / 3&quot;) ) h2 ## Hypothesis Tests for class b: ## Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 (groupVirgin1)-((... &lt; 0 -6.60 3.35 -Inf -1.09 38.22 0.97 * ## 2 (groupVirgin8)-((... &lt; 0 -23.15 3.38 -Inf -17.48 Inf 1.00 * ## --- ## &#39;*&#39;: The expected value under the hypothesis lies outside the 95%-CI. ## Posterior probabilities of point hypotheses assume equal prior probabilities. plot(h2) 19.5.3.2 Equality or inequality? In the previous example, we expressed our contrast as an inequality. We can also express it as an equality. The output that we get from hypothesis() is a bit different if we do so. h3 &lt;- hypothesis( flies3_brm, c(&quot;groupVirgin1 = (groupPregnant1 + groupPregnant8 + groupNone0) / 3&quot;, &quot;groupVirgin8 = (groupPregnant1 + groupPregnant8 + groupNone0) / 3&quot;) ) h3 ## Hypothesis Tests for class b: ## Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star ## 1 (groupVirgin1)-((... = 0 -6.60 3.35 -13.37 0.03 0.53 0.35 ## 2 (groupVirgin8)-((... = 0 -23.15 3.38 -29.77 -16.34 0.00 0.00 * ## --- ## &#39;*&#39;: The expected value under the hypothesis lies outside the 95%-CI. ## Posterior probabilities of point hypotheses assume equal prior probabilities. plot(h3) The CI is 2-sided rather than 1-sided. Evidence Ratio is defined differently. For inequalities, this is the ratio of the posterior probabilities for the inequality being true vs. false For equalities, this is the ratio of the posterior density (of the equality holding) to the prior density. (This only works if sample_prior = TRUE since prior samples are required to make the calculation.) 19.6 More Variations The models we have looked at above are very similar to a traditional ANOVA model, the key features of which are normal distributions for each group (normal noise), and same standard deviation in each group (homoskedasticity). In frequentist statistics, these are largely chosen for convenience (the mathematics is much easier). But we can easily relax these restrictions using Bayesian software. Let’s fit a model using t distributions instead normal distributions for the noise. This will make the results more robust against outliers in our sample or distributions with heavier tails. different standard deviation parameters for each group. Both are easy to do with brm(). The main new feature is the use of bf() to provide two formulas. The first describes the mean response (separate means for each group). The second formula describes sigma (separate values for each group). The rest should look familiar. flies5_brm &lt;- brm( bf(longevity ~ 0 + group, sigma ~ 0 + group), data = FruitflyReduced, family = student(), # t distribution for the noise prior = c( set_prior(class = &quot;b&quot;, &quot;normal(60, 10)&quot;) ), sample_prior = TRUE ) ## Compiling the C++ model ## Start sampling The Stan code for this model includes the following model section. model { vector[N] mu = X * b; vector[N] sigma = X_sigma * b_sigma; for (n in 1:N) { sigma[n] = exp(sigma[n]); } // priors including all constants target += normal_lpdf(b | 60, 10); target += gamma_lpdf(nu | 2, 0.1) - 1 * gamma_lccdf(1 | 2, 0.1); // likelihood including all constants if (!prior_only) { target += student_t_lpdf(Y | nu, mu, sigma); } } Note that the values of sigma are on the log scale and are converted (via exp()) to the natural scale before using them in the likelihood function. The sort of encoding of groups is used for (log) sigma as was used for the group means. Because we included 0 in our formula, we get a (log) sigma for each group. This is reported in the summary output for the brm model as a log link for sigma. flies5_brm ## Family: student ## Links: mu = identity; sigma = log; nu = identity ## Formula: longevity ~ 0 + group ## sigma ~ 0 + group ## Data: FruitflyReduced (Number of observations: 125) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat ## groupNone0 63.00 3.22 56.81 69.40 6962 1.00 ## groupPregnant1 64.12 3.18 57.75 70.19 6857 1.00 ## groupPregnant8 63.37 2.96 57.49 69.11 7327 1.00 ## groupVirgin1 57.17 2.90 51.41 62.85 7191 1.00 ## groupVirgin8 40.03 2.45 35.30 44.94 6739 1.00 ## sigma_groupNone0 2.78 0.16 2.50 3.10 7931 1.00 ## sigma_groupPregnant1 2.73 0.16 2.44 3.06 7940 1.00 ## sigma_groupPregnant8 2.66 0.15 2.39 2.98 6746 1.00 ## sigma_groupVirgin1 2.68 0.16 2.39 3.00 8859 1.00 ## sigma_groupVirgin8 2.49 0.15 2.20 2.81 7824 1.00 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat ## nu 27.47 14.96 7.92 65.65 6412 1.00 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). mcmc_areas_ridges(as.mcmc.list(stanfit(flies5_brm)), regex_pars = &quot;sigma&quot;) In this case, it doesn’t appear that there is a large difference among the (log) standard deviations in the five groups, but it is noteable that the group with the lowest longevity also has the smallest standard deviation. It is not uncommon for variability to larger when values are larger. Fortunately, it is no harder to fit a model with separate standard deviations than with one standard deviation for all of the groups. And if there substantial differences in the standard deviations, a model that takes that into account will perform better. If we prefer to see the standard deviations on the natural scale, we can tell Stan to compute and store those values. The naming isn’t quite as nice, however. flies5a_brm &lt;- brm( bf(longevity ~ 0 + group, sigma ~ 0 + group), data = FruitflyReduced, family = student(), # t distribution for the noise prior = c( set_prior(class = &quot;b&quot;, &quot;normal(60, 10)&quot;) ), sample_prior = TRUE, stanvars = stanvar( scode = &quot;vector[K_sigma] b_rsigma = exp(b_sigma);&quot;, block = &quot;genquant&quot;) ) ## Compiling the C++ model ## Start sampling flies5a_stan &lt;- stanfit(flies5a_brm) mcmc_areas_ridges(as.mcmc.list(flies5a_stan), regex_pars = &quot;rsigma&quot;) hdi(posterior(flies5a_stan), regex_pars = &quot;rsigma&quot;) par lo hi mode prob b_rsigma.1 11.787 21.52 15.68 0.95 b_rsigma.2 11.005 20.49 15.84 0.95 b_rsigma.3 10.398 19.07 14.93 0.95 b_rsigma.4 10.892 19.54 14.27 0.95 b_rsigma.5 8.527 16.12 11.58 0.95 19.7 Exercises It turns out that larger fruit flies tend to live longer. we can take this into account by adding thorax (the length of each fruit fly’s thorax in mm) to our model. Since we are primarily interested in the association between group and longevity, thorax is referred to as a covariate. But if we were primarily interested in the relationship between longevity and size, we could use the same model and call group the covariate. Same model, different focus. Fit two models: Let Model 1 be the model below and let Model 2 be one just like it but without thorax. Then answer the questions that follow. We’ll stick with the default priors for now, but it would be easy enough to choose your own. model1_brm &lt;- brm( bf(longevity ~ group + thorax, sigma ~ group + thorax), data = FruitflyReduced, family = student(), ) Does Model 1 think that longevity is different for large and small fruit flies? How do you know? How can you quantify your answer? We are primarily interested in whether the fruit flies that live with virgin females live less long than the others (those that live alone or with pregnant females). Using each model, compute a 95% HDI for the contrast that measures this. For Model 1, does it matter what value thorax has? (If yes, use thorax = 0.8 as an example.) How do the two HDI’s compare? Why? Using each model, compute a 95% HDI for the contrast that compares just the Virgin1 flies to the three types of controls (None0, Pregnant1, and Pregnant8). How do the two models compare? Now compare the values for sigma in the two models. To do this, we will need to specify both the group and the thorax size (since for different combinations of these the models estimate different values of sigma). For each of the combinations below, compute a 95% HDI for sigma in two models, one with thorax and one without. Don’t forget to convert to the natural scale. (Recall that brm() uses a log link for sigma.) group: Pregnant1; thorax: 0.7mm, 0.8mm, 0.9mm [That’s three different HDI’s for Model 1 and the same HDI 3 times for Model 2.] group: Virgin8; thorax: 0.7mm, 0.8mm, 0.9mm How do the results compare for the two models? Given the results above, is it important to include thorax in the model? Explain. Bonus (optional): Create a plot that shows the HDIs for sigma for every combination of model, group, and thorax measurement of 0.6, 0.7, 0.8, or 0.9 mm. "],
["multiple-nominal-predictors.html", "20 Multiple Nominal Predictors 20.1 Crop Yield by Till Method and Fertilizer 20.2 Split Plot Design 20.3 Which model should we use? 20.4 Using loo 20.5 Overfitting Example 20.6 Exercises", " 20 Multiple Nominal Predictors 20.1 Crop Yield by Till Method and Fertilizer The data in CalvinBayes::SplitPlotAgri are from an agricultural study in which different tilling methods and different fertilizers were used and the crop yield (in bushels per acre) was subsequently measured. gf_point(Yield ~ Fert | ~ Till, data = SplitPlotAgri, alpha = 0.4, size = 4) Here are two models. See if you can figure out what they are. (How can you use R to check if you are correct?) What parameters does each model have? Write a formula that describes the model. Be sure to clarify what the variables mean. How would you use each model to estimate the mean yield when using ridge tilling and deep fertilizer? (Imagine that you already have the posterior distribution in hand.) fert1_brm &lt;- brm(Yield ~ Till + Fert, data = SplitPlotAgri) ## Compiling the C++ model ## Start sampling fert2_brm &lt;- brm(Yield ~ Till * Fert, data = SplitPlotAgri) ## Compiling the C++ model ## recompiling to avoid crashing R session ## Start sampling In each of these models, the response (yield) is normally distributed around a mean value that depends on the type of fertilizer and tilling method used: \\[\\begin{align*} Y_i &amp;\\sim \\mu_i + {\\sf Norm}(0, \\sigma) \\\\ Y_i &amp;\\sim {\\ sf Norm}(\\mu_i, \\sigma) \\end{align*}\\] In model 1, the two nominal predictors are converted into indicator variables: \\[\\begin{align*} x_1 &amp;= [\\![ \\mathrm{Till} = \\mathrm{Moldbrd} ]\\!] \\\\ x_2 &amp;= [\\![ \\mathrm{Till} = \\mathrm{Ridge} ]\\!] \\\\ x_3 &amp;= [\\![ \\mathrm{Fert} = \\mathrm{Deep} ]\\!] \\\\ x_4 &amp;= [\\![ \\mathrm{Fert} = \\mathrm{Surface} ]\\!] \\\\ \\end{align*}\\] So the model becomes (omitting the subscripted \\(i\\)): \\[\\begin{align*} \\mu &amp;= \\beta0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\beta_4 x_4 \\\\ &amp;= \\beta_0 + \\beta_1 [\\![ \\mathrm{Till} = \\mathrm{Moldbrd} ]\\!] + \\beta_2 [\\![ \\mathrm{Till} = \\mathrm{Ridge} ]\\!] \\beta_3 [\\![ \\mathrm{Fert} = \\mathrm{Deep} ]\\!] + \\beta_4 [\\![ \\mathrm{Fert} = \\mathrm{Surface} ]\\!] + \\end{align*}\\] We can visualize this in a tabular form as Chisel Moldbrd Ridge Broad \\(\\beta_0\\) \\(\\beta_0 + \\beta_1\\) \\(\\beta_0 + \\beta_2\\) Deep \\(\\beta_0 + \\beta_3\\) \\(\\beta_0 + \\beta_1 + \\beta_3\\) \\(\\beta_0 + \\beta_2 + \\beta_3\\) Surface \\(\\beta_0 + \\beta_4\\) \\(\\beta_0 + \\beta_1 + \\beta_4\\) \\(\\beta_0 + \\beta_2 + \\beta_4\\) fert1_brm ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: Yield ~ Till + Fert ## Data: SplitPlotAgri (Number of observations: 99) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat ## Intercept 120.41 2.88 114.82 126.07 3946 1.00 ## TillMoldbrd 16.18 3.26 9.88 22.53 4800 1.00 ## TillRidge 15.74 3.09 9.69 21.77 4357 1.00 ## FertDeep 15.70 3.25 9.25 22.14 4642 1.00 ## FertSurface 12.59 3.20 5.99 18.70 4014 1.00 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat ## sigma 13.10 0.99 11.35 15.21 4613 1.00 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Note that this model implies that the difference in yield between using two fertilizers is the same for each of the three tilling methods and the difference due to tilling methods is the same for each of the three fertilizers. This may not be a reasonable assumption. Perhaps some fertilizers work better with certain tilling methods than with others. Model 2 allows for this. The interaction (Till * Fert) creates additional new variables of the form \\(x_i x_j\\) where \\(i = 1\\) or \\(2\\) and \\(j = 3\\) or \\(4\\). For example, \\[\\begin{align*} x_1 x_3 &amp;= [\\![ \\mathrm{Till} = \\mathrm{Moldbrd} ]\\!] \\cdot [\\![ \\mathrm{Fert} = \\mathrm{Deep} ]\\!] \\\\ &amp; = [\\![ \\mathrm{Till} = \\mathrm{Moldbrd} \\mathrm{\\ and \\ } \\mathrm{Fert} = \\mathrm{Deep} ]\\!] \\end{align*}\\] If we let \\(\\beta_{i:j}\\) be the coefficient on \\(x_i x_j\\), then our table for \\(\\mu\\) becomes Chisel Moldbrd Ridge Broad \\(\\beta_0\\) \\(\\beta_0 + \\beta_1\\) \\(\\beta_0 + \\beta_2\\) Deep \\(\\beta_0 + \\beta_3\\) \\(\\beta_0 + \\beta_1 + \\beta_3 + \\beta_{1:3}\\) \\(\\beta_0 + \\beta_2 + \\beta_3 + \\beta_{2:3}\\) Surface \\(\\beta_0 + \\beta_4\\) \\(\\beta_0 + \\beta_1 + \\beta_4 + \\beta_{1:4}\\) \\(\\beta_0 + \\beta_2 + \\beta_4 + \\beta_{2:4}\\) fert2_brm ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: Yield ~ Till * Fert ## Data: SplitPlotAgri (Number of observations: 99) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat ## Intercept 124.24 3.68 116.97 131.35 1957 1.00 ## TillMoldbrd 16.51 5.53 5.50 27.05 2185 1.00 ## TillRidge 3.74 5.45 -7.01 14.64 1879 1.00 ## FertDeep 9.41 5.26 -1.02 19.94 1959 1.00 ## FertSurface 7.08 5.28 -3.22 17.50 2032 1.00 ## TillMoldbrd:FertDeep 0.80 7.70 -13.95 16.14 2213 1.00 ## TillRidge:FertDeep 18.09 7.64 3.11 32.89 1940 1.00 ## TillMoldbrd:FertSurface -1.75 7.75 -17.27 13.45 2281 1.00 ## TillRidge:FertSurface 18.09 7.67 2.83 33.23 2078 1.00 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat ## sigma 12.70 0.97 10.99 14.71 3366 1.00 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). In this model, there is are no dependencies among the various group means and the interaction parameters (\\(\\beta_{i:j}\\)) are a measure of how much this mattered. (If they are close to 0, then this will be very much like the additive model.) As before, we can opt to fit the model without an intercept. This produces a different parameterization of the same model. fert2a_brm &lt;- brm(Yield ~ 0 + Till * Fert, data = SplitPlotAgri) ## Compiling the C++ model ## Start sampling fert2a_brm ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: Yield ~ 0 + Till * Fert ## Data: SplitPlotAgri (Number of observations: 99) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat ## TillChisel 124.29 3.71 117.05 131.78 1690 1.00 ## TillMoldbrd 140.72 3.90 132.93 148.39 3424 1.00 ## TillRidge 127.97 3.86 120.40 135.58 3457 1.00 ## FertDeep 9.40 5.17 -0.76 19.39 1854 1.00 ## FertSurface 7.02 5.28 -3.66 17.15 2017 1.00 ## TillMoldbrd:FertDeep 0.94 7.52 -13.67 15.63 2240 1.00 ## TillRidge:FertDeep 18.12 7.55 3.43 33.23 1898 1.00 ## TillMoldbrd:FertSurface -1.69 7.66 -16.55 13.19 2136 1.00 ## TillRidge:FertSurface 18.14 7.66 3.22 33.49 2189 1.00 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat ## sigma 12.69 0.97 10.95 14.75 3736 1.00 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). 20.1.1 What does \\(\\sigma\\) represent? In each of these models, \\(\\sigma\\) is the standard deviation of yield for all plots (not just those in our data) with a given combination of fertilizer and tilling method. These models specify that the standard deviation is the same in each of these groups (but we could modify that assumption and estimate separate standard deviations in each group if we wanted). The estimate of \\(\\sigma\\) is a bit smaller for the model with interaction because the added flexibility of the model allows us to estimate the means more flexibly. 20.2 Split Plot Design There is a bit more to our story. The study used 33 different fields. Each field was divided into 3 sections and a different fertilizer was applied to each of the three sections. (Which fertilizer was used on which section was determined at random.) This is called a “split-plot design” (even if it is applied to things that are not fields of crops). It would have been possible to divide each field into 9 sub-plots and use all combinations of tilling and fertilizer, but that’s not how this study was done. The tilling method was the same for the entire field – likely because it was much more efficient to plow the fields this way. The plot below indicates that different fields appear to have different baseline yields since the dots associated with one field tend to be near the top or bottom of each of the fertilizer clusters. We can add an additional variable to our model to handle this situation. gf_point(Yield ~ Fert | ~ Till, data = SplitPlotAgri, alpha = 0.4, size = 4) %&gt;% gf_line(group = ~Field) fert3_brm &lt;- # the use of factor() is important here because the field ids are numbers # factor converts this into a factor (ie, a nominal variable) brm(Yield ~ Till * Fert + factor(Field), data = SplitPlotAgri) ## Compiling the C++ model ## recompiling to avoid crashing R session ## Start sampling ## Warning: There were 3998 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 10. See ## http://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded ## Warning: Examine the pairs() plot to diagnose sampling problems fert3_brm ## Warning: The model has not converged (some Rhats are &gt; 1.1). Do not analyse the results! ## We recommend running more iterations and/or setting stronger priors. ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: Yield ~ Till * Fert + factor(Field) ## Data: SplitPlotAgri (Number of observations: 99) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat ## Intercept 117.25 4.22 109.90 126.14 25 1.12 ## TillMoldbrd -209.88 2308.47 -3652.64 4337.00 3 3.03 ## TillRidge -4833.06 9317.48 -22649.96 4918.68 2 6.37 ## FertDeep 9.44 2.19 5.00 13.64 93 1.06 ## FertSurface 7.11 2.28 2.72 11.61 65 1.06 ## factorField2 16.21 5.22 4.70 25.78 32 1.11 ## factorField3 19.87 5.29 8.67 29.79 39 1.07 ## factorField4 6.90 5.08 -3.75 16.13 36 1.09 ## factorField5 18.20 5.11 7.93 27.18 29 1.09 ## factorField6 0.72 5.28 -9.96 10.73 21 1.12 ## factorField7 -6.08 5.10 -16.21 3.46 31 1.11 ## factorField8 -8.59 5.01 -18.65 0.78 46 1.06 ## factorField9 1.62 5.05 -8.53 10.99 39 1.08 ## factorField10 18.43 4.98 7.34 27.60 37 1.08 ## factorField11 16.25 5.17 6.04 25.77 32 1.11 ## factorField12 -0.09 5.14 -10.34 8.99 32 1.10 ## factorField13 237.30 2308.06 -4313.69 3676.26 3 3.03 ## factorField14 241.95 2308.03 -4307.31 3684.34 3 3.03 ## factorField15 223.36 2307.99 -4319.04 3665.32 3 3.03 ## factorField16 254.59 2308.04 -4294.76 3695.21 3 3.03 ## factorField17 230.66 2307.99 -4317.48 3671.96 3 3.03 ## factorField18 222.95 2307.93 -4325.59 3664.35 3 3.03 ## factorField19 232.68 2308.02 -4316.46 3674.21 3 3.03 ## factorField20 240.98 2307.92 -4307.05 3684.15 3 3.03 ## factorField21 218.97 2308.05 -4331.21 3657.52 3 3.03 ## factorField22 229.01 2308.07 -4320.72 3668.83 3 3.03 ## factorField23 4833.14 9318.10 -4917.34 22653.67 2 6.38 ## factorField24 4866.18 9318.16 -4888.24 22686.75 2 6.38 ## factorField25 4834.45 9318.06 -4919.83 22652.77 2 6.38 ## factorField26 4826.52 9318.05 -4929.58 22648.23 2 6.38 ## factorField27 4843.88 9317.99 -4908.77 22668.71 2 6.38 ## factorField28 4842.79 9318.10 -4912.30 22663.22 2 6.38 ## factorField29 4831.17 9318.10 -4922.12 22651.44 2 6.38 ## factorField30 4834.10 9318.02 -4922.01 22652.95 2 6.38 ## factorField31 4860.77 9317.97 -4893.17 22682.47 2 6.38 ## factorField32 4844.80 9318.03 -4907.82 22661.54 2 6.38 ## factorField33 4862.77 9318.01 -4888.91 22687.78 2 6.38 ## TillMoldbrd:FertDeep 0.85 3.19 -5.54 7.29 129 1.04 ## TillRidge:FertDeep 18.07 3.29 12.02 24.95 99 1.06 ## TillMoldbrd:FertSurface -1.73 3.33 -8.00 4.75 72 1.05 ## TillRidge:FertSurface 18.09 3.26 11.78 24.66 82 1.05 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat ## sigma 5.65 0.52 4.70 6.78 219 1.02 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). That’s a lot of output. And the model is performing badly. Fortunately, we don’t really want this model anyway. We now have a an adjustment for each field, and there were 33 fields. But we are not really interested in predicting the yield for a given field. Our primary interest is in which fertilizers and tilling methods work well. We hope our results apply generally to all fields. So field field plays a different role in this study. We are only comparing 3 fertilizers and 3 tilling methods, but there are many more fields than the 33 in our study. They are intended to be representative of all fields (and their variable quality for producing large yields). If we think that field quality might be described by a normal distribution (or some other distribution), we might be more interested in the parameters of that distribution than in the specific estimates for the particular fields in this study. The kind of model we want for this is called a hierarchical or multi-level model, and brm() makes it easy to describe such a model. Here’s a way to think about such a model Each field has a baseline productivity. The baseline productivities are normal with some mean and standard deviation that tell us about the distribution of productivity among fields. Our 33 fields should helps us estimate this distribution. That baseline productivity can be adjusted up or down depending on the tilling method and fertilizer used. In brm() lingo, the effect of field is to adjust the intercept, so we can write it like this: fert4_brm &lt;- brm(Yield ~ Till * Fert + (1 | Field), data = SplitPlotAgri) ## Compiling the C++ model ## Start sampling We can see in the output below that the variability from plot to plot is estimated by a standard deviation of roughly 8 to 15. Individual field estimates are hidden in this report, but you can see them if you type stanfit(fert_brm). fert4_brm ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: Yield ~ Till * Fert + (1 | Field) ## Data: SplitPlotAgri (Number of observations: 99) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Group-Level Effects: ## ~Field (Number of levels: 33) ## Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat ## sd(Intercept) 11.60 1.69 8.77 15.38 722 1.01 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat ## Intercept 124.22 3.86 116.72 131.93 581 1.00 ## TillMoldbrd 16.74 5.68 5.38 28.02 466 1.00 ## TillRidge 3.65 5.74 -7.30 14.95 598 1.01 ## FertDeep 9.60 2.29 5.05 14.09 1674 1.00 ## FertSurface 7.24 2.33 2.67 11.68 1529 1.00 ## TillMoldbrd:FertDeep 0.64 3.41 -6.10 7.38 1934 1.00 ## TillRidge:FertDeep 17.81 3.31 11.24 24.32 1738 1.00 ## TillMoldbrd:FertSurface -2.00 3.41 -8.64 4.69 1841 1.00 ## TillRidge:FertSurface 17.89 3.36 11.25 24.38 1632 1.00 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat ## sigma 5.70 0.55 4.74 6.89 1616 1.00 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). The three groupings of the parameters shows are group-level effects This is where we find the standard deviation associated with Field. We are interested in the fields as a group, not as individual fields. population-level effects The parameters for Till and Fert go here. family specific This is where we find parameters associated with the “noise” of the model, in this case the standard deviation of the normal distribution. If we used a t-distribution, we would find nu and sigma here. 20.3 Which model should we use? 20.3.1 Modeling Choices Now that we are able to create more and more kinds of models, model selection is going to become a bigger issue. Here are just some of the choices we now have when constructing a model. What variables? If our primary goal is to study the association between the response and certain predictor variables, we need to include those variables in the model. But additional variables can be helpful if they explain some of the variation in the response variable in a way that makes it easier to see the association with the variables of interest. Since we have information about fields, and it seems plausible that productivity varies by field, we prefer models include Field. Similarly, even if we were only intersted in one of fertilizer or tilling method, it may be useful to include both. We might wish for some additional variables for our study of crop yields. Perhaps knowing additional information about the fields (soil type, hilly or flat? water shed or water basin? previous years crop, etc.). Any of these things might help explain the variation from field to field. But adding too many variables can actually make this worse! If variables are correlated in our data (colinearity of predictors), including both will usually make our posterior distributions for the associated parameters much wider. Additional variables can lead to over-fitting. Additional variables will always make our model fit the current data set better, but eventually we will begin fitting the idiosyncracies of our particular data set rather than patterns that are likely to extend to new observations. Interaction terms? When we use more than one predictor, we need to decide whether to include interaction terms. Interaction is important to include if we are open to to the possibility that the “effect” of one variable on the response may depend on the value of some other variable. Noise distribution? Normal distributions are traditional and relatively easy to interpret. T distributions are more robust against unusual observations or heavy tailed distributions. Both of these are symmetric distributions. If we expect or see evidience of a lack of symmetry, we may need to use transformations of the data or other families of distributions. What priors? Bayesian inference adds another layer: prior selection. For most of our models we have used “weakly informed priors”. These priors avoid parameter values that are impossible (negative values for standard deviations, for example) and provide crude order-of-magnitude guidance. They can also serve a mild regularizing effect (shrinking parameter estimates toward 0, for example, to counter against over fitting). If more information is available, it is possible to use more informed priors. Choice of prior matters more for small data sets than for large data sets. This makes sense both mathematically and intuitively. Intiuitively, if we don’t have much new data, it won’t change our beliefs much from what they were before. But if we have a lot of data, we will come to roughly the same conclusion no matter what we believed before. Multi-level? Are the values of nominal variables in our data exhaustive of the possibilities (or of our interests)? Or are they just representative of a larger set of possible values? In the latter case, a multi-level model may be called for. To clarify this, it can be good to imagine expanding the data set. If you were to collect additional data, would the variables take on new values? In our crop yield study, adding more data would require using new fields, but we could still use the same three fertilizers and same three tilling methods. Furthermore, the three tilling methods selected are not likely representative of some distribution of tilling methods the way the fields studied might be representative of many fields in a given region. These are only some of the questions we need to answer when constructing a model. But how do we decide? Part of the decision is based on things we know or believe in advance. Our model may be designed to reflect a theory about how data are generated or may be informed by other studies that have been done in similar situations. But there are also ways to investigate and compare models. 20.3.2 Measuring a Model – Prediction Error 20.3.2.1 Prediction vs. Observation One way to measure how well a model is working is to compare the predictions the model makes for the response variable \\(\\hat y_i\\) to the observed response values in the data \\(y_i\\). To simplify things, we would like to convert these \\(n\\) predictions and \\(n\\) observations into a single number. If you have taken a statistics course before, you may have done this using Sum of Squared Errors (SSE) or Mean Squared Error (MSE). \\[\\begin{align*} SSE &amp; = \\sum_{i = 1}^n (y_i - \\hat y_i)^2 \\\\ MSE &amp; = \\frac{1}{n} SSE = \\frac{1}{n} \\sum_{i = 1}^n (y_i - \\hat y_i)^2 \\end{align*}\\] If you are familiar with \\(r^2\\), it is related to MSE: \\[\\begin{align*} SSE &amp;= \\sum_{i = 1}^n (y_i - \\hat y_i)^2 \\\\ SST &amp;= \\sum_{i = 1}^n (y_i - \\overline{y})^2 \\\\ r^2 &amp;= 1 - \\frac{SSE}{SST} \\end{align*}\\] We are working with Bayesian models, so \\(SSE\\), \\(MSE\\) and \\(r^2\\) have posterior distributions, since they depend on (the posterior distribution of) \\(\\theta\\). Each posterior value of \\(\\theta\\) leads to a value of \\(\\hat y_i = E(y_i \\mid \\theta)\\) and that in turn leads to a values of \\(SSE\\), \\(MSE\\), and \\(r^2\\). Putting that all together to highlight the dependence on \\(\\theta\\), we get \\[MSE = \\frac{1}{n} \\sum_{i = 1}^n (y_i - E(y_i \\mid \\theta))^2\\] The intuition behind all three quantities is that model fit can be measured by how close the model prediction \\(\\hat y_i\\) is to the obsered resopnse \\(y_i\\). \\(MSE\\) adjusts for sample size to make it easier to compare values across data sets of different sizes. \\(r^2\\) makes a further normalization to put things on a 0-1 scale. (1 is a perfect fit. 0 means the model always gives the same prediction, so it isn’t doing anything useful.) 20.3.2.2 (Log) predictive density Another option is to compute log predictive density (lpd): \\[\\mathrm{lpd}(\\theta; y) = \\log p(y \\mid \\theta)\\] Once again, \\(y\\) is fixed, so this is a function of \\(\\theta\\). In fact, it is just the log likelihood function. For a given value of \\(\\theta\\), lpd measures (on a log scale) the probability of observing the data. A larger value indicates a better fit. Once again, because lpd is a function of \\(\\theta\\), it also has a posterior distribution. Assuming that the values of \\(y\\) are independent given the parameters (and the predictor values \\(x\\)), this can be written as \\[ \\mathrm{lpd}(\\theta; y) = \\log p(y \\mid \\theta) = \\log \\prod_{i = 1}^n p(y_i \\mid \\theta) = \\sum_{i = 1}^n \\log p(y_i \\mid \\theta) \\] In this case, we can compute the log posterior density pointwise and add. In practice, this is often done even when independence does not hold. So technically we are working with log pointwise posterior density: \\[ \\mathrm{lppd}(\\theta; y) = \\sum_{i = 1}^n \\log p(y_i \\mid \\theta) \\] As with \\(SSE\\), \\(MSE\\), and \\(r^2\\) this assigns a score to each \\(i\\) and then sums over those scores. For linear models with normal noise and uniform priors, lpd is proportional to \\(MSE\\) (and to \\(SSE\\)).8 20.3.2.3 Predictors In the notation above, we have been hiding the role of predictors \\(x\\) (and we will continue to do so below). A model with predictors makes different predictions depending on the vaules of the predictors. In all our examples, \\(x\\) will be fixed, but we could include it in the notation if we wanted. For example, \\[ \\mathrm{lpd}(\\theta; y, x) = \\log p(y \\mid \\theta, x) \\] 20.3.2.4 Numbers from distributions We can convert a measure \\(\\mathrm{lpd}(\\theta; y)\\), which depends on \\(\\theta\\), into a single number in several ways. We will illustrate below We could replace \\(\\theta\\) with a particular number \\(\\hat \\theta\\). (\\(\\hat \\theta\\) might be the mean, median, or mode of the posterior distribution or the mode of the likelihood function, for example). If we do this we get the number \\[ \\mathrm{lpd}(\\hat \\theta; y) = \\log p(y \\mid \\hat\\theta) = \\sum_{i = 1}^n \\log p(y_i \\mid \\theta) \\] This is sometimes called a “plug-in” estimate since we are plugging in a single number for \\(\\theta\\). Instead of summarizing \\(\\theta\\) with a single number, we could summarize \\(p(y_i \\mid \\theta)\\) with a single number by averaging over the posterior sample values \\(p(y_i \\mid \\theta^s)\\). (\\(\\theta^s\\) denotes the value of \\(\\theta\\) in row \\(s\\) of our \\(S\\) posterior samples.) If sum over \\(i\\), we get the log pointwise posterior density (lppd): \\[\\begin{align} \\mathrm{lppd} &amp;\\approx \\sum_{i = 1}^n \\log \\left( \\frac{1}{S} \\sum_{s = 1}^S p(y_i \\mid \\theta^s)\\right) \\end{align}\\] This is an approximation because our poseterior samples are only an approximation to the true posterior distribution. But if the effective sample size of the posterior is large, this approximation should be very good. Unfortunately, both of these measures (\\(MSE\\) and log predictive density) have a problem. They measure how well the model fits the data used to fit the model, but we are more interested in how well the model might fit new data (generated by the same random process that generated the current data). This leads to overfitting and prefers larger, more complex models, since the extra flexibility of these models makes it easier for them to “fit the data”. 20.3.3 Out-of-sample prediction error More interesting would be to measure how well the models would fit new data. This is referred to as out-of-sample prediction, in contrast to in-sample prediction. So let’s consider how well our model predicts new data \\(\\tilde y\\) rather than the observed data \\(y\\): \\[ \\mathrm{lpd}(\\theta; \\tilde y) = \\log p(\\tilde y \\mid \\theta) = \\log \\prod_{i = 1}^n p(\\tilde y_i \\mid \\theta) = \\sum_{i = 1}^n \\log p(\\tilde y_i \\mid \\theta) \\] which we can convert into a single number by plugging by posterior averaging: And since \\(\\tilde y\\) is not fixed (like \\(y\\) was), we take an additional step and compute the expected value (average) of this quantity over the distribution of \\(\\tilde y_i\\) to get the expected log (pointwise) predictive density for a new response \\(\\tilde y_i\\):9 \\[ \\mathrm{elppd} = \\mathrm{E}\\left(\\sum_{i = 1}^n \\log p_{\\mathrm{post}}(\\tilde y_i)\\right) \\approx \\sum_{i = 1}^n \\mathrm{E}\\left(\\log \\frac{1}{S} \\sum_{s = 1}^S p(\\tilde y_i \\mid \\theta^s))\\right) \\] This expected value is taken over the true distribution of \\(\\tilde y_i\\) (which is a problem, stay tuned.) 20.3.4 Approximating out-of-sample prediction error What we would ideally want (elppd), we cannot compute since it requires us to know the distribution of out-of-sample data (\\(\\tilde y_i\\)). This leads us to the following impossible set of goals for our ideal measure of model (predictive) performance (borrowed from (Gelman, Hwang, and Vehtari 2014)): an unbaised and accurate measure of out-of-sample prediction error (elppd) that will be valid over a general class of models, and that requires minimal computation beyond that need to fit the model in the first place. Here are three approaches to solving this problem Use within-sample predictive accuracy. But this isn’t ideal since it overestimates performace of the model (and more so for more complicated models). Adjust within-sample predictive accuracy. Within-sample predictive accuracy will over-estimate out-of-sample predictive accuracy. If we knew (or could estimate) by how much, we could adjust by that amount to eliminate (or reduce) the bias. Quantities like AIC (Aikeke’s information criterion), DIC (deviance information criterion), and WAIC (widely applicable information criterion) take the approach of substracting something from lppd that depends on the complexity of the model. Use cross-validation The main idea here is to use some of the data to fit the model and the rest of the data to evaluate prediction error. This is a poor person’s version of “out-of-sample”. We will focus on leave one out (LOO) cross validation where we fit the model \\(n\\) times, each time leaving out one row of the data and using the resulting model to predict the removed row. If we really needed to recompute the model \\(n\\) times, this would be too computationally expensive for large data sets and complex models. But there are (more) efficient approximations to LOO-cv that make it doable. They are based on the idea that the posterior distribution using \\(y(-i)\\) (all but row \\(i\\) of the data) should usually be similar to the posterior distribution using \\(y\\) (all of the data). So we can recycle the work done to compute our original posterior. The result is only an approximation, and it doesn’t always work well, so sometimes we have to recreate the posterior from scratch, at least for some of the rows. The formulas for estimated out-of-sample predictive density \\[\\begin{align*} \\widehat{\\mathrm{elppd}}_{\\mathrm{AIC}} &amp;= \\mathrm{lpd}(\\hat\\theta_{\\mathrm{mle}}, y) - p_{\\mathrm{AIC}} \\\\ \\widehat{\\mathrm{elppd}}_{\\mathrm{DIC}} &amp;= \\mathrm{lpd}(\\hat\\theta_{\\mathrm{Bayes}}, y) - p_{\\mathrm{DIC}} \\\\ \\widehat{\\mathrm{elppd}}_{\\mathrm{WAIC}} &amp;= \\mathrm{lppd} - p_{\\mathrm{WAIC}} \\\\ \\widehat{\\mathrm{elppd}}_{\\mathrm{LOO}} &amp;= \\sum_{i=1}^n \\log p_{\\mathrm{post}(-i)}(y_i) \\approx \\sum_{i=1}^n \\log \\left( \\frac{1}{S} \\sum_{s = 1}^S p(y_i \\mid \\theta^{is})\\right) \\end{align*}\\] and the associated effictive number of parameters: \\[\\begin{align*} p_{\\mathrm{AIC}} &amp;= \\mbox{number of parameters in the model}\\\\ p_{\\mathrm{DIC}} &amp;= 2 \\mathrm{var}_{\\mathrm{post}}(\\log p(y \\mid \\theta)) \\\\ p_{\\mathrm{WAIC}} &amp;= 2 \\mathrm{var}_{\\mathrm{post}}(\\sum_{i = 1}^n \\log p(y_i \\mid \\theta)) \\\\ p_{\\mathrm{LOO}} &amp;= \\hat{\\mathrm{llpd}} - \\hat{\\mathrm{llpd}}_{\\mathrm{LOO}} \\\\ \\end{align*}\\] Notes \\(\\theta^{is}\\) is the value of \\(\\theta\\) in row \\(s\\) of the posterior distribution when row \\(i\\) has been removed from the data. What makes LOO practical is that this can be approximated without refitting the model \\(n\\) times. AIC and DIC differ from WAIC and LOO in that they use a point estimate for \\(\\theta\\) (the maximum likelihood estimate for AIC and the mode of the posterior distribution for DIC) rather than using the full posterior distribution. AIC penalizes a model 1 for each parameter. This is correct for linear models with normal noise and uniform priors, but is not correct in general. You can think of DIC and WAIC as estimating the effective number of parameters by looking at how much variation there is in \\(\\log(p(y_i \\mid \\theta))\\). The more this quantity changes with changes in \\(\\theta\\), the more flexible the model is (and the more it should be penalized). LOO doesn’t work by adusting for an estimated number of parameters; it attempts to estimate elppd directly. But we can reverse engineer things to get an estimated number of parameters by taking the difference between the (estimated) within-sample and out-of-sample predictive density. LOO and WAIC are assymptotically equivalent (that is they give more and more similar values as the sample size increases), but LOO typically performs a bit better on small data sets, so the authors of the loo package recommend LOO over WAIC as the go-to measure for comparing models. Historically, information criteria have been expressed on the “devaiance scale”. To convert from log predictive density scale to deviance scale, we multiply by -2. On the deviance scale, smaller is better. On the log predictive density scale, larger is better (but the values are usually negative.) The waic() and loo() functions compute both values. The output from loo() and waic() labels things elpd rather than elppd. 20.4 Using loo The loo package provides functions for computing WAIC and LOO estimates of epld (and their information criterion counterparts). While the definitions are a bit involved, using WAIC or LOO to compare models is relatively easy. WAIC can be faster, but LOO performs better (according to the authors of the loo package). library(loo) waic(fert4_brm) ## ## Computed from 4000 by 99 log-likelihood matrix ## ## Estimate SE ## elpd_waic -331.2 7.5 ## p_waic 30.7 3.9 ## waic 662.3 15.0 ## Warning: 21 (21.2%) p_waic estimates greater than 0.4. We recommend trying loo instead. loo(fert4_brm) ## Warning: Found 7 observations with a pareto_k &gt; 0.7 in model &#39;fert4_brm&#39;. It is recommended to set ## &#39;reloo = TRUE&#39; in order to calculate the ELPD without the assumption that these observations are ## negligible. This will refit the model 7 times to compute the ELPDs for the problematic observations ## directly. ## ## Computed from 4000 by 99 log-likelihood matrix ## ## Estimate SE ## elpd_loo -335.2 8.2 ## p_loo 34.8 4.5 ## looic 670.5 16.3 ## ------ ## Monte Carlo SE of elpd_loo is NA. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 58 58.6% 822 ## (0.5, 0.7] (ok) 34 34.3% 308 ## (0.7, 1] (bad) 7 7.1% 27 ## (1, Inf) (very bad) 0 0.0% &lt;NA&gt; ## See help(&#39;pareto-k-diagnostic&#39;) for details. Sometimes the LOO-PSIS (Pareto-smoothed importance sampling) approximation method doesn’t work well and loo() recommends refitting some of the models from scratch. This is based on the shape parameter (k) of the Pareto distribution used to smooth the tails of the posterior. Let’s allow loo() to run from scratch the models it thinks need it. (This is still much faster than refitting a model for each row of the data since we only start from scratch a small number of times. And we don’t need to recompile the model, since that doesn’t change; we just need to generate posterior samples using a different data set.) If there are quite a number of these, loo() will suggest k-fold cross-validation instead of leave-one-out cross-validation. These leaves out multiple rows of data from each refit. Since there are fewer models this way, it can exchange speed for accuracy. fert4_loo &lt;- loo(fert4_brm, reloo = TRUE) # refit as necessary ## 7 problematic observation(s) found. ## The model will be refit 7 times. ## ## Fitting model 1 out of 7 (leaving out observation 15) ## ## Fitting model 2 out of 7 (leaving out observation 31) ## ## Fitting model 3 out of 7 (leaving out observation 57) ## ## Fitting model 4 out of 7 (leaving out observation 65) ## ## Fitting model 5 out of 7 (leaving out observation 77) ## ## Fitting model 6 out of 7 (leaving out observation 78) ## ## Fitting model 7 out of 7 (leaving out observation 83) ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling ## Start sampling In this case, things didn’t change that much when refitting the six “bad” models. fert4_loo ## ## Computed from 4000 by 99 log-likelihood matrix ## ## Estimate SE ## elpd_loo -335.2 8.2 ## p_loo 34.8 4.5 ## looic 670.5 16.3 ## ------ ## Monte Carlo SE of elpd_loo is 0.4. ## ## Pareto k diagnostic values: ## Count Pct. Min. n_eff ## (-Inf, 0.5] (good) 65 65.7% 27 ## (0.5, 0.7] (ok) 34 34.3% 308 ## (0.7, 1] (bad) 0 0.0% &lt;NA&gt; ## (1, Inf) (very bad) 0 0.0% &lt;NA&gt; ## ## All Pareto k estimates are ok (k &lt; 0.7). ## See help(&#39;pareto-k-diagnostic&#39;) for details. plot(fert4_loo) fert4a_loo &lt;- loo(fert4_brm) ## Warning: Found 7 observations with a pareto_k &gt; 0.7 in model &#39;fert4_brm&#39;. It is recommended to set ## &#39;reloo = TRUE&#39; in order to calculate the ELPD without the assumption that these observations are ## negligible. This will refit the model 7 times to compute the ELPDs for the problematic observations ## directly. plot(fert4a_loo) If we have multiple models, we can use loo::compare() to compare them based on WAIC or LOO. Before doing that, let’s add one more model to our list. fert5_brm &lt;- brm(Yield ~ Till + Fert + (1 | Field), data = SplitPlotAgri) ## Compiling the C++ model ## recompiling to avoid crashing R session ## Start sampling library(loo) compare( waic(fert1_brm), waic(fert2_brm), waic(fert4_brm), waic(fert5_brm) ) fert1_loo &lt;- loo(fert1_brm) fert2_loo &lt;- loo(fert2_brm) fert5_loo &lt;- loo(fert5_brm) ## Warning: Found 1 observations with a pareto_k &gt; 0.7 in model &#39;fert5_brm&#39;. It is recommended to set ## &#39;reloo = TRUE&#39; in order to calculate the ELPD without the assumption that these observations are ## negligible. This will refit the model 1 times to compute the ELPDs for the problematic observations ## directly. Now we can compare our four models using LOO: compare(fert1_loo, fert2_loo, fert4_loo, fert5_loo) elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic fert4_loo 0.00 0.000 -335.2 8.169 34.762 4.5456 670.5 16.34 fert5_loo -23.95 6.276 -359.2 7.542 29.517 3.6575 718.4 15.08 fert2_loo -61.43 7.784 -396.7 5.951 9.347 1.1145 793.4 11.90 fert1_loo -62.42 8.102 -397.7 5.601 5.459 0.6094 795.3 11.20 Important things to remember: Estimated elpd and information criteria are not meaningful on their own, they are only useful for comparisons. Comparisons can only be made among models that are fit using the same data since the computed values depend on both the model and the data. All of these methods are approximate. loo() and waic() provide standard errors as well as estimates. Use those to help determine whether differences between models are meaningful or not. p_loo (effective number of parameters) is also an interesting measure. If this estimate does not seem to correspond to roughly the number of free parameters in your model, that is usually a sign that something is wrong. (Perhaps the model is mis-specified.) Keep in mind that multi-level models or models with strong priors place some restrictions on the parameters. This can lead to an effective number of parameters that is smaller than the actual number of parameters. This is only one aspect of how a model is performing. There may be good reasons to prefer a model with lower (estimated) log predictive density. Posterior predictive checks, theory, interpretability, etc. can all be part of deciding which models are better. But these methods can help us avoid selecting models that only look good because they are overfitting. Note: Sometimes the best solution is to create a new model that combines elements from models tried along the way. Beware of “model hacking.” If you try enough models, you might stumble across something. But it might not be meaningful. Choose models with some thought, don’t just keep trying models in hopes that one of them will produce something interesting. 20.5 Overfitting Example 20.5.1 Brains Data This small data set giving the brain volume (cc) and body mass (kg) for several species. It is used to illustrate a very bad idea – improving the “fit” by increasing the degree of the polynomial used to model the relationship between brain size and body mass. Brains &lt;- data.frame( species = c(&quot;afarensis&quot;, &quot;africanus&quot;, &quot;habilis&quot;, &quot;boisei&quot;, &quot;rudolfensis&quot;, &quot;ergaster&quot;, &quot;sapiens&quot;), brain_size = c(438, 452, 612, 521, 752, 871, 1350), body_mass = c(37.0, 35.5, 34.5, 41.5, 55.5, 61.0, 53.5) ) gf_point(brain_size ~ body_mass, data = Brains, size = 2, color = &quot;red&quot;, alpha = 0.6, verbose = TRUE) %&gt;% gf_text(brain_size ~ body_mass, label = ~species, alpha = 0.8, color = &quot;navy&quot;, size = 3, angle = 30) To speed things up for this illustration, the model fits are frequentist using lm(), but we could fit the same models using bayesian methods and brm(). The model being fit below is \\[\\begin{align*} \\mbox{brain_size} &amp; \\sim \\mathrm{Norm}(\\mu, \\sigma) \\\\ \\mu &amp; \\sim a + b \\cdot \\mbox{body_mass} \\end{align*}\\] There are no priors because lm() isn’t using a Bayesian approach. We’re using lm() here because it is faster to fit, but the same principle would be illustrated if we used a Bayesian linear model instead. m1 &lt;- lm(brain_size ~ body_mass, data = Brains) (Note: \\lm() fits the parameters using “maximum likelihood”. You can think of this as using uniform priors on the coefficients, which means that the posterior is proportional to the likelihood, and maximum likelihood estimates are the same as the maximum a posteriori (mode of the posterior distribution) estimates. The estimate for \\(\\sigma\\) that \\lm() uses is modified to make it an unbiased estimator.) 20.5.2 Measuring fit with \\(r^2\\) \\(r^2\\) can be defined several equivalent ways. 1 - var(resid(m1)) / var(Brains$brain_size) ## [1] 0.4902 1 - sum((Brains$brain_size - fitted(m1))^2) / sum((Brains$brain_size - mean(Brains$brain_size))^2) ## [1] 0.4902 rsquared(m1) # rsquared is in the mosaic package ## [1] 0.4902 In a Bayesian setting we would have a distribution of \\(r^2\\) values, each computed using a different row from the posterior sampling. Now let’s consider a model that uses a quadratic relationship. m2 &lt;- lm(brain_size ~ poly(body_mass,2), data = Brains) 1 - var(resid(m2)) / var(Brains$brain_size) ## [1] 0.536 rsquared(m2) ## [1] 0.536 We can use any degree polynomial in the same way. m1 &lt;- lm(brain_size ~ poly(body_mass, 1), data = Brains) m2 &lt;- lm(brain_size ~ poly(body_mass, 2), data = Brains) m3 &lt;- lm(brain_size ~ poly(body_mass, 3), data = Brains) m4 &lt;- lm(brain_size ~ poly(body_mass, 4), data = Brains) m5 &lt;- lm(brain_size ~ poly(body_mass, 5), data = Brains) m6 &lt;- lm(brain_size ~ poly(body_mass, 6), data = Brains) poly(body_mass, k) creates a degree \\(k\\) polynomial in \\(k\\) (but parameterized in a special way that makes some kinds of statistical analysis easier – we aren’t concerned with the particular parameterization here, just the overall model fit). And finally, here is a degree 0 polynomial (a constant). m7 &lt;- lm(brain_size ~ 1, data = Brains) 20.5.3 Leave One Out Analysis Here’s how you remove one row from a data set. Brains.new &lt;- Brains[-2, ] One simple version of cross-validation is to fit the model several times, but each time leaving out one observation (hence the name “leave one out”). We can compare these models to each other to see how stable/volitile the moel fits are and to see how well the “odd one out” is predicted from the remaining observations. leave_one_out &lt;- function(index = 1, degree = 1, ylim = c(0, NA)) { pf &lt;- parent.frame(2) for(i in index) { BrainsLOO &lt;- Brains %&gt;% mutate(out = 1:nrow(Brains) %in% i) for(d in degree) { p &lt;- gf_point( brain_size ~ body_mass, data = BrainsLOO, color = ~out) %&gt;% gf_smooth( se = TRUE, fullrange = TRUE, brain_size ~ body_mass, formula = y ~ poly(x, d), data = BrainsLOO[-i, ], method = &quot;lm&quot;) %&gt;% gf_labs(title = paste(&quot;removed:&quot;, i, &quot; ; degree =&quot;, d)) %&gt;% gf_lims(y = ylim) print(p) } } } The simple linear model changes only slightly when we remove each data point (although the model’s uncertainty decreases quite a bit when we remove the data point that is least like the others). leave_one_out(1:nrow(Brains), degree = 1, ylim = c(-2200, 4000)) Cubic models and their uncertainties change more – they are more sensitive to the data. leave_one_out(1:nrow(Brains), degree = 3, ylim = c(-2200, 4000)) ## Warning: Removed 2 rows containing missing values (geom_smooth). With a 5th degree polynomial (6 coefficients), the fit to the six data points is “perfect”, but highly volitile. The model has no uncertainty, but it is overfitting and overconfident. The fit to the omitted point might not be very reliable. leave_one_out(1:nrow(Brains), degree = 5, ylim = c(-2200, 4000)) ## Warning in qt((1 - level)/2, df): NaNs produced ## Warning in qt((1 - level)/2, df): NaNs produced ## Warning in qt((1 - level)/2, df): NaNs produced ## Warning in qt((1 - level)/2, df): NaNs produced ## Warning in qt((1 - level)/2, df): NaNs produced ## Warning in qt((1 - level)/2, df): NaNs produced ## Warning: Removed 10 rows containing missing values (geom_smooth). ## Warning in qt((1 - level)/2, df): NaNs produced 20.6 Exercises The CalvinBayes::Seaweed data set (adapted from (Qian and Shen 2007)) records how quickly seaweed regenerates when in the presence of different types of grazers. Data were collected from eight different tidal areas of the Oregon coast. We want to predict the amount of seaweed from the two predictors: grazer type and tidal zone. The tidal zones are simply labeled A–H. The grazer type was more involved, with six levels: No grazers (None), small fish only (f), small and large fish (fF), limpets only (L), limpets and small fish (Lf), limpets and small fish and large fish (LfF). We would like to know the effects of the different types of grazers, and we would also like to know about the different zones. Create a plot that puts SeaweedAmt on the y-axis, Grazer on the x-axis, and uses Zone for faceting. Use gf_jitter() to avoid overplotting. Set height and width to appropriate values so the plot is still easily interpretable. Fit a model with both predictors and their interaction assuming homogeneous variances in each group. Why would it not be a good idea to fit a model with heterogenous variances? What is the effect of small fish across all the zones? Answer this question by setting up the following three contrasts: none versus small fish only; limpets only versus limpets and small fish; the average of none and limpets only versus the average of small fish only and limpets with small fish. Discuss the results. What is the effect of limpets? There are several contrasts that can address this question, but be sure to include a contrast that compares all of the locations with limpets to all of the locations without limpets. Set up a contrast to compare Zone A with Zone D. Briefly discuss the result. Does the effect of limpets depend on whether the location is in zone A or D? Use an appropriate contrast to find out. This problem investigates the synthetic data set CalvinBayes::NonhomogVar. From the plot, it is pretty clear that that variance is not the same across the groups. Fit two models. model1_brm &lt;- brm(Y ~ Group, data = NonhomogVar) model2_brm &lt;- brm(bf(Y ~ Group, sigma ~ Group), data = NonhomogVar) What is the difference between these two models? (That is, what does sigma ~ Group do?) Describe the priors for each model. (Use prior_summary() if you are not sure.) Create the following plots: A plot showing the posterior distributions of \\(\\sigma\\) from model 1 and each of the \\(\\sigma_j\\)’s from model 2. (Stack multiple calls to gf_dens() on a single plot. Use color or linetype or size or some combination of these to make them distinguishable. Note: color = ~&quot;sigmaA&quot;, etc will give you a nice legend. This works for linetype and size as well.) A plot showing the posterior distribution of \\(\\sigma_A - \\sigma_B\\) in model 2. A plot showing the posterior distribution of \\(\\sigma_B - \\sigma_C\\) in model 2. A plot showing the posterior distribution of \\(\\frac{\\sigma_A + \\sigma_D}{2} - \\frac{\\sigma_B + \\sigma_C}{2}\\) in model 2. Use each model to answer the following: Are the means of groups A and B different? Are the means of groups B and C different? Explain why the models agree or disagree. The original plot suggests that model 2 should be preferred over model 1. Compare the models using WAIC and LOOIC. Are these measures able to detect that model 2 is better than model 1? Create a model like fert4_brm but use family = student(). This will add a parameter to your model. According to WAIC and LOO, which model should your prefer? (Note: the answer can be neither.) References "],
["dichotymous-response.html", "21 Dichotymous Response 21.1 What Model? 21.2 Interpretting Logistic Regression Models 21.3 Robust Logistic Regression", " 21 Dichotymous Response 21.1 What Model? Let’s suppose we want to predict a person’s gender from their height and weight. What sort of model should we use? Give a particular height and weight, a person might be male or female. So for a given height/weight combination, the distribution of gender is a Bernoulli random variable. Our goal is to convert the height/weight combination into the parameter \\(\\theta\\) specifying what proportion of people with that height and weign combination are male (or female). So our model looks something like \\[\\begin{align*} Y &amp;\\sim {\\sf Bern}(\\theta) \\\\ \\theta &amp;= \\mathrm{f}(\\texttt{height}, \\texttt{weight}) \\end{align*}\\] But what functions should we use for \\(f\\)? 21.1.1 A method with issues: Linear regression One obvious thing to try is a linear function: \\[\\begin{align*} Y &amp;\\sim {\\sf Bern}(\\theta) \\\\ \\theta &amp;= \\beta_0 + \\beta_{\\texttt{height}} \\texttt{height} + \\beta_{\\texttt{weight}} \\texttt{weight} \\end{align*}\\] An interaction term could easily be added as well. This model is basically converting the dichotymous response into a quantitative variable (0’s and 1’s) and using the same sort of regression model we have used for metric variables, but with a different noise distribution. One problem with this model is that our linear function might well return values outside the interval \\([0, 1]\\). This would cause two problems: It is making a prediction we know is incorrect. The Bernoulli random variable needs a value of \\(\\theta\\) between 0 and 1, so our likelihood function would be broken. This model is still sometimes use (but with normal noise rather than Bernoulli noise to avoid breaking the likelihood function). But there are better approaches. 21.1.2 The usual approach: Logistic regression We would like to use a linear function, but convert its range from \\((-\\infty, \\infty)\\) to \\((0, 1)\\). Alternatively, we can convert the the range \\((0,1)\\) to \\((-\\infty, \\infty)\\) and parameterize the Bernoulli distribution differently. The most common transformation used the log odds transformation: \\[ \\begin{array}{rcl} \\mathrm{probability} &amp; \\theta &amp; (0, 1) \\\\ \\mathrm{odds} &amp; \\theta \\mapsto \\frac{\\theta}{1- \\theta} &amp; (0, \\infty) \\\\ \\mathrm{log\\ odds} &amp; \\theta \\mapsto \\log(\\frac{\\theta}{1- \\theta}) &amp; (-\\infty, \\infty) \\\\ \\end{array} \\] Read backwards, this is the logistic transformation \\[\\begin{array}{rcl} \\mathrm{log\\ odds} &amp; x &amp; (-\\infty, \\infty) \\\\ \\mathrm{odds} &amp; x \\mapsto e^x &amp; (0, \\infty) \\\\ \\mathrm{probability} &amp; x \\mapsto \\frac{e^x}{1 + e^x} &amp; (0, 1) \\\\ \\end{array}\\] These functions are available via the mosaic packge as logit() and ilogit(): logit ## function(x) ## { ## log(x/(1 - x)) ## } ## &lt;bytecode: 0x7f9fda1eeeb0&gt; ## &lt;environment: namespace:mosaicCore&gt; ilogit ## function (x) ## { ## exp(x)/(1 + exp(x)) ## } ## &lt;bytecode: 0x7f9fda064e08&gt; ## &lt;environment: namespace:mosaicCore&gt; The inverse logit function is also called the logistic function and the logistic regression model is \\[\\begin{align*} Y &amp;\\sim {\\sf Bern}(\\theta) \\\\ \\theta &amp;= \\mathrm{logistic}(\\beta_0 + \\beta_{\\texttt{height}} \\texttt{height} + \\beta_{\\texttt{weight}} \\texttt{weight}) \\\\ \\mathrm{logit}(\\theta) &amp;= \\beta_0 + \\beta_{\\texttt{height}} \\texttt{height} + \\beta_{\\texttt{weight}} \\texttt{weight} \\end{align*}\\] The logit function is called the link function and the logistic function is the inverse link function. 21.1.3 Other approaches We could do a similar thing with any pair of functions that convert back and forth between \\((0,1)\\) and \\((-\\infty, \\infty)\\). For any random variable, the cdf (cumulative distribution function) has domain \\((-\\infty, \\infty)\\) and range \\((0,1)\\), so Any cdf/inverse cdf pair can be used in place of the logistic tranformation. using pnorm() and qnorm() is called **probit regression*. We can also work this backwards and create a random variable that has the logistic function as its cdf. The random variable is called (wait for it) the logistic random variable. gf_function(ilogit, xlim = c(-6, 6), color = ~&quot;logistic&quot;) %&gt;% gf_function(pnorm, color = ~&quot;probit (standard)&quot;) %&gt;% gf_function(pnorm, args = list(sd = 1.8), color = ~&quot;probit (mean = 0, sd = 1.8)&quot;) %&gt;% gf_theme(legend.position = &quot;top&quot;) %&gt;% gf_labs(color = &quot;&quot;) 21.1.4 Preparing the data We will use a subset of the NHANES data for this example. This is a different data set from the example in the book (which uses synthetic data). Since the data there are in pounds and inches, we’ll convert the NHANES data to these units. As in other models, we need to convert our dichotymous variable into 0’s and 1’s. We certainly want to remove children from the model since height and weight patterns are different for children and adults. In fact, we’ll just select out the 22-year-olds. While we are at it, we’ll get rid of the variables we don’t need and remove any rows with missing values in those three rows. library(NHANES) library(brms) nhanes &lt;- NHANES %&gt;% mutate( weight = Weight * 2.2, height = Height / 2.54, male = as.numeric(NHANES$Gender == &quot;male&quot;), ) %&gt;% filter(Age == 22) %&gt;% select(male, height, weight) %&gt;% filter(complete.cases(.)) # remove rows where any of the 3 variables is missing 21.1.5 Specifying family and link function in brm() Compared to our usual linear regression model, we need to make two adjustments: Use the Bernoulli family of distriutions for the noise Use the logit link (logistic inverse link) function to translate back and forth between the linear part of the model and the distribution. Both are done simultaneously when we set the family argument in brm(). Each family comes with a default link function, but we can override that if we like. So for logistic and probit regression, we use logistic_brm &lt;- brm(male ~ height + weight, family = bernoulli(link = logit), data = nhanes) ## Compiling the C++ model ## Start sampling probit_brm &lt;- brm(male ~ height + weight, family = bernoulli(link = probit), data = nhanes) ## Compiling the C++ model ## Start sampling The rest of the model behaves as before. In particular, a t-distribution is used for the intercept and improper uniform distributions are used for the other regression coefficients. This model doesn’t have a \\(\\sigma\\) parameter. (The variance of a Bernoulli distribution is determined by the probability parameter.) prior_summary(logistic_brm) prior class coef group resp dpar nlpar bound b b height b weight student_t(3, 0, 10) Intercept 21.2 Interpretting Logistic Regression Models Beore getting our model with two predictors, let’s look at a model with only one predictor. male_by_weight_brm &lt;- brm(male ~ weight, family = bernoulli(), data = nhanes) ## Compiling the C++ model ## recompiling to avoid crashing R session ## Start sampling male_by_weight_brm ## Family: bernoulli ## Links: mu = logit ## Formula: male ~ weight ## Data: nhanes (Number of observations: 135) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat ## Intercept -2.12 0.82 -3.78 -0.58 3545 1.00 ## weight 0.01 0.00 0.00 0.02 3499 1.00 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). mcmc_combo(as.mcmc.list(stanfit(male_by_weight_brm))) plot_post(posterior(male_by_weight_brm)$b_weight) ## $posterior ## ESS mean median mode ## var1 3459 0.01261 0.01246 0.01218 ## ## $hdi ## prob lo hi ## 1 0.95 0.00397 0.02292 p &lt;- marginal_effects(male_by_weight_brm) %&gt;% plot(plot = FALSE) p$weight %&gt;% gf_jitter(male ~ weight, data = nhanes, inherit = FALSE, width = 0, height = 0.03, alpha = 0.3) Things we learn from this model: There is clearly a upward trend – heavier people are more likely to be male than lighter people are. This is seen in the posterior distribution for \\(\\beta_{\\mathrm{weight}}\\). hdi(posterior(male_by_weight_brm), pars = &quot;b_weight&quot;) par lo hi mode prob b_weight 0.004 0.0229 0.0123 0.95 The rise is gentle, not steep. There is no weight at which we abruptly believe gender is much more likely to be male above that weight and female below that weight. For a given value of \\(\\theta = \\langle \\beta_0, \\beta_{\\mathrm{weight}}\\rangle\\) we can compute the weight at which the model believes the gender split is 50/50. Probability is 0.5 when the odds is 1 and the log odds is 0. And \\(\\beta_0 + \\beta_{\\mathrm{weight}} \\mathrm{weight} = 0\\) when \\(\\mathrm{weight} = -\\beta_0 / \\beta_{\\mathrm{weight}}\\). A 95% HDI For this value is quite wide. Post &lt;- posterior(male_by_weight_brm) %&gt;% mutate(fifty_fifty = - b_Intercept / b_weight) h &lt;- hdi(Post, pars = &quot;fifty_fifty&quot;); h par lo hi mode prob fifty_fifty 126.6 204.3 172.6 0.95 p$weight %&gt;% gf_segment(0.5 + 0.5 ~ lo + hi, data = h, color = &quot;red&quot;, inherit = FALSE) logistic_brm ## Family: bernoulli ## Links: mu = logit ## Formula: male ~ height + weight ## Data: nhanes (Number of observations: 135) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat ## Intercept -64.73 10.86 -87.60 -45.91 3159 1.00 ## height 0.95 0.16 0.67 1.28 3223 1.00 ## weight 0.01 0.01 -0.01 0.02 3696 1.00 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). 21.3 Robust Logistic Regression For models with metric response, using t distribuitons instead of normal distributions made the models more robust (less influenced by unusually large or small values in the data). Logistic regression can also be strongly influenced by unusual observations. In our example, if there is an unusually heavy woman or an unusually light man, the likelihood will be very small unless we flatten the logistic curve. But we cannot simply replace a normal distribution with a t distribution because our likelihood does not involve a normal distribution. Kruschke recommends a methods that fits a mixture of the usual logistic regression model and a model that is “just guessing” (50-50 chance of being male or female). That Stan development folks (and others) recommend a different appraoch: Fit the model with an inverse t cdf. This is like a probit model, but with more flexibility. In particular, if the degrees of freedom is small, the inverse t cdf will approach its assymptotes more slowly than the probit or logistic models do. Getting brm() to fit this model requires a few extra steps: define the inverse t cdf function using stanvars use an identity link (since we will be coding in the link/inverse link manually). turn off linear model evaluation of the main formula with nl = TRUE. (This can be used for other non-linear model situations as well.) # define inverse robit function (Stan syntax) stan_inv_robit &lt;- &quot; real inv_robit(real y, real nu) { return student_t_cdf(y, nu, 0, (nu - 2) / nu); } &quot; bform &lt;- bf( male ~ inv_robit(theta, nu), # non-linear -- use algebra as is in *main* formula nl = TRUE, # theta = theta_Intercept + theta_weight * weight + theta_height * height theta ~ weight + height, nu ~ 1, # nu = nu_Intercept (ie. just one value of nu) family = bernoulli(&quot;identity&quot;) # identity link function ) bprior &lt;- prior(normal(0, 5), nlpar = &quot;theta&quot;) + prior(gamma(2, 0.1), nlpar = &quot;nu&quot;, lb = 2) robit_brm &lt;- brm(bform, prior = bprior, data = nhanes, stanvars = stanvar(scode = stan_inv_robit, block = &quot;functions&quot;) ) ## Compiling the C++ model ## Start sampling ## Warning: There were 3 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 10. See ## http://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded ## Warning: Examine the pairs() plot to diagnose sampling problems prior_summary(robit_brm) robit_brm loo(robit_brm, reloo = TRUE) loo(logistic_brm, reloo = TRUE) new_data &lt;- expand.grid( height = seq(60, 75, by = 3), weight = seq(125,225, by = 25) ) bind_cols( new_data, data.frame(predict(logistic_brm, newdata = new_data, transform = ilogit)) ) height weight Estimate Est.Error Q2.5 Q97.5 60 125 0.5006 0.0121 0.5000 0.5000 63 125 0.5051 0.0341 0.5000 0.5000 66 125 0.5631 0.1030 0.5000 0.7311 69 125 0.6947 0.0841 0.5000 0.7311 72 125 0.7275 0.0283 0.7311 0.7311 75 125 0.7307 0.0097 0.7311 0.7311 60 150 0.5006 0.0115 0.5000 0.5000 63 150 0.5069 0.0394 0.5000 0.7311 66 150 0.5741 0.1079 0.5000 0.7311 69 150 0.7023 0.0763 0.5000 0.7311 72 150 0.7284 0.0246 0.7311 0.7311 75 150 0.7308 0.0073 0.7311 0.7311 60 175 0.5003 0.0082 0.5000 0.5000 63 175 0.5098 0.0466 0.5000 0.7311 66 175 0.5835 0.1110 0.5000 0.7311 69 175 0.7069 0.0707 0.5000 0.7311 72 175 0.7289 0.0221 0.7311 0.7311 75 175 0.7309 0.0052 0.7311 0.7311 60 200 0.5007 0.0126 0.5000 0.5000 63 200 0.5113 0.0499 0.5000 0.7311 66 200 0.5964 0.1139 0.5000 0.7311 69 200 0.7119 0.0638 0.5000 0.7311 72 200 0.7296 0.0186 0.7311 0.7311 75 200 0.7309 0.0052 0.7311 0.7311 60 225 0.5014 0.0178 0.5000 0.5000 63 225 0.5136 0.0543 0.5000 0.7311 66 225 0.6095 0.1154 0.5000 0.7311 69 225 0.7133 0.0615 0.5000 0.7311 72 225 0.7297 0.0175 0.7311 0.7311 75 225 0.7310 0.0037 0.7311 0.7311 marginal_effects( logistic_brm, effects = &quot;height&quot;, conditions = data.frame(weight = seq(125, 225, by = 25))) "],
["nominal-response.html", "22 Nominal Response", " 22 Nominal Response "],
["ordinal-response.html", "23 Ordinal Response", " 23 Ordinal Response "],
["count-response.html", "24 Count Response 24.1 Hair and eye color data 24.2 Are hair and eye color independent? 24.3 Poisson model 24.4 Exercises", " 24 Count Response 24.1 Hair and eye color data Let’s take a look at the data. HairEyeColor %&gt;% tidyr::spread(Eye, Count) Hair Blue Brown Green Hazel Black 20 68 5 15 Blond 94 7 16 10 Brown 84 119 29 54 Red 17 26 14 14 gf_tile(Count ~ Hair + Eye, data = HairEyeColor) %&gt;% gf_text(Eye ~ Hair, label = ~Count, color = &quot;white&quot;, size = 10) %&gt;% gf_refine(scale_fill_viridis_c(option = &quot;C&quot;, begin = 0.1, end = 0.9)) gf_col(Count ~ Hair, fill = ~ Eye, data = HairEyeColor, position = &quot;dodge&quot;) %&gt;% gf_refine(scale_fill_manual(values = c(&quot;blue&quot;, &quot;brown&quot;, &quot;forestgreen&quot;, &quot;tan&quot;))) gf_col(Count ~ Eye, fill = ~ Hair, data = HairEyeColor, position = &quot;dodge&quot;) %&gt;% gf_refine(scale_fill_manual(values = c(&quot;black&quot;, &quot;wheat1&quot;, &quot;brown&quot;, &quot;red&quot;))) 24.2 Are hair and eye color independent? You probably suspect not. We expect blue eyes to be more common among blond-haired people than among black-haired people, perhaps. How do we fit a model to test if our intuition is correct using the data above? If the rows and columns of the table were independent, then for each row \\(r\\) and column \\(c\\) the probability of being in a row \\(r\\) and column \\(c\\) would be the product of the probabilities of being in row \\(r\\) and of being in column \\(c\\): \\[ \\begin{align*} \\frac{\\mu_{r c}}{N} &amp;= \\frac{y_{r\\cdot}}{N} \\cdot \\frac{y_{\\cdot c}}{N} \\\\ \\mu_{r c} &amp;= \\frac{1}{N} \\cdot y_{r\\cdot} \\cdot y_{\\cdot c} \\\\ \\log(\\mu_{r c}) &amp;= \\underbrace{\\log(\\frac{1}{N})}_{\\alpha_0}\\cdot1 + \\underbrace{\\log(y_{r\\cdot})}_{\\alpha_{r \\cdot}}\\cdot1 + \\underbrace{\\log(y_{\\cdot c})}_{\\alpha_{\\cdot c}}\\cdot1 \\\\ \\log(\\mu) &amp;= \\alpha_0 + \\sum_{r = 1}^R \\alpha_{r\\cdot} [\\![ \\mathrm{in\\ row\\ } r ]\\!] + \\sum_{c = 1}^C \\alpha_{\\cdot c} [\\![ \\mathrm{in\\ column\\ } c ]\\!] \\\\ \\log(\\mu) &amp;= \\underbrace{(\\alpha_0 + \\alpha_{1\\cdot} + \\alpha_{\\cdot 1})}_{\\beta_0} + \\sum_{r = 2}^R \\alpha_{r\\cdot} [\\![ \\mathrm{in\\ row\\ } r ]\\!] + \\sum_{c=2}^C \\alpha_{\\cdot c} [\\![ \\mathrm{in\\ column\\ } c ]\\!] \\\\ \\log(\\mu) &amp;= \\beta_0 + \\sum_{r = 2}^R \\beta_{r\\cdot} [\\![ \\mathrm{in\\ row\\ } r ]\\!] + \\sum_{c=2}^C \\beta_{\\cdot c} [\\![ \\mathrm{in\\ column\\ } c ]\\!] \\end{align*} \\] This looks exactly like our additive linear model (on the log scale) and so the common name for this model is the log linear model. If the rows and columns are not independent, then we will have non-zero interaction terms indicating how far things are from independent. We know how to add in interaction terms, so we are good to go there. All that remains is to come up with a good distribution that turns a mean \\(\\mu\\) into a count. We don’t expect the cell count $y_{rc} to be exactly \\(\\mu_{rc}\\) (especially when \\(\\mu_{rc}\\) in not an integer!). But values close to \\(\\mu_{rc}\\) should be more likely than values farther away from \\(\\mu_{rc}\\). A Poisson distribution has exactly these properties and makes a good model for the noise in this situation. Poisson distributions have one parameter (often denoted \\(\\lambda\\)) satisfying \\[ \\begin{align*} \\mathrm{mean} &amp;= \\lambda \\\\ \\mathrm{variance} &amp;= \\lambda \\\\ \\mathrm{standard\\ deviation} &amp;= \\sqrt{\\lambda} \\\\ \\end{align*} \\] Here are several examples of Poisson distributions. Notice that \\(\\lambda\\) need not be an integer, but all of the values produced by a Poisson random process are integers. gf_dist(&quot;pois&quot;, lambda = 1.8) gf_dist(&quot;pois&quot;, lambda = 5.8) gf_dist(&quot;pois&quot;, lambda = 25.8) gf_dist(&quot;pois&quot;, lambda = 254.8) The Poisson distributions become more and more symmetric as \\(\\lambda\\) increases. In fact, they become very nearly a normal distribution.10 24.3 Poisson model The discussion above gives us enough information to create the appropriate model in R using brm(). color_brm &lt;- brm(Count ~ Hair * Eye, data = HairEyeColor, family = poisson(link = log)) ## Compiling the C++ model ## Start sampling color_brm ## Family: poisson ## Links: mu = log ## Formula: Count ~ Hair * Eye ## Data: HairEyeColor (Number of observations: 16) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat ## Intercept 2.95 0.23 2.49 3.37 1178 1.00 ## HairBlond 1.58 0.25 1.13 2.07 1257 1.00 ## HairBrown 1.47 0.25 1.00 1.99 1215 1.00 ## HairRed -0.14 0.33 -0.79 0.50 1459 1.00 ## EyeBrown 1.26 0.26 0.78 1.76 1232 1.00 ## EyeGreen -1.44 0.51 -2.50 -0.49 1413 1.00 ## EyeHazel -0.28 0.34 -0.95 0.41 1328 1.00 ## HairBlond:EyeBrown -3.92 0.48 -4.91 -3.03 2073 1.00 ## HairBrown:EyeBrown -0.91 0.29 -1.49 -0.37 1296 1.00 ## HairRed:EyeBrown -0.84 0.41 -1.62 -0.02 1655 1.00 ## HairBlond:EyeGreen -0.36 0.58 -1.46 0.81 1621 1.00 ## HairBrown:EyeGreen 0.36 0.55 -0.68 1.49 1488 1.00 ## HairRed:EyeGreen 1.23 0.63 0.03 2.50 1601 1.00 ## HairBlond:EyeHazel -2.01 0.48 -2.96 -1.08 1894 1.00 ## HairBrown:EyeHazel -0.17 0.39 -0.94 0.58 1465 1.00 ## HairRed:EyeHazel 0.07 0.49 -0.89 1.04 1628 1.00 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Our main question is whether any of the interaction terms are credibly different from 0. That would indicate a cell that has more or fewer observations than we would expect if rows and columns were independent. We can construct contrasts to look at particular ways in which independence might fail. color2_brm &lt;- brm(Count ~ Hair + Eye, data = HairEyeColor, family = poisson(link = log)) ## Compiling the C++ model ## recompiling to avoid crashing R session ## Start sampling The model with interaction has higher estimated elpd than the model without interaction terms, an indication that there are credible interaction effects. loo_compare(waic(color_brm), waic(color2_brm)) elpd_diff se_diff elpd_waic se_elpd_waic p_waic se_p_waic waic se_waic color_brm 0.0 0.00 -53.84 1.904 7.932 0.0872 107.7 3.808 color2_brm -108.6 49.11 -162.42 49.293 67.638 28.6723 324.8 98.586 (LOO gives a similar result, but requires starting from scratch for several observations, so it is slower.) As an example, let’s test whether blond-haired people are more likely to have blue eyes than black-haired people. We don’t want to compare counts, however, since the number of blond-haired and black-haired people is not equal. Differences on a log scale are ratios on the natural scale. So we might compare \\[ \\begin{align*} \\log(\\mu_{\\mathrm{blond,\\ blue}}) - \\log(\\mu_{\\mathrm{blond,\\ not\\ blue}}) &amp;= \\log\\left( \\frac{\\mu_{\\mathrm{blond,\\ blue}}} {\\mu_{\\mathrm{blond,\\ not\\ blue}}}\\right) \\end{align*} \\] with \\[ \\begin{align*} \\log(\\mu_{\\mathrm{black,\\ blue}}) - \\log(\\mu_{\\mathrm{black,\\ not\\ blue}}) &amp;= \\log\\left( \\frac{\\mu_{\\mathrm{black,\\ blue}}} {\\mu_{\\mathrm{black,\\ not\\ blue}}}\\right) \\end{align*} \\] If those two quantities are equal, then the log odds, hence odds, hence probability of having blue eyes is the same in both groups. Let’s build the corresponding contrast and find out. Since the intercept coefficient shows up in every term (and then cancels out), we can drop it from our contrast to save some typing. Similarly in the blond difference b_HairBlond drops out and in the black-haired difference b_HairBlack drops out. Things are further simplified because blue eyes and black hair are the reference groups (because they come alphabetially first). Post &lt;- posterior(color_brm) names(Post) ## [1] &quot;b_Intercept&quot; &quot;b_HairBlond&quot; &quot;b_HairBrown&quot; &quot;b_HairRed&quot; ## [5] &quot;b_EyeBrown&quot; &quot;b_EyeGreen&quot; &quot;b_EyeHazel&quot; &quot;b_HairBlond:EyeBrown&quot; ## [9] &quot;b_HairBrown:EyeBrown&quot; &quot;b_HairRed:EyeBrown&quot; &quot;b_HairBlond:EyeGreen&quot; &quot;b_HairBrown:EyeGreen&quot; ## [13] &quot;b_HairRed:EyeGreen&quot; &quot;b_HairBlond:EyeHazel&quot; &quot;b_HairBrown:EyeHazel&quot; &quot;b_HairRed:EyeHazel&quot; ## [17] &quot;lp__&quot; Post &lt;- Post %&gt;% mutate( contrast = 0 - (b_EyeBrown + `b_HairBlond:EyeBrown` + b_EyeGreen + `b_HairBlond:EyeGreen` + b_EyeHazel + `b_HairBlond:EyeHazel`) / 3 + - 0 + (b_EyeBrown + b_EyeGreen + b_EyeHazel) / 3 ) hdi(Post, pars = ~ contrast) par lo hi mode prob contrast 1.423 2.804 2.118 0.95 plot_post(Post$contrast) ## $posterior ## ESS mean median mode ## var1 1328 2.096 2.09 2.103 ## ## $hdi ## prob lo hi ## 1 0.95 1.423 2.804 As expected, the posterior distribution for this contrast is shifted well away from 0, an indication that the proportion of blond-haired people with blue eyes is credibly higher than the proportion of black-haired people with blue eyes. The log odds ratio is about 2 (posterior HDI suggests somewhere betweeen 1.4 and 2.7). and the odds ratio can be obtained by exponentiation. hdi(Post, pars = ~ exp(contrast)) par lo hi mode prob exp(contrast) 3.333 14.97 8.318 0.95 plot_post(exp(Post$contrast)) ## $posterior ## ESS mean median mode ## var1 1307 8.678 8.085 6.979 ## ## $hdi ## prob lo hi ## 1 0.95 3.333 14.97 Unfortunately, we can’t convert the odds ratio directly into a relative risk. \\[ \\begin{align*} \\mathrm{odds\\ ratio} &amp;= \\frac{p_1 / (1-p_1)}{p_2 / (1-p_2)} \\\\ &amp;= \\frac{p_1}{1-p_1} \\cdot \\frac{1-p_2}{p_2} \\\\ &amp;= \\frac{p_1}{p_2}\\cdot \\frac{1-p_2}{1-p_1} \\\\ &amp;= \\mathrm{relative\\ risk} \\cdot \\frac{1-p_2}{1-p_1} \\\\ \\end{align*} \\] Relative risk and odds ratio are numerically close when \\(\\frac{1-p_2}{1-p_1}\\) is close to 1, which happens when \\(p_1\\) and \\(p_2\\) are both quite small. 24.4 Exercises A set of data from Snee (1974) reports counts of criminals on two attributes: the type of crime they committed and whether or not they regularly drink alcohol. gf_tile(Count ~ Crime + Drink, data = CrimeDrink) %&gt;% gf_text(Drink ~ Crime, label = ~ Count, color = &quot;white&quot;, size = 10) %&gt;% gf_refine(scale_fill_viridis_c(option = &quot;C&quot;, begin = 0.1, end = 0.9)) gf_col(Count ~ Crime, fill = ~ Drink, data = CrimeDrink, position = &quot;dodge&quot;) %&gt;% gf_refine(scale_fill_brewer(type = &quot;qual&quot;, palette = 3)) gf_col(Count ~ Drink, fill = ~ Crime, data = CrimeDrink, position = &quot;dodge&quot;) %&gt;% gf_refine(scale_fill_brewer(type = &quot;qual&quot;, palette = 3)) Use this model to answer the questions below. crime_brm &lt;- brm(Count ~ Drink * Crime, data = CrimeDrink, family = poisson(link = log)) ## Compiling the C++ model ## Start sampling a. What is the posterior estimate of the proportion of crimes that is committed by drinkers? Is the precision good enough to say that credibly more crimes are committed by drinkers than by nondrinkers? Hint: For a given row of the posterior, how do you compute the expected number of crimes in each category? &lt;!-- (This question is asking about a main-effect contrast.) --&gt; b. What is the posterior estimate of the proportion of crimes that are fraud and the proportion that are violent (other than rape, which is a separate category in this data set)? Overall, is the precision good enough to say that those proportions are credibly different? Take Stat 343 to find out why.↩ "],
["this-and-that.html", "25 This and That 25.1 Wells in Bangledesh 25.2 Gelman/Hill Principles for Buiding Models", " 25 This and That 25.1 Wells in Bangledesh Some things to learn from this example: We can use update() to speed up fitting multiple models. We can combine ideas to build up models with multiple predictors. marginal_effects() can simplify making certain plots that show how the model thingks the response depends on one of the predictors. It is a little bit clunky to use, but it saves a lot of work. Transforming predictors adds to our palette of models. Evaluating the model prediction at specific values can help us understand what the model says. For logistic regression, there is a handy short-cut to help understand the coefficients. 25.1.1 The data The rstanarm package contains a data set called wells that includes data from a survey of 3200 residents in a small area of Bangladesh suffering from arsenic contamination of groundwater. Respondents with elevated arsenic levels in their wells had been encouraged to switch their water source to a safe public or private well in the nearby area and the survey was conducted several years later to learn which of the affected residents had switched wells. The data include several variables. switch Indicator for well-switching (1 = switched, 0 = did not switch) arsenic Arsenic level in respondent’s well dist Distance (meters) from the respondent’s house to the nearest well with safe drinking water. association Indicator for member(s) of household participating in community organizations educ Years of education (of the head of household) library(rstanarm) glimpse(wells) ## Observations: 3,020 ## Variables: 5 ## $ switch &lt;int&gt; 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, … ## $ arsenic &lt;dbl&gt; 2.36, 0.71, 2.07, 1.15, 1.10, 3.90, 2.97, 3.24, 3.28, 2.52, 3.13, 3.04, 2.91, 3.2… ## $ dist &lt;dbl&gt; 16.83, 47.32, 20.97, 21.49, 40.87, 69.52, 80.71, 55.15, 52.65, 75.07, 29.77, 34.5… ## $ assoc &lt;int&gt; 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, … ## $ educ &lt;int&gt; 0, 0, 10, 12, 14, 9, 4, 10, 0, 0, 5, 0, 0, 0, 0, 7, 7, 7, 0, 10, 7, 0, 5, 0, 8, 8… 25.1.2 The Question Our goal is to use this data to determine which factors impact the decision to switch. 25.1.3 Distance as a predictor It seems reasonable that people might be more likely to switch to a well if it isn’t too far away. Let’s see. wells1_brm &lt;- brm(switch ~ dist, data = wells, family = bernoulli(link = logit)) ## Compiling the C++ model ## Start sampling wells1_brm ## Family: bernoulli ## Links: mu = logit ## Formula: switch ~ dist ## Data: wells (Number of observations: 3020) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat ## Intercept 0.61 0.06 0.49 0.72 1822 1.00 ## dist -0.01 0.00 -0.01 -0.00 4241 1.00 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). What do we make of dist as a predictor? Ideally, we’d like some more digits. hdi(posterior(wells1_brm), regex_pars = &quot;b_&quot;) par lo hi mode prob b_Intercept 0.4863 0.7208 0.6207 0.95 b_dist -0.0081 -0.0043 -0.0065 0.95 mcmc_combo(as.mcmc(wells1_brm), regex_pars = &quot;b_&quot;) b_dist is “small”, but well separated from 0. But keep in mind that our unit of distance is meters, so this is telling us about the change in log odds of switching per meter that the clean well is farther away. One meter probably doesn’t matter much. Perhaps 100 or 1000 meters would matter more, however. This model predicts a change in log odds of roughly 0.6 for every 100 meters. Don’t ignore small coefficients if they get multiplied by large variables! So what does our model “look like”. It would be nice to see how the probability of switching depends on distance from a clean well. The marginal_effects() function can help us make such a plot. marginal_effects(wells1_brm) If we would like to add to the plot we have some work to do. marginal_effects() doesn’t return the plot, it prints it, so we have to tell it not to do that. The result will be a list of plots (because in a more complicated model there would be multiple predictors), so to get the plot we want, we have to select it from the list. p &lt;- marginal_effects(wells1_brm) %&gt;% plot(plot = FALSE) p[[1]] %&gt;% gf_jitter(switch ~ dist, data = wells, height = 0.2, width = 0, alpha = 0.4, inherit = FALSE) %&gt;% gf_labs(x = &quot;distance (m)&quot;) 25.1.4 Updating a model without recompiling Seems a shame to recompile our Stan model just to use the new distance variable. Fortunately, brms includes and update() function for updating models and it will avoid recompiling when it can. For example, there is no need to recompile if we use a different data set (that still has the needed variables for the model) we want change the number of iterations or chains. Let’s give it a try. wells &lt;- wells %&gt;% mutate(dist100 = dist / 100) wells2_brm &lt;- update(wells1_brm, switch ~ dist100, newdata = wells) ## Start sampling wells2_brm ## Family: bernoulli ## Links: mu = logit ## Formula: switch ~ dist100 ## Data: wells (Number of observations: 3020) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat ## Intercept 0.61 0.06 0.49 0.72 3926 1.00 ## dist100 -0.62 0.10 -0.81 -0.44 3780 1.00 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). p &lt;- marginal_effects(wells2_brm) %&gt;% plot(plot = FALSE) p[[1]] %&gt;% gf_jitter(switch ~ dist100, data = wells, height = 0.2, width = 0, alpha = 0.4, inherit = FALSE) %&gt;% gf_labs(x = &quot;distance (100 m)&quot;) # Two ways use a log transformation on distance wells &lt;- wells %&gt;% mutate(log10dist = log10(dist)) wells3_brm &lt;- update(wells1_brm, newdata = wells, formula. = switch ~ log10(dist)) ## Start sampling wells4_brm &lt;- update(wells1_brm, newdata = wells, formula. = switch ~ log10dist) ## Start sampling wells3_brm ## Family: bernoulli ## Links: mu = logit ## Formula: switch ~ log10(dist) ## Data: wells (Number of observations: 3020) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat ## Intercept 1.02 0.16 0.72 1.34 3428 1.00 ## log10dist -0.46 0.10 -0.66 -0.27 3450 1.00 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). p &lt;- marginal_effects(wells3_brm) %&gt;% plot(plot = FALSE) p[[1]] %&gt;% gf_jitter(switch ~ dist, data = wells, height = 0.2, width = 0, alpha = 0.4, inherit = FALSE) %&gt;% gf_labs(x = &quot;distance&quot;) wells4_brm ## Family: bernoulli ## Links: mu = logit ## Formula: switch ~ log10dist ## Data: wells (Number of observations: 3020) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat ## Intercept 1.02 0.17 0.70 1.34 3390 1.00 ## log10dist -0.46 0.10 -0.66 -0.26 3458 1.00 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). p &lt;- marginal_effects(wells4_brm) %&gt;% plot(plot = FALSE) p[[1]] %&gt;% gf_jitter(switch ~ log10(dist), data = wells, height = 0.2, width = 0, alpha = 0.4, inherit = FALSE) %&gt;% gf_labs(x = &quot;log distance&quot;) compare(loo(wells1_brm), loo(wells2_brm), loo(wells3_brm), loo(wells4_brm)) elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic loo(wells1_brm) 0.0000 0.0000 -2040 10.424 1.935 0.0469 4080 20.85 loo(wells2_brm) -0.0915 0.0097 -2040 10.417 2.026 0.0472 4080 20.83 loo(wells3_brm) -10.5534 3.2084 -2051 9.448 1.998 0.0394 4101 18.90 loo(wells4_brm) -10.6293 3.2097 -2051 9.462 2.076 0.0424 4101 18.92 25.1.5 Interpreting coefficients – discrete change 25.1.6 Interpreting coefficients – the divide by 4 trick Rather than consider a discrete change in our predictor \\(x\\), we can compute the derivative of the logistic curve at the central value. Differentiating the function \\(\\mathrm{ilogit}(\\alpha + \\beta x)\\) with respect to \\(x\\) yields \\[ \\begin{align*} \\frac{d}{dx} \\mathrm{ilogit}(\\alpha + \\beta x) &amp;= \\beta e^{\\alpha + \\beta x}/ (1 + e^{\\alpha + \\beta x})^2 \\end{align*} \\] Now consider the \\(x\\) value for which model predicts a probability of 50%. That is \\[ \\begin{align*} 0.5 &amp;= \\mathrm{ilogit}(\\alpha + \\beta x) \\\\ \\mathrm{logit}(0.5) &amp;= \\alpha + \\beta x \\\\ 0 &amp;= \\alpha + \\beta x \\\\ x &amp;= \\frac{-\\alpha}{\\beta} \\\\ \\end{align*} \\] Plugging this into the derivative we get. \\[ \\begin{align*} \\beta e^{\\alpha + \\beta x} / (1 + e^{\\alpha + \\beta x})^2 &amp;= \\beta e^{\\alpha + \\beta \\frac{-\\alpha}{\\beta}} / (1 + e^{\\alpha + \\frac{-\\alpha}{\\beta}})^2 \\\\ &amp;= \\beta e^{0} / (1 + e^{0})^2 \\\\ &amp;= \\beta / 4 \\end{align*} \\] This is the steepest slope on the logistic curve. So \\(\\beta/4\\) gives us an upper bound on how much the probability changes as \\(x\\) changes. This upper bound is a good approximation for values near this central point. Applying this to our example, The central value of \\(x\\) is approximately (plugging the posterior means for the paramters) \\(- \\frac{0.61}{- 0.62} = 0.98 \\approx 1\\). So an increase of 100 meters decreases the probabity of switching by about 15%. Let’s see how this compares to the direct calculation of the change. Again, using the posterior mean parameter values we get. difference in probability of switching at 100m: \\(\\mathrm{ilogit}(\\hat \\alpha + \\hat \\beta \\cdot 1) = - \\frac{0.61}{- 0.62} =\\) 0.98. probability of switching at 200m: $(+ 2) = $ -0.63. That’s pretty close to our \\(\\beta/4\\) estimate. 25.1.7 Other predictors: arsenic If a person’s well is heavily contaminated with arsenic, perhaps they are more likely to switch. wells5_brm &lt;- update(wells1_brm, newdata = wells, switch ~ dist100 + arsenic) ## Start sampling wells6_brm &lt;- update(wells1_brm, switch ~ dist100 + log(arsenic), newdata = wells) ## Start sampling compare(waic(wells2_brm), waic(wells5_brm), waic(wells6_brm)) elpd_diff se_diff elpd_waic se_elpd_waic p_waic se_p_waic waic se_waic waic(wells6_brm) 0.00 0.000 -1952 16.32 3.011 0.0753 3904 32.64 waic(wells5_brm) -16.24 4.435 -1968 15.67 3.185 0.1324 3937 31.33 waic(wells2_brm) -87.97 13.076 -2040 10.42 2.024 0.0471 4080 20.83 Looks like a log transformation on arsenic is useful. wells6_brm ## Family: bernoulli ## Links: mu = logit ## Formula: switch ~ dist100 + log(arsenic) ## Data: wells (Number of observations: 3020) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat ## Intercept 0.53 0.06 0.41 0.65 3677 1.00 ## dist100 -0.98 0.11 -1.19 -0.78 3196 1.00 ## logarsenic 0.88 0.07 0.75 1.01 3060 1.00 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). gf_point(log(arsenic) ~ dist100, data = wells) %&gt;% gf_smooth() ## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; gf_point(arsenic ~ dist100, data = wells) %&gt;% gf_smooth() ## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; wells7_brm &lt;- update(wells1_brm, switch ~ dist100 * log10(arsenic), newdata = wells) ## Start sampling compare(waic(wells2_brm), waic(wells6_brm), waic(wells7_brm)) elpd_diff se_diff elpd_waic se_elpd_waic p_waic se_p_waic waic se_waic waic(wells6_brm) 0.00 0.000 -1952 16.32 3.011 0.0753 3904 32.64 waic(wells7_brm) -0.20 1.325 -1952 16.38 4.024 0.1438 3905 32.77 waic(wells2_brm) -87.97 13.076 -2040 10.42 2.024 0.0471 4080 20.83 Looks like a log transformation on arsenic is useful. wells7_brm ## Family: bernoulli ## Links: mu = logit ## Formula: switch ~ dist100 + log10(arsenic) + dist100:log10(arsenic) ## Data: wells (Number of observations: 3020) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat ## Intercept 0.49 0.07 0.36 0.62 2606 1.00 ## dist100 -0.87 0.13 -1.13 -0.61 2287 1.00 ## log10arsenic 2.27 0.25 1.79 2.77 1951 1.00 ## dist100:log10arsenic -0.54 0.42 -1.40 0.29 1681 1.00 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). mcmc_areas(as.mcmc.list(stanfit(wells7_brm)), regex_pars = &quot;b_&quot;) 25.1.8 Still more predictors wells8_brm &lt;- update(wells1_brm, switch ~ dist100 * log10(arsenic) + educ + assoc, newdata = wells) ## Start sampling wells8_brm ## Family: bernoulli ## Links: mu = logit ## Formula: switch ~ dist100 + log10(arsenic) + educ + assoc + dist100:log10(arsenic) ## Data: wells (Number of observations: 3020) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat ## Intercept 0.34 0.09 0.17 0.52 3464 1.00 ## dist100 -0.89 0.14 -1.15 -0.63 2539 1.00 ## log10arsenic 2.27 0.26 1.78 2.77 2535 1.00 ## educ 0.04 0.01 0.02 0.06 4442 1.00 ## assoc -0.12 0.08 -0.27 0.03 3912 1.00 ## dist100:log10arsenic -0.47 0.42 -1.31 0.36 2199 1.00 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Marginal effects are getting more interesting now. conditions &lt;- make_conditions( expand.grid( educ = c(5, 12) ), vars = c(&quot;educ&quot;) ) marginal_effects(wells8_brm, effects = &quot;dist100:arsenic&quot;, conditions = conditions) 25.2 Gelman/Hill Principles for Buiding Models (Gelman and Hill 2006) offers a nice set of “general principles for building regression models for prediction”. Include all input variables that, for substantive reasons, might be expected to be important in predicting the outcome. It is not always necessary to include these inputs as separate predictors – for example, sometimes several inputs can be averaged or summed to create a “total score” that can be used as a single predictor in the model. For inputs that have large effects, consider including their interactions as well.11 We suggest the following strategy for decisions regarding whether to exclude a variable from a prediction model based on expected sign and statistical significance (typically measured at the 5% level; that is, a coefficient is “statistically significant” if its estimate is more than 2 standard errors from zero): If a predictor is not statistically significant and has the expected sign, it is generally fine to keep it in. It may not help predictions dramatically but is also probably not hurting them. If a predictor is not statistically significant and does not have the expected sign (for example, incumbency having a negative effect on vote share), consider removing it from the model (that is, setting its coefficient to zero). If a predictor is statistically significant and does not have the expected sign, then think hard if it makes sense. (For example, perhaps this is a country such as India in which incumbents are generally unpopular; see Linden, 2006.) Try to gather data on potential lurking variables and include them in the analysis. If a predictor is statistically significant and has the expected sign, then by all means keep it in the model. They conlcude by saying These strategies do not completely solve our problems but they help keep us from making mistakes such as discarding important information. They are predicated on having thought hard about these relationships before fitting the model. It’s always easier to justify a coefficient’s sign after the fact than to think hard ahead of time about what we expect. On the other hand, an explanation that is determined after running the model can still be valid. We should be able to adjust our theories in light of new information. Since we are doing things in a Bayesian context, we should replace “statistically significant” with an equivalent notion based on the posterior distribution (using a posterior probability or and HDI, for example). In addition I’ll add: Use interactions if it makes sense that the effect of one predictor might depend on the value of another predictor. Linear models are inherentally monotonic. If you suspect instead a maximum or miniumum effect consider including both \\(x\\) and \\(x^2\\) (or something equivalent) as predictors. (Unlike lines with either always rise or always fall, parabolas have a maximum or a minumum.) If a parabola isn’t the “right shape”, additional transformations of \\(x\\) or \\(y\\) may be able to improve the fit. For example, we might use \\(\\log(x)\\) and \\((\\log(x)^2)\\). Consider transformation of either a predictor or the response variable if There is a natural reason to prefer the transformed variable, perhaps because it makes the model more interpretable or corresponds to intuition about the situation at hand. Transforming the variable improves the fit either by improving the “average” or by making the shape of the “noise” match the model’s family better. Don’t fret the intercept. The intercept should nearly always be included. The rules about statistical significance and sign do not apply to the intercept since often it has no meaninful interpretation. If you want to make the intercept somewhat more meaninful, centering the predictors (subtracting the mean) may help. (See if you can figure out why.) 25.2.1 Example: Bicycling Suppose we want to predict the maximum speed a bicyclist can ride based on two predictors: the gear ratio they are using and the steepness of the road they are riding on. We expect both variables to impact speed, so we include both in our model. We expect the effect of steepness to be monitonic. So no quadratic term required. We expect gear ratio to have a maximum effect – there is a gear ratio with which we can go fastest. Choosing a gear ratio that is lower than this will make our legs need to move to fast. Choosing a gear ratio that is higher will make it too hard to pedal. So a quadratic term for gear ratio seems reasonable. The best gear ratio to use depends on steepness (that’s why bikes have multiple gears), so it makes sense to include an interaction. That sort of reasoning gives us a good starting point for exploring model options. References "],
["references.html", "References", " References "]
]
