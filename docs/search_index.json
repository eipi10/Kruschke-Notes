[
["index.html", "(Re)Doing Bayesain Data Analysis 1 What’s in These Notes", " (Re)Doing Bayesain Data Analysis R Pruim 2019-02-25 1 What’s in These Notes This “book” is a companion to Kruschke’s Doing Bayesian Data Analysis. The main reasons for this companion are to use a different style of R code that includes: use of modern packages like tidyverse, R2jags, bayesplot, and ggformula; adherence to a different style guide; less reliance on manually editing scripts and more use of resusable code available in packages; a workflow that takes advantage of RStudio and RMarkdown. This is a work in progress. Please accept my apologies in advance for errors, inconsistencies lack of complete coverage But feel free to post an issue on github if you spot things that require attention or care to make suggestions for improvement. I’ll be teaching from this book in Spring 2019, so I expect rapid development during those months. "],
["credibility-models-and-parameters.html", "2 Credibility, Models, and Parameters 2.1 The Steps of Bayesian Data Analysis 2.2 Example 1: Which coin is it? 2.3 Distributions 2.4 Example 2: Height vs Weight 2.5 Where do we go from here? 2.6 Exercises 2.7 Footnotes", " 2 Credibility, Models, and Parameters 2.1 The Steps of Bayesian Data Analysis In general, Bayesian analysis of data follows these steps: Identify the data relevant to the research questions. What are the measurement scales of the data? Which data variables are to be predicted, and which data variables are supposed to act as predictors? Define a descriptive model for the relevant data. The mathematical form and its parameters should be meaningful and appropriate to the theoretical purposes of the analysis. Specify a prior distribution on the parameters. The prior must pass muster with the audience of the analysis, such as skeptical scientists. Use Bayesian inference to re-allocate credibility across parameter values. Interpret the posterior distribution with respect to theoretically meaningful issues (assuming that the model is a reasonable description of the data; see next step). Check that the posterior predictions mimic the data with reasonable accuracy (i.e., conduct a “posterior predictive check”). If not, then consider a different descriptive model. In this chapter we will focus on two examples so we can get an overview of what Bayesian data analysis looks like. In subsequent chapters we will fill in lots of the missing details. 2.1.1 R code Some of the R code used in this chapter has been hidden, and some of it is visible. In any case the point of this chapter is not to understand the details of the R code. It is there mainly for those of you who are curious, or because you might come back and look at this chapter later in the semester. For those of you new to R, we will be learning it as we go along. For those of you who have used R before, some of this will be familiar to you, but other things likely will not be familiar. 2.1.2 R packages We will make use of a number of R packages as we go along. Here is the code used to load the packages used in this chapter. If you try to mimic the code on your own machine, you will need to use these packages. library(ggformula) # for creating plots theme_set(theme_bw()) # change the default graphics settings library(dplyr) # for data wrangling library(mosaic) # includes the previous 2 (and some other stuff) library(CalvinBayes) # includes BernGrid() library(brms) # used to fit the model in the second exmample, ## Loading required package: Rcpp ## Loading &#39;brms&#39; package (version 2.7.0). Useful instructions ## can be found by typing help(&#39;brms&#39;). A more detailed introduction ## to the package is available through vignette(&#39;brms_overview&#39;). ## Run theme_set(theme_default()) to use the default bayesplot theme. ## ## Attaching package: &#39;brms&#39; ## The following object is masked from &#39;package:rstan&#39;: ## ## loo ## The following object is masked from &#39;package:mosaic&#39;: ## ## mm # but hidden from view here 2.2 Example 1: Which coin is it? As first simple illustration of the big ideas of Bayesian inference, let’s consider a situation where we have a coin that is known to result in heads in either 0, 20, 40, 60, 80, or 100% of tosses. But we don’t know which. Our plan is to gather data by flipping the coin and recording the results. If we let \\(\\theta\\) be the true probability of tossing a head, we can refer to these 5 possibilities as \\(\\theta = 0\\), \\(\\theta = 0.2\\), \\(\\theta = 0.4\\), \\(\\theta = 0.6\\), \\(\\theta = 0.8\\), and \\(\\theta = 1\\). Before collecting our data, if have no other information, we will consider each coin to be equally credible. We could represent that as follows. Now suppose we toss the coin and obtain a head. What does that do to our credibilities? Clearly \\(\\theta = 0\\) is no longer possible. So the credibility of that option becomes 0. The other credibilities are adjusted as well. We will see later just how, but the following should be intuitive: the options with larger values of \\(\\theta\\) should increase in credibility more than those with lower values of \\(\\theta\\). the total credibility of all options should remain 1 (100%). In fact, the adjusted credibility after one head toss looks like this: This updating of credibility of possible values of \\(\\theta\\) is the key idea in Bayesian inference. Bayesians don’t call these distributions of credibility “before” and “after”, however. Instead they use the longer words “prior” and “posterior”, which mean the same thing. Now suppose we toss the coin again and get another head. Once again we can update the credibility, and once again, the larger values of \\(\\theta\\) will see their credibility increase while the smaller values of \\(\\theta\\) will see their credibility decrease. Time for a third toss. This time we obtain a tail. Now the credibility of \\(\\theta = 1\\) drops to 0, and the relative credibilities of the smaller values of \\(\\theta\\) will increase and of the larger values of \\(\\theta\\) will decrease. Finally, we flip one more tail. As expected, the posterior is now symmetric with the two central values of \\(\\theta\\) having the larger credibility. We can keep playing this game as long as we like. Each coin toss provides a bit more information with which to update the posterior, which becomes our new prior for subsequent data. The BernGrid() function in the CalvinBayes package makes it easy to generate plots similar to the ones above. 1 BernGrid(&quot;HHTTTHTTT&quot;, # the data steps = TRUE, # show each step p = c(0, 0.2, 0.4, 0.6, 0.8, 1)) # possible probabilities ## Converting data to 1, 1, 0, 0, 0, 1, 0, 0, 0 2.2.1 Freedom of choice In practice, we are usually not given a small number of possible values for the probability (of obtaining heads in our example, but it could be any probability). Instead, the probability could be any value between 0 and 1. But we can do Bayesian updating in essentially the same way. Instead of a bar chart, we will use a line graph (called a density plot) to show how the credibility depends on the parameter value. BernGrid(&quot;HHTTTHTTT&quot;, # the data steps = TRUE) # show each step ## Converting data to 1, 1, 0, 0, 0, 1, 0, 0, 0 2.3 Distributions The (prior and posterior) distributions in the previous plots were calculated numerically using a Bayesian update rule that we will soon learn. Density functions have the properties that * they are never negative, and * the total area under the curve is 1. Where the density curve is taller, values are more likely. So in the last posterior credibility above, we see that values near 1/3 are the most credible while values below 0.015 or above 0.065 are not very credible. In particular, we still can’t discount the possibility that we are dealing with a fair coin since 0.5 lies well within the most credible central portion of the plot. We will also encounter densities with names like “normal”, “beta”, and “t”. The gf_dist() function from ggformula can be used to plot distributions. We just need to provide R’s version of the name for the family and any required parameter values. 2.3.1 Beta distributions The curves in our coins example above look a lot like beta distributions. In fact, we will eventually learn that they are beta distributions, and that each new observed coin toss increases either shape1 or shape2 by 1. gf_dist(&quot;beta&quot;, shape1 = 1, shape2 = 1, color = &quot;gray50&quot;) %&gt;% gf_dist(&quot;beta&quot;, shape1 = 2, shape2 = 1, color = &quot;red&quot;) %&gt;% gf_dist(&quot;beta&quot;, shape1 = 3, shape2 = 1, color = &quot;orange&quot;) %&gt;% gf_dist(&quot;beta&quot;, shape1 = 3, shape2 = 2, color = &quot;forestgreen&quot;) %&gt;% gf_dist(&quot;beta&quot;, shape1 = 3, shape2 = 3, color = &quot;navy&quot;) 2.3.2 Normal distributions Another important family of distributions is the normal family. These are bell-shaped, symmetric distributions centered at the mean (\\(\\mu\\)). A second parameter, the standard deviation (\\(\\sigma\\)) quantifies how spread out the distribution is. To plot a normal distribution with mean 10 and standard deviation 1 or 2, we use gf_dist(&quot;norm&quot;, mean = 10, sd = 1, color = &quot;steelblue&quot;) %&gt;% gf_dist(&quot;norm&quot;, mean = 10, sd = 2, color = &quot;red&quot;) The red curve is “twice as spread out” as the blue one. We can also draw random samples from distributions. Random samples will not exactly follow the shape of the distribution they were drawn from, so it takes some experience to get calibrated to know when things are “close enough” to consider a proposed distribution to be believable, and when they are “different enough” to be skeptical. Generating some random data and comparing to the theoretical distribution can help us calibrate. In the example below, we generate 25 random samples of size 100 and compare their (density) histograms to the theoretical Norm(10, 2) distribution. expand.grid() produces a data frame with two columns containing every combination of the numbers 1 through 100 with the numbers 1 through 25, for a total of 2500 rows. mutate() is used to add a new variable to the data frame. Rdata &lt;- expand.grid( rep = 1:100, sample = 1:25) %&gt;% mutate( x = rnorm(2500, mean = 10, sd = 2) ) head(Rdata) rep sample x 1 1 11.171 2 1 11.419 3 1 9.781 4 1 9.093 5 1 11.212 6 1 6.364 gf_dhistogram( ~ x | sample, data = Rdata, color = &quot;gray30&quot;, alpha = 0.5) %&gt;% gf_dist(&quot;norm&quot;, mean = 10, sd = 2, color = &quot;red&quot;) We will see many other uses of these functions. See the next chapter for in introduction to R functions that will be useful. 2.4 Example 2: Height vs Weight The coins example above is overly simple compared to typical applications. Before getting to the nuts and bolts of doing Bayesian data analysis, let’s look at a somewhat more realistic example. Suppose we want to model the relationship between weight and height in 40-year-old Americans. 2.4.1 Data Here’s a scatter plot of some data from the NHANES study that we will use for this example. (Note: this is not the same data set used in the book. The data here come from the NHANES::NHANES data set.) 2.4.2 Describing a model for the relationship between height and weight A plausible model is that weight is linearly related to height. We will make this model a bit more precise by defining the model parameters and distributions involved. Typically statisticians use Greek letters to represent parameters. This model has three parameters (\\(\\beta_0\\), \\(\\beta_1\\), and \\(\\sigma\\)) and makes two claims The average weight of people with height \\(x\\) is \\(\\beta_0 + \\beta_1 x\\) (some linear function of \\(x\\)). We can express this as \\[ \\mu_{Y|x} = E(Y \\mid x) = \\beta_0 + \\beta_1 x \\] or \\[ \\mu_{\\mbox{weight}|\\mbox{height}} = E(\\mbox{weight} \\mid \\mbox{height}) = \\beta_0 + \\beta_1 \\cdot \\mbox{height} \\] The \\(Y\\) and \\(x\\) notation is useful for general formulas; for specific problems (especially in R code), it is usually better to use descriptive names for the variables. The capital \\(Y\\) indicates that it has a distribution. \\(x\\) is lower case because we are imagining a specific value there. So for each value of \\(x\\), the there is a distribution of \\(Y\\)’s. But not everyone is average. The model used here assumes that the distributions of the heights of people with a given weight are symmetrically distributed around the average weight for that height and that the distribution is normal (bell-shaped). The parameter \\(\\sigma\\) is called the standard deviation and measures the amount of variability. If \\(\\sigma\\) is small, then most people’s weights are very close to the average for their height. If \\(\\sigma\\) is larger, then there is more variability in weights for people who have the same height. We express this as \\[\\begin{align} y \\mid x \\sim {\\sf Norm}(\\mu_{y|x}, \\sigma) \\end{align}\\] Notice the \\(\\sim\\) in this expression. It is read “is distributed as” and describes the distribution (shape) of some quantity. Putting this all together, and being a little bit sloppy we might write it this way: \\[\\begin{align} Y &amp;\\sim {\\sf Norm}(\\mu, \\sigma) \\\\ \\mu &amp; \\sim \\beta_0 + \\beta_1 x \\end{align}\\] In this style the dependence of \\(y\\) on \\(x\\) is implicit (via \\(\\mu\\)’s dependence on \\(x\\)) and we save writing \\(\\mid x\\) in a few places. 2.4.3 Prior A prior distribution describes what is known/believed about the parameters before we use the information from our data. This could be informed by previous data, or it may be a fairly uninformative prior that considers many values of the parameter to be credible. For this example, we use very flat broad priors (centered at 0 for the \\(\\beta\\)’s and extending from 0 to a very large number of \\(\\sigma\\). (We know that \\(\\sigma &gt; 0\\), so our prior should reflect that knowledge.) 2.4.4 Posterior The posterior distribution is calculated by combining the information about the model (via the likelihood function) with the prior. The posterior will provide updated distributions for \\(\\beta_0\\), \\(\\beta_1\\) and \\(\\sigma\\). These distributions will be narrow if our data give a strong evidence about their values and wider if even after considering the data, there is still considerable uncertainty about the parameter values. For now we won’t worry about how the posterior distribution is computed, but we can inspect it visually. (It is called Post in the R code below.) For example, if we are primarily interested in the slope (how much heavier are people on average for each inch they are taller?), we can plot the posterior distribution of \\(\\beta_1\\) or calculate its mean, or the region containing the central 95% of the distribution. Such a region is called a highest density interval (HDI) (sometimes called the highest posterior density interval (HPDI), to emphasize that we are looking at a posterior distribution, but an HDI can be computed for other distributions as well). gf_density( ~ b_height, data = Post, alpha = 0.5) mean(~ b_height, data = Post) ## [1] 7.223 hdi(Post, pars = &quot;b_height&quot;) par lo hi prob b_height 5.551 9.045 0.95 mcmc_areas(as.mcmc(Post), pars = &quot;b_height&quot;, prob = 0.95) Although we don’t get a very precise estimate of \\(\\beta_1\\) from this model/data combination, we can be quite confident that taller people are indeed heavier (on average), somewhere between 5 and 10 pounds heavier per inch taller. Another interesting plot shows lines overlaid on the scatter plot. Each line represents a plausible (according to the posterior distribution) combination of slope and intercept. 100 such lines are included in the plot below. 2.4.5 Posterior Predictive Check Notice that only a few of the dots are covered by the blue lines. That’s because the blue lines represent plausible average weights. But the model takes into account that some people may be quite a bit heavier or lighter than average. A posterior predictive check is a way of checking that the data look like they could have been plausibly generated by our model. We can generate a simulated weight for a given height by randomly selecting values of \\(\\beta_0\\), \\(\\beta_1\\), \\(\\sigma\\) so that the more credible values are more likely to be selected, and using the normal distribution to generate a difference between an individual weight and the average weight (as determined by the parameters \\(\\beta_0\\) and \\(\\beta_1\\). For example, here are the first two rows of our posterior distribution: Post %&gt;% head(2) b_Intercept b_height sigma lp__ -217.0 6.028 40.11 -784.5 -422.1 9.030 48.28 -786.5 To simulate a weight for a height of 65 inches based on the fist row, we could take a random draw from a \\({\\sf Norm}(-217 + 6.028 \\cdot 65, 40.11)\\) distribution. We can do a similar thing for the second row. Post %&gt;% head(2) %&gt;% mutate(pred_y = rnorm(2, mean = b_Intercept + b_height * 65, sd = sigma)) b_Intercept b_height sigma lp__ pred_y -217.0 6.028 40.11 -784.5 185.3 -422.1 9.030 48.28 -786.5 219.4 Those values are quite different. This is because credible values of \\(\\sigma\\) are quite large – an indication that individuals will vary quite substantially from the average weight for their height. gf_density( ~ sigma, data = Post) We should not be surprised to see some (~ 5%) of people who are 85 pounds above or below the average weight for their height. If we do this many times for several height values and plot the central 95% of the weights, we get a plot that looks like this: PPC &lt;- expand.grid( height = seq(56, 76, by = 1), rep = 1:nrow(Post) ) %&gt;% mutate( b_Intercept = Post$b_Intercept[rep], b_height = Post$b_height[rep], sigma = Post$sigma[rep], weight = b_Intercept + b_height * height + rnorm(n = n(), 0, sigma) ) %&gt;% group_by(height) %&gt;% summarise( mean = mean(weight), lo = quantile(weight, prob = 0.025), hi = quantile(weight, prob = 0.975) ) gf_point(weight ~ height, data = NHANES40, shape = 1) %&gt;% gf_pointrange(mean + lo + hi ~ height, data = PPC, alpha = 0.7, color = &quot;steelblue&quot;) Now we see that indeed, most (but not all) of the data points fall within a range that the model believes is credible. If this were not the case, it would be evidence that our model is not well aligned with the data and might lead us to explore other models. Notice that by taking many different credible values of the parameters (including \\(\\sigma\\)), we are taking into account both our uncertainty about the parameter values and the variability that the model describes in the population (even for given parameter values). 2.5 Where do we go from here? Now that we have seen an overview of Bayesian inference at work, you probably have lots of questions. Of time we will improve our answers to each of them. How do we create models? One of the nice things about Bayesian inference is that it is so flexible. That allows us to create all sorts of models. We will begin with models of a proportion (and how that proportion might depend on other variables) because these are the simplest to understand. Then we will move on other important examples. (The back half of our book is a smorgasbord of example situations.) How do we select priors? We will begin with fairly “uninformative” priors that say very little, and we will experiment with different priors to see what affect the choice of prior has on our analysis. Gradually we will learn more about prior selection. How do we update the prior based on data to get the posterior? Here we will learn several approaches, most of them computational. (There are only a limited number of examples where the prior can be computed analytically.) We will start with computational methods that are simple to implement and relatively easy to understand, but are too inefficient to use on large or complex problems. Eventually we will learn how to use two important algorithms (JAGS and Stan) to describe and fit Bayesian models. How do we tell whether the algorithm that generated the posterior worked well? The computainal algorithms that compute posterior distributions can fail. No one algorithm works best on every problem, and sometimes we need to describe our model differently to help the computer. We will learn some diagnostics to help us detect when there may be problems with our computations. What can we do with the posterior once we have it? After all the work of building a model, selectig a prior, fitting the model to obtain a posterior, and convincing ourselves that no disasters have happened along the way, what can we do with the posterior? We will use it both to diagnose the model itself and to see what the model has to say. 2.6 Exercises Consider Figure 2.6 on page 29 of DBDA2E. Two of the data points fall above the vertical bars. Does this mean that the model does not describe the data well? Briefly explain your answer. Run the following examples in R. Compare the plots produced and comment the big idea(s) illustrated by this comparison. library(CalvinBayes) BernGrid(&quot;H&quot;, resolution = 4, prior = triangle::dtriangle) BernGrid(&quot;H&quot;, resolution = 10, prior = triangle::dtriangle) BernGrid(&quot;H&quot;, prior = 1, resolution = 100, geom = geom_col) BernGrid(&quot;H&quot;, resolution = 100, prior = function(p) abs(p - 0.5) &gt; 0.48, geom = geom_col) Run the following examples in R. Compare the plots produced and comment the big idea(s) illustrated by this comparison. library(CalvinBayes) BernGrid(&quot;TTHT&quot;, prior = triangle::dtriangle) BernGrid(&quot;TTHT&quot;, prior = function(x) triangle::dtriangle(x)^0.1) BernGrid(&quot;TTHT&quot;, prior = function(x) triangle::dtriangle(x)^10) Run the following examples in R. Compare the plots produced and comment the big idea(s) illustrated by this comparison. library(CalvinBayes) dfoo &lt;- function(p) { 0.02 * dunif(p) + 0.49 * triangle::dtriangle(p, 0.1, 0.2) + 0.49 * triangle::dtriangle(p, 0.8, 0.9) } BernGrid(c(rep(0,13), rep(1,14)), prior = triangle::dtriangle) BernGrid(c(rep(0,13), rep(1,14)), resolution = 1000, prior = dfoo) Run the following examples in R. Compare the plots produced and comment the big idea(s) illustrated by this comparison. library(CalvinBayes) dfoo &lt;- function(p) { 0.02 * dunif(p) + 0.49 * triangle::dtriangle(p, 0.1, 0.2) + 0.49 * triangle::dtriangle(p, 0.8, 0.9) } BernGrid(c(rep(0, 3), rep(1, 3)), prior = dfoo) BernGrid(c(rep(0, 10), rep(1, 10)), prior = dfoo) BernGrid(c(rep(0, 30), rep(1, 30)), prior = dfoo) BernGrid(c(rep(0, 100), rep(1, 100)), prior = dfoo) Run the following examples in R and compare them to the ones in the previous exercise. What do you observe? library(CalvinBayes) dfoo &lt;- function(p) { 0.02 * dunif(p) + 0.49 * triangle::dtriangle(p, 0.1, 0.2) + 0.49 * triangle::dtriangle(p, 0.8, 0.9) } BernGrid(c(rep(0, 3), rep(1, 4)), prior = dfoo) BernGrid(c(rep(0, 4), rep(1, 3)), prior = dfoo) BernGrid(c(rep(0, 10), rep(1, 11)), prior = dfoo) BernGrid(c(rep(0, 11), rep(1, 10)), prior = dfoo) BernGrid(c(rep(0, 30), rep(1, 31)), prior = dfoo) BernGrid(c(rep(0, 31), rep(1, 30)), prior = dfoo) 2.7 Footnotes This is a bit of a trick that R2jags uses. The function created is never run. The code is inspected and taken as the description of the model. If you were to run the funtion, all it would do is create R formulas.↩ "],
["some-useful-bits-of-r.html", "3 Some Useful Bits of R 3.1 You Gotta Have Style 3.2 Vectors, Lists, and Data Frames 3.3 Plotting with ggformula 3.4 Creating data with expand.grid() 3.5 Transforming and summarizing data dplyr and tidyr 3.6 Writing Functions 3.7 Some common error messages 3.8 Exercises 3.9 Footnotes", " 3 Some Useful Bits of R 3.1 You Gotta Have Style Good programming style is incredibly important. It makes your code easier to read and edit. That leads to fewer errors. Here is a brief style guide you are expected to follow for all code in this course: For more detailed see http://adv-r.had.co.nz/Style.html, on which this is based. No long lines. Lines of code should have at most 80 characters. Programming lines should not wrap, you should choose the line breaks yourself. Choose them in natural places. In R markdown, long codes lines don’t wrap, they flow off the page, so the end isn’t visible. (And it makes it obvious that you didn’t look at your own print out.) # Don&#39;t ever use really long lines. Not even in comments. They spill off the page and make people wonder what they are missing. Use your space bar. There is a reason it is the largest key on the keyboard. Use it often. Spaces after commas (always). Spaces around operators (always). Spaces after the comment symbol # (always). Use other spaces judiciously to align similar code chunks to make things easier to read or compare. x&lt;-c(1,2,4)+5 # BAD BAD BAD x &lt;- c(1, 2, 4) + 5 # Ah :^) But don’t go crazy with the space bar. There are a few places you should not use spaces: after open parentheses or before closed parentheses between function names and the parentheses that follow Indent to show the structure of your code. Use 2 spaces to indent (to keep things from drifting right too quickly). Fortunately, this is really easy. Highlight your code and hit &lt;CTRL&gt;-i (PC) or &lt;command&gt;-i (Mac). If the indention looks odd to you, you have most likely messed up commas, quotes, parentheses, or curly braces. Choose names wisely and consistently. Naming things is hard, but take a moment to choose good names, and go back and change them if you come up with a better name later. Here are some helpful hints: Very short names should only be used for a very short time (a couple lines of code). Else we tend to forget what they meant. Avoid names like x, f, etc. unless the use is brief and mimics some common mathematical formula. Break long names visually. Common ways to do this are with a dot (.), an underscore _, or camelCase. There are R coders who prefer all three, but don’t mix and match for similar kinds of things, that just makes it harder to remember what to do the next time. good_name &lt;- 10 good.name &lt;- 10 goodName &lt;- 10 # note alignment via extra space in this line really_terrible.ideaToDo &lt;- -5 The trend in R is toward using underscore (_) and I recommend it. Older code often used dot (.). CamelCase is the least common in R. Recommendation: capitalize data frame names; use lower case for variables inside data frames. This is not a common convention in R, but it can really help to keep things straight. I’ll do this in the data sets I create, but when we use other data sets, they may not follow this convention. Avoid using names that are already in use by R. This can be hard to avoid when you are starting out because you don’t know what all is defined. Here are a few things to avoid. T # abbreviation for TRUE F # abbreviation for FALSE c # used to concetenate vectors and lists df # density function for f distributions dt # density function for t distributions Use comments (#), but use them for the right thing. Comments can be used to clarify names, point out subtlties in code, etc. They should not be used for your analysis or discussion of results. Don’t comment things that are obvious without comment. Comments should add value. x &lt;- 4 # set x to 4 &lt;----------------------- no need for this comment x &lt;- 4 # b/c there are four grade levels in the study &lt;------- useful Exceptions should be exceptional. No style guide works perfectly in all situations. Ocassionally you may need to violate the style guide. But these instances should be rare and should have a good reason. They should not arise form your sloppiness or laziness. 3.1.1 An additional note about homework When you do homework, I want to see your code and the results (and your discussion of those results). Writing in R Markdown makes this all easy to do. But make sure that I can see all the necessary things to evaluate what you are doing. You have access to your code and can investigate variables, etc. But make sure I can see what’s going one in the document. This often means displaying intermediate results. Once common way to do this is with a semi-colon: x &lt;- 57 * 23; x ## [1] 1311 3.2 Vectors, Lists, and Data Frames 3.2.1 Vectors In R, a vector is a homogeneous ordered collection (indexing starts at 1). By homogeneous, we mean that each element is he same kind of thing. Short vectors can be created using c(): x &lt;- c(1, 3, 5) x ## [1] 1 3 5 Evenly spaced sequences can be created using seq(): x &lt;- seq(0, 100, by = 5); x ## [1] 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 ## [18] 85 90 95 100 y &lt;- seq(0, 1, length.out = 11); y ## [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 0:10 # short cut for consecutive integers ## [1] 0 1 2 3 4 5 6 7 8 9 10 Repeated values can be created with rep(): rep(5, 3) ## [1] 5 5 5 rep(c(1, 2, 3), each = 2) ## [1] 1 1 2 2 3 3 rep(c(1, 2, 3), times = 2) ## [1] 1 2 3 1 2 3 rep(c(1, 2, 3), times = c(1, 2, 3)) ## [1] 1 2 2 3 3 3 rep(c(1, 2, 3), each = c(1, 2, 3)) # Ack! see warning message. ## Warning in rep(c(1, 2, 3), each = c(1, 2, 3)): first element used of &#39;each&#39; ## argument ## [1] 1 2 3 When a function acts on a vector, there are several things that could happen. One result can be computed from the entire vector. x &lt;- c(1, 3, 6, 10) length(x) ## [1] 4 mean(x) ## [1] 5 The function may be applied to each element of the vector and a vector of results returned. (Such functions are called vectorized.) log(x) ## [1] 0.000 1.099 1.792 2.303 2 * x ## [1] 2 6 12 20 x^2 ## [1] 1 9 36 100 The first element of the vector may be used and the others ignored. (Less common but dangerous – be on the lookout. See example above.) Items in a vector can be accessed using []: x &lt;- seq(10, 20, by = 2) x[2] ## [1] 12 x[10] # NA indicates a missing value ## [1] NA x[10] &lt;- 4 x # missing values filled in to make room! ## [1] 10 12 14 16 18 20 NA NA NA 4 is.na(x) ## [1] FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE FALSE In addition to using integer indices, there are two other ways to access elements of a vector: names and logicals. If the items in a vector are named, names are displayed when a vector is displayed, and names can be used to access elements. x &lt;- c(a = 5, b = 3, c = 12, 17, 1) x ## a b c ## 5 3 12 17 1 names(x) ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;&quot; &quot;&quot; x[&quot;b&quot;] ## b ## 3 Logicals (TRUE and FALSE) are very interesting in R. In indexing, they tell us which items to keep and which to discard. x &lt;- (1:10)^2 x &lt; 50 ## [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE FALSE FALSE FALSE x[x &lt; 50] ## [1] 1 4 9 16 25 36 49 x[c(TRUE, FALSE)] # T/F recycled to length 10 ## [1] 1 9 25 49 81 which(x &lt; 50) ## [1] 1 2 3 4 5 6 7 3.2.2 Lists Lists are a lot like vectors, but Create a list with list(). The elements can be different kinds of things (including other lists) Use [[ ]] to access elements. You can also use $ to access named elements If you use [] you will get a list back not an element. # a messy list L &lt;- list(5, list(1, 2, 3), x = TRUE, y = list(5, a = 3, 7)) L ## [[1]] ## [1] 5 ## ## [[2]] ## [[2]][[1]] ## [1] 1 ## ## [[2]][[2]] ## [1] 2 ## ## [[2]][[3]] ## [1] 3 ## ## ## $x ## [1] TRUE ## ## $y ## $y[[1]] ## [1] 5 ## ## $y$a ## [1] 3 ## ## $y[[3]] ## [1] 7 L[[1]] ## [1] 5 L[[2]] ## [[1]] ## [1] 1 ## ## [[2]] ## [1] 2 ## ## [[3]] ## [1] 3 L[1] ## [[1]] ## [1] 5 L$y ## [[1]] ## [1] 5 ## ## $a ## [1] 3 ## ## [[3]] ## [1] 7 L[[&quot;x&quot;]] ## [1] TRUE L[1:3] ## [[1]] ## [1] 5 ## ## [[2]] ## [[2]][[1]] ## [1] 1 ## ## [[2]][[2]] ## [1] 2 ## ## [[2]][[3]] ## [1] 3 ## ## ## $x ## [1] TRUE glimpse(L) ## List of 4 ## $ : num 5 ## $ :List of 3 ## ..$ : num 1 ## ..$ : num 2 ## ..$ : num 3 ## $ x: logi TRUE ## $ y:List of 3 ## ..$ : num 5 ## ..$ a: num 3 ## ..$ : num 7 3.2.3 Data frames for rectangular data Rectangular data is organized in rows and columns (much like an excel spreadsheet). These rows and columns have a particular meaning: Each row represents one observational unit. Observational units go by many others names depending whether they are people, or inanimate objects, our events, etc. Examples include case, subject, item, etc. Regardless, the observational units are the things about which we collect information, and each one gets its own row in rectangular data. Each column represents a variable – one thing that is “measured” and recorded (at least in principle, some measurements might be missing) for each observational unit. Example In a study of nutritional habits of college students, our observational units are the college students in the study. Each student gets her own row in the data frame. The variables might include things like an ID number (or name), sex, height, weight, whether the student lives on campus or off, what type of meal plan they have at the dining hall, etc., etc. Each of these is recorded in a separate column. Data frames are the standard way to store rectangular data in R. Usually variables (elements of the list) are vectors, but this isn’t required, sometimes you will see list variables in data frames. Each element (ie, variable) must have the same length (to keep things rectangular). Here, for example, are the first few rows of a data set called KidsFeet: library(mosaicData) # Load package to make KidsFeet data available head(KidsFeet) # first few rows name birthmonth birthyear length width sex biggerfoot domhand David 5 88 24.4 8.4 B L R Lars 10 87 25.4 8.8 B L L Zach 12 87 24.5 9.7 B R R Josh 1 88 25.2 9.8 B L R Lang 2 88 25.1 8.9 B L R Scotty 3 88 25.7 9.7 B R R 3.2.3.1 Accessing via [ ] We can access rows, columns, or individual elements of a data frame using [ ]. This is the more usual way to do things. KidsFeet[, &quot;length&quot;] ## [1] 24.4 25.4 24.5 25.2 25.1 25.7 26.1 23.0 23.6 22.9 27.5 24.8 26.1 27.0 ## [15] 26.0 23.7 24.0 24.7 26.7 25.5 24.0 24.4 24.0 24.5 24.2 27.1 26.1 25.5 ## [29] 24.2 23.9 24.0 22.5 24.5 23.6 24.7 22.9 26.0 21.6 24.6 KidsFeet[, 4] ## [1] 24.4 25.4 24.5 25.2 25.1 25.7 26.1 23.0 23.6 22.9 27.5 24.8 26.1 27.0 ## [15] 26.0 23.7 24.0 24.7 26.7 25.5 24.0 24.4 24.0 24.5 24.2 27.1 26.1 25.5 ## [29] 24.2 23.9 24.0 22.5 24.5 23.6 24.7 22.9 26.0 21.6 24.6 KidsFeet[3, ] name birthmonth birthyear length width sex biggerfoot domhand 3 Zach 12 87 24.5 9.7 B R R KidsFeet[3, 4] ## [1] 24.5 KidsFeet[3, 4, drop = FALSE] # keep it a data frame length 3 24.5 KidsFeet[1:3, 2:3] birthmonth birthyear 5 88 10 87 12 87 By default, Accessing a row returns a 1-row data frame. Accessing a column returns a vector (at least for vector columns) Accessing a element returns that element (technically a vector with one element in it). 3.2.3.2 Accessing columns via $ We can also access individual variables using the $ operator: KidsFeet$length ## [1] 24.4 25.4 24.5 25.2 25.1 25.7 26.1 23.0 23.6 22.9 27.5 24.8 26.1 27.0 ## [15] 26.0 23.7 24.0 24.7 26.7 25.5 24.0 24.4 24.0 24.5 24.2 27.1 26.1 25.5 ## [29] 24.2 23.9 24.0 22.5 24.5 23.6 24.7 22.9 26.0 21.6 24.6 KidsFeet$length[2] ## [1] 25.4 KidsFeet[2, &quot;length&quot;] ## [1] 25.4 KidsFeet[2, &quot;length&quot;, drop = FALSE] # keep it a data frame length 2 25.4 As we will see, there are are other tools that will help us avoid needing to us $ or [ ] for access columns in a data frame. This is especially nice when we are working with several variables all coming from the same data frame. 3.2.3.3 Accessing by number is dangerous Generally speaking, it is safer to access things by name than by number when that is an option. It is easy to miscalculate the row or column number you need, and if rows or columns are added to or deleted from a data frame, the numbering can change. 3.2.3.4 Implementation Data frames are implemented in R as a special type (technically, class) of list. The elements of the list are the columns in the data frame. Each column must have the same length (so that our data frame has coherent rows). Most often the columns are vectors, but this isn’t required. This explains why $ works the way it does – we are just accessing one item in a list. It also means that we can use [[ ]] to access a column: KidsFeet[[&quot;length&quot;]] ## [1] 24.4 25.4 24.5 25.2 25.1 25.7 26.1 23.0 23.6 22.9 27.5 24.8 26.1 27.0 ## [15] 26.0 23.7 24.0 24.7 26.7 25.5 24.0 24.4 24.0 24.5 24.2 27.1 26.1 25.5 ## [29] 24.2 23.9 24.0 22.5 24.5 23.6 24.7 22.9 26.0 21.6 24.6 KidsFeet[[4]] ## [1] 24.4 25.4 24.5 25.2 25.1 25.7 26.1 23.0 23.6 22.9 27.5 24.8 26.1 27.0 ## [15] 26.0 23.7 24.0 24.7 26.7 25.5 24.0 24.4 24.0 24.5 24.2 27.1 26.1 25.5 ## [29] 24.2 23.9 24.0 22.5 24.5 23.6 24.7 22.9 26.0 21.6 24.6 KidsFeet[4] length 24.4 25.4 24.5 25.2 25.1 25.7 26.1 23.0 23.6 22.9 27.5 24.8 26.1 27.0 26.0 23.7 24.0 24.7 26.7 25.5 24.0 24.4 24.0 24.5 24.2 27.1 26.1 25.5 24.2 23.9 24.0 22.5 24.5 23.6 24.7 22.9 26.0 21.6 24.6 3.2.4 Other types of data Some types of data do not work well in a rectangular arrangement of a data frame, and there are many other ways to store data. In R, other types of data commonly get stored in a list of some sort. 3.3 Plotting with ggformula R has several plotting systems. Base graphics is the oldest. lattice and ggplot2 are both built on a system called grid graphics. ggformula is built on ggplot2 to make it easier to use and to bring in some of the advantages of lattice. You can find out about more about ggformula at https://projectmosaic.github.io/ggformula/news/index.html. 3.4 Creating data with expand.grid() We will frequently have need of synthetic data that includes all combinations of some variable values. expand.grid() does this for us: expand.grid( a = 1:3, b = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;)) a b 1 A 2 A 3 A 1 B 2 B 3 B 1 C 2 C 3 C 1 D 2 D 3 D 3.5 Transforming and summarizing data dplyr and tidyr See the tutorial at http://rsconnect.calvin.edu/wrangling-jmm2019 or https://rpruim.shinyapps.io/wrangling-jmm2019 3.6 Writing Functions 3.6.1 Why write functions? There are two main reasons for writing functions. You may want to use a tool that requires a function as input. To use integrate(), for example, you must provide the integrand as a function. To make your own work easier. Functions make it easier to reuse code or to break larger tasks into smaller parts. 3.6.2 Function parts Functions consist of several parts. Most importantly An argument list. A list of named inputs to the function. These may have default values (or not). There is also a special argument ... which gathers up any other arguments provided by the user. Many R functions make use of ... args(ilogit) # one argument, called x, no default value ## function (x) ## NULL The body. This is the code the tells R to do when the function is executed. body(ilogit) ## { ## exp(x)/(1 + exp(x)) ## } An environment where code is executed. Each function has its own “scratch pad” where it can do work without interfering with global computations. But environments in R are nested, so it is possible to reach outside of this narrow environment to access other things (and possible to change them). For the most part we won’t worry about this, but if you use a variable not defined in your function but defined elsewhere, you may see unexpecte results. If you type the name of a function without parenthesis, you will see all three parts listed: ilogit ## function (x) ## { ## exp(x)/(1 + exp(x)) ## } ## &lt;bytecode: 0x7ffcd700bab8&gt; ## &lt;environment: namespace:mosaicCore&gt; 3.6.3 The function() function has its function To write a function we use the function() function to specify the arguments and the body. (R will assign an environment for us.) The general outline is my_function_name &lt;- function(arg1 = default1, arg2 = default2, arg3, arg4, ...) { # stuff for my function to do } We may include as many named arguments as we like, and some or all or none of them may have default values. The results of the last line of the function are returned. If we like, we can also use the return() function to make it clear what is being returned when. Let’s write a function that adds. (Redundant, but a useful illustration.) foo &lt;- function(x, y = 5) { x + y # or return(x + y) } foo(3, 5) ## [1] 8 foo(3) ## [1] 8 foo(2, x = 3) # Note: this makes y = 2 ## [1] 5 foo(x = 1:3, y = 100) ## [1] 101 102 103 foo(x = 1:3, y = c(100, 200, 300)) # vectorized! ## [1] 101 202 303 foo(x = 1:3, y = c(100, 200)) # You have been warned! ## Warning in x + y: longer object length is not a multiple of shorter object ## length ## [1] 101 202 103 Here is a more useful example. Suppose we want to integrate \\(f(x) = x^2 (2-x)\\) on the interval from 0 to 2. Since this is such a simple function, if we are not going to reuse it, we don’t need to bother naming it, we can just create the function inside our call to integrate(). integrate(function(x) { x^2 * (2-x) }, 0, 2) ## 1.333 with absolute error &lt; 1.5e-14 3.7 Some common error messages 3.7.1 object not found If R claims some object is not found, the two most likely causes are a typo – if you spell the name of the object slightly differently, R can’t figure out what you mean blah &lt;- 17 bla ## Error in eval(expr, envir, enclos): object &#39;bla&#39; not found forgetting to load a package – if the object is in a package, that package must be loaded detach(&quot;package:mosaic&quot;, unload = TRUE) detach(&quot;package:ggformula&quot;, unload = TRUE) # without packages, no gf_line() ## Error: package &#39;ggformula&#39; is required by &#39;CalvinBayes&#39; so will not be detached gf_line() ## gf_line() uses ## * a formula with shape y ~ x. ## * geom: line ## * key attributes: alpha, color, fill, group, linetype, size, lineend, ## linejoin, linemitre, arrow ## ## For more information, try ?gf_line library(ggformula) # reload package; now things work gf_line() ## gf_line() uses ## * a formula with shape y ~ x. ## * geom: line ## * key attributes: alpha, color, fill, group, linetype, size, lineend, ## linejoin, linemitre, arrow ## ## For more information, try ?gf_line 3.7.1 Package inputenc Error: Unicode char not set up for use with LaTeX. Sometimes if you copy and paste text from a web page or PDF document you will get symbols knitr doesn’t know how to handle. Smart quotes, ligatures, and other special characters are the most likely cause. tools::showNonASCIIfile() can help you locate non-ASCII characters in a file. 3.7.2 Any message mentioning yaml YAML stand for yet another markup language. The first part of an R Markdown file is called the YAML header. If you get a yaml error when you knit a document, most likely you have messed up the YAML header someone. If you don’t see the problem, you can start a new document and copy-and-paste the contents (without the TAML header) into the new document (after its YAML header). 3.8 Exercises Create a function in R that converts Fahrenheit temperatures to Celsius temperatures. [Hint: \\(C = (F-32) \\cdot 5/9\\).] What you turn in should show the code that defines your function. some test cases that show that your function is working. (Show that -40, 32, 98.6, and 212 convert to -40, 0, 37, and 100.) Note: you should be able to test all these cases by calling the function only once. Use c(-40, 32, 98.6, 212) as the input. See if you can predict the output of each line below. Then run in R to see if you are correct. If you are not correct, see if you can figure out why R does what it does (and make a note so you are not surprised the next time). odds &lt;- 1 + 2 * (0:4); odds primes &lt;- c(2, 3, 5, 7, 11, 13) length(odds) length(primes) odds + 1 odds + primes odds * primes odds &gt; 5 sum(odds &gt; 5) sum(primes &lt; 5 | primes &gt; 9) odds[3] odds[10] odds[-3] primes[odds] primes[primes &gt;= 7] sum(primes[primes &gt; 5]) sum(odds[odds &gt; 5]) odds[10] &lt;- 1 + 2 * 9 odds y &lt;- 1:10 y &lt;- 1:10; y (x &lt;- 1:5) The problem uses the KidsFeet data set from the mosaicData package. The hints are suggested functions that might be of use. How many kids are represented in the data set. [Hint: nrow() or dim()] Which of the variables are factors? [Hint: glimpse()] Add a new variable called foot_ratio that is equal to length divided by width. [Hint: mutate()] Add a new variable called biggerfoot2 that has values &quot;dom&quot; (if domhand and biggerfoot are the same) and &quot;nondom&quot; (if domhand and biggerfoot are different). [Hint: mutate(), ==, ifelse()] Create new data set called Boys that contains only the boys. [Hint: filter(), ==] What is the name of the boy with the largest foot_ratio? Show how to find this programmatically, don’t just scan through the whole data set yourself. [Hint: max() or arrange()] 3.9 Footnotes "],
["probability.html", "4 Probability 4.1 Some terminology 4.2 Distributions in R 4.3 Joint, marginal, and conditional distributions 4.4 Exercises 4.5 Footnotes", " 4 Probability 4.1 Some terminology Probability is about quantifying the relative chances of various possible outcomes of a random process. As a very simple example (used to illustrate the terminology below), considering rolling a single 6-sided die. sample space: The set of all possible outcomes of a random process. [{1, 2, 3, 4, 5, 6}] event: a set of outcomes (subset of sample space) [E = {2, 4, 6} is the event that we obtain an even number] probability: a number between 0 and 1 assigned to an event (really a function that assigns numbers to each event). We write this P(E). [P(E) = 1/2 where E = {1, 2, 3}] random variable: a random process that produces a number. [So rolling a die can be considered a random variable.] probability distribution: a description of all possible outcomes and their probabilities. For rolling a die we might do this with a table like this: 1 2 3 4 5 6 1/6 1/6 1/6 1/6 1/6 1/6 support (of a random variable): the set of possible values of a random variable. This is very similar to the sample space. probability mass function (pmf): a function (often denoted with \\(p\\) or \\(f\\)) that takes possible values of a discrete random variable as input and returns the probability of that outcome. If \\(S\\) is the support of the random variable, then \\[ \\sum_{x \\in S} p(x) = 1 \\] and any function with this property is a pmf. Probabilities of events are obtained by adding the probabilities of all outcomes in the event: \\[ \\operatorname{Pr}(E) = \\sum_{x \\in E} p(x) \\] * pmfs can be represented in a table (like the one above) or graphically with a probability histogram or lollipop plot like the ones below. [These are not for the 6-sided die, as we can tell because the probabilities are not the same for each input; the die rolling example would make very boring plots.] Histograms are generally presented on the density scale so the total area of the histogram is 1. (In this example, the bin widths are 1, so this is the same as being on the probability scale.) probability density function (pdf): a function (often denoted with \\(p\\) or \\(f\\)) that takes the possible values of continuous random variable as input and returns the probability density. If \\(S\\) is the support of the random variable, then 2 \\[ \\int_{x \\in S} f(x) \\; dx = 1 \\] and any function with this property is a pmf. Probabilities are obtained by integrating (visualized by the area under the density curve): \\[ \\operatorname{Pr}(a \\le X \\le b) = \\int_a^b f(x) \\; dx \\] kernel function: If \\(\\int_{x \\in S} f(x) \\; dx = k\\) for some real number \\(k\\), then \\(f\\) is a kernel function. We can obtain the pdf from the kernel by dividing by \\(k\\). cumulative distribution function (cdf): a function (often denoted with a capital \\(F\\)) that takes a possible value of a random variable as input and returns the probability of obtaining a value less than or equal to the input: \\[ F_X(x) = \\operatorname{Pr}(X \\le x) \\] cdfs can be defined for both discrete and continuous random variables. a family of distributions: is a collection of distributions which share common features but are distinguished by different parameter values. For example, we could have the family of distributions of fair dice random variables. The parameter would tell us how many sides the die has. Statisticians call this family the discrete uniform distributions because all the probabilities are equal (1/6 for 6-sided die, 1/10 for a \\(D_10\\), etc.). We will get to know several important families of distributions, among them the binomial, beta, normal, and t families will be especially useful. You may already be familiar with some or all of these. We will also use distributions that have no name and are only described by a pmf or pdf, or perhaps only by a large number of random samples from which we attempt to estimate the pmf or pdf. 4.2 Distributions in R pmfs, pdfs, and cdfs are available in R for many important families of distributions. You just need to know a few things: each family has a standard abbreviation in R pmf and pdf functions begin with the letter d followed by the family abbreviation cdf functions begin with the letter p followed by the family abbreviation the inverse of the cdf function is called a quantile function, it starts with the letter q functions beginning with r can generate random samples from a distribution help for any of these functions will tell you what R calls the parameters of the family. gf_dist() can be used to make various plots of distributions. 4.2.1 Example: Normal distributions As an example, let’s look the family of normal distributions. If you type dnorm( and then hit TAB or if you type args(dnorm) you can see the arguments for this function. args(dnorm) ## function (x, mean = 0, sd = 1, log = FALSE) ## NULL From this we see that the parameters are called mean and sd and have default value of 0 and 1. These values will be used if we don’t specify something else. As with many of the pmf and pdf functions, there is also an option to get back the log of the pmf or pdf by setting log = TRUE. This turns out to be computationally much more efficient in many contexts, as we will see. Let’s begin with some pictures of a normal distribution with mean 10 and standard deviation 1: gf_dist(&quot;norm&quot;, mean = 10, sd = 2, title = &quot;pdf for Norm(10, 2)&quot;) gf_dist(&quot;norm&quot;, mean = 10, sd = 2, kind = &quot;cdf&quot;, title = &quot;cdf for Norm(10, 2)&quot;) Now some exercises. Assume \\(X \\sim {\\sf Norm}(10, 2)\\). What is \\(\\operatorname{Pr}(X \\le 5)\\)? We can see by inspection that it is less that 0.5. pnorm() will give us the value we are after; xpnorm() will provide more verbose output and a plot as well. pnorm(5, mean = 10, sd = 2) ## [1] 0.00621 xpnorm(5, mean = 10, sd = 2) ## ## If X ~ N(10, 2), then ## P(X &lt;= 5) = P(Z &lt;= -2.5) = 0.00621 ## P(X &gt; 5) = P(Z &gt; -2.5) = 0.9938 ## ## [1] 0.00621 What is \\(\\operatorname{Pr}(5 \\le X \\le 10)\\)? pnorm(10, mean = 10, sd = 2) - pnorm(5, mean = 10, sd = 2) ## [1] 0.4938 How tall is the density function at it’s peak? Normal distributions are symmetric about their means, so we need the value of the pdf at 10. dnorm(10, mean = 10, sd = 2) ## [1] 0.1995 What is the mean of a Norm(10, 2) distribution? Ignoring for the moment that we know the answer is 10, we can compute it. Notice the use of dnorm() in the computation. integrate(function(x) x * dnorm(x, mean = 10, sd = 2), -Inf, Inf) ## 10 with absolute error &lt; 0.0011 What is the variance of a Norm(10, 2) distribution? Again, we know the answer is the square of the standard deviation, so 4. But let’s get R to compute it in a way that would work for other distributions as well. integrate(function(x) (x - 10)^2 * dnorm(x, mean = 10, sd = 2), -Inf, Inf) ## 4 with absolute error &lt; 7.1e-05 Simulate a data set with 50 values drawn from a \\({\\sf Norm}(10, 2)\\) distribution and make a histogram of the results and overlay the normal pdf for comparison. x &lt;- rnorm(50, mean = 10, sd = 2) # be sure to use a density histogram so it is on the same scale as the pdf! gf_dhistogram(~ x, bins = 10) %&gt;% gf_dist(&quot;norm&quot;, mean = 10, sd = 2, color = &quot;red&quot;) 4.2.2 Simulating running proportions library(ggformula) library(dplyr) theme_set(theme_bw()) Flips &lt;- tibble( n = 1:500, flip = rbinom(500, 1, 0.5), running_count = cumsum(flip), running_prop = running_count / n ) gf_line( running_prop ~ n, data = Flips, color = &quot;skyblue&quot;, ylim = c(0, 1.0), xlab = &quot;Flip Number&quot;, ylab = &quot;Proportion Heads&quot;, main = &quot;Running Proportion of Heads&quot;) %&gt;% gf_hline(yintercept = 0.5, linetype = &quot;dotted&quot;) 4.3 Joint, marginal, and conditional distributions Sometimes (most of the time, actually) we are interested joint distributions. A joint distribution is the distribution of multiple random variables that result from the same random process. For example, we might roll a pair of dice and obtain two numbers (one for each die). Or we might collect a random sample of people and record the height for each of them. Or we might randomly select one person, but record multiple facts (height and weight, for example). All of these situations are covered by joint distributions.3 4.3.1 Example: Hair and eye color Kruschke illustrates joint distributions with an example of hair and eye color recorded for a number of people. [^3] That table below has the proportions for each hair/eye color combination. For example, Hair/Eyes Blue Green Hazel Brown Black 0.034 0.115 0.008 0.025 Blond 0.159 0.012 0.027 0.017 Brown 0.142 0.201 0.049 0.091 Red 0.029 0.044 0.024 0.024 Each value in the table indicates the proportion of people that have a particular hair color and a particular eye color. So the upper left cell says that 3.4% of people have black hair and blue eyes (in this particular sample – the proportions will vary a lot depending on the population of interest). We will denote this as \\[ \\operatorname{Pr}(\\mathrm{Hair} = \\mathrm{black}, \\mathrm{Eyes} = \\mathrm{blue}) = 0.034 \\;. \\] or more succinctly as \\[ p(\\mathrm{black}, \\mathrm{blue}) = 0.034 \\;. \\] This type of probability is called a joint probability because it tells about the probability of both things happening. Use the table above to do the following. What is \\(p(\\mathrm{brown}, \\mathrm{green})\\) and what does that number mean? Add the proportion across each row and down each column. (Record them to the right and along the bottom of the table.) For example, in the first row we get \\[ 0.034 + 0.115 + 0.008 + 0.025 = 0.182 \\;. \\] Explain why \\(p(\\mathrm{black}) = 0.182\\) is good notation for this number. Up to round-off error, the total of all the proportions should be 1. Check that this is true. What proportion of people with black hair have blue eyes? This is called a conditional probability. We denote it as \\(\\operatorname{Pr}(\\mathrm{Eyes} = \\mathrm{blue} \\mid \\mathrm{Hair} = \\mathrm{black})\\). or \\(p(\\mathrm{blue} \\mid \\mathrm{black})\\). Compute some other conditional probabilities. \\(p(\\mathrm{black} \\mid \\mathrm{blue})\\). \\(p(\\mathrm{blue} \\mid \\mathrm{blond})\\). \\(p(\\mathrm{blond} \\mid \\mathrm{blue})\\). \\(p(\\mathrm{brown} \\mid \\mathrm{hazel})\\). \\(p(\\mathrm{hazel} \\mid \\mathrm{brown})\\). There are 32 such conditional probabilities that we can compute from this table. Which is largest? Which is smallest? Write a general formula for computing the conditional probability \\(p(c \\mid r)\\) from the \\(p(r,c)\\) values. (\\(r\\) and \\(c\\) are to remind you of rows and columns.) Write a general formula for computing the conditional probability \\(p(r \\mid c)\\) from the \\(p(r,c)\\) values. If we have continuous random variables, we can do a similar thing. Instead of working with probability, we will work with a pdf. Instead of sums, we will have integrals. Write a general formula for computing each of the following if \\(p(x,y)\\) is a continuous joint pdf. \\(p_X(x) = p(x) =\\) \\(p_Y(y) = p(y) =\\) \\(p_{Y\\mid X}(y\\mid x) = p(y \\mid x) =\\) \\(p_{X\\mid Y}(y\\mid x) = (x \\mid y) =\\) We can expression both versions of conditional probability using a word equation. Fill in the missing numerator and denominator \\[ \\mathrm{conditional} = \\frac{\\phantom{joint}}{\\phantom{marginal}} \\] 4.3.2 Independence If \\(p(x \\mid y) = p(x)\\) (conditional = marginal) for all combinations of \\(x\\) and \\(y\\), we say that \\(X\\) and \\(Y\\) are independent. Use the definitions above to express independence another way. Are hair and eye color independent in our example? True or False. If we randomly select a card from a standard deck (52 cards, 13 denominations, 4 suits), are suit and denomination independent? Create a table for two independent random variables \\(X\\) and \\(Y\\), each of which takes on only 3 possible values. Now create a table for a different pair \\(X\\) and \\(Y\\) that are not independent but have the same marginal probabilities as in the previous exercise. 4.4 Exercises Suppose a random variable has the pdf \\(p(x) = 6x (1-x)\\) on the interval \\([0,1]\\). (That means it is 0 outside of that interval.) Use function() to create a function in R that is equivalent to p(x). Use gf_function() to plot the function on the interval \\([0, 1]\\). Integrate by hand to show that the total area under the pdf is 1 (as it should be for any pdf). Now have R compute that same integral (using integrate()). What is the largest value of \\(p(x)\\)? At what value of \\(x\\) does it occur? Is it a problem that this value is larger than 1? Hint: differentiation might be useful. Recall that \\(\\operatorname{E}(X) = \\int x f(x) \\;dx\\) for a continuous random variable with pdf \\(f\\) and \\(\\operatorname{E}(X) = \\sum x f(x) \\;dx\\) for a discrete random variable with pmf \\(f\\). (The integral or sum is over the support of the random variable.) Compute the expected value for the following random variables. \\(A\\) is discrete with pmf \\(f(x) = x/10\\) for \\(x \\in \\{1, 2, 3, 4\\}\\). \\(B\\) is continuous with kernel \\(f(x) = x^2(1-x)\\) on \\([0, 1]\\). Hint: first figure out what the pdf is. Compute the variance and standard deviation of each of the distributions in the previous problem. In Bayesian inference, we will often need to come up with a distribution that matches certain features that correspond to our knowledge or intuition about a situation. Find a normal distribution with a mean of 10 such that half of the distribution is within 3 of 10 (ie, between 7 and 13). Hint: use qnorm() to determine how many standard deviations are between 10 and 7. School children were surveyed regarding their favorite foods. Of the total sample, 20% were 1st graders, 20% were 6th graders, and 60% were 11th graders. For each grade, the following table shows the proportion of respondents that chose each of three foods as their favorite. From that information, construct a table of joint probabilities of grade and favorite food. Are grade and favorite food independent? Explain how you ascertained the answer. grade Ice cream Fruit French fries 1st 0.3 0.6 0.1 6th 0.6 0.3 0.1 11th 0.3 0.1 0.6 Three cards are placed in a hat. One is black on both sides, one is white on both sides, and the third is white on one side and black on the other. One card is selected at random from the three cards in the hat and placed on the table. The top of the card is black. What is the probability that the bottom is also black? What notation should we use for this probability? The three cards from the previous problem are returned to the hat. Once again a card is pulled and placed on the table, and once again the top is black. This time a second card is drawn and placed on the table. The top side of the second card is white. What is the probability that the bottom side of the first card is black? What is the probability that the bottom side of the second card is black? What is the probability that the bottom side of both cards is black? Pandas. Suppose there are two species of panda, A and B. Without a special blood test, it is not possible to tell them apart. But it is known that half of pandas are of each species and that 10% of births from species A are twins and 20% of births from species B are twins. If a female panda has twins, what is the probability that she is from species A? If the same panda later has another set of twins, what is the probability that she is from species A? A different panda has twins and a year later gives birth to a single panda. What is the probability that this panda is from species A? More Pandas. You get more interested in pandas and learn that at your favorite zoo, 70% of pandas are species A and 30% are species B. You learn that one of the pandas has twins. What is the probability that the panda is species A? The same panda has a single panda the next year. Now what is the probability that the species is A? 4.5 Footnotes This is a bit of a trick that R2jags uses. The function created is never run. The code is inspected and taken as the description of the model. If you were to run the funtion, all it would do is create R formulas.↩ Kruschke calls these 2-way distributions, but there can be more than variables involved.↩ "],
["bayes-rule-and-the-grid-method.html", "5 Bayes’ Rule and the Grid Method 5.1 The Big Bayesian Idea 5.2 Estimating the bias in a coin using the Grid Method 5.3 Working on the log scale 5.4 Discrete Parameters 5.5 Exercises 5.6 Footnotes", " 5 Bayes’ Rule and the Grid Method 5.1 The Big Bayesian Idea Model specifies \\[\\begin{align*} \\mbox{prior: } \\quad &amp; p(\\mbox{parameter values}) \\\\ \\mbox{likelihood: } \\quad &amp; p(\\mbox{data values} \\mid \\mbox{parameter values}) \\end{align*}\\] Bayes rule + data gives \\[\\begin{align*} \\mbox{posterior: } \\quad &amp; p(\\mbox{parameter values} \\mid \\mbox{data values}) \\end{align*}\\] Let’s let \\(D\\) be the data values and \\(\\theta\\) the parameter values. So the prior is \\(p(\\theta)\\), and the posterior is \\(p(\\theta \\mid D)\\). Recall that \\[\\begin{align*} p(D, \\theta) &amp;= p(\\theta) \\cdot p(D \\mid \\theta) \\\\ &amp;= p(D) \\cdot p(\\theta \\mid D) \\\\[3mm] p(D) \\cdot p(\\theta \\mid D) &amp;= p(\\theta) \\cdot p(D \\mid \\theta) \\end{align*}\\] Solving that last equation for \\(p(\\theta \\mid D)\\) gives \\[\\begin{align*} p(\\theta \\mid D) &amp;= \\frac{ p(\\theta) \\cdot p(D \\mid \\theta)}{p(D)} \\\\ &amp;= \\frac{ p(\\theta) \\cdot p(D \\mid \\theta)}{\\sum_{\\theta^*} p(\\theta^*) p(D \\mid \\theta^*)} \\mbox{or} \\frac{ p(\\theta) \\cdot p(D \\mid \\theta)}{\\int p(\\theta^*) p(D \\mid \\theta^*) \\; d\\theta^*} \\\\ \\end{align*}\\] Important facts about the denominator: The denominator sums or integrates over all possible numerators. The denominator depends on \\(D\\) but not on \\(\\theta\\). So it is just a normalizing constant that guarantees that total probability is 1 for the posterior distribution. That is, it converts the kernel into a pdf. If we only need a kernel, we don’t need to compute the denominator. Another way of saying all this is that \\[\\begin{align*} p(\\theta \\mid D) &amp;\\propto p(\\theta) \\cdot p(D \\mid \\theta) \\\\[3mm] \\mbox{posterior} &amp; \\propto \\mbox{prior} \\cdot \\mbox{likelihood} \\\\[3mm] \\mbox{kernel of posterior} &amp;= \\mbox{prior} \\cdot \\mbox{likelihood} \\end{align*}\\] That last line is worth repeating. It’s the most important equation in this course: \\[ \\LARGE \\mbox{(kernel of) posterior} = \\mbox{prior} \\cdot \\mbox{likelihood} \\] 5.1.1 Likelihood For a fixed data set \\(D\\), \\(p(\\theta)\\) and \\(p(\\theta \\mid D)\\) are pdfs (or pmfs) describing the prior and posterior distributions of \\(\\theta\\). The likelihood function is different. If we consider \\(p(D \\mid \\theta)\\) to be a function of \\(D\\), it is not a pdf or pmf, and the total area under the curve for all possible data sets need not be 1. The likelihood function is specified by the model. The model must tell us “how likely a given data set would be” for a specified value of the parameters \\(\\theta\\). 5.1.2 When Bayes is easy If the number of possible values for \\(\\theta\\) is small (so we could just do all the arithmetic by brute force) or if the integrals and sums are easy to compute, then Bayesian updating (computing the posterior) is relatively easy. We’ll start with examples (at least approximately) in those two happy situations and worry about some of the complications a little bit later. 5.2 Estimating the bias in a coin using the Grid Method Big ideas: Discretize the parameter space if it is not already discrete. Compute prior and likelihood at each “grid point” in the (discretized) parameter space. Compute (kernel of) posterior as prior \\(\\cdot\\) likelihood at each “grid point”. Normalize to get posterior, if desired. Below we will see how to perform these four steps in R. 5.2.1 Creating a Grid The parameter is \\(\\theta\\) and we will discretize by selecting 1001 grid points from 0 to 1 by 0.001.4 CoinsGrid &lt;- expand.grid( theta = seq(0, 1, by = 0.001) ) head(CoinsGrid) theta 0.000 0.001 0.002 0.003 0.004 0.005 Now let’s add on a triangle prior with a peak when \\(\\theta = 0.5\\). library(triangle) CoinsGrid &lt;- expand.grid( theta = seq(0, 1, by = 0.001) ) %&gt;% mutate( prior = dtriangle(theta) # triangle distribution ) gf_area(prior ~ theta, data = CoinsGrid) Now the likelihood for a small data set: 1 success out of 4 trials. This is the trickiest part. dbinom(x, size = n, prob = theta) will calculate the probability that we want for a given value of x, n, and theta. We want to do this for each value of theta but using the same values for x and n each time purrr:map_dbl() helps us tell R how to do this. Each value of theta gets plugged in for .x and a vector of numbers (dbl stands for double – computer talk for real number) is returned. library(purrr) x &lt;- 1; n &lt;- 4 CoinsGrid &lt;- expand.grid( theta = seq(0, 1, by = 0.001) ) %&gt;% mutate( prior = dtriangle(theta), # triangle distribution likelihood = map_dbl(theta, ~ dbinom(x = x, size = n, .x)) ) gf_area( prior ~ theta, data = CoinsGrid, alpha = 0.3) %&gt;% gf_area( likelihood ~ theta, data = CoinsGrid, alpha = 0.3, fill = &quot;green&quot;) Note: Likelihoods are NOT pmfs or pdfs, so the total area under a likelihood function is usually not 1. We can make a normalized version for the purpose of plotting. (Recall, we will normalize the posterior at the end anyway, so it is fine if the likelihood is off by a constant multiple at this point in the process.) We do this by dividing by sum of the likelihoods and by the width of the spaces between grid points. library(purrr) x &lt;- 1; n &lt;- 4 CoinsGrid &lt;- expand.grid( theta = seq(0, 1, by = 0.001) ) %&gt;% mutate( prior = dtriangle(theta), # triangle distribution likelihood = map_dbl(theta, ~ dbinom(x = x, size = n, .x)), likelihood1 = likelihood / sum(likelihood) / 0.001 # &quot;normalized&quot; ) gf_area( prior ~ theta, data = CoinsGrid, alpha = 0.3) %&gt;% gf_area( likelihood1 ~ theta, data = CoinsGrid, alpha = 0.3, fill = &quot;green&quot;) The hardest part of the coding (computing the likelihood) is now done. Getting the posterior is as simple as computing a product. library(purrr) x &lt;- 1; n &lt;- 4 CoinsGrid &lt;- expand.grid( theta = seq(0, 1, by = 0.001) ) %&gt;% mutate( prior = dtriangle(theta), # triangle distribution likelihood = map_dbl(theta, ~ dbinom(x = x, size = n, .x)), likelihood1 = likelihood / sum(likelihood) / 0.001, # &quot;normalized&quot; posterior0 = prior * likelihood, # unnormalized posterior = posterior0 / sum(posterior0) / 0.001 # normalized ) gf_area( prior ~ theta, data = CoinsGrid, alpha = 0.3) %&gt;% gf_area( likelihood1 ~ theta, data = CoinsGrid, alpha = 0.3, fill = &quot;green&quot;) %&gt;% gf_area( posterior ~ theta, data = CoinsGrid, alpha = 0.3, fill = &quot;steelblue&quot;) gf_line( prior ~ theta, data = CoinsGrid) %&gt;% gf_line( likelihood1 ~ theta, data = CoinsGrid, color = &quot;green&quot;) %&gt;% gf_line( posterior ~ theta, data = CoinsGrid, color = &quot;steelblue&quot;) 5.2.2 HDI from the grid The CalvinBayes packages includes a function hdi_from_grid() to compute highest density intervals from a grid. The basic idea of the algorithm used is to sort the grid by the posterior values. The mode will be at the end of the list, and the “bottom 95%” will be the HDI (or some other percent if we choose a different level). This method works as long as the posterior is unimodal, increasing to the mode from either side. hdi_from_grid() is slightly more complicated because it handles things like multiple parameters and performs some standardization (so we can work with kernels, for example). It does assume that the grid is uniform (ie, evenly spaced). We simply provide the data frame containing our grid calculations, pars: the name of the parameter (or parameters) for which we want intervals (default is the first column in the grid), prob: the probability we want in covered by our interval (0.95 by default), posterior: the name of the column containing the posterior kernel values (&quot;posterior&quot; by default) library(CalvinBayes) hdi_from_grid(CoinsGrid, pars = &quot;theta&quot;, prob = 0.95) param lo hi prob height mode_height mode theta 0.098 0.681 0.9501 0.4833 2.37 0.4 With this information in hand, we can add a representation of the 95% HDI to our plot. HDICoins &lt;- hdi_from_grid(CoinsGrid, pars = &quot;theta&quot;, prob = 0.95) gf_line(posterior ~ theta, data = CoinsGrid) %&gt;% gf_hline(yintercept = ~height, data = HDICoins, color = &quot;red&quot;, alpha = 0.5) %&gt;% gf_pointrangeh(height ~ mode + lo + hi, data = HDICoins, color = &quot;red&quot;, size = 1) %&gt;% gf_labs(caption = &quot;posterior mode and 95% HPI indicated in red&quot;) 5.2.3 Automating the grid Note: This function is a bit different from CalvinBayes::BernGrid(). MyBernGrid &lt;- function( x, n, # x successes in n tries prior = dunif, resolution = 1000, # number of intervals to use for grid ...) { Grid &lt;- expand.grid( theta = seq(0, 1, length.out = resolution + 1) ) %&gt;% mutate( # saving only the normalized version of each prior = prior(theta, ...), prior = prior / sum(prior) * resolution, likelihood = dbinom(x, n, theta), likelihood = likelihood / sum(likelihood) * resolution, posterior = prior * likelihood, posterior = posterior / sum(posterior) * resolution ) H &lt;- hdi_from_grid(Grid, pars = &quot;theta&quot;, prob = 0.95) gf_line(prior ~ theta, data = Grid, color = ~&quot;prior&quot;, size = 1.15, alpha = 0.8) %&gt;% gf_line(likelihood ~ theta, data = Grid, color = ~&quot;likelihood&quot;, size = 1.15, alpha = 0.7) %&gt;% gf_line(posterior ~ theta, data = Grid, color = ~&quot;posterior&quot;, size = 1.15, alpha = 0.6) %&gt;% gf_pointrangeh( height ~ mode + lo + hi, data = H, color = &quot;red&quot;, size = 1) %&gt;% gf_labs(title = &quot;Prior/Likelihood/Posterior&quot;, subtitle = paste(&quot;Data: n =&quot;, n, &quot;, x =&quot;, x)) %&gt;% gf_refine( scale_color_manual( values = c( &quot;prior&quot; = &quot;forestgreen&quot;, &quot;likelihood&quot; = &quot;blue&quot;, &quot;posterior&quot; = &quot;red&quot;), breaks = c(&quot;prior&quot;, &quot;likelihood&quot;, &quot;posterior&quot;) )) %&gt;% print() invisible(Grid) # return the Grid, but don&#39;t show it } This function let’s us quickly explore several scenarios and compare the results. How does changing the prior affect the posterior? How does changing the data affect the posterior? library(triangle) MyBernGrid(1, 4, prior = dtriangle, a = 0, b = 1, c = 0.5) MyBernGrid(1, 4, prior = dunif) MyBernGrid(10, 40, prior = dtriangle, a = 0, b = 1, c = 0.5) MyBernGrid(10, 40, prior = dunif) MyBernGrid(1, 4, prior = dtriangle, a = 0, b = 1, c = 0.8) MyBernGrid(10, 40, prior = dtriangle, a = 0, b = 1, c = 0.8) MyBernGrid(10, 40, prior = dbeta, shape1 = 25, shape2 = 12) 5.3 Working on the log scale Very often it is numerically better to work on the log scale, computing the logs of the prior, likelihood, and posterior. There are at least two reasons for this: Likelihoods are often very small, especially if there is a lot of data. (Even with the most credible parameter values, the probability of getting exactly the data set that was observed is very low.) Likelihoods often involve products and exponentiation. Take logarithms turns these into sums and products. In fact, we can often compute these logs without first computing the prior, likelihood, or posterior. (It depends on the form of those functions.) Let’s redo our previous example working on the log scale until the very end. x &lt;- 1; n &lt;- 4 CoinsGridLog &lt;- expand.grid( theta = seq(0, 1, by = 0.001) ) %&gt;% mutate( logprior = log(dtriangle(theta, 0, 1)), # triangle distribution loglik = map_dbl(theta, ~ dbinom(x = x, size = n, prob = .x, log = TRUE)), logpost = logprior + loglik, posterior = exp(logpost), posterior1 = posterior / sum(posterior, na.rm = TRUE) ) gf_line(posterior1 ~ theta, data = CoinsGridLog) 5.4 Discrete Parameters Most of the parameters we will encounter will be able to take on all values in some interval. If we have parameter that can only take on a discrete set of values, then the grid method is exact if we make a grid point for each of those values. Usually we think of parameters taking on numerical values, but here is an example where a parameter takes on categorical labels for values. Suppose we have a medical test for a disease and we know the following information. Only 1 person in 1000 has the disease in our population of interest If a person is healthy, the probability that the test will be correct is 97%. (97% = specificity = true negative rate) If a person is diseased, the probability that the test will be correct is 99%. (99% = sensitivity = true positive rate) If a person is tested and the test comes back “positive” (indicating disease), what is the probability that the person actually has the disease? Our parameter that we want to estimate is disease status, which can take on only two possible values: healthy or diseased. Disease_Grid &lt;- tibble( status = c(&quot;healthy&quot;, &quot;sick&quot;), prior = c(999/1000, 1/1000) ) Disease_Grid status prior healthy 0.999 sick 0.001 Now let’s add in the likelihood and posterior information assuming a positive test result. Disease_Grid &lt;- tibble( status = c(&quot;healthy&quot;, &quot;sick&quot;), prior = c(999/1000, 1/1000), likelihood = c(.03, .99), posterior = prior * likelihood, posterior1 = posterior / sum(posterior) ) Disease_Grid status prior likelihood posterior posterior1 healthy 0.999 0.03 0.030 0.968 sick 0.001 0.99 0.001 0.032 So we have updated our belief from a 0.1% chance the person has the disease to a 3.2$ chance that they have the disease. That’s a sizable increase, but the person is still most likely healthy, not diseased. 5.5 Exercises More testing. Suppose that the population consists of 100,000 people. Compute how many people would be expected to fall into each cell of Table 5.4 on page 104 of DBDA2e. (To compute the expected number of people in a cell, just multiply the cell probability by the size of the population.) You should find that out of 100,000 people, only 100 have the disease, while 99,900 do not have the disease. These marginal frequencies instantiate the prior probability that \\(p(\\theta = \\frown) = 0.001\\). Notice also the cell frequencies in the column \\(\\theta = \\frown\\), which indicate that of 100 people with the disease, 99 have a positive test result and 1 has a negative test result. These cell frequencies instantiate the hit rate of 0.99. Your job for this part of the exercise is to fill in the frequencies of the remaining cells of the table. Take a good look at the frequencies in the table you just computed for the previous part. These are the so-called “natural frequencies” of the events, as opposed to the somewhat unintuitive expression in terms of conditional probabilities (Gigerenzer &amp; Hoffrage, 1995). From the cell frequencies alone, determine the proportion of people who have the disease, given that their test result is positive. Your answer should match the result from applying Bayes’ rule to the probabilities. Now we’ll consider a related representation of the probabilities in terms of natural frequencies, which is especially useful when we accumulate more data. This type of representation is called a “Markov” representation by Krauss, Martignon, and Hoffrage (1999). Suppose now we start with a population of \\(N = 10,000,000\\) people. We expect 99.9% of them (i.e., 9,990,000) not to have the disease, and just 0.1% (i.e., 10,000) to have the disease. Now consider how many people we expect to test positive. Of the 10,000 people who have the disease, 99%, (i.e., 9,900) will be expected to test positive. Of the 9,990,000 people who do not have the disease, 5% (i.e., 499,500) will be expected to test positive. Now consider re-testing everyone who has tested positive on the first test. How many of them are expected to show a negative result on the re-test? What proportion of people who test positive at first and then negative on retest, actually have the disease? In other words, of the total number of people at the bottom of the diagram in the previous part (those are the people who tested positive then negative), what proportion of them are in the left branch of the tree? How does the result compare with your answer to Exercise 5.1? Suppose we have a test with a 97% specificity and a 99% sensitivity just like in Section 5.4. Now suppose that a random person is selected, has a first test that is positive, then is retested and has a second test that is negative. Taking into account both tests, and assuming the results of the two tests are independent, what is the probability that the person has the disease? Hint: We can use the the posterior after the first test as a prior for the second test. Be sure to keep as many decimal digits as possible (use R and don’t round intermediate results). Note: In this problem we are assuming the the results of the two tests are independent, which might not be the case for some medical tests. Consider again the disease and diagnostic test of the previous exercise and Section 5.4. Suppose that a person selected at random from the population gets the test and it comes back negative. Compute the probability that the person has the disease. The person then gets re-tested, and on the second test the result is positive. Compute the probability that the person has the disease. How does the result compare with your answer in the previous exercise? Modify MyBernGrid() so that it takes an argument specifying the probability for the HDI. Use it to create a plot showing 50% HDI for theta using a symmetric triangle prior and data consisting of 3 success and 5 failures. Let’s try the grid method for a model with two parameters. Suppose we want to estimate the mean and standard deviation of the heights of 21-year-old American men or women (your choice which group). First, lets get some data. library(NHANES) Men &lt;- NHANES %&gt;% filter(Gender == &quot;male&quot;, Age == 21) Women &lt;- NHANES %&gt;% filter(Gender == &quot;female&quot;, Age == 21) Likelihood Our model is that heights are normally distributed with mean \\(\\mu\\) and standard deviation \\(\\sigma\\): Prior. For our prior, let’s use something informed just a little bit by what we know about people (we could do better with these priors, but that’s not our goal at the moment): the mean height is somewhere between 5 and 7 feet (let’s use 150 and 200 cm which are close to that) the standard deviation is positive, but no more than 20 cm (so 95% of people are within 40 cm (~ 16 inches) of average – that seems like a pretty safe bet). we will use a uniform prior over these ranges (even though you probably believe that some parts of the ranges are much more credible than others). So our model is \\[\\begin{align*} \\mathrm{Height} &amp; \\sim {\\sf Norm}(\\mu, \\sigma) \\\\ \\mu &amp; \\sim {\\sf Unif}(150, 200) \\\\ \\sigma &amp; \\sim {\\sf Unif}(0, 20) \\end{align*}\\] Grid. Use a grid that has 200-500 values for each parameter. Fill in the ?? below to create and update your grid. Notes: It is more numerically stable to work on the log-scale as much as possible, You may normalize if you want to, but it isn’t necessary for this problem. library(purrr) Height_Grid &lt;- expand.grid( mu = seq(??, ??, ?? = ??), sigma = seq(??, ??, ?? = ??) ) %&gt;% filter(sigma != 0) %&gt;% # remove sigma = 0 mutate( prior = ??, logprior = ??, loglik = map2_dbl(mu, sigma, ~ ?? ) # use .x for mu and .y for sigma logpost = logprior + loglik, posterior = exp(logpost) ) Once you have created and updated your grid, you can visualize your posterior using a command like this (use gf_lims() if you want to zoom in a bit): gf_tile(posterior ~ mu + sigma, data = Height_Grid) %&gt;% gf_contour(posterior ~ mu+ sigma, data = Height_Grid, color = &quot;yellow&quot;) Now answer the following questions. Using the picture you just created, what would you say are credible values for \\(\\mu\\) and for \\(\\sigma\\)? Now use hdi_from_grid() to compute a 90% highest density (posterior) intervals for each parameter. Do those make sense when you compare to the picture? Create a plot showing the posterior distribution for \\(\\mu\\) and a 90% HDI for \\(\\mu\\). [Hint: how can you get a grid for the marginal distribution of \\(\\mu\\) from the grid for \\(\\mu\\) and \\(\\sigma\\)?] Redo the previous problem using a triangle prior for each parameter. You may choose where to put the peak of the triangle. Bob plays basketball. He shoots 70% of his shots from 2-point range and makes 48% of these shots. He shoots 30% of his shots from 3-point range and makes 32% of these shots. Joe just made a shot. What is the probability that it was a 3-point shot? Do this problem twice. The first time, use probability rules, carefully denoting the probabilities involved. (For any number that appears, I should be able to tell from your notation where it came from.) The second time, use the “grid method”. Alice has 3 hats labeled with the letters H, A, and T. In each hat are marbles of various colors. Hat White marbles Red marbles Yellow marbles H 4 10 6 A 6 12 2 T 5 3 2 Alice randomly selects a hat by flipping two coins. If both are heads, she chooses hat H. If both are tails, she chooses hat T. If there is one head and one tail, she chooses hat A. Once that hat is selected, she draws out two marbles. If the two marbles are both white, what is the probability that the hat was hat A? If there is one red marble and one yellow marble, what is the probability that the hat was hat A? If the two marbles are the same color, what is the probability that the hat was hat A? 5.6 Footnotes This is a bit of a trick that R2jags uses. The function created is never run. The code is inspected and taken as the description of the model. If you were to run the funtion, all it would do is create R formulas.↩ "],
["inferring-a-binomial-probability-via-exact-mathematical-analysis.html", "6 Inferring a Binomial Probability via Exact Mathematical Analysis 6.1 Beta distributions 6.2 Beta and Bayes 6.3 Getting to know the Beta distributions 6.4 What if the prior isn’t a beta distribution? 6.5 Exercises", " 6 Inferring a Binomial Probability via Exact Mathematical Analysis 6.1 Beta distributions A few important facts about beta distributions two parameters: \\(\\alpha = a =\\) shape1; \\(\\beta = b =\\) shape2. kernel: \\(x^{\\alpha - 1} (1-x)^{\\beta -1}\\) on \\([0, 1]\\) area under the kernel: \\(B(a, b)\\) [\\(B()\\) is the beta function, beta() in R] scaling contant: \\(1 / B(a, b)\\) We can use gf_dist() to see what a beta distribution looks like. gf_dist(&quot;beta&quot;, shape1 = 5, shape2 = 3, color = ~ &quot;Beta(5, 3)&quot;) %&gt;% gf_dist(&quot;beta&quot;, shape1 = 3, shape2 = 5, color = ~ &quot;Beta(3, 5)&quot;) %&gt;% gf_dist(&quot;beta&quot;, shape1 = 0.9, shape2 = 0.9, color = ~ &quot;Beta(0.9, 0.9)&quot;) %&gt;% gf_dist(&quot;beta&quot;, shape1 = 0.9, shape2 = 1.1, color = ~ &quot;Beta(0.9, 1.1)&quot;) %&gt;% gf_labs(title = &quot;Some Beta distributions&quot;, color = &quot;distribution&quot;) 6.2 Beta and Bayes Suppose we want to estimate a proportion \\(\\theta\\) by repeating some random process (like a coin toss) \\(N\\) times. We will code each result using a 0 (failure) or a 1 (success): \\(Y_1, Y_2, \\dots, Y_N\\). Here’s our model. The prior, to be determined shortly, is indicated as ??? for the moment. \\[\\begin{align*} Y_i &amp; \\sim {\\sf Bern}(\\theta) \\\\ \\theta &amp; \\sim{} ??? \\end{align*}\\] 6.2.1 The Bernoulli likelihood function The first line turns into the following likelihood function – the probability of observing \\(y_i\\) for a give parameter value \\(\\theta\\): \\[\\begin{align*} Pr{Pr}(Y_i = y_i \\mid \\theta) = p(y_i \\mid \\theta) &amp;= \\begin{cases} \\theta &amp; y_i = 1 \\\\ (1-\\theta) &amp; y_i = 0 \\end{cases} \\\\ &amp;= \\theta^{y_i} (1-\\theta)^{y_i} \\end{align*}\\] The likelihood for the entire data set is then \\[\\begin{align*} p(\\langle y_1, y_2, \\dots, y_N \\rangle \\mid \\theta) &amp;= \\prod_{i = 1}^N \\theta^{y_i} (1-\\theta)^{y_i} \\\\ &amp;= \\theta^{x} (1-\\theta)^{N - x} \\end{align*}\\] where \\(x\\) is the number of “successes” and \\(N\\) is the number of trials. Since the likelihood only depends on \\(x\\) and \\(N\\), not the particular order in which the 0’s and 1’s are observed, we will write the likelihood as \\[\\begin{align*} p(x, N \\mid \\theta) &amp;= \\theta^{x} (1-\\theta)^{N - x} \\end{align*}\\] Reminder: If we think of this expression as a function of \\(\\theta\\) for fixed data (rather than as a function of the data for fixed \\(\\theta\\)), we see that it is the kernel of a \\({\\sf Beta}(x + 1, N - x + 1)\\) distribution. But even thought of this way, the likelihood need not be a PDF – the total sum or integral need not be 1. But we will sometimes normalize likelihood functions if we want to display them on plots with priors and posteriors. 6.2.2 A convenient prior Now let think about our posterior: \\[\\begin{align*} p(\\theta \\mid x, N) &amp; = \\overbrace{p(x, N \\mid \\theta)}^{\\mathrm{likelihood}} \\cdot \\overbrace{p(\\theta)}^{\\mathrm{prior}} / p(x, N) \\\\ &amp; = {\\theta^x (1-\\theta)^{N - x}} \\cdot {p(\\theta)} / p(x, N) \\end{align*}\\] If we let \\(p(\\theta) = \\theta^a (1-\\theta^b)\\), the product is epsecially easy to evaluate: \\[\\begin{align*} p(\\theta \\mid x, N) &amp; = \\overbrace{p(x, N \\mid \\theta)}^{\\mathrm{likelihood}} \\cdot \\overbrace{p(\\theta)}^{\\mathrm{prior}} / p(x, N) \\\\ &amp; = {\\theta^x (1-\\theta)^{N - x}} \\cdot {\\theta^a (1-\\theta)^b)} / p(x, N) \\\\ &amp; = {\\theta^{x+a} (1-\\theta)^{N - x + b}} / p(x, N) \\end{align*}\\] In this happy situation, when mutlipying the likelihood and the prior leads to a posterior with same form as the prior, we say that the prior is a conjugate prior (for that particular likelihood function). So beta priors are conjugate priors for the Bernoulli likelihood, and if we use a beta prior, we will get a beta posterior and it is easy to calculate which one: prior data posterior \\(\\sf{Beta}(a, b)\\) \\(x, N\\) \\({\\sf Beta}(x + a, N - x + b)\\) 6.2.3 Pros and Cons of conjugate priors Pros: Easy and fast calculation; can reason about the relationship between prior, likelihood, and posterior based on a known distributions. Cons: We are restricted to using a conjugate prior, and that isn’t always the prior we want; many situations don’t have natural conjugate priors available; the computations are often not as simple as in our current example. 6.3 Getting to know the Beta distributions 6.3.1 Important facts You can often look up this sort of information on the Wikipedia page for a family of distributions. If you go to https://en.wikipedia.org/wiki/Beta_distribution you will find, among other things, the following: Notation Beta(\\(\\alpha, \\beta\\)) Parameters \\(\\alpha &gt; 0\\) shape (real) \\(\\beta &gt; 0\\) shape (real) Support \\(\\displaystyle x\\in [0,1]\\) or \\(\\displaystyle x\\in (0,1)\\) PDF \\(\\displaystyle \\frac{x^{\\alpha -1}(1-x)^{\\beta -1}}{\\mathrm{B}(\\alpha, \\beta )}\\) Mean \\(\\displaystyle \\frac{\\alpha }{\\alpha +\\beta }\\) Mode \\(\\displaystyle {\\frac{\\alpha -1}{\\alpha +\\beta -2}}\\) for \\(\\alpha, \\beta &gt; 1\\) 0 for \\(\\alpha = 1, \\beta &gt; 1\\) 1 for \\(\\alpha &gt; 1, \\beta = 1\\) Variance \\(\\displaystyle \\frac{\\alpha \\beta}{(\\alpha +\\beta )^{2}(\\alpha +\\beta +1)}\\) Concentration \\(\\displaystyle \\kappa =\\alpha +\\beta\\) 6.3.2 Alternative parameterizations of Beta distributions There are several different parameterizations of the beta distributions that can be helpful in selecting a prior or interpreting a posterior. 6.3.2.1 Mode and concentration Let the concentration be defined as \\(\\kappa =\\alpha +\\beta\\). Since the mode (\\(\\omega\\)) is \\(\\displaystyle {\\frac{\\alpha -1}{\\alpha +\\beta -2}}\\) for \\(\\alpha, \\beta &gt; 1\\), we can solve for \\(\\alpha\\) and \\(\\beta\\) to get \\[\\begin{align} \\alpha &amp;= \\omega (\\kappa - 2) + 1\\\\ \\beta &amp;= (1-\\omega)(\\kappa -2) + 1 \\end{align}\\] 6.3.2.2 Mean and concentration The beta distribution may also be reparameterized in terms of its mean \\(\\mu\\) and the concentration \\(\\kappa\\). If we solve for \\(\\alpha\\) and \\(\\beta\\), we get \\[\\begin{align} \\alpha &amp;= \\mu \\kappa \\\\ \\beta &amp;= (1 - \\mu) \\kappa \\end{align}\\] 6.3.2.3 Mean and variance (or standard deviation) We can also parameterize with the mean \\(\\mu\\) and variance \\(\\sigma^2\\). Solving the system of equations for mean and variance given in the table above, we get \\[\\begin{align} \\kappa &amp;=\\alpha +\\beta = \\frac{\\mu (1-\\mu )}{\\sigma^2} - 1 \\\\ \\alpha &amp;=\\mu \\kappa = \\mu \\left({\\frac{\\mu (1-\\mu )}{\\sigma^2}}-1\\right) \\\\ \\beta &amp;= (1-\\mu )\\kappa = (1-\\mu ) \\left({\\frac{\\mu (1-\\mu)} {\\sigma^2}} -1 \\right), \\end{align}\\] provided \\(\\sigma^2 &lt; \\mu (1-\\mu)\\). 6.3.3 beta_params() CalvinBayes::beta_params() will compute several summaries of a beta distribution given any of these 2-parameter summaries. This can be very handy for converting from one type of information about a beta distribution to another. For example. Suppose you want a beta distribution with mean 0.3 and standard deviation 0.1. Which beta distribution is it? library(CalvinBayes) beta_params(mean = 0.3, sd = 0.1) shape1 shape2 mean mode sd concentration 6 14 0.3 0.2778 0.1 20 We can do a similar thing with other combinations. bind_rows( beta_params(mean = 0.3, concentration = 10), beta_params(mode = 0.3, concentration = 10), beta_params(mean = 0.3, sd = 0.2), beta_params(shape1 = 5, shape2 = 10), ) shape1 shape2 mean mode sd concentration 3.000 7.000 0.3000 0.2500 0.1382 10.00 3.400 6.600 0.3400 0.3000 0.1428 10.00 1.275 2.975 0.3000 0.1222 0.2000 4.25 5.000 10.000 0.3333 0.3077 0.1179 15.00 6.3.4 Automating Bayesian updates for a proportion (beta prior) Since we have formulas for this case, we can write a function handle any beta prior and any data set very simply. (Much simpler than doing the grid method each time). quick_bern_beta &lt;- function( x, n, # data, successes and trials ... # see clever trick below ) { pars &lt;- beta_params(...) a &lt;- pars$shape1 b &lt;- pars$shape2 theta_hat &lt;- x / n # value that makes likelihood largest posterior_mode &lt;- (a + x - 1) / (a + b + n - 2) # scale likelihood to be as tall as the posterior likelihood &lt;- function(theta) { dbinom(x, n, theta) / dbinom(x, n, theta_hat) * dbeta(posterior_mode, a + x, b + n - x) # posterior height at mode } gf_dist(&quot;beta&quot;, shape1 = a, shape2 = b, color = ~ &quot;prior&quot;, alpha = 0.5, xlim = c(0,1), size = 1.2) %&gt;% gf_function(likelihood, color = ~ &quot;likelihood&quot;, alpha = 0.5, size = 1.2) %&gt;% gf_dist(&quot;beta&quot;, shape1 = a + x, shape2 = b + n - x, color = ~ &quot;posterior&quot;, alpha = 0.5, size = 1.6) %&gt;% gf_labs( color = &quot;function&quot;, title = paste0(&quot;posterior: Beta(&quot;, a + x, &quot;, &quot;, b + n - x, &quot;)&quot;) ) %&gt;% gf_refine( scale_color_manual( values = c(&quot;prior&quot; = &quot;gray50&quot;, &quot;likelihood&quot; = &quot;forestgreen&quot;, &quot;posterior&quot; = &quot;steelblue&quot;))) } With such a function in hand, we can explore examples very quickly. Here are three examples from DBDA2e (pp. 134-135). quick_bern_beta(17, 20, mode = 0.5, k = 500) quick_bern_beta(17, 20, mode = 0.75, k = 25) quick_bern_beta(17, 20, a = 1, b = 1) 6.4 What if the prior isn’t a beta distribution? Unless it is some other distribution where we can work things out mathematically, we are back to the grid method. Here’s an example like the one on page 136. dtwopeaks &lt;- function(x) { 0.48 * triangle::dtriangle(x, 0.2, 0.3) + 0.48 * triangle::dtriangle(x, 0.7, 0.8) + 0.04 * dunif(x) } BernGrid(data = c(rep(0, 13), rep(1, 14)), prior = dtwopeaks) %&gt;% gf_function(function(theta) 0.3 * dbinom(13, 27, theta), color = &quot;forestgreen&quot;) 6.5 Exercises Show that if \\(\\alpha, \\beta &gt; 1\\), then the mode of a Beta(\\(\\alpha\\), \\(\\beta\\)) distribution is \\(\\displaystyle {\\frac{\\alpha -1}{\\alpha +\\beta -2}}\\). Hint: What would you do if you were in Calculus I? Suppose we have a coin that we know comes from a magic-trick store, and therefore we believe that the coin is strongly biased either usually to come up heads or usually to come up tails, but we don’t know which. Express this belief as a beta prior. That is, find shape parameters that lead to a beta distribution that corresponds to this belief. Now we flip the coin 5 times and it comes up heads in 4 of the 5 flips. What is the posterior distribution? Use quick_bern_beta() or a similar function of your own creation to show the prior and posterior graphically. Suppose we estimate a proprtion \\(\\theta\\) using a \\({\\sf Beta}(10, 10)\\) prior and a observe 26 successes and 48 failures. What is the posterior distribution? What is the mean of the posterior distribution? What is the mode of the posterior distribution? Compute a 90% HDI for \\(\\theta\\). [Hint: qbeta()] Suppose a state-wide election is approaching, and you are interested in knowing whether the general population prefers the democrat or the republican. There is a just-published poll in the newspaper, which states that of 100 randomly sampled people, 58 preferred the republican and the remainder preferred the democrat. Suppose that before the newspaper poll, your prior belief was a uniform distribution. What is the 95% HDI on your beliefs after learning of the newspaper poll results? Based on what you know about elections, why is a uniform prior not a great choice? Repeat part (a) with a prior the conforms better to what you know about elections. How much does the change of prior affect the 95% HDI? You find another poll conducted by a different news organization In this second poll, 56 of 100 people preferred the republican. Assuming that peoples’ opinions have not changed between polls, what is the 95% HDI on the posterior taking both polls into account. Make it clear which prior you are using. Based on this data (and your choice of prior, and assuming public opinion doesn’t change between the time of the polls and election day), what is the probability that the republican will win the election. "],
["markov-chain-monte-carlo-mcmc.html", "7 Markov Chain Monte Carlo (MCMC) 7.1 King Markov and Adviser Metropolis 7.2 Quick Intro to Markov Chains 7.3 Back to King Markov 7.4 How well does the Metropolis Algorithm work? 7.5 Markov Chains and Posterior Sampling 7.6 Two coins 7.7 MCMC posterior sampling: Big picture 7.8 Exercises", " 7 Markov Chain Monte Carlo (MCMC) 7.1 King Markov and Adviser Metropolis King Markov is king of a chain of 5 islands. Rather than live in a palace, he lives in a royal boat. Each night the royal boat anchors in the harbor of one of the islands. The law declares that the king must harbor at each island in proportion to the population of the island. Question 1: If the populations of the islands are 100, 200, 300, 400, and 500 people, how often must King Markov harbor at each island? King Markov has some personality quirks: He can’t stand record keeping. So he doesn’t know the populations on his islands and doesn’t keep track of which islands he has visited when. He can’t stand routine (variety is the spice of his life), so he doesn’t want to know each night where he will be the next night. He asks Adviser Metropolis to devise a way for him to obey the law but that randomly picks which island to stay at each night, doesn’t require him to remember where he has been in the past, and doesn’t require him to remember the populations of all the islands. He can ask the clerk on any island what the island’s population is whenever he needs to know. But it takes half a day to sail from one island to another, so he is limited in how much information he can obtain this way each day. Metropolis devises the following scheme: Each morning, have breakfast with the island clerk and inquire about the population of the current island. Then randomly pick one of the 4 other islands (a proposal island) and travel there in the morning Let \\(J(b \\mid a)\\) be the conditional probability of selecting island \\(b\\) as the candidate if \\(a\\) is the current island. \\(J\\) does not depend on the populations of the islands (since the King can’t remember them). Over lunch at the proposal island, inquire about its population. If the proposal island has more people, stay at the proposal island for the night (since the king should prefer more populated islands). If the proposal island has fewer people, stay at the proposal island with probability \\(A\\), else return to the “current” island (ie, last night’s island). Metropolis is convinced that for the right choices of \\(J\\) and \\(A\\), this will satisfy the law. He quickly determines that \\(A\\) cannot be 0 and cannot be 1: Question 2. What happens if \\(A = 0\\)? What happens if \\(A = 1\\)? It seems like \\(A\\) might need to depend on the populations of the current and proposal islands. When we want to emphasize that, we’ll denote it as \\(A = A(b \\mid a)\\). But how? If \\(A\\) is too large, the king will visit small islands too often. If \\(A\\) is too small, he will visit large islands too often. Fortunately, Metropolis knows about Markov Chains. Unfortunately, some of you may not. So let’s learn a little bit about Markov Chains and then figure out how Metropolis should choose \\(J\\) and \\(A\\). 7.2 Quick Intro to Markov Chains 7.2.1 More info, please This is going to be very quick. You can learn more, if you are interested, by going to https://www.dartmouth.edu/~chance/teaching_aids/books_articles/probability_book/Chapter11.pdf 7.2.2 Definition Consider a random process that proceeds in discrete steps (often referred to as time). Let \\(X_t\\) represent the “state” of the process at time \\(t\\). Since this is a random process, \\(X_t\\) is random, and we can ask probability questions like ``What is the probability of being in state ____ at time ____?&quot;, ie, What is \\(\\mathrm{Pr}(X_t = x)\\)? If \\[ \\mathrm{Pr}(X_{t+1} = x \\mid X_t = x_t, X_{t-1} = x_{t-1}, \\dots , X_0 = x_0) = \\mathrm{Pr}(X_{t+1} \\mid X_{t} = x_t) \\] then we say that the process is a Markov Chain. The intuition is that (the probabilities of) what happens next depends only on the current state and not on previous history. 7.2.3 Time-Homogeneous Markov Chains The simplest version of a Markov Chain is one that is time-homogeneous: \\[ \\mathrm{Pr}(X_{t+1} = b \\mid X_t = a) = p_{ab} \\] That is, the (conditional) probability of moving from state \\(a\\) to state \\(b\\) in one step is the same at every time. 7.2.4 Matrix representation A time-homogeneous Markov Chain can be represented by a square matrix \\(M\\) with \\[ M_{ij} = p_{ij} = \\mbox{probability of transition from state $i$ to state $j$ in one step} \\] (This will be an infinite matrix if the state space in infinite, but we’ll start with simple examples with small, finite state spaces.) \\(M_{ij}\\) is the probability of moving in one step from state \\(i\\) to state \\(j\\). More generally, we will write \\(M^{(k)}_{ij}\\) for the probability of moving from state \\(i\\) to state \\(j\\) in \\(k\\) steps. Small Example: M &lt;- rbind( c(0, 0.5, 0.5), c(0.25, 0.25, 0.5), c(0.5, 0.3, 0.2)) M 0.00 0.50 0.5 0.25 0.25 0.5 0.50 0.30 0.2 Question 3: How many states does this process have? What is the probability of moving from state 1 to state 3 in 1 step? What is the probability of moving from state 1 to state 3 in 2 steps? (Hint: what are the possible stopping points along the way?) How do we obtain \\(M^{(2)}\\) from \\(M\\)? How do we obtain \\(M^{(k)}\\) from \\(M\\)? Question 4: The Metropolis Algorithm as a Markov process What are the states of the Metropolis algorithm? If King Markov is on island 2, what is the probability of moving to Island 3? If King Markov is on island 3, what is the probability of moving to Island 2? What is the general formula for the probability of moving from island \\(a\\) to island \\(b\\) (in one step)? (\\(\\mathrm{Pr}(X_{t+1}=b \\mid X_t = a)\\)) 7.2.5 Regular Markov Chains A time-homogeneous Markov Chain, is called regular if there is a number \\(k\\) such that every state is reachable from every other state with non-zero probability in \\(k\\) steps Question 5a Is our small example regular? If so, how many steps are required? Question 5b Under what conditions is the Metropolis algorithm regular? Regular Markov Chains have a very nice property: \\[ \\lim_{k \\to \\infty} M^{(k)} = W \\] where every row of \\(W\\) is the same. This says that, no matter where you start the process, the long-run probability of being in each state will be the same. In our small example above, convergence is quite rapid: M %^% 20 0.2769 0.3385 0.3846 0.2769 0.3385 0.3846 0.2769 0.3385 0.3846 M %^% 21 0.2769 0.3385 0.3846 0.2769 0.3385 0.3846 0.2769 0.3385 0.3846 Note: If we apply the matrix \\(M\\) to the limiting probability (\\(w\\), one row of \\(W\\)), we just get \\(w\\) back again: \\[w M = w\\] W &lt;- M %^% 30 W[1,] ## [1] 0.2769 0.3385 0.3846 W[1,] %*% M 0.2769 0.3385 0.3846 In fact, this is a necessary and sufficient condition for the limiting probability. So, here’s what Metropolis needs to do: Choose \\(J\\) and \\(A\\) so that his algorithm is a regular Markov Chain with matrix \\(M\\) If \\(w = \\langle p(1), p(2), p(3), p(4), p(5) \\rangle\\) is the law-prescribed probabilities for island harboring, then \\(w M = w\\). 7.3 Back to King Markov If \\(A\\) is between 0 and 1, and the jumping rule allows us to get to all the islands (eventually), then the Markov Chain will be regular, so there will be a limiting distribution. But the limiting distribution must be the one the law requires. It suffices to show that if the law is satisfied at time \\(t\\) it is satisfied at time \\(t+1\\) (\\(wM = w\\)): \\[ \\mathrm{Pr}(X_t = a) = p(a) \\mbox{ for all $a$ } \\Rightarrow \\mathrm{Pr}(X_{t+1} = a) = p(a) \\mbox{ for all $a$} \\] Here’s the trick: We will choose \\(J\\) and \\(A\\) so that the following two unconditional probabilities are equal. \\[ \\mathrm{Pr}(a \\to_t b) = \\mathrm{Pr}(b \\to_t a) \\] where \\(\\mathrm{Pr}(a \\to_t b) = \\mathrm{Pr}(X_t = a \\ \\&amp; \\ X_{t+1} = b)\\). Why does this work? Suppose \\(\\mathrm{Pr}(X_t = a) = p(a)\\) as the law prescribes. \\(\\mathrm{Pr}(a \\to_t b) = \\mathrm{Pr}(b \\to_t a)\\) makes the joint distribution symmetric: For any \\(a\\) and any \\(b\\). \\[\\mathrm{Pr}(X_{t} = a \\ \\&amp; \\ X_{t+1} = b) = \\mathrm{Pr}(X_{t} = b \\ \\&amp; \\ X_{t+1} = a)\\] This means that both marginals are the same, so for any \\(a\\): \\[\\mathrm{Pr}(X_t = a) = \\mathrm{Pr}(X_{t+1} = a)\\] In other words, the probability of the current island will be the same as the probability of the next island: \\(w M = w\\). Time for some algebra (and probability)! How do we choose \\(J\\) and \\(A\\)? Recall the ingredients: \\(P(a)\\) be the population of island \\(a\\) \\(p(a)\\) be the proportion of the total population living on island \\(a\\): \\(p(a) = \\frac{p(a)}{\\sum_x p(x)}\\) \\(J(b \\mid a)\\) is the conditional probability of selecting island \\(b\\) as the candidate when \\(a\\) is the current island. (J for Jump probability) \\(A(b \\mid a)\\) is the probability of accepting proposal island \\(b\\) if it is proposed from island \\(a\\). Question 6: Consider two islands – \\(a\\) and \\(b\\) – with \\(P(b) &gt; P(a)\\). Assume that probability of being on island \\(x\\) is \\(p(x)\\). Calculate the following probabilities (in terms of things like \\(p\\), \\(J\\), and \\(A\\)). (Unconditional) probability of moving from \\(a\\) to \\(b = \\mathrm{Pr}(a \\to_t b) =\\) (Unconditional) probability of moving from \\(b\\) to \\(a = \\mathrm{Pr}(b \\to_t a) =\\) Question 7: How do we choose J and A to make these probabilities equal? \\[ A(a \\mid b) = \\phantom{\\frac{p(a) J(b \\mid a)}{p(b) J(a \\mid b)}} \\] Question 8: Symmetric jump rules. Is it possible to do this with symmetric jump rules? That is, can we require \\(J(b \\mid a) = J(a \\mid b)\\)? (Remember, the king doesn’t like to remember stuff, and this means half as much stuff to remember about the jump rules). Does using a symmetric jump rule make the acceptance rule \\(A\\) any simpler or more complicated? (The king won’t be so happy if the simpler jump rule makes the acceptance rule a lot more complicated.) Question 9: Constant jump rules. Is it possible to do this if we require that \\(J(y \\mid x) = J(y&#39; \\mid x&#39;)\\) for all \\(y \\neq x\\) and \\(y&#39; \\neq x&#39;\\)? (This would make life even easier for the king.) For King Markov, what would \\(J\\) be if we did it this way? The original Metropolis algorithm used symmetric jump rules. The later generalization (Metropolis-Hastings) employed non-symmetric jump rules to get better performance of the Markov Chain. 7.4 How well does the Metropolis Algorithm work? Let’s let the computer simulate this algorithm. And since the computer is doing all the work, let’s make a general function so we can experiment a bit. KingMarkov &lt;- function( num_steps = 1e5, population = 1:5, island_names = 1:length(population), start = 1, J = function(a, b) {1 / (length(population) - 1)} ) { num_islands &lt;- length(population) island_seq &lt;- rep(NA, num_steps) # trick to pre-alocate memory proposal_seq &lt;- rep(NA, num_steps) # trick to pre-alocate memory current &lt;- start proposal &lt;- NA for (i in 1:num_steps) { # record current island island_seq[i] &lt;- current proposal_seq[i] &lt;- proposal # propose one of the other islands other_islands &lt;- setdiff(1:num_islands, current) proposal &lt;- sample(other_islands, 1, prob = purrr::map(other_islands, ~ J(current, .x))) # move? prob_move &lt;- population[proposal] / population[current] # new current island (either current current or proposal) current &lt;- ifelse(runif(1) &lt; prob_move, proposal, current) } tibble( step = 1:num_steps, island = island_names[island_seq], proposal = island_names[proposal_seq] ) } Question 10: Look at the code above and answer the following. What are the default populations of the islands? What is the default jump rule? Explain what each of the following bits of code are doing: other_islands &lt;- setdiff(1:num_islands, current) prob = purrr::map(other_islands, ~ J(current, .x)) the call to sample() prob_move &lt;- population[proposal] / population[current] current &lt;- ifelse(runif(1) &lt; prob_move, proposal, current) the call to tibble() 7.4.1 Jumping to any island Now let’s simulate the first 5000 nights of King Markov’s reign. Tour &lt;- KingMarkov(5000) Target &lt;- tibble(island = 1:5, prop = (1:5)/ sum(1:5)) gf_line(island ~ step, data = Tour %&gt;% filter(step &lt;= 200)) %&gt;% gf_point(proposal ~ step, data = Tour %&gt;% filter(step &lt;= 200), color = &quot;red&quot;, alpha = 0.4) %&gt;% gf_refine(scale_y_continuous(breaks = 1:10)) ## Warning: Removed 1 rows containing missing values (geom_point). gf_dhistogram( ~ island, data = Tour, binwidth = 1, color = &quot;black&quot;) %&gt;% gf_point(prop ~ island, data = Target, color = &quot;red&quot;) %&gt;% gf_refine(scale_x_continuous(breaks = 1:10)) Question 11: Look at the first plot. It shows where the king stayed each of the first 200 nights. Did the king ever stay two consecutive nights on the same island? (How can you tell from the plot?) Did the king ever stay two consecutive nights on the smallest island? (How can you answer this without looking at the plot?) 7.4.2 Jumping only to neighbor islands What if we only allow jumping to neighboring islands? (Imagine the islands are arranged in a circle and we only sail clockwise or counterclockwise around the circle to the nearest island.) neighbor &lt;- function(a, b) as.numeric(abs(a-b) %in% c(1,4)) Tour &lt;- KingMarkov(10000, population = 1:5, J = neighbor) Target &lt;- tibble(island = 1:5, prop = (1:5)/ sum(1:5)) gf_line(island ~ step, data = Tour %&gt;% filter(step &lt;= 200)) %&gt;% gf_refine(scale_y_continuous(breaks = 1:10)) gf_dhistogram( ~ island, data = Tour, binwidth = 1) %&gt;% gf_point(prop ~ island, data = Target, color = &quot;red&quot;) %&gt;% gf_refine(scale_x_continuous(breaks = 1:10)) The effect of visiting only neighbors is more dramatic with more islands. neighbor &lt;- function(a, b) as.numeric(abs(a-b) %in% c(1,9)) Tour &lt;- KingMarkov(10000, population = 1:10, J = neighbor) Target &lt;- tibble(island = 1:10, prop = (1:10)/ sum(1:10)) gf_line(island ~ step, data = Tour %&gt;% filter(step &lt;= 200)) %&gt;% gf_refine(scale_y_continuous(breaks = 1:10)) gf_dhistogram( ~ island, data = Tour, binwidth = 1) %&gt;% gf_point(prop ~ island, data = Target, color = &quot;red&quot;) %&gt;% gf_refine(scale_x_continuous(breaks = 1:10)) 7.5 Markov Chains and Posterior Sampling That was a nice story, and some nice probability theory. But what does it have to do with Bayesian computation? Regular Markov Chains (and some generalizations of them) can be used to sample from a posterior distribution: state = island = set of parameter values in typical applications, this will be an infinite state space population = prior * likelihood importantly, we do not need to normalize the posterior; that would typically be a very computationally expensive thing to do start in any island = start at any parameter values convergence may be faster from some starting states than from others, but in principle, any state will do randomly choose a proposal island = randomly select a proposal set of parameter values if the posterior is greater there, move if the posterior is smaller, move anyway with probability \\[A = \\frac{\\mbox{proposal `posterior&#39;}}{\\mbox{current `posterior&#39;}}\\] Metropolis-Hastings variation: More choices for \\(J()\\) (need not be symmetric) gives more opportunity to tune for convergence Other variations: Can allow \\(M\\) to change over the course of the algorithm. (No longer time-homogeneous.) 7.5.1 Example 1: Estimating a proportion To see how this works in practice, let’s consider our familiar model that has a Bernoulli likelihood and a beta prior: \\(Y_i \\sim {\\sf Bern}(\\theta)\\) \\(\\theta \\sim {\\sf Beta}(a, b)\\) Since we are already familiar with situation, we know that the posterior should be a beta distribution when the prior is a beta distribution. We can use this information to see how well the algorithm works in that situation. Let’s code up our Metropolis algorithm for this situation. There is a new wrinkle, however: The state space for the parameter is a continuous interval [0,1]. So we need a new kind of jump rule Instead of sampling from a finite state space, we use rnorm() The standard deviation of the normal distribution (called size in the code below) controls how large a step we take (on average). This number has nothing to do with the model, it is a tuning parameter of the algorithm. metro_bern &lt;- function( x, n, # x = successes, n = trials size = 0.01, # sd of jump distribution start = 0.5, # value of theta to start at num_steps = 1e4, # number of steps to run the algorithm prior = dunif, # function describing prior ... # additional arguments for prior ) { theta &lt;- rep(NA, num_steps) # trick to pre-alocate memory proposed_theta &lt;- rep(NA, num_steps) # trick to pre-alocate memory move &lt;- rep(NA, num_steps) # trick to pre-alocate memory theta[1] &lt;- start for (i in 1:(num_steps-1)) { # head to new &quot;island&quot; proposed_theta[i + 1] &lt;- rnorm(1, theta[i], size) if (proposed_theta[i + 1] &lt;= 0 || proposed_theta[i + 1] &gt;= 1) { prob_move &lt;- 0 # because prior is 0 } else { current_prior &lt;- prior(theta[i], ...) current_likelihood &lt;- dbinom(x, n, theta[i]) current_posterior &lt;- current_prior * current_likelihood proposed_prior &lt;- prior(proposed_theta[i+1], ...) proposed_likelihood &lt;- dbinom(x, n, proposed_theta[i+1]) proposed_posterior &lt;- proposed_prior * proposed_likelihood prob_move &lt;- proposed_posterior / current_posterior } # sometimes we &quot;sail back&quot; if (runif(1) &gt; prob_move) { # sail back move[i + 1] &lt;- FALSE theta[i + 1] &lt;- theta[i] } else { # stay move[i + 1] &lt;- TRUE theta[i + 1] &lt;- proposed_theta[i + 1] } } tibble( step = 1:num_steps, theta = theta, proposed_theta = proposed_theta, move = move, size = size ) } Question 12: What happens if the proposed value for \\(\\theta\\) is not in the interval \\([0,1]\\)? Why? Question 13: What do proposed_posterior and current_posterior correspond to in the story of King Markov? Question 14: Notice that we are using the unnormalized posterior. Why don’t we need to normalize the posterior? Why is it important that we don’t have to normalize the posterior? 7.5.1.1 Looking at posterior samples The purpose of all this was to get samples from the posterior distribution. We can use histograms or density plots to see what our MCMC algorithm shows us for the posterior distribution. When using MCMC algorithms, we won’t typically have ways of knowing the “right answer”. But in this case, we know the posterior is Beta(6, 11), so we can compare our posterior samples to that distribution to see how well things worked. Let’s try a nice small step size like 0.2%. set.seed(341) Tour &lt;- metro_bern(5, 15, size = 0.002) gf_dhistogram(~ theta, data = Tour, bins = 100) %&gt;% gf_dens(~ theta, data = Tour) %&gt;% gf_dist(&quot;beta&quot;, shape1 = 6, shape2 = 11, color = &quot;red&quot;) Hmm. That’s not too good. Let’s see if we can figure out why. 7.5.1.2 Trace Plots A trace plot shows the “tour of King Markov’s ship” – the sequence of parameter values sampled (in order). gf_line(theta ~ step, data = Tour) %&gt;% gf_hline(yintercept = 5/15, color = &quot;red&quot;) Question 15: Why does the trace plot begin at a height of 0.5? Question 16: What features of this trace plot indicate that our posterior sampling isn’t working well? Would making the step size larger or smaller be more likely to help? Question 17: Since we know that the posterior distribution is Beta(6, 11), how could we use R to show us what an ideal trace plot would look like? 7.5.1.3 Comparing step sizes Let’s see how our choice of step affects the sampling. Size 0 is sampling from a true Beta(6, 11) distribution. set.seed(341) Tours &lt;- bind_rows( metro_bern(5, 15, size = 0.02), metro_bern(5, 15, size = 0.2), metro_bern(5, 15, size = 0.002), tibble(theta = rbeta(1e4, 6, 11), size = 0, step = 1:1e4) ) gf_dhistogram( ~ theta | size ~ ., data = Tours, bins = 100) %&gt;% gf_dist(&quot;beta&quot;, shape1 = 6, shape2 = 11, color = &quot;red&quot;) Sizes 0.2 and 0.02 look much better than 0.002. Looking at the trace plots, we see that the samples using a step size of 0.02 are still highly auto-correlated (neighboring values are similar to each other). Thus the “effective sample size” is not nearly as big as the number of posterior samples we have generated. With a step size of 0.2, the amount of auto-correlation is substantially reduced, but not eliminated. gf_line(theta ~ step, data = Tours) %&gt;% gf_hline(yintercept = 5/14, color = &quot;red&quot;) %&gt;% gf_facet_grid(size ~ .) %&gt;% gf_lims(x = c(0,1000)) ## Warning: Removed 9000 rows containing missing values (geom_path). 7.5.1.4 Auto-correlation and Thinning One way to reduce the auto-correlation in posterior samples is by thinning. This auto-correlation plot suggests that keeping every 7th or 8th value when size is 0.2 should give us a posterior sample that is nearly independent. acf(Tours %&gt;% filter(size == 0.2) %&gt;% pull(theta)) gf_line(theta ~ step, data = Tours %&gt;% filter(step %% 8 == 0)) %&gt;% gf_hline(yintercept = 5/14, color = &quot;red&quot;) %&gt;% gf_facet_grid(size ~ .) %&gt;% gf_lims(x = c(0,1000)) ## Warning: Removed 1125 rows containing missing values (geom_path). Now the idealized trace plot and the trace plot for step = 0.2 are quite similar looking. So the effective sample size for that step size is approximately 1/8 the number of posterior samples generated. For step=0.02 we must thin even more, which would require generating many more posterior samples to begin with: ACF &lt;- broom::tidy(acf(Tours %&gt;% filter(size == 0.02, step &gt; 1000) %&gt;% pull(theta), plot = FALSE, lag.max = 50)) gf_col(acf ~ lag, data = ACF, width = 0.2) 7.5.2 Example 2: Estimating mean and variance Consider the following simple model: \\(Y_i \\sim {\\sf Norm}(\\mu, \\sigma)\\) \\(\\mu \\sim {\\sf Norm}(0, 1)\\) \\(\\log(\\sigma) \\sim {\\sf Norm}(0,1)\\) In this case the posterior distribution for \\(\\mu\\) can be worked out exactly and should be normal. Let’s code up our Metropolis algorithm for this situation. New stuff: we have two parameters, so we’ll use separate jumps for each and combine we could use a jump rule based on both values together, but we’ll keep this simple the state space for each parameter is infinite, so we need a new kind of jump rule instead of sampling from a finite state space, we use rnorm() the standard deviation controls how large a step we take (on average) example below uses same standard deviation for both parameters, but we should select them individually if the parameters are on different scales metro_norm &lt;- function( y, # data vector num_steps = 1e5, size = 1, # sd&#39;s of jump distributions start = list(mu = 0, log_sigma = 0) ) { size &lt;- rep(size, 2)[1:2] # make sure exactly two values mu &lt;- rep(NA, num_steps) # trick to pre-alocate memory log_sigma &lt;- rep(NA, num_steps) # trick to pre-alocate memory move &lt;- rep(NA, num_steps) # trick to pre-alocate memory mu[1] &lt;- start$mu log_sigma[1] &lt;- start$log_sigma move[1] &lt;- TRUE for (i in 1:(num_steps - 1)) { # head to new &quot;island&quot; mu[i + 1] &lt;- rnorm(1, mu[i], size[1]) log_sigma[i + 1] &lt;- rnorm(1, log_sigma[i], size[2]) move[i + 1] &lt;- TRUE log_post_current &lt;- dnorm(mu[i], 0, 1, log = TRUE) + dnorm(log_sigma[i], 0, 1, log = TRUE) + sum(dnorm(y, mu[i], exp(log_sigma[i]), log = TRUE)) log_post_proposal &lt;- dnorm(mu[i + 1], 0, 1, log = TRUE) + dnorm(log_sigma[i + 1], 0, 1, log = TRUE) + sum(dnorm(y, mu[i + 1], exp(log_sigma[i+1]), log = TRUE)) prob_move &lt;- exp(log_post_proposal - log_post_current) # sometimes we &quot;sail back&quot; if (runif(1) &gt; prob_move) { move[i + 1] &lt;- FALSE mu[i + 1] &lt;- mu[i] log_sigma[i + 1] &lt;- log_sigma[i] } } tibble( step = 1:num_steps, mu = mu, log_sigma = log_sigma, move = move, size = paste(size, collapse = &quot;, &quot;) ) } Let’s use the algorithm with three different size values and compare results. set.seed(341) y &lt;- rnorm(25, 1, 2) # sample of 25 from Norm(1, 2) Tour1 &lt;- metro_norm(y = y, num_steps = 5000, size = 1) Tour0.1 &lt;- metro_norm(y = y, num_steps = 5000, size = 0.1) Tour0.01 &lt;- metro_norm(y = y, num_steps = 5000, size = 0.01) Norm_Tours &lt;- bind_rows(Tour1, Tour0.1, Tour0.01) df_stats(~ move | size, data = Norm_Tours, props) size prop_FALSE prop_TRUE 0.01, 0.01 0.0422 0.9578 0.1, 0.1 0.2380 0.7620 1, 1 0.9134 0.0866 7.5.2.1 Density plots gf_dhistogram( ~ mu | size ~ ., data = Norm_Tours, bins = 100) gf_dhistogram( ~ exp(log_sigma) | size ~ ., data = Norm_Tours, bins = 100) 7.5.2.2 Trace plots gf_line(mu ~ step | size ~ ., data = Norm_Tours) gf_line(log_sigma ~ step | size ~ ., data = Norm_Tours) 7.5.2.3 Comparing Multiple Chains If we run multiple chains with different starting points and different random choices, we hope to see similar trace plots. After all, we don’t want our analysis to be an analysis of starting points or of random choices. Tour1a &lt;- metro_norm(y = y, num_steps = 5000, size = 1) %&gt;% mutate(chain = &quot;A&quot;) Tour1b &lt;- metro_norm(y = y, num_steps = 5000, size = 1) %&gt;% mutate(chain = &quot;B&quot;) Tour1c &lt;- metro_norm(y = y, num_steps = 5000, size = 1, start = list(mu = 10, log_sigma = 5)) %&gt;% mutate(chain = &quot;C&quot;) Tour1d &lt;- metro_norm(y = y, num_steps = 5000, size = 1, start = list(mu = 10, log_sigma = 5)) %&gt;% mutate(chain = &quot;D&quot;) Tours1 &lt;- bind_rows(Tour1a, Tour1b, Tour1c, Tour1d) gf_line(mu ~ step, color = ~chain, alpha = 0.5, data = Tours1) gf_line(mu ~ step, color = ~chain, alpha = 0.5, data = Tours1) %&gt;% gf_facet_grid( chain ~ .) 7.5.2.4 Comparing Chains to an Ideal Chain Not all posteriors are normal, but here’s what a chain would look like if the posterior is normal and there is no correlation between draws. Ideal &lt;- tibble(step = 1:5000, mu = rnorm(5000, 1, .3), size = &quot;ideal&quot;) gf_line(mu ~ step | size, data = Norm_Tours %&gt;% bind_rows(Ideal)) If the draws are correlated, then we might get more ideal behavior if we selected only a subset – every 20th or every 30th value, for example. This is the idea behind “effective sample size”. The effective sample size of a correlated chain is the length of an ideal chain that contains as much independent information as the correlated chain. acf(Norm_Tours %&gt;% filter(size == &quot;1, 1&quot;) %&gt;% pull(mu)) gf_line(mu ~ step | size ~ ., data = bind_rows(Norm_Tours, Ideal) %&gt;% filter(step %% 20 == 0)) %&gt;% gf_labs(title = &quot;Every 20th draw&quot;) gf_line(mu ~ step | size ~ ., data = bind_rows(Norm_Tours, Ideal) %&gt;% filter(step %% 30 == 0)) %&gt;% gf_labs(title = &quot;Every 30th draw&quot;) If we thin to every 20th value, our chains with size = 1 and size = 0.1 look quite similar to the ideal chain. The chain with size = 0.01 still moves too slowly through the parameter space. So tuning parameters will affect the effective sample size. 7.5.2.5 Discarding the first portion of a chain The first portion of a chain may not work as well. This portion is typically removed from the analysis since it is more an indication of the starting values used than the long-run sampling from the posterior. gf_line(log_sigma ~ step | size ~ ., data = Norm_Tours) gf_path(log_sigma ~ mu | size ~ (step &gt; 500), data = Norm_Tours, alpha = 0.5) %&gt;% gf_density2d(log_sigma ~ mu, data = Norm_Tours) gf_histogram( ~ mu | size ~ (step &gt; 500) , data = Norm_Tours, binwidth = 0.1) gf_histogram( ~ log_sigma | size ~ (step &gt; 500), data = Norm_Tours, binwidth = 0.1) 7.5.3 Issues with Metropolis Algorithm These are really issues with all MCMC algorithms, not just the Metropolis version: First portion of a chain might not be very good, need to discard it Tuning can affect performance – how do we tune? Samples are correlated – although the long-run probabilities are right, the next stop is not independent of the current one so our effective posterior sample size isn’t as big as it appears 7.6 Two coins 7.6.1 The model Suppose we have two coins and want to compare the proportion of heads each coin generates. Parameters: \\(\\theta_1\\), \\(\\theta_2\\) Data: \\(N_1\\) flips of coin 1 and \\(N_2\\) flips of coin 2. (Results: \\(z_1\\) and \\(z_2\\) heads, respectivly.) Likelihood: indepdendent Bernoulli (each flip independent of the other flips, each coin independent of the other coin) Prior: Independent Beta distributions for each \\(\\theta_i\\) That is, \\(y_{1i} \\sim {\\sf Bern}(\\theta_1), y_{2i} \\sim {\\sf Bern}(\\theta_2)\\) \\(\\theta_1 \\sim {\\sf Beta(a_1, b_1)}, \\theta_2 \\sim {\\sf Beta(a_2, b_2)}\\) (independent) For the examples below we will use data showing that 6 of 8 tosses of the first coin were heads and only 2 of 7 tosses of the second coin. But the methods work equally well with other data sets. While comparing a small number of coin tosses like this is not so interesting, the method can be used for a wide range of practical things, liking testing whether two treatments for a condition are equally effective, etc. 7.6.2 Exact analysis From this we can work out the posterior as usual. (Pay attention to the important parts of the kernel, that is, the numerators.) \\[\\begin{align*} p(\\theta_1, \\theta_2 \\mid D) &amp;= p(D \\mid \\theta_1, \\theta_2) p(\\theta_1, \\theta_2) / p(D) \\\\[3mm] &amp;= \\theta_1^{z_1} (1 − \\theta_1)^{N_1−z_1} \\theta_1^{z_2} (1 − \\theta_2)^{N_2−z_2} p(\\theta_1, \\theta_2) / p(D) \\\\[3mm] &amp;= \\frac{ \\theta_1^{z_1} (1 − \\theta_1)^{N_1 − z_1} \\theta_1^{z_2} (1 − \\theta_2)^{N_2 − z_2} \\theta_1^{a_1−1}(1 − \\theta_1)^{b_1 - 1} \\theta_2^{a_2−1}(1 − \\theta_2)^{b_2 - 1}} {p(D)B(a_1, b_1)B(a_2, b_2)} \\\\[3mm] &amp;= \\frac{ \\theta_1^{z_1 + a_1 − 1}(1 − \\theta_1)^{N_1 − z_1 + b_1 − 1} \\theta_2^{z_2 + a_2 − 1}(1 − \\theta_2)^{N_2 − z_2 + b_2 − 1} }{p(D)B(a_1, b_1)B(a_2, b_2)} \\end{align*}\\] So the posterior distribution of \\(\\langle \\theta_1, \\theta_2 \\rangle\\) is two independent Beta distributions: \\({\\sf Beta}(z_1 + a, N_1 - z_1 + b_1)\\) and \\({\\sf Beta}(z_2 + a, N_2 - z_2 + b_2)\\). Some nice images of these distributions appear on page 167. 7.6.3 Metropolis metro_2coins &lt;- function( z1, n1, # z = successes, n = trials z2, n2, # z = successes, n = trials size = c(0.1, 0.1), # sds of jump distribution start = c(0.5, 0.5), # value of thetas to start at num_steps = 5e4, # number of steps to run the algorithm prior1 = dbeta, # function describing prior prior2 = dbeta, # function describing prior args1 = list(), # additional args for prior1 args2 = list() # additional args for prior2 ) { theta1 &lt;- rep(NA, num_steps) # trick to pre-alocate memory theta2 &lt;- rep(NA, num_steps) # trick to pre-alocate memory proposed_theta1 &lt;- rep(NA, num_steps) # trick to pre-alocate memory proposed_theta2 &lt;- rep(NA, num_steps) # trick to pre-alocate memory move &lt;- rep(NA, num_steps) # trick to pre-alocate memory theta1[1] &lt;- start[1] theta2[1] &lt;- start[2] size1 &lt;- size[1] size2 &lt;- size[2] for (i in 1:(num_steps-1)) { # head to new &quot;island&quot; proposed_theta1[i + 1] &lt;- rnorm(1, theta1[i], size1) proposed_theta2[i + 1] &lt;- rnorm(1, theta2[i], size2) if (proposed_theta1[i + 1] &lt;= 0 || proposed_theta1[i + 1] &gt;= 1 || proposed_theta2[i + 1] &lt;= 0 || proposed_theta2[i + 1] &gt;= 1) { proposed_posterior &lt;- 0 # because prior is 0 } else { current_prior &lt;- do.call(prior1, c(list(theta1[i]), args1)) * do.call(prior2, c(list(theta2[i]), args2)) current_likelihood &lt;- dbinom(z1, n1, theta1[i]) * dbinom(z2, n2, theta2[i]) current_posterior &lt;- current_prior * current_likelihood proposed_prior &lt;- do.call(prior1, c(list(proposed_theta1[i+1]), args1)) * do.call(prior2, c(list(proposed_theta2[i+1]), args2)) proposed_likelihood &lt;- dbinom(z1, n1, proposed_theta1[i+1]) * dbinom(z2, n2, proposed_theta2[i+1]) proposed_posterior &lt;- proposed_prior * proposed_likelihood } prob_move &lt;- proposed_posterior / current_posterior # sometimes we &quot;sail back&quot; if (runif(1) &gt; prob_move) { # sail back move[i + 1] &lt;- FALSE theta1[i + 1] &lt;- theta1[i] theta2[i + 1] &lt;- theta2[i] } else { # stay move[i + 1] &lt;- TRUE theta1[i + 1] &lt;- proposed_theta1[i + 1] theta2[i + 1] &lt;- proposed_theta2[i + 1] } } tibble( step = 1:num_steps, theta1 = theta1, theta2 = theta2, proposed_theta1 = proposed_theta1, proposed_theta2 = proposed_theta2, move = move, size1 = size1, size2 = size2 ) } Metro_2coinsA &lt;- metro_2coins( z1 = 6, n1 = 8, z2 = 2, n2 = 7, size = c(0.02, 0.02), args1 = list(shape1 = 2, shape2 = 2), args2 = list(shape1 = 2, shape2 = 2) ) Metro_2coinsA %&gt;% gf_density2d(theta2 ~ theta1) Metro_2coinsA %&gt;% gf_density(~ (theta2 - theta1)) # effective sample size is much smaller than apparent sample size due to auto-correlation acf(Metro_2coinsA$theta2 - Metro_2coinsA$theta1) Metro_2coinsA %&gt;% filter(step &lt; 500) %&gt;% gf_path(theta2 ~ theta1, color = ~ step, alpha = 0.5) %&gt;% gf_point(theta2 ~ theta1, color = ~ step, alpha = 0.5) Metro_2coinsB &lt;- metro_2coins( z1 = 6, n1 = 8, z2 = 2, n2 = 7, size = c(0.2, 0.2), args1 = list(shape1 = 2, shape2 = 2), args2 = list(shape1 = 2, shape2 = 2) ) Metro_2coinsB %&gt;% gf_density2d(theta2 ~ theta1) Metro_2coinsB %&gt;% gf_density(~ (theta2 - theta1)) # effective sample size is better but still quite a bit # smaller than apparent sample size due to auto-correlation acf(Metro_2coinsB$theta2 - Metro_2coinsB$theta1) Metro_2coinsB %&gt;% filter(step &lt; 500) %&gt;% gf_path(theta2 ~ theta1, color = ~ step, alpha = 0.5) %&gt;% gf_point(theta2 ~ theta1, color = ~ step, alpha = 0.5) 7.6.4 Gibbs sampling Gibbs sampling provides an attempt to improve on the efficiency of the standard Metropolis algorithm by using a different method to propose new parameter values. The idea is this: Pick one of the parameter values: \\(\\theta_i\\) Determine the posterior distribution of \\(\\theta_i\\) using current estimates of the other parameters \\(\\{\\theta_j \\mid j \\neq i\\}\\) This won’t be exactly right, because those estimates are not exactly right, but it should be good when the parameters estimates are close to correct. Sample from the posterior distribution for \\(\\theta_i\\) to get a new proposed value for \\(\\theta_i\\). Always accept this proposal, since it is being sampled from a distribution that already makes more likely values more likely to be proposed. Keep cycling through all the parameters, each time updating one using the current estimates for the others. It takes some work to show that this also converges, and in practice it is often more efficient than the basic Metropolis algorithm. But it is limited to situations where the marginal posterior can be be sampled from. In our example, we can work out the marginal posterior fairly easily: \\[\\begin{align*} p(\\theta_1|\\theta_2, D) &amp;= p(\\theta_1, \\theta_2|D)/p(\\theta_2|D) \\\\ &amp;= p(\\theta_1, \\theta_2|D) \\int d\\theta_1 p(\\theta_1, \\theta_2|D) \\\\ &amp;= \\frac{\\mathrm{dbeta}(\\theta_1, z_1 + a_1, N_1 −z_1 + b_1) \\cdot \\mathrm{dbeta}(\\theta_2, z_2 + a_2, N_2 −z_2 + b_2)} {\\int d\\theta_1 \\mathrm{dbeta}(\\theta_1, z_1 + a_1, N_1 −z_1 +b_1) \\cdot \\mathrm{dbeta}(\\theta_2 \\mid z_2 +a_2, N_2 −z_2 +b_2)} \\\\ &amp;= \\frac{\\mathrm{dbeta}(\\theta_1, z_1 + a_1, N_1 − z_1 + b_1) \\cdot \\mathrm{dbeta}(\\theta_2, z_2 + a_2, N_2 − z_2 + b_2)} {\\mathrm{dbeta}(\\theta_2 \\mid z_2 + a_2, N_2 −z_2 +b_2) \\int d\\theta_1 \\mathrm{dbeta}(\\theta_1, z_1 + a_1, N_1 − z_1 + b_1)} \\\\ &amp;= \\frac{\\mathrm{dbeta}(\\theta_1, z_1 + a_1, N_1 − z_1 + b_1)} {\\int d\\theta_1 \\mathrm{dbeta}(\\theta_1, z_1 + a_1, N_1 − z_1 + b_1)} \\\\ &amp;= \\mathrm{dbeta}(\\theta_1, z_1 + a_1, N_1 − z_1 + b_1) \\end{align*}\\] In other words, \\(p(\\theta_1 \\mid \\theta_2, D) = p(\\theta_1, D)\\), which isn’t surprising since we already know that the posterior distributions \\(\\theta_1\\) and \\(\\theta_2\\) are independent. (In more complicated models, the marginal posterior may depend on all of the parameters, so the calculation above might not be so simple.) Of course, the analogous statement holds for \\(\\theta_2\\) in this model. This examples shows off Gibbs sampling in a situation where it shines: when the posterior distribution is a collection of independent marginals. gibbs_2coins &lt;- function( z1, n1, # z = successes, n = trials z2, n2, # z = successes, n = trials start = c(0.5, 0.5), # value of thetas to start at num_steps = 1e4, # number of steps to run the algorithm a1, b1, # params for prior for theta1 a2, b2 # params for prior for theta2 ) { theta1 &lt;- rep(NA, num_steps) # trick to pre-alocate memory theta2 &lt;- rep(NA, num_steps) # trick to pre-alocate memory theta1[1] &lt;- start[1] theta2[1] &lt;- start[2] for (i in 1:(num_steps-1)) { if (i %% 2 == 1) { # update theta1 theta1[i+1] &lt;- rbeta(1, z1 + a1, n1 - z1 + b1) theta2[i+1] &lt;- theta2[i] } else { # update theta2 theta1[i+1] &lt;- theta1[i] theta2[i+1] &lt;- rbeta(1, z2 + a2, n2 - z2 + b2) } } tibble( step = 1:num_steps, theta1 = theta1, theta2 = theta2, ) } Gibbs &lt;- gibbs_2coins(z1 = 6, n1 = 8, z2 = 2, n2 = 7, a1 = 2, b1 = 2, a2 = 2, b2 = 2) Gibbs %&gt;% gf_density2d(theta2 ~ theta1) Gibbs %&gt;% gf_dens( ~ theta1) acf(Gibbs$theta1) Gibbs %&gt;% filter(step &lt; 500) %&gt;% gf_path(theta2 ~ theta1, color = ~ step, alpha = 0.5) %&gt;% gf_point(theta2 ~ theta1, color = ~ step, alpha = 0.5) Note: Software like JAGS only records results each time it makes a complete cycle through the parameters. We could do that by keeping every other row: Gibbs %&gt;% filter(step %% 2 == 0) %&gt;% gf_density2d(theta2 ~ theta1) Gibbs %&gt;% filter(step %% 2 == 0) %&gt;% gf_density( ~ (theta2 - theta1)) Gibbs %&gt;% filter(step %% 2 == 0) %&gt;% mutate(difference = theta2 - theta1) %&gt;% pull(difference) %&gt;% acf() Gibbs %&gt;% filter(step &lt; 500, step %% 2 == 0) %&gt;% gf_path(theta2 ~ theta1, color = ~ step, alpha = 0.5) %&gt;% gf_point(theta2 ~ theta1, color = ~ step, alpha = 0.5) 7.6.5 Advantages and Disadvantages of Gibbs vs Metropolis Advantages No need to tune. The preformance of the Metropolis algorithm depends on the jump rule used. Gibbs “auto-tunes” by using the marginal posteriors. Gibbs sampling has the potential to sample much more efficiently than Metropolis. It doesn’t propose updates only to reject them, and doesn’t suffer from poor tuning that can make Metropolis search very slowly through the posterior space. Disadvantages Less general: We need to be able to sample from the marginal posterior. Gibbs sampling can be slow if the posterior has highly correlated parameters since given all but one of them, the algorithm with be very certain about the remaining one and adjust it only a very small amount. It is hard for Gibbs samplers to quickly move along “diagonal ridges” in the posterior. The good news is that other people have done the hard work of coding up Gibbs sampling for us, we just need to learn how to describe the model in a way that works with their code. We will be using JAGS (just another Gibbs Sampler) and later Stan (which generalizes the metropolis algorithm in a different way) to fit more interesting models that would be too time consuming to custom code on our own. The examples in the chapter are to help us understand better how these algorithms work so we can interpret the results we obtian when using them. 7.6.6 So what do we learn about the coins? We have seen that we can fit this model a number of different ways now, but we haven’t actually looked at the results. Are the coins different? How much different? Since the Gibbs sampler is more efficient than the Metropolis algorithm for this situation, we’ll use the posterior samples from the Gibbs sampler to answer. We are interested in \\(\\theta_2 - \\theta_1\\), the difference in the biases of the two coins. To learn about that, we simply investigate the distribution of that quantity in our posterior samples. (Note: You cannot learn about this difference by only considering \\(\\theta_1\\) and \\(\\theta_2\\) sepearately.) gf_dhistogram(~(theta2 - theta1), data = Gibbs) %&gt;% gf_dens() hdi(Gibbs %&gt;% mutate(difference = theta2 - theta1), pars = &quot;difference&quot;) par lo hi prob difference -0.6623 0.057 0.95 mosaic::prop(~(theta2 - theta1 &gt; 0), data = Gibbs) ## prop_TRUE ## 0.0601 We don’t have much data, so the posterior distribution of the difference in biases is pretty wide. 0 is within the 95% HDI for \\(\\theta_2 - \\theta_1\\), so we don’t have compelling evidence that the two biases are different based on this small data set. 7.7 MCMC posterior sampling: Big picture 7.7.1 MCMC = Markov chain Monte Carlo Markov chain because the process is a Markov process with probabilities of transitioning from one state to another Monte Carlo because it inovles randomness. (Monte Carlo is a famous casino location.) We will refer to one random walk starting from a pariticular starting value as a chain. 7.7.2 Posterior sampling: Random walk through the posterior Our goal, whether we use Metropolis, Gibbs sampling, Stan, or some other MCMC posterior samping method, is to generate random values from the posterior distribution. Ideally these samples should be representative of the posterior and not of other artifacts like the starting location of the chain, or tuning parameters used to generate the walk. accurate to the posterior. If we run the algorithm multiple times, we would like the results to be similar from run to run. (They won’t match exactly, but if they are all giving good approximations to the same thing, then they should all close to each other.) efficient. The theory says that all of these methods converge to the correct posterior distribution, but in practice, we can only do a finite run. If the sampling is not efficient enough, our finite run might give us a distorted picture (that would eventually have been corrected had we run things long enough). If we are convinced that the posterior sampling is of high enough quality, we can use the posterior samples to answer all sorts of questions relatively easily. 7.7.3 Where do we go from here? Learn to design more interesting models to answer more interesting questions. Learn to describe these models and hand them to JAGS or Stan for posterior sampling. Learn to diagnose posterior samples to detect potential problems with the posterior sampling. Learn how to interpret the results. 7.8 Exercises In this exercise, you will see how the Metropolis algorithm operates with a multimodal prior. Define the function \\(p(\\theta) = (cos(4 \\pi \\theta) + 1)^2/1.5\\) in R. Use gf_function() to plot \\(p(\\theta)\\) on the interval from 0 to 1. [Hint: Use the xlim argument.] Use integrate() to confirm that \\(p\\) is a pdf. Run metro_bern() with \\(p\\) as your prior, with no data (x = 0, n = 0), and with size = 0.2. Plot the posterior distribution of \\(\\theta\\) and explain why it looks the way it does. Now create a posterior histogram or density plot using x = 2, n = 3. Do the results look reasonable? Explain. Now create a posterior histogram or density plot with x = 1, n = 3, and size = 0.02. Comment on how this compares to plot you made in the previous item. Repeat the previous two items but with start = 0.15 and start = 0.95. How does this help explain what is happening? Why is it good practice to run MCMC algorithms with several different starting values as part of the diagnositc process? How would looking at trace plots from multiple starting points help you detect this problem? (What would the trace plots look like when things are good? What would they look like when things are bad?) "],
["jags-just-another-gibbs-sampler.html", "8 JAGS – Just Another Gibbs Sampler 8.1 What JAGS is 8.2 Example 1: estimating a proportion 8.3 Extracting information from a JAGS run 8.4 Optional arguments to jags() 8.5 Example 2: comparing two proportions 8.6 Exercises", " 8 JAGS – Just Another Gibbs Sampler This chapter focuses on a very simple model – one for which JAGS is overkill. This allows us to get familiar with JAGS and the various tools to investigate JAGS models in a simple setting before moving on to more interesting models soon. 8.1 What JAGS is JAGS (Just Another Gibbs Sampler) is an implementation of an MCMC algorithm called Gibbs sampling to sample the posterior distribution of a Bayesian model. We will interact with JAGS from within R using the following packages: R2jags – interface between R and JAGS coda – general tools for analyzing and graphing MCMC algorithms bayesplot – a number of useful plots using ggplot2 CalvinBayes – includes some of the functions from Kruschke’s text and other things to make our lives better. 8.1.1 JAGS documentation You can find JAGS documentation at http://people.stat.sc.edu/hansont/stat740/jags_user_manual.pdf. This can be useful if you need to find out particulars about things like the distributions that are availble in JAGS. 8.1.2 Updating C and CLANG Based on limited testing, it appears that things are good to go and you should not need to do this. To use the newest versions of JAGS, Stan, and the R packages that accompany them, we need to use a newer version of some software than is standard for &lt;rstudio.calvin.edu&gt;. I have taken care of this at the system level, and that may suffice, but if things don’t work in your account, take the following steps: Open a terminal with Tools &gt; Terminal &gt; New Terminal Copy-and-paste this into the terminal window. echo &quot;source scl_source enable devtoolset-7 llvm-toolset-7&quot; &gt;&gt; ~/.bashrc This tells the server to use a newer version of C++ and CLANG. Close the terminal Restart R with Session &gt; Restart R You should only need to go through these steps once. 8.2 Example 1: estimating a proportion 8.2.1 The Model That is \\[\\begin{align*} Y_i &amp;\\sim {\\sf Bern}(\\theta) \\\\ \\theta &amp;\\sim {\\sf Beta}(a, b) \\end{align*}\\] 8.2.2 Load Data The data sets provided as csv files by Kruschke also live in the CalvinBayes package, so you can read this file with library(CalvinBayes) data(&quot;z15N50&quot;) glimpse(z15N50) ## Observations: 50 ## Variables: 1 ## $ y &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,… We see that the data are coded as 50 0’s and 1’s in a variable named y. (You should use better names when creating your own data sets.) 8.2.3 Specify the model There are at least three R packages that provide an interface to JAGS: rjags, R2jags, and runjags. We will primarily use R2jags. Kruschke primarily uses rjags. The main advantage of R2jags is that we can specify the model by creating a special kind of function. 5 The avoids the need to create temporary files (as rjags requires) and keeps things tidier in our R markdown documents. The main part of the model description is the same in either style, but notice that the using the function style, we do not need to include model{ ... } in our description. Here’s how we describe our simple model. bern_model &lt;- function() { for (i in 1:N) { y[i] ~ dbern(theta) # each response is Bernoulli with fixed parameter theta } theta ~ dbeta(1, 1) # prior for theta } Some things to note: dbern() and dbeta() are JAGS functions. The JAGS distribution functions are similar to, but not identical to the ones in R. (R doesn’t have Bernoulli at all, for example.) Sometimes the parameterization are different. Importantly, JAGS doesn’t have named arguments, so the arguments must go in the order JAGS requires. Notice that we are only giving the distribution name and its parameters. (So the first argument that R requires is not part of this in JAGS.) JAGS is also not vectorized the way R is, so we will need to write some explicit for loops to say “do this to every that”. In the example above, the for loops says that for each row of the data (i in 1:N), the response (y[i]) is Bernoulli with paramter \\(\\theta\\) (dbern(theta)). 8.2.4 Run the model R2jags::jags() can be used to run our JAGS model. We need to specify three things: (1) the model we are using (as defined above), (2) the data we are using, (3) the parameters we want saved in the posterior sampling. (theta is the only parameter in this model, but in larger models, we might choose to save only some of the parameters). The data do not need to be in a data frame, and this usually means a bit more work on our part to tell JAGS things like how much data there is. We will prepare all the information JAGS needs about the data in a list using list(). There are some additional, optional things we might want to control as well. More on those later. For now, let’s fit the model using the default values for everything else. # Load the R2jags package library(R2jags) # Make the same &quot;random&quot; choices each time this is run. # This makes the Rmd file stable so you can comment on specific results. set.seed(123) # Fit the model bern_jags &lt;- jags( data = list(y = z15N50$y, N = nrow(z15N50)), model.file = bern_model, parameters.to.save = c(&quot;theta&quot;) ) ## module glm loaded ## Compiling model graph ## Resolving undeclared variables ## Allocating nodes ## Graph information: ## Observed stochastic nodes: 50 ## Unobserved stochastic nodes: 1 ## Total graph size: 53 ## ## Initializing model Let’s take a quick look at what we have. bern_jags ## Inference for Bugs model at &quot;/var/folders/py/txwd26jx5rq83f4nn0f5fmmm0000gn/T//Rtmpq7YteV/model42644f8a2df6.txt&quot;, fit using jags, ## 3 chains, each with 2000 iterations (first 1000 discarded) ## n.sims = 3000 iterations saved ## mu.vect sd.vect 2.5% 25% 50% 75% 97.5% Rhat n.eff ## theta 0.308 0.064 0.191 0.261 0.306 0.351 0.435 1.001 3000 ## deviance 62.089 1.395 61.087 61.186 61.571 62.459 65.770 1.001 3000 ## ## For each parameter, n.eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor (at convergence, Rhat=1). ## ## DIC info (using the rule, pD = var(deviance)/2) ## pD = 1.0 and DIC = 63.1 ## DIC is an estimate of expected predictive error (lower deviance is better). Some notes on the output above: 3 chains: The Gibbs sampler was run 3 times with 3 different starting values. Each chain ran for 2000 steps, but only the last 1000 steps were saved. n.sims = 3000 (1000 in each of 3 chains). mu.vect: We see that the average value of theta in our posterior sample is 0.308. n.eff = 3000 is the number of effective samples. In this case, JAGS is being very efficient, as we would expect since it is just sampling directly from the posterior distribution. Rhat = 1: This is a check for possible convergence problems. If an MCMC sampler has converged, Rhat will be 1. So if the value we see is not very close to 1, that is a sign of problems. Any value greater than 1.1 is a cause for concern. We’ll talk more about deviance later. 8.3 Extracting information from a JAGS run 8.3.1 posterior() We can plot the posterior distribution, using posterior() to extract the posterior samples as a data frame. Since we know the posterior distribution should be Beta(16, 36), we’ll add that to our plot as a reference to see how well our posterior sample is doing. library(CalvinBayes) head(posterior(bern_jags)) deviance theta 61.85 0.2455 61.13 0.3129 61.13 0.2860 61.13 0.3133 61.83 0.3577 62.85 0.2193 gf_dhistogram(~theta, data = posterior(bern_jags), bins = 50) %&gt;% gf_dens(~theta, size = 1.5, alpha = 0.8) %&gt;% gf_dist(&quot;beta&quot;, shape1 = 16, shape2 = 36, color = &quot;red&quot;) 8.3.2 Side note: posterior sampling and the grid method It is also possible to generate posterior samples when we use the grid method. The mosaic package include the resample() function that will sample rows of a data frame with replacement using specified probabilities (given by the posterior, for example). Here’s how that works. Grid &lt;- expand.grid( theta = seq(0, 1, by = 0.001) ) %&gt;% mutate( prior = dbeta(theta, 1, 1), likelihood = dbinom(15, 50, theta), posterior = prior * likelihood, posterior = posterior / sum(posterior) / 0.001 ) Posterior &lt;- resample(Grid, size = 5000, prob = Grid$posterior) gf_dhistogram(~ theta, data = Posterior, bins = 50) %&gt;% gf_dens(~theta, size = 1.5, alpha = 0.8) %&gt;% gf_dist(&quot;beta&quot;, shape1 = 16, shape2 = 36, color = &quot;red&quot;) 8.3.3 Using coda The coda package provides output analysis and diagnostics for MCMC algorithms. In order to use it, we must convert our JAGS object into something coda recognizes. We do with with the as.mcmc() function. bern_mcmc &lt;- as.mcmc(bern_jags) plot(bern_mcmc) Note: Kruschke uses rjags without R2jags, so he does this step using rjags::coda.samples() instead of as.mcmc(). Both functions result in the same thing – posterior samples in a format that coda expects, but they have different starting points. 8.3.4 Using bayesplot The mcmc object we extracted with as.mcmc() can be used by the utilities in the bayesplot(). Here, for example is the bayesplot plot of the posterior distribution for theta. By default, a vertical line segment is drawn at the median of the posterior distribution. library(bayesplot) mcmc_areas( bern_mcmc, pars = c(&quot;theta&quot;), # make a plot for the theta parameter prob = 0.90) # shade the central 90% One advantage of bayesplot is that the plots use the ggplot2 system and so interoperate well with ggformula. mcmc_trace(bern_mcmc, pars = &quot;theta&quot;) # spearate the chains using facets and modify the color scheme mcmc_trace(bern_mcmc, pars = &quot;theta&quot;) %&gt;% gf_facet_grid(Chain ~ .) %&gt;% gf_refine(scale_color_viridis_d()) ## Scale for &#39;colour&#39; is already present. Adding another scale for ## &#39;colour&#39;, which will replace the existing scale. We will encounter additional plots from bayesplot as we go along. 8.3.5 Using Kruschke’s functions I have put (modified versions of) some of functions from Kruschke’s book into the CalvinBayes package so that you don’t have to source his files to use them. diag_mcmc() [diagMCMC()] diag_mcmc(bern_mcmc, par = &quot;theta&quot;) plot_post() [plotPost()] The plot_post() function takes as its first argument a vector of posterior sampled values for one of the parameters. We can extract such a vector a couple different ways: ## # these produce the same output plot_post(bern_mcmc[, &quot;theta&quot;], main = &quot;theta&quot;, xlab = expression(theta)) ## $posterior ## ESS mean median mode ## var1 3000 0.3075 0.3056 0.2982 ## ## $hdi ## prob lo hi ## 1 0.95 0.1896 0.4342 ## plot_post(posterior(bern_jags)$theta, main = &quot;theta&quot;, xlab = expression(theta)) There are a number of options that allow you to add some additional information to the plot. Specifying quietly = TRUE will turn off the numerical display that plot_post() generates along with the plot. Here is an example.6 plot_post(bern_mcmc[, &quot;theta&quot;], main = &quot;theta&quot;, xlab = expression(theta), cenTend = &quot;median&quot;, compVal = 0.5, ROPE = c(0.45, 0.55), credMass = 0.90, quietly = TRUE) 8.4 Optional arguments to jags() 8.4.1 Number and size of chains Sometimes we want to use more or longer chains (or fewer or shorter chains if we are doing a quick preliminary check before running longer chains later). jags() has three arguments for this: n.chains: number of chains n.iter: number of iterations per chain n.burnin: number of burn in steps per chain n.thin: keep one sample per n.thin. The default value of n.thin is set to save about 1000 values per chain. So in the example below, we end up with only 4000 samples (1000 per chain) rather than the 16000 you might have expected. set.seed(76543) bern_jags2 &lt;- jags( data = list(y = z15N50$y, N = nrow(z15N50)), model.file = bern_model, parameters.to.save = c(&quot;theta&quot;), n.chains = 4, n.iter = 5000, n.burnin = 1000, ) bern_jags2 Setting n.thin = 1 will save them all. set.seed(76543) bern_jags2a &lt;- jags( data = list(y = z15N50$y, N = nrow(z15N50)), model.file = bern_model, parameters.to.save = c(&quot;theta&quot;), n.chains = 4, n.iter = 5000, n.burnin = 1000, n.thin = 1 ) bern_jags2a 8.4.2 Starting point for chains We can also control the starting point for the chains. Starting different chains and quite different parameter values can help verify that the MCMC algorithm is not overly sensitive to where we are starting from, and ensure that the MCMC algorithm has explored the posterior distribution sufficiently. On the other hand, if we start a chain too far from the peak of the posterior distribution, the chain may have trouble converging. We can provide either specific starting points for each chain or a function that generates random starting points. gf_dist(&quot;beta&quot;, shape1 = 3, shape2 = 3) set.seed(2345) bern_jags3 &lt;- jags( data = list(y = z15N50$y, N = nrow(z15N50)), model.file = bern_model, parameters.to.save = c(&quot;theta&quot;), # start each chain by sampling from the prior inits = function() list(theta = rbeta(1, 3, 3)) ) bern_jags4 &lt;- jags( data = list(y = z15N50$y, N = nrow(z15N50)), model.file = bern_model, parameters.to.save = c(&quot;theta&quot;), # choose specific starting point for each chain inits = list( list(theta = 0.5), list(theta = 0.7), list(theta = 0.9) ) ) mcmc_trace(as.mcmc(bern_jags4), pars = &quot;theta&quot;) It is a good sign that our three traces look very similar and overlap a lot. This indicates that the chains are mixing well and not overly affected by their starting point. 8.4.3 Running chains in parallel Although this model runs very quickly, others models may take considerably longer. We can use jags.parallel() in place of jags() to take advantage of multiple cores to run more than one chain at a time. jags.seed can be used to set the seed for the parallel random number generator used. (Note: set.seed() does not work when using jags.parallel() and jags.seed has no effect when using jags().) library(R2jags) bern_jags5 &lt;- jags.parallel( data = list(y = z15N50$y, N = nrow(z15N50)), model.file = bern_model, parameters.to.save = c(&quot;theta&quot;), n.chains = 4, n.iter = 5000, n.burnin = 1000, jags.seed = 12345 ) 8.5 Example 2: comparing two proportions We have seen this situation before when we compared two coins. This time we’ll be a little more personal and compare two people. We will also work with a data set in a slightly different form. But the main point will be to see how we describe this familiar model to JAGS. 8.5.1 The data Suppose we want to compare Reginald and Tony’s abilities to hit a target (with a dart, perhaps). For each attempt, we record two pieces of information: the person making the attempt (the subject) and whether the attempt succeeded (0 or 1). Kruschke’s provides a data frame for this, but the names he uses are not good practice, so let’s remanme them to be more like what you might see in a real data set. library(mosaic) head(z6N8z2N7) y s 1 Reginald 0 Reginald 1 Reginald 1 Reginald 1 Reginald 1 Reginald # Let&#39;s do some renaming Target &lt;- z6N8z2N7 %&gt;% rename(hit = y, subject = s) df_stats(hit ~ subject, data = Target, props, attempts = length) subject prop_0 prop_1 attempts Reginald 0.2500 0.7500 8 Tony 0.7143 0.2857 7 Reginald was more successful than Tony, but neither had very many attempts. 8.5.2 The model Now our model is that each person has his own success rate – we have two \\(\\theta\\)’s, one for Reginald and one for Tony. We express this as \\[\\begin{align*} Y_i|s &amp;\\sim {\\sf Bern}(\\theta_{s}) \\\\ \\theta_s &amp;\\sim {\\sf Beta}(a, b) \\end{align*}\\] 8.5.3 Describing the model to JAGS bern2_model &lt;- function() { for (i in 1:Nobs) { # each response is Bernoulli with the appropriate theta hit[i] ~ dbern(theta[subject[i]]) } for (s in 1:Nsub) { theta[s] ~ dbeta(2, 2) # prior for each theta } } JAGS will also need access to four pieces of information from our data set: a vector of hit values a vector of subject values – coded as integers 1 and 2 (so that subject[i] makes sense to JAGS. (In general, JAGS is much less fluid in handling data than R is, so we often need to do some manual data conversion for JAGS.) Nobs – the total number of observations Nsub – the number of subjects We will prepare these as a list. TargetList &lt;- list( Nobs = nrow(Target), Nsub = 2, hit = Target$hit, subject = as.numeric(as.factor(Target$subject)) ) TargetList ## $Nobs ## [1] 15 ## ## $Nsub ## [1] 2 ## ## $hit ## [1] 1 0 1 1 1 1 1 0 0 0 1 0 0 1 0 ## ## $subject ## [1] 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 8.5.4 Fitting the model bern2_jags &lt;- jags( data = TargetList, model = bern2_model, parameters.to.save = &quot;theta&quot;) 8.5.5 Inspecting the results bern2_mcmc &lt;- as.mcmc(bern2_jags) # Kruschke diagnostic plots diag_mcmc(bern2_mcmc) # bayesplot plots mcmc_acf(bern2_mcmc) mcmc_acf_bar(bern2_mcmc) mcmc_pairs(bern2_mcmc, pars = c(&quot;theta[1]&quot;, &quot;theta[2]&quot;)) mcmc_combo(bern2_mcmc) mcmc_combo(bern2_mcmc, combo = c(&quot;dens&quot;, &quot;dens_overlay&quot;, &quot;trace&quot;, &quot;scatter&quot;), pars = c(&quot;theta[1]&quot;, &quot;theta[2]&quot;)) Here is a list of mcmc_ functions available: apropos(&quot;^mcmc_&quot;) ## [1] &quot;mcmc_acf&quot; &quot;mcmc_acf_bar&quot; ## [3] &quot;mcmc_areas&quot; &quot;mcmc_areas_data&quot; ## [5] &quot;mcmc_areas_ridges&quot; &quot;mcmc_areas_ridges_data&quot; ## [7] &quot;mcmc_combo&quot; &quot;mcmc_dens&quot; ## [9] &quot;mcmc_dens_chains&quot; &quot;mcmc_dens_chains_data&quot; ## [11] &quot;mcmc_dens_overlay&quot; &quot;mcmc_hex&quot; ## [13] &quot;mcmc_hist&quot; &quot;mcmc_hist_by_chain&quot; ## [15] &quot;mcmc_intervals&quot; &quot;mcmc_intervals_data&quot; ## [17] &quot;mcmc_neff&quot; &quot;mcmc_neff_data&quot; ## [19] &quot;mcmc_neff_hist&quot; &quot;mcmc_nuts_acceptance&quot; ## [21] &quot;mcmc_nuts_divergence&quot; &quot;mcmc_nuts_energy&quot; ## [23] &quot;mcmc_nuts_stepsize&quot; &quot;mcmc_nuts_treedepth&quot; ## [25] &quot;mcmc_pairs&quot; &quot;mcmc_parcoord&quot; ## [27] &quot;mcmc_parcoord_data&quot; &quot;mcmc_recover_hist&quot; ## [29] &quot;mcmc_recover_intervals&quot; &quot;mcmc_recover_scatter&quot; ## [31] &quot;mcmc_rhat&quot; &quot;mcmc_rhat_data&quot; ## [33] &quot;mcmc_rhat_hist&quot; &quot;mcmc_scatter&quot; ## [35] &quot;mcmc_trace&quot; &quot;mcmc_trace_highlight&quot; ## [37] &quot;mcmc_violin&quot; The functions ending in _data() return the data used to make the corresponding plot. This can be useful if you want to display that same information in a different way or if you just want to inspect the data to make sure you understand the plot. 8.5.6 Difference in proportions If we are primarily interested in the difference between Reginald and Tony, we can plot the difference in their theta values. head(posterior(bern2_jags)) deviance theta.1 theta.2 21.98 0.5002 0.5821 18.75 0.5718 0.3790 17.87 0.8429 0.3192 18.26 0.5912 0.2855 17.68 0.6661 0.3230 18.69 0.6519 0.4671 gf_density( ~(theta.1 - theta.2), data = posterior(bern2_jags)) 8.5.7 Sampling from the prior To sample from the prior, we must do the following: remove the response variable from our data list change Nobs to 0 set DIC = FALSE in the call to jags(). This will run the model without any data, which means the posterior will be the same as the prior. # make a copy of our data list TargetList0 &lt;- list( Nobs = 0, Nsub = 2, subject = as.numeric(as.factor(Target$subject)) ) bern2_jags0 &lt;- jags( data = TargetList0, model.file = bern2_model, parameters.to.save = c(&quot;theta&quot;), n.chains = 2, n.iter = 5000, n.burnin = 1000, DIC = FALSE) ## Compiling model graph ## Resolving undeclared variables ## Allocating nodes ## Graph information: ## Observed stochastic nodes: 0 ## Unobserved stochastic nodes: 2 ## Total graph size: 20 ## ## Initializing model 8.5.7.1 Note about : in JAGS and in R From the JAGS documentation: The sequence operator : can only produce increasing sequences. If n &lt; m then m:n produces a vector of length zero and when this is used in a for loop index expression the contents of loop inside the curly brackets are skipped. Note that this behavior is different from the sequence operator in R, where m:n will produce a decreasing sequence if n &lt; m. So in our JAGS model, 1:0 correctly represents no data (and no trips through the for loop). 8.5.7.2 What good is it to generate samples from the prior? Our model set priors for \\(\\theta_1\\) and \\(\\theta_2\\), but this implies a distribution for \\(\\theta_1 - \\theta_2\\), and we might like to see what that distribution looks like. gf_density( ~(theta.1 - theta.2), data = posterior(bern2_jags0)) 8.6 Exercises Sampling from priors. You want to know who is the better free throw shooter, Alice or Bob. You decide to have each shoot a number of shots and record their makes and misses. You are primarily interested in the difference between their free throw shooting proportions (\\(\\theta_2 - \\theta_1\\)), and you are curious to know how your choice of priors for \\(\\theta_1\\) and \\(\\theta_2\\) affects the prior for \\(\\theta_2 - \\theta_1\\). For each situation below, use JAGS to sample from the prior distribution for \\(\\theta_2 - \\theta_1\\) and create a density plot. (In each case, assume the priors for \\(\\theta_1\\) and \\(\\theta_2\\) are independent.) Both priors are uniform. What distribution do you think the prior for \\(\\theta_2 - \\theta_1\\) is? Both priors are \\({\\sf Beta}(0.2, 0.2)\\). Explain why the prior for \\(\\theta_2 - \\theta_1\\) looks the way it does. Hint: Don’t forget to set DIC = FALSE when sampling from the prior. Now suppose that Alice makes 25 out of 30 shots and Bob makes 18 out of 32. Is this enough evidence to conclude that Alice is the better shooter? Do this two ways. In each case, use a \\({\\sf Beta}(4, 2)\\) prior for both \\(\\theta_1\\) and \\(\\theta_2\\). Create data and use a model like the one used elsewhere in this chapter. [Hint: rep() is handy for creating a bunch of values that are the same.] Instead of using dbern(), use dbin() (JAGS version of the binomial distribution). This should allow you to get by with simpler data that consists only of the numbers 25, 30, 18, and 32. Note: the order of arguments for dbin() is probability first, then number of trials. This is reversed from the order in R. In the previous problem, what does this prior say about the beliefs about Alice and Bob’s shooting before gathering data? Let’s think about Alice and Bob some more. We don’t know how to do this yet, but explain why if you knew very little about basketball, you might like to have a prior for \\(\\theta_1\\) and \\(\\theta_2\\) that was not indpendent. How might the priors for \\(\\theta_1\\) and \\(\\theta_2\\) be related? Consider the model below. Create a plot of the prior distribution of theat1 and theta2. A scatter plot with overlayed density plot works well. How does this prior compare to the priors in problem 1. (Hint: Don’t forget to use DIC = FALSE when sampling from the prior.) Fit the model to the Alice and Bob data. How does this choice of prior change things? diff_model &lt;- function() { z1 ~ dbin(theta1, n1) z2 ~ dbin(theta2, n2) theta2 &lt;- theta1 + diff theta1 ~ dbeta(4, 2) diff ~ dnorm(0, 400) # Normal with mean 0 and sd = 0.05 } diff_jags &lt;- jags.parallel( model = diff_model, data = list(n1 = 30, z1 = 25, n2 = 32, z2 = 18), parameters.to.save = c(&quot;theta1&quot;, &quot;theta2&quot;, &quot;diff&quot;), n.iter = 5000, n.chains = 4 ) Redo problem 5 using the grid method. This is a bit of a trick that R2jags uses. The function created is never run. The code is inspected and taken as the description of the model. If you were to run the funtion, all it would do is create R formulas.↩ Kruschke calls these 2-way distributions, but there can be more than variables involved.↩ "],
["heierarchical-models.html", "9 Heierarchical Models 9.1 Gamma Distributions 9.2 One coin from one mint 9.3 Multiple coins from one mint 9.4 Multiple coins from multiple mints 9.5 Therapeutic Touch 9.6 Exerciess", " 9 Heierarchical Models 9.1 Gamma Distributions We will use gamma distributions for some of our priors in this chapter. Gamma distributions have support \\((0,\\infty)\\) and are skewed to the right. Both R and JAGS paramterize the gamma distributions with two parameters called shape and rate. gf_dist(&quot;gamma&quot;, shape = 2, rate = 3, color = ~&quot;Gamma(2, 3)&quot;) %&gt;% gf_dist(&quot;gamma&quot;, shape = 4, rate = 3, color = ~&quot;Gamma(4, 3)&quot;) %&gt;% gf_dist(&quot;gamma&quot;, shape = 2, rate = 6, color = ~&quot;Gamma(2, 6)&quot;) %&gt;% gf_dist(&quot;gamma&quot;, shape = 4, rate = 6, color = ~&quot;Gamma(4, 6)&quot;) %&gt;% gf_labs(title = &quot;Some Gamma distributions&quot;) The mean, mode, standard deviation can be calcuated from the shape \\(s\\) and rate \\(r\\) as follows: \\[\\begin{align*} \\mu &amp;= \\frac{s}{r} \\\\ \\omega &amp;= \\frac{s−1}{r} \\qquad (s &gt; 1) \\\\ \\sigma &amp; = \\frac{\\sqrt{s}}{r} \\end{align*}\\] In addition, the scale parameter (1/rate) is sometimes used in place of the rate parameter. The gamma_params() function will automate conversion between various parameterizations. It works just like beta_params() that we have seen before. gamma_params(mode = 15, sd = 10, plot = TRUE) shape rate scale mode mean sd 4 0.2 5 15 20 10 As the shape parameter gets larger and larger, the gamma distribution becomes less and less skewed (and more and more like a normal distribution): gf_dist(&quot;gamma&quot;, shape = 25, rate = 5, color = ~&quot;Gamma(25, 5)&quot;) %&gt;% gf_dist(&quot;norm&quot;, mean = 5, sd = 1, color = ~&quot;Norm(5, 1)&quot;) gf_dist(&quot;gamma&quot;, shape = 100, rate = 5, color = ~&quot;Gamma(25, 5)&quot;) %&gt;% gf_dist(&quot;norm&quot;, mean = 20, sd = 2, color = ~&quot;Norm(5, 1)&quot;) 9.2 One coin from one mint 9.3 Multiple coins from one mint 9.4 Multiple coins from multiple mints gamma_params(mean = 1, sd = 10) shape rate scale mode mean sd 0.01 0.01 100 NA 1 10 model &lt;- function() { for ( i in 1:Ntotal ) { y[i] ~ dbern(theta[s[i]]) } for ( s in 1:Nsubj ) { theat[s] ~ dbeta(omega * (kappa - 2) + 1, (1 - omega) * (kappa - 2) + 1) } omega ~ dbeta(1, 1) kappa &lt;- kappaMinusTwo + 2 kappaMinusTwo ~ dgamma(0.01, 0.01) # mean = 1, sd = 10 } 9.5 Therapeutic Touch The study is described in the text. The article reporting on the study can be found at https://jamanetwork.com/journals/jama/fullarticle/187390. Here’s the abstract: 9.5.1 Abstract Context.— Therapeutic Touch (TT) is a widely used nursing practice rooted in mysticism but alleged to have a scientific basis. Practitioners of TT claim to treat many medical conditions by using their hands to manipulate a “human energy field” perceptible above the patient’s skin. Objective.— To investigate whether TT practitioners can actually perceive a “human energy field.” Design.— Twenty-one practitioners with TT experience for from 1 to 27 years were tested under blinded conditions to determine whether they could correctly identify which of their hands was closest to the investigator’s hand. Placement of the investigator’s hand was determined by flipping a coin. Fourteen practitioners were tested 10 times each, and 7 practitioners were tested 20 times each. Main Outcome Measure.— Practitioners of TT were asked to state whether the investigator’s unseen hand hovered above their right hand or their left hand. To show the validity of TT theory, the practitioners should have been able to locate the investigator’s hand 100% of the time. A score of 50% would be expected through chance alone. Results.— Practitioners of TT identified the correct hand in only 123 (44%) of 280 trials, which is close to what would be expected for random chance. There was no significant correlation between the practitioner’s score and length of experience (r=0.23). The statistical power of this experiment was sufficient to conclude that if TT practitioners could reliably detect a human energy field, the study would have demonstrated this. Conclusions.— Twenty-one experienced TT practitioners were unable to detect the investigator’s “energy field.” Their failure to substantiate TT’s most fundamental claim is unrefuted evidence that the claims of TT are groundless and that further professional use is unjustified. 9.5.2 Data library(mosaic) head(TherapeuticTouch, 3) y s 1 S01 0 S01 0 S01 # how many times does each subject appear in the data? tally(~ s, data = TherapeuticTouch) S01 S02 S03 S04 S05 S06 S07 S08 S09 S10 S11 S12 S13 S14 S15 S16 S17 S18 S19 S20 S21 S22 S23 S24 S25 S26 S27 S28 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 gf_barh(s ~ ., data = TherapeuticTouch, fill = ~ factor(y)) gamma_params(mean = 1, sd = 10) shape rate scale mode mean sd 0.01 0.01 100 NA 1 10 touch_model &lt;- function() { for (i in 1:Ntotal) { y[i] ~ dbern(theta[s[i]]) } for (s in 1:Nsubj) { theta[s] ~ dbeta(omega * (kappa - 2) + 1, (1 - omega) * (kappa - 2) + 1) } omega ~ dbeta(1, 1) kappa &lt;- kappaMinusTwo + 2 kappaMinusTwo ~ dgamma(0.01, 0.01) # mean = 1, sd = 10 } set.seed(1234) TouchData = list( Ntotal = nrow(TherapeuticTouch), Nsubj = length(unique(TherapeuticTouch$s)), y = TherapeuticTouch$y, # must convert subjects to sequence 1:Nsubj s = as.numeric(factor(TherapeuticTouch$s)) ) touch_jags &lt;- jags( data = TouchData, model = touch_model, parameters.to.save = c(&quot;theta&quot;, &quot;kappa&quot;, &quot;omega&quot;), ) touch_jags What do we learn from a quick look at this output? The Rhat values look good The autocorrelation varies from parameter to parameter. For some parameters, it looks like it will take a much longer run to get a large effective sample size. So let’s do a larger run. touch_jags &lt;- jags.parallel( data = TouchData, model = touch_model, parameters.to.save = c(&quot;theta&quot;, &quot;kappa&quot;, &quot;omega&quot;), n.burnin = 1000, n.iter = 41000, n.chains = 5, n.thin = 10, jags.seed = 54321 ) touch_jags touch_mcmc &lt;- as.mcmc(touch_jags) diag_mcmc(touch_mcmc, par = &quot;omega&quot;) diag_mcmc(touch_mcmc, par = &quot;kappa&quot;) diag_mcmc(touch_mcmc, par = &quot;theta[1]&quot;) mcmc_pairs(touch_mcmc, pars = c(&quot;omega&quot;, &quot;kappa&quot;)) GGally::ggpairs(posterior(touch_jags) %&gt;% select(omega, kappa)) gf_point(kappa ~ omega, data = posterior(touch_jags), alpha = 0.05) %&gt;% gf_density2d(kappa ~ omega, data = posterior(touch_jags)) 9.6 Exerciess "]
]
