<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>4 Probability | (Re)Doing Bayesain Data Analysis</title>
  <meta name="description" content="Code, exercises and discussion to accompany a course taught from Kruschke’s Doing Bayesian Data Analysis (2ed)">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="4 Probability | (Re)Doing Bayesain Data Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Code, exercises and discussion to accompany a course taught from Kruschke’s Doing Bayesian Data Analysis (2ed)" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Probability | (Re)Doing Bayesain Data Analysis" />
  
  <meta name="twitter:description" content="Code, exercises and discussion to accompany a course taught from Kruschke’s Doing Bayesian Data Analysis (2ed)" />
  

<meta name="author" content="R Pruim">


<meta name="date" content="2019-04-13">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="some-useful-bits-of-r.html">
<link rel="next" href="bayes-rule-and-the-grid-method.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">(Re)Doing Bayesian Data Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> What’s in These Notes</a></li>
<li class="part"><span><b>I The Basics: Models, Probability, Bayes, and R</b></span></li>
<li class="chapter" data-level="2" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html"><i class="fa fa-check"></i><b>2</b> Credibility, Models, and Parameters</a><ul>
<li class="chapter" data-level="2.1" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#the-steps-of-bayesian-data-analysis"><i class="fa fa-check"></i><b>2.1</b> The Steps of Bayesian Data Analysis</a><ul>
<li class="chapter" data-level="2.1.1" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#r-code"><i class="fa fa-check"></i><b>2.1.1</b> R code</a></li>
<li class="chapter" data-level="2.1.2" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#r-packages"><i class="fa fa-check"></i><b>2.1.2</b> R packages</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#example-1-which-coin-is-it"><i class="fa fa-check"></i><b>2.2</b> Example 1: Which coin is it?</a><ul>
<li class="chapter" data-level="2.2.1" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#freedom-of-choice"><i class="fa fa-check"></i><b>2.2.1</b> Freedom of choice</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#distributions"><i class="fa fa-check"></i><b>2.3</b> Distributions</a><ul>
<li class="chapter" data-level="2.3.1" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#beta-distributions"><i class="fa fa-check"></i><b>2.3.1</b> Beta distributions</a></li>
<li class="chapter" data-level="2.3.2" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#normal-distributions"><i class="fa fa-check"></i><b>2.3.2</b> Normal distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#example-2-height-vs-weight"><i class="fa fa-check"></i><b>2.4</b> Example 2: Height vs Weight</a><ul>
<li class="chapter" data-level="2.4.1" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#data"><i class="fa fa-check"></i><b>2.4.1</b> Data</a></li>
<li class="chapter" data-level="2.4.2" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#describing-a-model-for-the-relationship-between-height-and-weight"><i class="fa fa-check"></i><b>2.4.2</b> Describing a model for the relationship between height and weight</a></li>
<li class="chapter" data-level="2.4.3" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#prior"><i class="fa fa-check"></i><b>2.4.3</b> Prior</a></li>
<li class="chapter" data-level="2.4.4" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#posterior"><i class="fa fa-check"></i><b>2.4.4</b> Posterior</a></li>
<li class="chapter" data-level="2.4.5" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#posterior-predictive-check"><i class="fa fa-check"></i><b>2.4.5</b> Posterior Predictive Check</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#where-do-we-go-from-here"><i class="fa fa-check"></i><b>2.5</b> Where do we go from here?</a></li>
<li class="chapter" data-level="2.6" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#ch02-exercises"><i class="fa fa-check"></i><b>2.6</b> Exercises</a></li>
<li class="chapter" data-level="2.7" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#footnotes"><i class="fa fa-check"></i><b>2.7</b> Footnotes</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html"><i class="fa fa-check"></i><b>3</b> Some Useful Bits of R</a><ul>
<li class="chapter" data-level="3.1" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#style-guide"><i class="fa fa-check"></i><b>3.1</b> You Gotta Have Style</a><ul>
<li class="chapter" data-level="3.1.1" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#an-additional-note-about-homework"><i class="fa fa-check"></i><b>3.1.1</b> An additional note about homework</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#vectors-lists-and-data-frames"><i class="fa fa-check"></i><b>3.2</b> Vectors, Lists, and Data Frames</a><ul>
<li class="chapter" data-level="3.2.1" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#vectors"><i class="fa fa-check"></i><b>3.2.1</b> Vectors</a></li>
<li class="chapter" data-level="3.2.2" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#lists"><i class="fa fa-check"></i><b>3.2.2</b> Lists</a></li>
<li class="chapter" data-level="3.2.3" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#data-frames-for-rectangular-data"><i class="fa fa-check"></i><b>3.2.3</b> Data frames for rectangular data</a></li>
<li class="chapter" data-level="3.2.4" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#other-types-of-data"><i class="fa fa-check"></i><b>3.2.4</b> Other types of data</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#plotting-with-ggformula"><i class="fa fa-check"></i><b>3.3</b> Plotting with ggformula</a></li>
<li class="chapter" data-level="3.4" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#creating-data-with-expand.grid"><i class="fa fa-check"></i><b>3.4</b> Creating data with expand.grid()</a></li>
<li class="chapter" data-level="3.5" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#transforming-and-summarizing-data-dplyr-and-tidyr"><i class="fa fa-check"></i><b>3.5</b> Transforming and summarizing data dplyr and tidyr</a></li>
<li class="chapter" data-level="3.6" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#writing-functions"><i class="fa fa-check"></i><b>3.6</b> Writing Functions</a><ul>
<li class="chapter" data-level="3.6.1" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#why-write-functions"><i class="fa fa-check"></i><b>3.6.1</b> Why write functions?</a></li>
<li class="chapter" data-level="3.6.2" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#function-parts"><i class="fa fa-check"></i><b>3.6.2</b> Function parts</a></li>
<li class="chapter" data-level="3.6.3" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#the-function-function-has-its-function"><i class="fa fa-check"></i><b>3.6.3</b> The function() function has its function</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#some-common-error-messages"><i class="fa fa-check"></i><b>3.7</b> Some common error messages</a><ul>
<li class="chapter" data-level="3.7.1" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#object-not-found"><i class="fa fa-check"></i><b>3.7.1</b> object not found</a></li>
<li class="chapter" data-level="3.7.2" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#any-message-mentioning-yaml"><i class="fa fa-check"></i><b>3.7.2</b> Any message mentioning yaml</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#ch03-exercises"><i class="fa fa-check"></i><b>3.8</b> Exercises</a></li>
<li class="chapter" data-level="3.9" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#footnotes-1"><i class="fa fa-check"></i><b>3.9</b> Footnotes</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>4</b> Probability</a><ul>
<li class="chapter" data-level="4.1" data-path="probability.html"><a href="probability.html#some-terminology"><i class="fa fa-check"></i><b>4.1</b> Some terminology</a></li>
<li class="chapter" data-level="4.2" data-path="probability.html"><a href="probability.html#distributions-in-r"><i class="fa fa-check"></i><b>4.2</b> Distributions in R</a><ul>
<li class="chapter" data-level="4.2.1" data-path="probability.html"><a href="probability.html#example-normal-distributions"><i class="fa fa-check"></i><b>4.2.1</b> Example: Normal distributions</a></li>
<li class="chapter" data-level="4.2.2" data-path="probability.html"><a href="probability.html#simulating-running-proportions"><i class="fa fa-check"></i><b>4.2.2</b> Simulating running proportions</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="probability.html"><a href="probability.html#joint-marginal-and-conditional-distributions"><i class="fa fa-check"></i><b>4.3</b> Joint, marginal, and conditional distributions</a><ul>
<li class="chapter" data-level="4.3.1" data-path="probability.html"><a href="probability.html#example-hair-and-eye-color"><i class="fa fa-check"></i><b>4.3.1</b> Example: Hair and eye color</a></li>
<li class="chapter" data-level="4.3.2" data-path="probability.html"><a href="probability.html#independence"><i class="fa fa-check"></i><b>4.3.2</b> Independence</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="probability.html"><a href="probability.html#ch04-exercises"><i class="fa fa-check"></i><b>4.4</b> Exercises</a></li>
<li class="chapter" data-level="4.5" data-path="probability.html"><a href="probability.html#footnotes-2"><i class="fa fa-check"></i><b>4.5</b> Footnotes</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html"><i class="fa fa-check"></i><b>5</b> Bayes’ Rule and the Grid Method</a><ul>
<li class="chapter" data-level="5.1" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#the-big-bayesian-idea"><i class="fa fa-check"></i><b>5.1</b> The Big Bayesian Idea</a><ul>
<li class="chapter" data-level="5.1.1" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#likelihood"><i class="fa fa-check"></i><b>5.1.1</b> Likelihood</a></li>
<li class="chapter" data-level="5.1.2" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#when-bayes-is-easy"><i class="fa fa-check"></i><b>5.1.2</b> When Bayes is easy</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#estimating-the-bias-in-a-coin-using-the-grid-method"><i class="fa fa-check"></i><b>5.2</b> Estimating the bias in a coin using the Grid Method</a><ul>
<li class="chapter" data-level="5.2.1" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#creating-a-grid"><i class="fa fa-check"></i><b>5.2.1</b> Creating a Grid</a></li>
<li class="chapter" data-level="5.2.2" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#hdi-from-the-grid"><i class="fa fa-check"></i><b>5.2.2</b> HDI from the grid</a></li>
<li class="chapter" data-level="5.2.3" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#automating-the-grid"><i class="fa fa-check"></i><b>5.2.3</b> Automating the grid</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#working-on-the-log-scale"><i class="fa fa-check"></i><b>5.3</b> Working on the log scale</a></li>
<li class="chapter" data-level="5.4" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#discrete-params"><i class="fa fa-check"></i><b>5.4</b> Discrete Parameters</a></li>
<li class="chapter" data-level="5.5" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#ch05-exercises"><i class="fa fa-check"></i><b>5.5</b> Exercises</a></li>
<li class="chapter" data-level="5.6" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#footnotes-3"><i class="fa fa-check"></i><b>5.6</b> Footnotes</a></li>
</ul></li>
<li class="part"><span><b>II Inferring a Binomial Probability</b></span></li>
<li class="chapter" data-level="6" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><i class="fa fa-check"></i><b>6</b> Inferring a Binomial Probability via Exact Mathematical Analysis</a><ul>
<li class="chapter" data-level="6.1" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#beta-distributions-1"><i class="fa fa-check"></i><b>6.1</b> Beta distributions</a></li>
<li class="chapter" data-level="6.2" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#beta-and-bayes"><i class="fa fa-check"></i><b>6.2</b> Beta and Bayes</a><ul>
<li class="chapter" data-level="6.2.1" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#the-bernoulli-likelihood-function"><i class="fa fa-check"></i><b>6.2.1</b> The Bernoulli likelihood function</a></li>
<li class="chapter" data-level="6.2.2" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#a-convenient-prior"><i class="fa fa-check"></i><b>6.2.2</b> A convenient prior</a></li>
<li class="chapter" data-level="6.2.3" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#pros-and-cons-of-conjugate-priors"><i class="fa fa-check"></i><b>6.2.3</b> Pros and Cons of conjugate priors</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#getting-to-know-the-beta-distributions"><i class="fa fa-check"></i><b>6.3</b> Getting to know the Beta distributions</a><ul>
<li class="chapter" data-level="6.3.1" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#important-facts"><i class="fa fa-check"></i><b>6.3.1</b> Important facts</a></li>
<li class="chapter" data-level="6.3.2" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#alternative-parameterizations-of-beta-distributions"><i class="fa fa-check"></i><b>6.3.2</b> Alternative parameterizations of Beta distributions</a></li>
<li class="chapter" data-level="6.3.3" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#beta_params"><i class="fa fa-check"></i><b>6.3.3</b> beta_params()</a></li>
<li class="chapter" data-level="6.3.4" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#automating-bayesian-updates-for-a-proportion-beta-prior"><i class="fa fa-check"></i><b>6.3.4</b> Automating Bayesian updates for a proportion (beta prior)</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#what-if-the-prior-isnt-a-beta-distribution"><i class="fa fa-check"></i><b>6.4</b> What if the prior isn’t a beta distribution?</a></li>
<li class="chapter" data-level="6.5" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#ch06-exercises"><i class="fa fa-check"></i><b>6.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html"><i class="fa fa-check"></i><b>7</b> Markov Chain Monte Carlo (MCMC)</a><ul>
<li class="chapter" data-level="7.1" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#king-markov-and-adviser-metropolis"><i class="fa fa-check"></i><b>7.1</b> King Markov and Adviser Metropolis</a></li>
<li class="chapter" data-level="7.2" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#quick-intro-to-markov-chains"><i class="fa fa-check"></i><b>7.2</b> Quick Intro to Markov Chains</a><ul>
<li class="chapter" data-level="7.2.1" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#more-info-please"><i class="fa fa-check"></i><b>7.2.1</b> More info, please</a></li>
<li class="chapter" data-level="7.2.2" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#definition"><i class="fa fa-check"></i><b>7.2.2</b> Definition</a></li>
<li class="chapter" data-level="7.2.3" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#time-homogeneous-markov-chains"><i class="fa fa-check"></i><b>7.2.3</b> Time-Homogeneous Markov Chains</a></li>
<li class="chapter" data-level="7.2.4" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#matrix-representation"><i class="fa fa-check"></i><b>7.2.4</b> Matrix representation</a></li>
<li class="chapter" data-level="7.2.5" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#regular-markov-chains"><i class="fa fa-check"></i><b>7.2.5</b> Regular Markov Chains</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#back-to-king-markov"><i class="fa fa-check"></i><b>7.3</b> Back to King Markov</a></li>
<li class="chapter" data-level="7.4" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#how-well-does-the-metropolis-algorithm-work"><i class="fa fa-check"></i><b>7.4</b> How well does the Metropolis Algorithm work?</a><ul>
<li class="chapter" data-level="7.4.1" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#jumping-to-any-island"><i class="fa fa-check"></i><b>7.4.1</b> Jumping to any island</a></li>
<li class="chapter" data-level="7.4.2" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#jumping-only-to-neighbor-islands"><i class="fa fa-check"></i><b>7.4.2</b> Jumping only to neighbor islands</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#markov-chains-and-posterior-sampling"><i class="fa fa-check"></i><b>7.5</b> Markov Chains and Posterior Sampling</a><ul>
<li class="chapter" data-level="7.5.1" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#example-1-estimating-a-proportion"><i class="fa fa-check"></i><b>7.5.1</b> Example 1: Estimating a proportion</a></li>
<li class="chapter" data-level="7.5.2" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#example-2-estimating-mean-and-variance"><i class="fa fa-check"></i><b>7.5.2</b> Example 2: Estimating mean and variance</a></li>
<li class="chapter" data-level="7.5.3" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#issues-with-metropolis-algorithm"><i class="fa fa-check"></i><b>7.5.3</b> Issues with Metropolis Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#two-coins"><i class="fa fa-check"></i><b>7.6</b> Two coins</a><ul>
<li class="chapter" data-level="7.6.1" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#the-model"><i class="fa fa-check"></i><b>7.6.1</b> The model</a></li>
<li class="chapter" data-level="7.6.2" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#exact-analysis"><i class="fa fa-check"></i><b>7.6.2</b> Exact analysis</a></li>
<li class="chapter" data-level="7.6.3" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#metropolis"><i class="fa fa-check"></i><b>7.6.3</b> Metropolis</a></li>
<li class="chapter" data-level="7.6.4" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#gibbs-sampling"><i class="fa fa-check"></i><b>7.6.4</b> Gibbs sampling</a></li>
<li class="chapter" data-level="7.6.5" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#advantages-and-disadvantages-of-gibbs-vs-metropolis"><i class="fa fa-check"></i><b>7.6.5</b> Advantages and Disadvantages of Gibbs vs Metropolis</a></li>
<li class="chapter" data-level="7.6.6" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#so-what-do-we-learn-about-the-coins"><i class="fa fa-check"></i><b>7.6.6</b> So what do we learn about the coins?</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#mcmc-posterior-sampling-big-picture"><i class="fa fa-check"></i><b>7.7</b> MCMC posterior sampling: Big picture</a><ul>
<li class="chapter" data-level="7.7.1" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#mcmc-markov-chain-monte-carlo"><i class="fa fa-check"></i><b>7.7.1</b> MCMC = Markov chain Monte Carlo</a></li>
<li class="chapter" data-level="7.7.2" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#posterior-sampling-random-walk-through-the-posterior"><i class="fa fa-check"></i><b>7.7.2</b> Posterior sampling: Random walk through the posterior</a></li>
<li class="chapter" data-level="7.7.3" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#where-do-we-go-from-here-1"><i class="fa fa-check"></i><b>7.7.3</b> Where do we go from here?</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#ch07-exercises"><i class="fa fa-check"></i><b>7.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html"><i class="fa fa-check"></i><b>8</b> JAGS – Just Another Gibbs Sampler</a><ul>
<li class="chapter" data-level="8.1" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#what-jags-is"><i class="fa fa-check"></i><b>8.1</b> What JAGS is</a><ul>
<li class="chapter" data-level="8.1.1" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#jags-documentation"><i class="fa fa-check"></i><b>8.1.1</b> JAGS documentation</a></li>
<li class="chapter" data-level="8.1.2" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#updating-c-and-clang"><i class="fa fa-check"></i><b>8.1.2</b> Updating C and CLANG</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#example-1-estimating-a-proportion-1"><i class="fa fa-check"></i><b>8.2</b> Example 1: estimating a proportion</a><ul>
<li class="chapter" data-level="8.2.1" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#the-model-1"><i class="fa fa-check"></i><b>8.2.1</b> The Model</a></li>
<li class="chapter" data-level="8.2.2" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#load-data"><i class="fa fa-check"></i><b>8.2.2</b> Load Data</a></li>
<li class="chapter" data-level="8.2.3" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#specify-the-model"><i class="fa fa-check"></i><b>8.2.3</b> Specify the model</a></li>
<li class="chapter" data-level="8.2.4" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#run-the-model"><i class="fa fa-check"></i><b>8.2.4</b> Run the model</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#extracting-information-from-a-jags-run"><i class="fa fa-check"></i><b>8.3</b> Extracting information from a JAGS run</a><ul>
<li class="chapter" data-level="8.3.1" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#posterior-1"><i class="fa fa-check"></i><b>8.3.1</b> posterior()</a></li>
<li class="chapter" data-level="8.3.2" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#side-note-posterior-sampling-and-the-grid-method"><i class="fa fa-check"></i><b>8.3.2</b> Side note: posterior sampling and the grid method</a></li>
<li class="chapter" data-level="8.3.3" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#using-coda"><i class="fa fa-check"></i><b>8.3.3</b> Using coda</a></li>
<li class="chapter" data-level="8.3.4" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#using-bayesplot"><i class="fa fa-check"></i><b>8.3.4</b> Using bayesplot</a></li>
<li class="chapter" data-level="8.3.5" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#using-kruschkes-functions"><i class="fa fa-check"></i><b>8.3.5</b> Using Kruschke’s functions</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#optional-arguments-to-jags"><i class="fa fa-check"></i><b>8.4</b> Optional arguments to jags()</a><ul>
<li class="chapter" data-level="8.4.1" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#number-and-size-of-chains"><i class="fa fa-check"></i><b>8.4.1</b> Number and size of chains</a></li>
<li class="chapter" data-level="8.4.2" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#starting-point-for-chains"><i class="fa fa-check"></i><b>8.4.2</b> Starting point for chains</a></li>
<li class="chapter" data-level="8.4.3" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#running-chains-in-parallel"><i class="fa fa-check"></i><b>8.4.3</b> Running chains in parallel</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#example-2-comparing-two-proportions"><i class="fa fa-check"></i><b>8.5</b> Example 2: comparing two proportions</a><ul>
<li class="chapter" data-level="8.5.1" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#the-data"><i class="fa fa-check"></i><b>8.5.1</b> The data</a></li>
<li class="chapter" data-level="8.5.2" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#the-model-2"><i class="fa fa-check"></i><b>8.5.2</b> The model</a></li>
<li class="chapter" data-level="8.5.3" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#describing-the-model-to-jags"><i class="fa fa-check"></i><b>8.5.3</b> Describing the model to JAGS</a></li>
<li class="chapter" data-level="8.5.4" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#fitting-the-model"><i class="fa fa-check"></i><b>8.5.4</b> Fitting the model</a></li>
<li class="chapter" data-level="8.5.5" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#inspecting-the-results"><i class="fa fa-check"></i><b>8.5.5</b> Inspecting the results</a></li>
<li class="chapter" data-level="8.5.6" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#difference-in-proportions"><i class="fa fa-check"></i><b>8.5.6</b> Difference in proportions</a></li>
<li class="chapter" data-level="8.5.7" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#sampling-from-the-prior"><i class="fa fa-check"></i><b>8.5.7</b> Sampling from the prior</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#ch08-exercises"><i class="fa fa-check"></i><b>8.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="heierarchical-models.html"><a href="heierarchical-models.html"><i class="fa fa-check"></i><b>9</b> Heierarchical Models</a><ul>
<li class="chapter" data-level="9.1" data-path="heierarchical-models.html"><a href="heierarchical-models.html#gamma-distributions"><i class="fa fa-check"></i><b>9.1</b> Gamma Distributions</a></li>
<li class="chapter" data-level="9.2" data-path="heierarchical-models.html"><a href="heierarchical-models.html#one-coin-from-one-mint"><i class="fa fa-check"></i><b>9.2</b> One coin from one mint</a></li>
<li class="chapter" data-level="9.3" data-path="heierarchical-models.html"><a href="heierarchical-models.html#multiple-coins-from-one-mint"><i class="fa fa-check"></i><b>9.3</b> Multiple coins from one mint</a></li>
<li class="chapter" data-level="9.4" data-path="heierarchical-models.html"><a href="heierarchical-models.html#multiple-coins-from-multiple-mints"><i class="fa fa-check"></i><b>9.4</b> Multiple coins from multiple mints</a></li>
<li class="chapter" data-level="9.5" data-path="heierarchical-models.html"><a href="heierarchical-models.html#therapeutic-touch"><i class="fa fa-check"></i><b>9.5</b> Therapeutic Touch</a><ul>
<li class="chapter" data-level="9.5.1" data-path="heierarchical-models.html"><a href="heierarchical-models.html#abstract"><i class="fa fa-check"></i><b>9.5.1</b> Abstract</a></li>
<li class="chapter" data-level="9.5.2" data-path="heierarchical-models.html"><a href="heierarchical-models.html#data-1"><i class="fa fa-check"></i><b>9.5.2</b> Data</a></li>
<li class="chapter" data-level="9.5.3" data-path="heierarchical-models.html"><a href="heierarchical-models.html#a-heierarchical-model"><i class="fa fa-check"></i><b>9.5.3</b> A heierarchical model</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="heierarchical-models.html"><a href="heierarchical-models.html#other-parameterizations-we-might-have-tried"><i class="fa fa-check"></i><b>9.6</b> Other parameterizations we might have tried</a><ul>
<li class="chapter" data-level="9.6.1" data-path="heierarchical-models.html"><a href="heierarchical-models.html#shape-parameters-for-beta"><i class="fa fa-check"></i><b>9.6.1</b> Shape parameters for Beta</a></li>
<li class="chapter" data-level="9.6.2" data-path="heierarchical-models.html"><a href="heierarchical-models.html#mean-instead-of-mode"><i class="fa fa-check"></i><b>9.6.2</b> Mean instead of mode</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="heierarchical-models.html"><a href="heierarchical-models.html#shrinkage"><i class="fa fa-check"></i><b>9.7</b> Shrinkage</a></li>
<li class="chapter" data-level="9.8" data-path="heierarchical-models.html"><a href="heierarchical-models.html#example-baseball-batting-average"><i class="fa fa-check"></i><b>9.8</b> Example: Baseball Batting Average</a></li>
<li class="chapter" data-level="9.9" data-path="heierarchical-models.html"><a href="heierarchical-models.html#ch09-exercises"><i class="fa fa-check"></i><b>9.9</b> Exerciess</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="model-comparison.html"><a href="model-comparison.html"><i class="fa fa-check"></i><b>10</b> (Model Comparison)</a></li>
<li class="chapter" data-level="11" data-path="nhst.html"><a href="nhst.html"><i class="fa fa-check"></i><b>11</b> (NHST)</a></li>
<li class="chapter" data-level="12" data-path="point-null-hypotheses.html"><a href="point-null-hypotheses.html"><i class="fa fa-check"></i><b>12</b> (Point Null Hypotheses)</a></li>
<li class="chapter" data-level="13" data-path="goals-power-sample-size.html"><a href="goals-power-sample-size.html"><i class="fa fa-check"></i><b>13</b> (Goals, Power, Sample Size)</a></li>
<li class="chapter" data-level="14" data-path="stan.html"><a href="stan.html"><i class="fa fa-check"></i><b>14</b> Stan</a><ul>
<li class="chapter" data-level="14.1" data-path="stan.html"><a href="stan.html#why-stan-might-work-better"><i class="fa fa-check"></i><b>14.1</b> Why Stan might work better</a></li>
<li class="chapter" data-level="14.2" data-path="stan.html"><a href="stan.html#describing-a-model-to-stan"><i class="fa fa-check"></i><b>14.2</b> Describing a model to Stan</a></li>
<li class="chapter" data-level="14.3" data-path="stan.html"><a href="stan.html#samping-from-the-prior"><i class="fa fa-check"></i><b>14.3</b> Samping from the prior</a></li>
<li class="chapter" data-level="14.4" data-path="stan.html"><a href="stan.html#ch14-exercises"><i class="fa fa-check"></i><b>14.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="glm-overview.html"><a href="glm-overview.html"><i class="fa fa-check"></i><b>15</b> GLM Overview</a><ul>
<li class="chapter" data-level="15.1" data-path="glm-overview.html"><a href="glm-overview.html#data-consists-of-observations-of-variables"><i class="fa fa-check"></i><b>15.1</b> Data consists of observations of variables</a><ul>
<li class="chapter" data-level="15.1.1" data-path="glm-overview.html"><a href="glm-overview.html#variable-roles"><i class="fa fa-check"></i><b>15.1.1</b> Variable Roles</a></li>
<li class="chapter" data-level="15.1.2" data-path="glm-overview.html"><a href="glm-overview.html#types-of-variables"><i class="fa fa-check"></i><b>15.1.2</b> Types of Variables</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="glm-overview.html"><a href="glm-overview.html#glm-framework"><i class="fa fa-check"></i><b>15.2</b> GLM Framework</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html"><i class="fa fa-check"></i><b>16</b> Estimating One and Two Means</a><ul>
<li class="chapter" data-level="16.1" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#basic-model-for-two-means"><i class="fa fa-check"></i><b>16.1</b> Basic Model for Two Means</a><ul>
<li class="chapter" data-level="16.1.1" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#data-2"><i class="fa fa-check"></i><b>16.1.1</b> Data</a></li>
<li class="chapter" data-level="16.1.2" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#model"><i class="fa fa-check"></i><b>16.1.2</b> Model</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#an-old-sleep-study"><i class="fa fa-check"></i><b>16.2</b> An Old Sleep Study</a><ul>
<li class="chapter" data-level="16.2.1" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#data-3"><i class="fa fa-check"></i><b>16.2.1</b> Data</a></li>
<li class="chapter" data-level="16.2.2" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#model-1"><i class="fa fa-check"></i><b>16.2.2</b> Model</a></li>
<li class="chapter" data-level="16.2.3" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#separate-standard-deviations-for-each-group"><i class="fa fa-check"></i><b>16.2.3</b> Separate standard deviations for each group</a></li>
<li class="chapter" data-level="16.2.4" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#comparison-to-t-test"><i class="fa fa-check"></i><b>16.2.4</b> Comparison to t-test</a></li>
<li class="chapter" data-level="16.2.5" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#rope-region-of-practical-equivalence"><i class="fa fa-check"></i><b>16.2.5</b> ROPE (Region of Practical Equivalence)</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#variations-on-the-theme"><i class="fa fa-check"></i><b>16.3</b> Variations on the theme</a><ul>
<li class="chapter" data-level="16.3.1" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#other-distributions-for-the-response"><i class="fa fa-check"></i><b>16.3.1</b> Other distributions for the response</a></li>
<li class="chapter" data-level="16.3.2" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#other-priors-for-sigma-or-tau"><i class="fa fa-check"></i><b>16.3.2</b> Other Priors for <span class="math inline">\(\sigma\)</span> (or <span class="math inline">\(\tau\)</span>)</a></li>
<li class="chapter" data-level="16.3.3" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#paired-comparisons"><i class="fa fa-check"></i><b>16.3.3</b> Paired Comparisons</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#how-many-chains-how-long"><i class="fa fa-check"></i><b>16.4</b> How many chains? How long?</a><ul>
<li class="chapter" data-level="16.4.1" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#why-multiple-chains"><i class="fa fa-check"></i><b>16.4.1</b> Why multiple chains?</a></li>
<li class="chapter" data-level="16.4.2" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#what-large-n.eff-does-and-doesnt-do-for-us"><i class="fa fa-check"></i><b>16.4.2</b> What large n.eff does and doesn’t do for us</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#looking-at-likelihood"><i class="fa fa-check"></i><b>16.5</b> Looking at Likelihood</a></li>
<li class="chapter" data-level="16.6" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#ch16-exercises"><i class="fa fa-check"></i><b>16.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>17</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="17.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#the-deluxe-basic-model"><i class="fa fa-check"></i><b>17.1</b> The deluxe basic model</a><ul>
<li class="chapter" data-level="17.1.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#likelihood-1"><i class="fa fa-check"></i><b>17.1.1</b> Likelihood</a></li>
<li class="chapter" data-level="17.1.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#priors"><i class="fa fa-check"></i><b>17.1.2</b> Priors</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#example-galtons-data"><i class="fa fa-check"></i><b>17.2</b> Example: Galton’s Data</a><ul>
<li class="chapter" data-level="17.2.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#describing-the-model-to-jags-1"><i class="fa fa-check"></i><b>17.2.1</b> Describing the model to JAGS</a></li>
<li class="chapter" data-level="17.2.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#problems-and-how-to-fix-them"><i class="fa fa-check"></i><b>17.2.2</b> Problems and how to fix them</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#centering-and-standardizing"><i class="fa fa-check"></i><b>17.3</b> Centering and Standardizing</a><ul>
<li class="chapter" data-level="17.3.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#beta_0-and-beta_1-are-still-correlated"><i class="fa fa-check"></i><b>17.3.1</b> <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are still correlated</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#weve-fit-a-model-now-what"><i class="fa fa-check"></i><b>17.4</b> We’ve fit a model, now what?</a><ul>
<li class="chapter" data-level="17.4.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#estimate-parameters"><i class="fa fa-check"></i><b>17.4.1</b> Estimate parameters</a></li>
<li class="chapter" data-level="17.4.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#make-predictions"><i class="fa fa-check"></i><b>17.4.2</b> Make predictions</a></li>
<li class="chapter" data-level="17.4.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#posterior-predictive-checks"><i class="fa fa-check"></i><b>17.4.3</b> Posterior Predictive Checks</a></li>
<li class="chapter" data-level="17.4.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#posterior-predictive-checks-with-bayesplot"><i class="fa fa-check"></i><b>17.4.4</b> Posterior predictive checks with bayesplot</a></li>
<li class="chapter" data-level="17.4.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#ppc-with-custom-data"><i class="fa fa-check"></i><b>17.4.5</b> PPC with custom data</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#fitting-models-with-stan"><i class="fa fa-check"></i><b>17.5</b> Fitting models with Stan</a></li>
<li class="chapter" data-level="17.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#two-intercepts-model"><i class="fa fa-check"></i><b>17.6</b> Two Intercepts model</a></li>
<li class="chapter" data-level="17.7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#ch17-exercises"><i class="fa fa-check"></i><b>17.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html"><i class="fa fa-check"></i><b>18</b> Multiple Metric Predictors</a><ul>
<li class="chapter" data-level="18.1" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#sat"><i class="fa fa-check"></i><b>18.1</b> SAT</a><ul>
<li class="chapter" data-level="18.1.1" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#sat-vs-expenditure"><i class="fa fa-check"></i><b>18.1.1</b> SAT vs expenditure</a></li>
<li class="chapter" data-level="18.1.2" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#sat-vs-expenditure-and-percent-taking-the-test"><i class="fa fa-check"></i><b>18.1.2</b> SAT vs expenditure and percent taking the test</a></li>
<li class="chapter" data-level="18.1.3" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#whats-wrong-with-this-picture"><i class="fa fa-check"></i><b>18.1.3</b> What’s wrong with this picture?</a></li>
<li class="chapter" data-level="18.1.4" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#multiple-predictors-in-pictures"><i class="fa fa-check"></i><b>18.1.4</b> Multiple predictors in pictures</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#interaction"><i class="fa fa-check"></i><b>18.2</b> Interaction</a><ul>
<li class="chapter" data-level="18.2.1" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#sat-with-interaction-term"><i class="fa fa-check"></i><b>18.2.1</b> SAT with interaction term</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#fitting-a-linear-model-with-brms"><i class="fa fa-check"></i><b>18.3</b> Fitting a linear model with brms</a><ul>
<li class="chapter" data-level="18.3.1" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#adjusting-the-model-with-brm"><i class="fa fa-check"></i><b>18.3.1</b> Adjusting the model with brm()</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#interpretting-a-model-with-an-interaction-term"><i class="fa fa-check"></i><b>18.4</b> Interpretting a model with an interaction term</a><ul>
<li class="chapter" data-level="18.4.1" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#thinking-about-the-noise"><i class="fa fa-check"></i><b>18.4.1</b> Thinking about the noise</a></li>
</ul></li>
<li class="chapter" data-level="18.5" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#ch18-exercises"><i class="fa fa-check"></i><b>18.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="nominal-predictors.html"><a href="nominal-predictors.html"><i class="fa fa-check"></i><b>19</b> Nominal Predictors</a><ul>
<li class="chapter" data-level="19.1" data-path="nominal-predictors.html"><a href="nominal-predictors.html#example-fruitflies"><i class="fa fa-check"></i><b>19.1</b> Example: Fruitflies</a><ul>
<li class="chapter" data-level="19.1.1" data-path="nominal-predictors.html"><a href="nominal-predictors.html#comparing-two-groups"><i class="fa fa-check"></i><b>19.1.1</b> Comparing two groups</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">(Re)Doing Bayesain Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="probability" class="section level1">
<h1><span class="header-section-number">4</span> Probability</h1>

<div id="some-terminology" class="section level2">
<h2><span class="header-section-number">4.1</span> Some terminology</h2>
<p>Probability is about quantifying the relative chances of various possible
outcomes of a random process.</p>
<p>As a very simple example (used to illustrate the terminology below), considering
rolling a single 6-sided die.</p>
<p><strong>sample space:</strong> The set of all possible outcomes of a random process.
[{1, 2, 3, 4, 5, 6}]</p>
<p><strong>event:</strong> a set of outcomes (subset of sample space) [E = {2, 4, 6} is the event that we obtain an even number]</p>
<p><strong>probability:</strong> a number between 0 and 1 assigned to an event
(really a function that assigns numbers to each event). We write this
P(E). [P(E) = 1/2 where E = {1, 2, 3}]</p>
<p><strong>random variable:</strong> a random process that produces a number. [So rolling a die can
be considered a random variable.]</p>
<p><strong>probability distribution:</strong> a description of all possible outcomes and their
probabilities.
For rolling a die we might do this with a table like this:</p>
<table>
<thead>
<tr class="header">
<th align="right">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
<th align="center">5</th>
<th align="left">6</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1/6</td>
<td align="center">1/6</td>
<td align="center">1/6</td>
<td align="center">1/6</td>
<td align="center">1/6</td>
<td align="left">1/6</td>
</tr>
</tbody>
</table>
<p><strong>support (of a random variable):</strong> the set of possible values of
a random variable. This is very similar to the sample space.</p>
<p><strong>probability mass function (pmf):</strong> a function (often denoted with
<span class="math inline">\(p\)</span> or <span class="math inline">\(f\)</span>) that takes possible values of a
discrete random variable as input and returns the probability of that outcome.</p>
<ul>
<li><p>If <span class="math inline">\(S\)</span> is the support of the random variable, then
<span class="math display">\[
\sum_{x \in S} p(x) = 1
\]</span>
and any function with this property is a pmf.</p></li>
<li><p>Probabilities of events are
obtained by adding the probabilities of all outcomes in the event:</p></li>
</ul>
<p><span class="math display">\[
\operatorname{Pr}(E) = \sum_{x \in E} p(x)
\]</span>
* pmfs can be represented in a table (like the one above) or graphically with a
probability histogram or lollipop plot like the ones below. [These are not
for the 6-sided die, as we can tell because the probabilities are not
the same for each input; the die rolling example would make very boring plots.]</p>
<p><img src="Redoing_files/figure-html/ch04-binom-01-1.png" width="65%" /><img src="Redoing_files/figure-html/ch04-binom-01-2.png" width="65%" /></p>
<ul>
<li>Histograms are generally presented on the <strong>density scale</strong> so the total
area of the histogram is 1. (In this example, the bin widths are 1, so this
is the same as being on the probability scale.)</li>
</ul>
<p><strong>probability density function (pdf):</strong> a function (often denoted with <span class="math inline">\(p\)</span> or <span class="math inline">\(f\)</span>)
that takes the possible
values of continuous random variable as input and returns the probability
<em>density</em>.</p>
<ul>
<li>If <span class="math inline">\(S\)</span> is the support of the random variable, then <a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>
<span class="math display">\[
\int_{x \in S} f(x) \; dx = 1
\]</span>
and any function with this property is a pmf.</li>
</ul>
<ul>
<li>Probabilities are obtained by integrating
(visualized by the area under the density curve):</li>
</ul>
<p><span class="math display">\[
\operatorname{Pr}(a \le X \le b) = \int_a^b f(x) \; dx
\]</span></p>
<p><img src="Redoing_files/figure-html/ch04-beta-01-1.png" width="65%" /></p>
<p><strong>kernel function:</strong>
If <span class="math inline">\(\int_{x \in S} f(x) \; dx = k\)</span> for some real number <span class="math inline">\(k\)</span>, then
<span class="math inline">\(f\)</span> is a kernel function. We can obtain the pdf from the kernel by dividing
by <span class="math inline">\(k\)</span>.</p>
<p><strong>cumulative distribution function (cdf):</strong> a function (often denoted with a
capital <span class="math inline">\(F\)</span>) that takes a possible value
of a random variable as input and returns the probability of obtaining a
value less than or equal to the input:
<span class="math display">\[
F_X(x) = \operatorname{Pr}(X \le x)
\]</span>
cdfs can be defined for both discrete and continuous random variables.</p>
<p><strong>a family of distributions:</strong> is a collection of distributions which
share common features but are distinguished by different parameter values.
For example, we could have the family of distributions of fair dice
random variables. The parameter would tell us how many sides the die has.
Statisticians call this family the <strong>discrete uniform distributions</strong> because
all the probabilities are equal (1/6 for 6-sided die, 1/10 for a <span class="math inline">\(D_10\)</span>, etc.).</p>
<p>We will get to know several important families of distributions, among them
the <strong>binomial</strong>, <strong>beta</strong>, <strong>normal</strong>, and <strong>t</strong> families will be
especially useful. You may already be familiar with some or all of these.
We will also use distributions that have no name and are only described by
a pmf or pdf, or perhaps only by a large number of random samples from which
we attempt to estimate the pmf or pdf.</p>
</div>
<div id="distributions-in-r" class="section level2">
<h2><span class="header-section-number">4.2</span> Distributions in R</h2>
<p>pmfs, pdfs, and cdfs are available in R for many important families
of distributions. You just need to know a few things:</p>
<ul>
<li>each family has a standard abbreviation in R</li>
<li>pmf and pdf functions begin with the letter <code>d</code> followed by the family abbreviation</li>
<li>cdf functions begin with the letter <code>p</code> followed by the family abbreviation</li>
<li>the inverse of the cdf function is called a quantile function,
it starts with the letter <code>q</code></li>
<li>functions beginning with <code>r</code> can generate random samples from a distribution</li>
<li>help for any of these functions will tell you what R calls the parameters
of the family.</li>
<li><code>gf_dist()</code> can be used to make various plots of distributions.</li>
</ul>
<div id="example-normal-distributions" class="section level3">
<h3><span class="header-section-number">4.2.1</span> Example: Normal distributions</h3>
<p>As an example, let’s look the family of normal distributions. If you type
<code>dnorm(</code> and then hit TAB or if you type <code>args(dnorm)</code> you can see the arguments
for this function.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">args</span>(dnorm)</code></pre>
<pre><code>## function (x, mean = 0, sd = 1, log = FALSE) 
## NULL</code></pre>
<p>From this we see that the parameters are called <code>mean</code> and <code>sd</code> and have
default value of 0 and 1. These values will be used if we don’t specify
something else.
As with many of the pmf and pdf functions,
there is also an option to get back the log of the
pmf or pdf by setting <code>log = TRUE</code>. This turns out to be computationally much
more efficient in many contexts, as we will see.</p>
<p>Let’s begin with some pictures of a normal distribution with
mean 10 and standard deviation 1:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">gf_dist</span>(<span class="st">&quot;norm&quot;</span>, <span class="dt">mean =</span> <span class="dv">10</span>, <span class="dt">sd =</span> <span class="dv">2</span>, <span class="dt">title =</span> <span class="st">&quot;pdf for Norm(10, 2)&quot;</span>)</code></pre>
<p><img src="Redoing_files/figure-html/ch04-norm-01-1.png" width="65%" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">gf_dist</span>(<span class="st">&quot;norm&quot;</span>, <span class="dt">mean =</span> <span class="dv">10</span>, <span class="dt">sd =</span> <span class="dv">2</span>, <span class="dt">kind =</span> <span class="st">&quot;cdf&quot;</span>, <span class="dt">title =</span> <span class="st">&quot;cdf for Norm(10, 2)&quot;</span>)</code></pre>
<p><img src="Redoing_files/figure-html/ch04-norm-01-2.png" width="65%" /></p>
<p>Now some exercises. Assume <span class="math inline">\(X \sim {\sf Norm}(10, 2)\)</span>.</p>
<ol style="list-style-type: decimal">
<li><p>What is <span class="math inline">\(\operatorname{Pr}(X \le 5)\)</span>?</p>
<p>We can see by inspection that it is less that 0.5. <code>pnorm()</code> will give us
the value we are after; <code>xpnorm()</code> will provide more verbose output and a plot
as well.</p></li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pnorm</span>(<span class="dv">5</span>, <span class="dt">mean =</span> <span class="dv">10</span>, <span class="dt">sd =</span> <span class="dv">2</span>)</code></pre>
<pre><code>## [1] 0.00621</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">xpnorm</span>(<span class="dv">5</span>, <span class="dt">mean =</span> <span class="dv">10</span>, <span class="dt">sd =</span> <span class="dv">2</span>)</code></pre>
<pre><code>## </code></pre>
<pre><code>## If X ~ N(10, 2), then</code></pre>
<pre><code>##  P(X &lt;= 5) = P(Z &lt;= -2.5) = 0.00621</code></pre>
<pre><code>##  P(X &gt;  5) = P(Z &gt;  -2.5) = 0.9938</code></pre>
<pre><code>## </code></pre>
<p><img src="Redoing_files/figure-html/ch04-pnorm-01-1.png" width="65%" /></p>
<pre><code>## [1] 0.00621</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>What is <span class="math inline">\(\operatorname{Pr}(5 \le X \le 10)\)</span>?</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pnorm</span>(<span class="dv">10</span>, <span class="dt">mean =</span> <span class="dv">10</span>, <span class="dt">sd =</span> <span class="dv">2</span>) <span class="op">-</span><span class="st"> </span><span class="kw">pnorm</span>(<span class="dv">5</span>, <span class="dt">mean =</span> <span class="dv">10</span>, <span class="dt">sd =</span> <span class="dv">2</span>)</code></pre>
<pre><code>## [1] 0.4938</code></pre>
<ol start="3" style="list-style-type: decimal">
<li><p>How tall is the density function at it’s peak?</p>
<p>Normal distributions are symmetric about their means, so we need the
value of the pdf at 10.</p></li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dnorm</span>(<span class="dv">10</span>, <span class="dt">mean =</span> <span class="dv">10</span>, <span class="dt">sd =</span> <span class="dv">2</span>)</code></pre>
<pre><code>## [1] 0.1995</code></pre>
<ol start="4" style="list-style-type: decimal">
<li><p>What is the mean of a Norm(10, 2) distribution?</p>
<p>Ignoring for the moment that we know the answer is 10, we can compute it.
Notice the use of <code>dnorm()</code> in the computation.</p></li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">integrate</span>(<span class="cf">function</span>(x) x <span class="op">*</span><span class="st"> </span><span class="kw">dnorm</span>(x, <span class="dt">mean =</span> <span class="dv">10</span>, <span class="dt">sd =</span> <span class="dv">2</span>), <span class="op">-</span><span class="ot">Inf</span>, <span class="ot">Inf</span>)</code></pre>
<pre><code>## 10 with absolute error &lt; 0.0011</code></pre>
<ol start="5" style="list-style-type: decimal">
<li><p>What is the variance of a Norm(10, 2) distribution?</p>
<p>Again, we know the answer is the square of the standard deviation, so 4.
But let’s get R to compute it in a way that would work for other distributions
as well.</p></li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">integrate</span>(<span class="cf">function</span>(x) (x <span class="op">-</span><span class="st"> </span><span class="dv">10</span>)<span class="op">^</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">dnorm</span>(x, <span class="dt">mean =</span> <span class="dv">10</span>, <span class="dt">sd =</span> <span class="dv">2</span>), <span class="op">-</span><span class="ot">Inf</span>, <span class="ot">Inf</span>)</code></pre>
<pre><code>## 4 with absolute error &lt; 7.1e-05</code></pre>
<ol start="6" style="list-style-type: decimal">
<li>Simulate a data set with 50 values drawn from a <span class="math inline">\({\sf Norm}(10, 2)\)</span>
distribution and make a histogram of the results and overlay the
normal pdf for comparison.</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">50</span>, <span class="dt">mean =</span> <span class="dv">10</span>, <span class="dt">sd =</span> <span class="dv">2</span>)
<span class="co"># be sure to use a density histogram so it is on the same scale as the pdf!</span>
<span class="kw">gf_dhistogram</span>(<span class="op">~</span><span class="st"> </span>x, <span class="dt">bins =</span> <span class="dv">10</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gf_dist</span>(<span class="st">&quot;norm&quot;</span>, <span class="dt">mean =</span> <span class="dv">10</span>, <span class="dt">sd =</span> <span class="dv">2</span>, <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>)</code></pre>
<p><img src="Redoing_files/figure-html/ch04-rnorm-1.png" width="65%" /></p>
</div>
<div id="simulating-running-proportions" class="section level3">
<h3><span class="header-section-number">4.2.2</span> Simulating running proportions</h3>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggformula)
<span class="kw">library</span>(dplyr)
<span class="kw">theme_set</span>(<span class="kw">theme_bw</span>())
Flips &lt;-
<span class="st">  </span><span class="kw">tibble</span>(
    <span class="dt">n =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">500</span>,
    <span class="dt">flip =</span> <span class="kw">rbinom</span>(<span class="dv">500</span>, <span class="dv">1</span>, <span class="fl">0.5</span>),
    <span class="dt">running_count =</span> <span class="kw">cumsum</span>(flip),
    <span class="dt">running_prop  =</span> running_count <span class="op">/</span><span class="st"> </span>n
  )

<span class="kw">gf_line</span>(
  running_prop <span class="op">~</span><span class="st"> </span>n, <span class="dt">data =</span> Flips, 
  <span class="dt">color =</span> <span class="st">&quot;skyblue&quot;</span>,
  <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">1.0</span>), 
  <span class="dt">xlab =</span> <span class="st">&quot;Flip Number&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Proportion Heads&quot;</span>, 
  <span class="dt">main =</span> <span class="st">&quot;Running Proportion of Heads&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gf_hline</span>(<span class="dt">yintercept =</span> <span class="fl">0.5</span>, <span class="dt">linetype =</span> <span class="st">&quot;dotted&quot;</span>)</code></pre>
<p><img src="Redoing_files/figure-html/ch04-simulation-1.png" width="65%" /></p>

</div>
</div>
<div id="joint-marginal-and-conditional-distributions" class="section level2">
<h2><span class="header-section-number">4.3</span> Joint, marginal, and conditional distributions</h2>
<p>Sometimes (most of the time, actually) we are interested joint distributions.
A joint distribution is the distribution of multiple random variables
that result from the same random process. For example, we might roll a pair
of dice and obtain two numbers (one for each die). Or we might collect
a random sample of people and record the height for each of them. Or we might
randomly select one person, but record multiple facts (height and weight, for example). All of these situations are covered by joint distributions.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
<div id="example-hair-and-eye-color" class="section level3">
<h3><span class="header-section-number">4.3.1</span> Example: Hair and eye color</h3>
<p>Kruschke illustrates joint distributions with an example of hair and eye color
recorded for a number of people. <a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> That table below has the proportions
for each hair/eye color combination.
For example,</p>
<!-- Hair/Eyes | Blue  | Green | Hazel | Brown -->
<!-- ---------:|:-----:|:-----:|:-----:|:------: -->
<!-- Black     | 20  | 5      | 15  | 68 -->
<!-- Blond      | 94    | 16    | 10    | 7 -->
<!-- Brown      | 84    | 29    | 54    | 119 -->
<!-- Red          | 17  | 14    | 14    | 26 -->
<table>
<thead>
<tr class="header">
<th align="right">Hair/Eyes</th>
<th align="center">Blue</th>
<th align="center">Green</th>
<th align="center">Hazel</th>
<th align="center">Brown</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">Black</td>
<td align="center">0.034</td>
<td align="center">0.115</td>
<td align="center">0.008</td>
<td align="center">0.025</td>
</tr>
<tr class="even">
<td align="right">Blond</td>
<td align="center">0.159</td>
<td align="center">0.012</td>
<td align="center">0.027</td>
<td align="center">0.017</td>
</tr>
<tr class="odd">
<td align="right">Brown</td>
<td align="center">0.142</td>
<td align="center">0.201</td>
<td align="center">0.049</td>
<td align="center">0.091</td>
</tr>
<tr class="even">
<td align="right">Red</td>
<td align="center">0.029</td>
<td align="center">0.044</td>
<td align="center">0.024</td>
<td align="center">0.024</td>
</tr>
</tbody>
</table>
<p>Each value in the table indicates the proportion
of people that have a particular hair color <em>and</em>
a particular eye color. So the upper left
cell says that 3.4% of people
have black hair and blue eyes
(in this particular
sample – the proportions will vary a lot depending
on the population of interest).
We will denote this as</p>
<p><span class="math display">\[
\operatorname{Pr}(\mathrm{Hair} = \mathrm{black}, \mathrm{Eyes} = \mathrm{blue}) = 0.034 \;.
\]</span>
or more succinctly as
<span class="math display">\[
p(\mathrm{black}, \mathrm{blue}) = 0.034 \;.
\]</span>
This type of probability is called a <strong>joint probability</strong>
because it tells about the probability of <strong>both</strong> things
happening.</p>
<p>Use the table above to do the following.</p>
<ol style="list-style-type: decimal">
<li><p>What is <span class="math inline">\(p(\mathrm{brown}, \mathrm{green})\)</span> and what
does that number mean?</p></li>
<li><p>Add the proportion across each row and down each column.
(Record them to the right and along the bottom of the table.)
For example, in the first row we get
<span class="math display">\[
0.034 + 0.115 + 0.008 + 0.025 =  
0.182 \;.
\]</span></p>
<ol style="list-style-type: lower-alpha">
<li>Explain why
<span class="math inline">\(p(\mathrm{black}) = 0.182\)</span>
is good notation for this number.</li>
</ol></li>
<li><p>Up to round-off error, the total of all the
proportions should be 1. Check that this is true.</p></li>
<li><p>What proportion of people with black hair have
blue eyes?</p>
<p>This is called a conditional probability. We denote it
as
<span class="math inline">\(\operatorname{Pr}(\mathrm{Eyes} = \mathrm{blue} \mid \mathrm{Hair} = \mathrm{black})\)</span>.
or
<span class="math inline">\(p(\mathrm{blue} \mid \mathrm{black})\)</span>.</p></li>
<li><p>Compute some other conditional probabilities.</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(p(\mathrm{black} \mid \mathrm{blue})\)</span>.</li>
<li><span class="math inline">\(p(\mathrm{blue} \mid \mathrm{blond})\)</span>.</li>
<li><span class="math inline">\(p(\mathrm{blond} \mid \mathrm{blue})\)</span>.</li>
<li><span class="math inline">\(p(\mathrm{brown} \mid \mathrm{hazel})\)</span>.</li>
<li><span class="math inline">\(p(\mathrm{hazel} \mid \mathrm{brown})\)</span>.</li>
</ol></li>
<li><p>There are 32 such conditional probabilities that we can
compute from this table. Which is largest? Which is smallest?</p></li>
<li><p>Write a general formula for computing the
conditional probability
<span class="math inline">\(p(c \mid r)\)</span> from the <span class="math inline">\(p(r,c)\)</span> values.
(<span class="math inline">\(r\)</span> and <span class="math inline">\(c\)</span> are to remind you of rows and columns.)</p></li>
<li><p>Write a general formula for computing the
conditional probability
<span class="math inline">\(p(r \mid c)\)</span> from the <span class="math inline">\(p(r,c)\)</span> values.</p></li>
</ol>
<p>If we have continuous random variables, we can do a similar
thing. Instead of working with probability, we will
work with a pdf. Instead of sums, we will have integrals.</p>
<ol start="8" style="list-style-type: decimal">
<li><p>Write a general formula for computing each of the following
if <span class="math inline">\(p(x,y)\)</span> is a continuous joint pdf.</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(p_X(x) = p(x) =\)</span></li>
<li><span class="math inline">\(p_Y(y) = p(y) =\)</span></li>
<li><span class="math inline">\(p_{Y\mid X}(y\mid x) = p(y \mid x) =\)</span></li>
<li><span class="math inline">\(p_{X\mid Y}(y\mid x) = (x \mid y) =\)</span></li>
</ol></li>
<li><p>We can expression both versions of conditional probability
using a word equation. Fill in the missing numerator and
denominator</p></li>
</ol>
<p><span class="math display">\[
\mathrm{conditional} = \frac{\phantom{joint}}{\phantom{marginal}}
\]</span></p>
</div>
<div id="independence" class="section level3">
<h3><span class="header-section-number">4.3.2</span> Independence</h3>
<p>If <span class="math inline">\(p(x \mid y) = p(x)\)</span> (conditional = marginal)
for all combinations of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, we say that
<span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are <strong>independent</strong>.</p>
<ol start="10" style="list-style-type: decimal">
<li><p>Use the definitions above to express independence another way.</p></li>
<li><p>Are hair and eye color independent in our example?</p></li>
<li><p>True or False. If we randomly select a card from
a standard deck (52 cards, 13 denominations, 4 suits),
are suit and denomination independent?</p></li>
<li><p>Create a table for two independent random variables
<span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, each of which takes on only 3 possible values.</p></li>
<li><p>Now create a table for a different pair <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>
that are not independent but have the same marginal probabilities
as in the previous exercise.</p></li>
</ol>
</div>
</div>
<div id="ch04-exercises" class="section level2">
<h2><span class="header-section-number">4.4</span> Exercises</h2>
<!-- similar to Kruschke2-4.4     -->
<ol style="list-style-type: decimal">
<li>Suppose a random variable has the pdf <span class="math inline">\(p(x) = 6x (1-x)\)</span> on the interval
<span class="math inline">\([0,1]\)</span>. (That means it is 0 outside of that interval.)
<ol style="list-style-type: lower-alpha">
<li>Use <code>function()</code> to create a function in R that is equivalent to <code>p(x)</code>.</li>
<li>Use <code>gf_function()</code> to plot the function on the interval <span class="math inline">\([0, 1]\)</span>.</li>
<li>Integrate by hand to show that the total area under the pdf is 1
(as it should be for any pdf).</li>
<li>Now have R compute that same integral (using <code>integrate()</code>).</li>
<li><p>What is the largest value of <span class="math inline">\(p(x)\)</span>? At what value of <span class="math inline">\(x\)</span> does it occur?
Is it a problem that this value is larger than 1?</p>
<p>Hint: differentiation might be useful.</p></li>
</ol></li>
<li>Recall that
<span class="math inline">\(\operatorname{E}(X) = \int x f(x) \;dx\)</span> for a continuous random variable with pdf <span class="math inline">\(f\)</span> and
<span class="math inline">\(\operatorname{E}(X) = \sum x f(x) \;dx\)</span> for a discrete random variable with pmf <span class="math inline">\(f\)</span>. (The
integral or sum is over the support of the random variable.) Compute
the expected value for the following random variables.
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(A\)</span> is discrete with pmf <span class="math inline">\(f(x) = x/10\)</span> for <span class="math inline">\(x \in \{1, 2, 3, 4\}\)</span>.</li>
<li><p><span class="math inline">\(B\)</span> is continuous with kernel <span class="math inline">\(f(x) = x^2(1-x)\)</span> on <span class="math inline">\([0, 1]\)</span>.</p>
<p>Hint: first figure out what the pdf is.</p></li>
</ol></li>
<li>Compute the variance and standard deviation
of each of the distributions in the previous problem.</li>
</ol>
<!-- similar to Kruschke2-4.5     -->
<ol start="4" style="list-style-type: decimal">
<li><p>In Bayesian inference, we will often need to come up with a distribution
that matches certain features that correspond to our knowledge or intuition about
a situation. Find a normal distribution with a mean of 10 such that half of the
distribution is within 3 of 10 (ie, between 7 and 13).</p>
<p>Hint: use <code>qnorm()</code> to determine how many standard deviations are between 10 and 7.</p></li>
</ol>
<!-- Kruschke2-4.6     -->
<ol start="5" style="list-style-type: decimal">
<li><p>School children were surveyed regarding their favorite foods. Of the total
sample, 20% were 1st graders, 20% were 6th graders, and 60% were 11th graders.
For each grade, the following table shows the proportion of respondents that
chose each of three foods as their favorite.</p>
<ol style="list-style-type: lower-alpha">
<li><p>From that information, construct a table of joint probabilities of grade and favorite food.</p></li>
<li><p>Are grade and favorite food independent? Explain how you ascertained the answer.</p>
<table>
<thead>
<tr class="header">
<th align="center">grade</th>
<th align="center">Ice cream</th>
<th align="center">Fruit</th>
<th align="center">French fries</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1st</td>
<td align="center">0.3</td>
<td align="center">0.6</td>
<td align="center">0.1</td>
</tr>
<tr class="even">
<td align="center">6th</td>
<td align="center">0.6</td>
<td align="center">0.3</td>
<td align="center">0.1</td>
</tr>
<tr class="odd">
<td align="center">11th</td>
<td align="center">0.3</td>
<td align="center">0.1</td>
<td align="center">0.6</td>
</tr>
</tbody>
</table></li>
</ol></li>
</ol>
<!-- 
Hint: You are given p(grade) and p(food|grade). 
You need to determine p(grade,food). -->
<ol start="6" style="list-style-type: decimal">
<li><p>Three cards are placed in a hat. One is black on both sides, one is white on both sides, and the third is white on one side and black on the other. One card is selected at random from the three cards in the hat and placed on the table.<br />
The top of the card is black.</p>
<ol style="list-style-type: lower-alpha">
<li>What is the probability that the bottom is also black?</li>
<li>What notation should we use for this probability?</li>
</ol></li>
<li><p>The three cards from the previous problem are returned to the hat.
Once again a card is pulled and placed on the table, and once again the top
is black. This time a second card is drawn and placed on the table. The
top side of the second card is white.</p>
<ol style="list-style-type: lower-alpha">
<li>What is the probability that the bottom side of the first card is black?</li>
<li>What is the probability that the bottom side of the second card is black?</li>
<li>What is the probability that the bottom side of both cards is black?</li>
</ol></li>
<li><p><strong>Pandas.</strong>
Suppose there are two species of panda, A and B. Without a special blood
test, it is not possible to tell them apart. But it is known that half of
pandas are of each species and that 10% of births from species A are twins and
20% of births from species B are twins.</p>
<ol style="list-style-type: lower-alpha">
<li><p>If a female panda has twins, what is the probability that she is
from species A?</p></li>
<li><p>If the same panda later has another set of twins, what is the probability
that she is from species A?</p></li>
<li><p>A different panda has twins and a year later gives birth to a single panda.
What is the probability that this panda is from species A?</p></li>
</ol></li>
<li><p><strong>More Pandas.</strong>
You get more interested in pandas and learn that at your favorite zoo,
70% of pandas are species A and 30% are species B. You learn that one of the
pandas has twins.</p>
<ol style="list-style-type: lower-alpha">
<li><p>What is the probability that the panda is species A?</p></li>
<li><p>The same panda has a single panda the next year. Now what is the probability
that the species is A?</p></li>
</ol></li>
</ol>
</div>
<div id="footnotes-2" class="section level2">
<h2><span class="header-section-number">4.5</span> Footnotes</h2>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="2">
<li id="fn2"><p>Kruschke likes to write his integrals in a different order: <span class="math inline">\(\int dx \; f(x)\)</span>
instead of <span class="math inline">\(\int f(x) \; dx\)</span>. Either order means the same thing.<a href="probability.html#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>Kruschke calls these 2-way distributions, but there can be more than variables
involved.<a href="probability.html#fnref3" class="footnote-back">↩</a></p></li>
<li id="fn4"><p>The datasets package has a version of this data with a third
variable: <code>sex</code>. (It is as a 3d table rather than as a data frame). According
to the help for this data set, these data come from
“a survey of students at the University of Delaware reported by Snee (1974).
The split by Sex was added by Friendly (1992a) for didactic purposes.”
It isn’t exactly clear what population this might represent<a href="probability.html#fnref4" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="some-useful-bits-of-r.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bayes-rule-and-the-grid-method.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["Redoing.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
