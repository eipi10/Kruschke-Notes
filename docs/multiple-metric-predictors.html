<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>18 Multiple Metric Predictors | (Re)Doing Bayesain Data Analysis</title>
  <meta name="description" content="Code, exercises and discussion to accompany a course taught from Kruschke’s Doing Bayesian Data Analysis (2ed)">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="18 Multiple Metric Predictors | (Re)Doing Bayesain Data Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Code, exercises and discussion to accompany a course taught from Kruschke’s Doing Bayesian Data Analysis (2ed)" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="18 Multiple Metric Predictors | (Re)Doing Bayesain Data Analysis" />
  
  <meta name="twitter:description" content="Code, exercises and discussion to accompany a course taught from Kruschke’s Doing Bayesian Data Analysis (2ed)" />
  

<meta name="author" content="R Pruim">


<meta name="date" content="2019-04-24">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="simple-linear-regression.html">
<link rel="next" href="nominal-predictors.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">(Re)Doing Bayesian Data Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> What’s in These Notes</a></li>
<li class="part"><span><b>I The Basics: Models, Probability, Bayes, and R</b></span></li>
<li class="chapter" data-level="2" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html"><i class="fa fa-check"></i><b>2</b> Credibility, Models, and Parameters</a><ul>
<li class="chapter" data-level="2.1" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#the-steps-of-bayesian-data-analysis"><i class="fa fa-check"></i><b>2.1</b> The Steps of Bayesian Data Analysis</a><ul>
<li class="chapter" data-level="2.1.1" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#r-code"><i class="fa fa-check"></i><b>2.1.1</b> R code</a></li>
<li class="chapter" data-level="2.1.2" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#r-packages"><i class="fa fa-check"></i><b>2.1.2</b> R packages</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#example-1-which-coin-is-it"><i class="fa fa-check"></i><b>2.2</b> Example 1: Which coin is it?</a><ul>
<li class="chapter" data-level="2.2.1" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#freedom-of-choice"><i class="fa fa-check"></i><b>2.2.1</b> Freedom of choice</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#distributions"><i class="fa fa-check"></i><b>2.3</b> Distributions</a><ul>
<li class="chapter" data-level="2.3.1" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#beta-distributions"><i class="fa fa-check"></i><b>2.3.1</b> Beta distributions</a></li>
<li class="chapter" data-level="2.3.2" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#normal-distributions"><i class="fa fa-check"></i><b>2.3.2</b> Normal distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#example-2-height-vs-weight"><i class="fa fa-check"></i><b>2.4</b> Example 2: Height vs Weight</a><ul>
<li class="chapter" data-level="2.4.1" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#data"><i class="fa fa-check"></i><b>2.4.1</b> Data</a></li>
<li class="chapter" data-level="2.4.2" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#describing-a-model-for-the-relationship-between-height-and-weight"><i class="fa fa-check"></i><b>2.4.2</b> Describing a model for the relationship between height and weight</a></li>
<li class="chapter" data-level="2.4.3" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#prior"><i class="fa fa-check"></i><b>2.4.3</b> Prior</a></li>
<li class="chapter" data-level="2.4.4" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#posterior"><i class="fa fa-check"></i><b>2.4.4</b> Posterior</a></li>
<li class="chapter" data-level="2.4.5" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#posterior-predictive-check"><i class="fa fa-check"></i><b>2.4.5</b> Posterior Predictive Check</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#where-do-we-go-from-here"><i class="fa fa-check"></i><b>2.5</b> Where do we go from here?</a></li>
<li class="chapter" data-level="2.6" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#ch02-exercises"><i class="fa fa-check"></i><b>2.6</b> Exercises</a></li>
<li class="chapter" data-level="2.7" data-path="credibility-models-and-parameters.html"><a href="credibility-models-and-parameters.html#footnotes"><i class="fa fa-check"></i><b>2.7</b> Footnotes</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html"><i class="fa fa-check"></i><b>3</b> Some Useful Bits of R</a><ul>
<li class="chapter" data-level="3.1" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#style-guide"><i class="fa fa-check"></i><b>3.1</b> You Gotta Have Style</a><ul>
<li class="chapter" data-level="3.1.1" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#an-additional-note-about-homework"><i class="fa fa-check"></i><b>3.1.1</b> An additional note about homework</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#vectors-lists-and-data-frames"><i class="fa fa-check"></i><b>3.2</b> Vectors, Lists, and Data Frames</a><ul>
<li class="chapter" data-level="3.2.1" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#vectors"><i class="fa fa-check"></i><b>3.2.1</b> Vectors</a></li>
<li class="chapter" data-level="3.2.2" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#lists"><i class="fa fa-check"></i><b>3.2.2</b> Lists</a></li>
<li class="chapter" data-level="3.2.3" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#data-frames-for-rectangular-data"><i class="fa fa-check"></i><b>3.2.3</b> Data frames for rectangular data</a></li>
<li class="chapter" data-level="3.2.4" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#other-types-of-data"><i class="fa fa-check"></i><b>3.2.4</b> Other types of data</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#plotting-with-ggformula"><i class="fa fa-check"></i><b>3.3</b> Plotting with ggformula</a></li>
<li class="chapter" data-level="3.4" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#creating-data-with-expand.grid"><i class="fa fa-check"></i><b>3.4</b> Creating data with expand.grid()</a></li>
<li class="chapter" data-level="3.5" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#transforming-and-summarizing-data-dplyr-and-tidyr"><i class="fa fa-check"></i><b>3.5</b> Transforming and summarizing data dplyr and tidyr</a></li>
<li class="chapter" data-level="3.6" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#writing-functions"><i class="fa fa-check"></i><b>3.6</b> Writing Functions</a><ul>
<li class="chapter" data-level="3.6.1" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#why-write-functions"><i class="fa fa-check"></i><b>3.6.1</b> Why write functions?</a></li>
<li class="chapter" data-level="3.6.2" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#function-parts"><i class="fa fa-check"></i><b>3.6.2</b> Function parts</a></li>
<li class="chapter" data-level="3.6.3" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#the-function-function-has-its-function"><i class="fa fa-check"></i><b>3.6.3</b> The function() function has its function</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#some-common-error-messages"><i class="fa fa-check"></i><b>3.7</b> Some common error messages</a><ul>
<li class="chapter" data-level="3.7.1" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#object-not-found"><i class="fa fa-check"></i><b>3.7.1</b> object not found</a></li>
<li class="chapter" data-level="3.7.2" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#any-message-mentioning-yaml"><i class="fa fa-check"></i><b>3.7.2</b> Any message mentioning yaml</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#ch03-exercises"><i class="fa fa-check"></i><b>3.8</b> Exercises</a></li>
<li class="chapter" data-level="3.9" data-path="some-useful-bits-of-r.html"><a href="some-useful-bits-of-r.html#footnotes-1"><i class="fa fa-check"></i><b>3.9</b> Footnotes</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>4</b> Probability</a><ul>
<li class="chapter" data-level="4.1" data-path="probability.html"><a href="probability.html#some-terminology"><i class="fa fa-check"></i><b>4.1</b> Some terminology</a></li>
<li class="chapter" data-level="4.2" data-path="probability.html"><a href="probability.html#distributions-in-r"><i class="fa fa-check"></i><b>4.2</b> Distributions in R</a><ul>
<li class="chapter" data-level="4.2.1" data-path="probability.html"><a href="probability.html#example-normal-distributions"><i class="fa fa-check"></i><b>4.2.1</b> Example: Normal distributions</a></li>
<li class="chapter" data-level="4.2.2" data-path="probability.html"><a href="probability.html#simulating-running-proportions"><i class="fa fa-check"></i><b>4.2.2</b> Simulating running proportions</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="probability.html"><a href="probability.html#joint-marginal-and-conditional-distributions"><i class="fa fa-check"></i><b>4.3</b> Joint, marginal, and conditional distributions</a><ul>
<li class="chapter" data-level="4.3.1" data-path="probability.html"><a href="probability.html#example-hair-and-eye-color"><i class="fa fa-check"></i><b>4.3.1</b> Example: Hair and eye color</a></li>
<li class="chapter" data-level="4.3.2" data-path="probability.html"><a href="probability.html#independence"><i class="fa fa-check"></i><b>4.3.2</b> Independence</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="probability.html"><a href="probability.html#ch04-exercises"><i class="fa fa-check"></i><b>4.4</b> Exercises</a></li>
<li class="chapter" data-level="4.5" data-path="probability.html"><a href="probability.html#footnotes-2"><i class="fa fa-check"></i><b>4.5</b> Footnotes</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html"><i class="fa fa-check"></i><b>5</b> Bayes’ Rule and the Grid Method</a><ul>
<li class="chapter" data-level="5.1" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#the-big-bayesian-idea"><i class="fa fa-check"></i><b>5.1</b> The Big Bayesian Idea</a><ul>
<li class="chapter" data-level="5.1.1" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#likelihood"><i class="fa fa-check"></i><b>5.1.1</b> Likelihood</a></li>
<li class="chapter" data-level="5.1.2" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#when-bayes-is-easy"><i class="fa fa-check"></i><b>5.1.2</b> When Bayes is easy</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#estimating-the-bias-in-a-coin-using-the-grid-method"><i class="fa fa-check"></i><b>5.2</b> Estimating the bias in a coin using the Grid Method</a><ul>
<li class="chapter" data-level="5.2.1" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#creating-a-grid"><i class="fa fa-check"></i><b>5.2.1</b> Creating a Grid</a></li>
<li class="chapter" data-level="5.2.2" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#hdi-from-the-grid"><i class="fa fa-check"></i><b>5.2.2</b> HDI from the grid</a></li>
<li class="chapter" data-level="5.2.3" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#automating-the-grid"><i class="fa fa-check"></i><b>5.2.3</b> Automating the grid</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#working-on-the-log-scale"><i class="fa fa-check"></i><b>5.3</b> Working on the log scale</a></li>
<li class="chapter" data-level="5.4" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#discrete-params"><i class="fa fa-check"></i><b>5.4</b> Discrete Parameters</a></li>
<li class="chapter" data-level="5.5" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#ch05-exercises"><i class="fa fa-check"></i><b>5.5</b> Exercises</a></li>
<li class="chapter" data-level="5.6" data-path="bayes-rule-and-the-grid-method.html"><a href="bayes-rule-and-the-grid-method.html#footnotes-3"><i class="fa fa-check"></i><b>5.6</b> Footnotes</a></li>
</ul></li>
<li class="part"><span><b>II Inferring a Binomial Probability</b></span></li>
<li class="chapter" data-level="6" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><i class="fa fa-check"></i><b>6</b> Inferring a Binomial Probability via Exact Mathematical Analysis</a><ul>
<li class="chapter" data-level="6.1" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#beta-distributions-1"><i class="fa fa-check"></i><b>6.1</b> Beta distributions</a></li>
<li class="chapter" data-level="6.2" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#beta-and-bayes"><i class="fa fa-check"></i><b>6.2</b> Beta and Bayes</a><ul>
<li class="chapter" data-level="6.2.1" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#the-bernoulli-likelihood-function"><i class="fa fa-check"></i><b>6.2.1</b> The Bernoulli likelihood function</a></li>
<li class="chapter" data-level="6.2.2" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#a-convenient-prior"><i class="fa fa-check"></i><b>6.2.2</b> A convenient prior</a></li>
<li class="chapter" data-level="6.2.3" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#pros-and-cons-of-conjugate-priors"><i class="fa fa-check"></i><b>6.2.3</b> Pros and Cons of conjugate priors</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#getting-to-know-the-beta-distributions"><i class="fa fa-check"></i><b>6.3</b> Getting to know the Beta distributions</a><ul>
<li class="chapter" data-level="6.3.1" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#important-facts"><i class="fa fa-check"></i><b>6.3.1</b> Important facts</a></li>
<li class="chapter" data-level="6.3.2" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#alternative-parameterizations-of-beta-distributions"><i class="fa fa-check"></i><b>6.3.2</b> Alternative parameterizations of Beta distributions</a></li>
<li class="chapter" data-level="6.3.3" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#beta_params"><i class="fa fa-check"></i><b>6.3.3</b> beta_params()</a></li>
<li class="chapter" data-level="6.3.4" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#automating-bayesian-updates-for-a-proportion-beta-prior"><i class="fa fa-check"></i><b>6.3.4</b> Automating Bayesian updates for a proportion (beta prior)</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#what-if-the-prior-isnt-a-beta-distribution"><i class="fa fa-check"></i><b>6.4</b> What if the prior isn’t a beta distribution?</a></li>
<li class="chapter" data-level="6.5" data-path="inferring-a-binomial-probability-via-exact-mathematical-analysis.html"><a href="inferring-a-binomial-probability-via-exact-mathematical-analysis.html#ch06-exercises"><i class="fa fa-check"></i><b>6.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html"><i class="fa fa-check"></i><b>7</b> Markov Chain Monte Carlo (MCMC)</a><ul>
<li class="chapter" data-level="7.1" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#king-markov-and-adviser-metropolis"><i class="fa fa-check"></i><b>7.1</b> King Markov and Adviser Metropolis</a></li>
<li class="chapter" data-level="7.2" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#quick-intro-to-markov-chains"><i class="fa fa-check"></i><b>7.2</b> Quick Intro to Markov Chains</a><ul>
<li class="chapter" data-level="7.2.1" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#more-info-please"><i class="fa fa-check"></i><b>7.2.1</b> More info, please</a></li>
<li class="chapter" data-level="7.2.2" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#definition"><i class="fa fa-check"></i><b>7.2.2</b> Definition</a></li>
<li class="chapter" data-level="7.2.3" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#time-homogeneous-markov-chains"><i class="fa fa-check"></i><b>7.2.3</b> Time-Homogeneous Markov Chains</a></li>
<li class="chapter" data-level="7.2.4" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#matrix-representation"><i class="fa fa-check"></i><b>7.2.4</b> Matrix representation</a></li>
<li class="chapter" data-level="7.2.5" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#regular-markov-chains"><i class="fa fa-check"></i><b>7.2.5</b> Regular Markov Chains</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#back-to-king-markov"><i class="fa fa-check"></i><b>7.3</b> Back to King Markov</a></li>
<li class="chapter" data-level="7.4" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#how-well-does-the-metropolis-algorithm-work"><i class="fa fa-check"></i><b>7.4</b> How well does the Metropolis Algorithm work?</a><ul>
<li class="chapter" data-level="7.4.1" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#jumping-to-any-island"><i class="fa fa-check"></i><b>7.4.1</b> Jumping to any island</a></li>
<li class="chapter" data-level="7.4.2" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#jumping-only-to-neighbor-islands"><i class="fa fa-check"></i><b>7.4.2</b> Jumping only to neighbor islands</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#markov-chains-and-posterior-sampling"><i class="fa fa-check"></i><b>7.5</b> Markov Chains and Posterior Sampling</a><ul>
<li class="chapter" data-level="7.5.1" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#example-1-estimating-a-proportion"><i class="fa fa-check"></i><b>7.5.1</b> Example 1: Estimating a proportion</a></li>
<li class="chapter" data-level="7.5.2" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#example-2-estimating-mean-and-variance"><i class="fa fa-check"></i><b>7.5.2</b> Example 2: Estimating mean and variance</a></li>
<li class="chapter" data-level="7.5.3" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#issues-with-metropolis-algorithm"><i class="fa fa-check"></i><b>7.5.3</b> Issues with Metropolis Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#two-coins"><i class="fa fa-check"></i><b>7.6</b> Two coins</a><ul>
<li class="chapter" data-level="7.6.1" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#the-model"><i class="fa fa-check"></i><b>7.6.1</b> The model</a></li>
<li class="chapter" data-level="7.6.2" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#exact-analysis"><i class="fa fa-check"></i><b>7.6.2</b> Exact analysis</a></li>
<li class="chapter" data-level="7.6.3" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#metropolis"><i class="fa fa-check"></i><b>7.6.3</b> Metropolis</a></li>
<li class="chapter" data-level="7.6.4" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#gibbs-sampling"><i class="fa fa-check"></i><b>7.6.4</b> Gibbs sampling</a></li>
<li class="chapter" data-level="7.6.5" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#advantages-and-disadvantages-of-gibbs-vs-metropolis"><i class="fa fa-check"></i><b>7.6.5</b> Advantages and Disadvantages of Gibbs vs Metropolis</a></li>
<li class="chapter" data-level="7.6.6" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#so-what-do-we-learn-about-the-coins"><i class="fa fa-check"></i><b>7.6.6</b> So what do we learn about the coins?</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#mcmc-posterior-sampling-big-picture"><i class="fa fa-check"></i><b>7.7</b> MCMC posterior sampling: Big picture</a><ul>
<li class="chapter" data-level="7.7.1" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#mcmc-markov-chain-monte-carlo"><i class="fa fa-check"></i><b>7.7.1</b> MCMC = Markov chain Monte Carlo</a></li>
<li class="chapter" data-level="7.7.2" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#posterior-sampling-random-walk-through-the-posterior"><i class="fa fa-check"></i><b>7.7.2</b> Posterior sampling: Random walk through the posterior</a></li>
<li class="chapter" data-level="7.7.3" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#where-do-we-go-from-here-1"><i class="fa fa-check"></i><b>7.7.3</b> Where do we go from here?</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="markov-chain-monte-carlo-mcmc.html"><a href="markov-chain-monte-carlo-mcmc.html#ch07-exercises"><i class="fa fa-check"></i><b>7.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html"><i class="fa fa-check"></i><b>8</b> JAGS – Just Another Gibbs Sampler</a><ul>
<li class="chapter" data-level="8.1" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#what-jags-is"><i class="fa fa-check"></i><b>8.1</b> What JAGS is</a><ul>
<li class="chapter" data-level="8.1.1" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#jags-documentation"><i class="fa fa-check"></i><b>8.1.1</b> JAGS documentation</a></li>
<li class="chapter" data-level="8.1.2" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#updating-c-and-clang"><i class="fa fa-check"></i><b>8.1.2</b> Updating C and CLANG</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#example-1-estimating-a-proportion-1"><i class="fa fa-check"></i><b>8.2</b> Example 1: estimating a proportion</a><ul>
<li class="chapter" data-level="8.2.1" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#the-model-1"><i class="fa fa-check"></i><b>8.2.1</b> The Model</a></li>
<li class="chapter" data-level="8.2.2" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#load-data"><i class="fa fa-check"></i><b>8.2.2</b> Load Data</a></li>
<li class="chapter" data-level="8.2.3" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#specify-the-model"><i class="fa fa-check"></i><b>8.2.3</b> Specify the model</a></li>
<li class="chapter" data-level="8.2.4" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#run-the-model"><i class="fa fa-check"></i><b>8.2.4</b> Run the model</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#extracting-information-from-a-jags-run"><i class="fa fa-check"></i><b>8.3</b> Extracting information from a JAGS run</a><ul>
<li class="chapter" data-level="8.3.1" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#posterior-1"><i class="fa fa-check"></i><b>8.3.1</b> posterior()</a></li>
<li class="chapter" data-level="8.3.2" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#side-note-posterior-sampling-and-the-grid-method"><i class="fa fa-check"></i><b>8.3.2</b> Side note: posterior sampling and the grid method</a></li>
<li class="chapter" data-level="8.3.3" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#using-coda"><i class="fa fa-check"></i><b>8.3.3</b> Using coda</a></li>
<li class="chapter" data-level="8.3.4" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#using-bayesplot"><i class="fa fa-check"></i><b>8.3.4</b> Using bayesplot</a></li>
<li class="chapter" data-level="8.3.5" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#using-kruschkes-functions"><i class="fa fa-check"></i><b>8.3.5</b> Using Kruschke’s functions</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#optional-arguments-to-jags"><i class="fa fa-check"></i><b>8.4</b> Optional arguments to jags()</a><ul>
<li class="chapter" data-level="8.4.1" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#number-and-size-of-chains"><i class="fa fa-check"></i><b>8.4.1</b> Number and size of chains</a></li>
<li class="chapter" data-level="8.4.2" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#starting-point-for-chains"><i class="fa fa-check"></i><b>8.4.2</b> Starting point for chains</a></li>
<li class="chapter" data-level="8.4.3" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#running-chains-in-parallel"><i class="fa fa-check"></i><b>8.4.3</b> Running chains in parallel</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#example-2-comparing-two-proportions"><i class="fa fa-check"></i><b>8.5</b> Example 2: comparing two proportions</a><ul>
<li class="chapter" data-level="8.5.1" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#the-data"><i class="fa fa-check"></i><b>8.5.1</b> The data</a></li>
<li class="chapter" data-level="8.5.2" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#the-model-2"><i class="fa fa-check"></i><b>8.5.2</b> The model</a></li>
<li class="chapter" data-level="8.5.3" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#describing-the-model-to-jags"><i class="fa fa-check"></i><b>8.5.3</b> Describing the model to JAGS</a></li>
<li class="chapter" data-level="8.5.4" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#fitting-the-model"><i class="fa fa-check"></i><b>8.5.4</b> Fitting the model</a></li>
<li class="chapter" data-level="8.5.5" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#inspecting-the-results"><i class="fa fa-check"></i><b>8.5.5</b> Inspecting the results</a></li>
<li class="chapter" data-level="8.5.6" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#difference-in-proportions"><i class="fa fa-check"></i><b>8.5.6</b> Difference in proportions</a></li>
<li class="chapter" data-level="8.5.7" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#sampling-from-the-prior"><i class="fa fa-check"></i><b>8.5.7</b> Sampling from the prior</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="jags-just-another-gibbs-sampler.html"><a href="jags-just-another-gibbs-sampler.html#ch08-exercises"><i class="fa fa-check"></i><b>8.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="heierarchical-models.html"><a href="heierarchical-models.html"><i class="fa fa-check"></i><b>9</b> Heierarchical Models</a><ul>
<li class="chapter" data-level="9.1" data-path="heierarchical-models.html"><a href="heierarchical-models.html#gamma-distributions"><i class="fa fa-check"></i><b>9.1</b> Gamma Distributions</a></li>
<li class="chapter" data-level="9.2" data-path="heierarchical-models.html"><a href="heierarchical-models.html#one-coin-from-one-mint"><i class="fa fa-check"></i><b>9.2</b> One coin from one mint</a></li>
<li class="chapter" data-level="9.3" data-path="heierarchical-models.html"><a href="heierarchical-models.html#multiple-coins-from-one-mint"><i class="fa fa-check"></i><b>9.3</b> Multiple coins from one mint</a></li>
<li class="chapter" data-level="9.4" data-path="heierarchical-models.html"><a href="heierarchical-models.html#multiple-coins-from-multiple-mints"><i class="fa fa-check"></i><b>9.4</b> Multiple coins from multiple mints</a></li>
<li class="chapter" data-level="9.5" data-path="heierarchical-models.html"><a href="heierarchical-models.html#therapeutic-touch"><i class="fa fa-check"></i><b>9.5</b> Therapeutic Touch</a><ul>
<li class="chapter" data-level="9.5.1" data-path="heierarchical-models.html"><a href="heierarchical-models.html#abstract"><i class="fa fa-check"></i><b>9.5.1</b> Abstract</a></li>
<li class="chapter" data-level="9.5.2" data-path="heierarchical-models.html"><a href="heierarchical-models.html#data-1"><i class="fa fa-check"></i><b>9.5.2</b> Data</a></li>
<li class="chapter" data-level="9.5.3" data-path="heierarchical-models.html"><a href="heierarchical-models.html#a-heierarchical-model"><i class="fa fa-check"></i><b>9.5.3</b> A heierarchical model</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="heierarchical-models.html"><a href="heierarchical-models.html#other-parameterizations-we-might-have-tried"><i class="fa fa-check"></i><b>9.6</b> Other parameterizations we might have tried</a><ul>
<li class="chapter" data-level="9.6.1" data-path="heierarchical-models.html"><a href="heierarchical-models.html#shape-parameters-for-beta"><i class="fa fa-check"></i><b>9.6.1</b> Shape parameters for Beta</a></li>
<li class="chapter" data-level="9.6.2" data-path="heierarchical-models.html"><a href="heierarchical-models.html#mean-instead-of-mode"><i class="fa fa-check"></i><b>9.6.2</b> Mean instead of mode</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="heierarchical-models.html"><a href="heierarchical-models.html#shrinkage"><i class="fa fa-check"></i><b>9.7</b> Shrinkage</a></li>
<li class="chapter" data-level="9.8" data-path="heierarchical-models.html"><a href="heierarchical-models.html#example-baseball-batting-average"><i class="fa fa-check"></i><b>9.8</b> Example: Baseball Batting Average</a></li>
<li class="chapter" data-level="9.9" data-path="heierarchical-models.html"><a href="heierarchical-models.html#ch09-exercises"><i class="fa fa-check"></i><b>9.9</b> Exerciess</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="model-comparison.html"><a href="model-comparison.html"><i class="fa fa-check"></i><b>10</b> (Model Comparison)</a></li>
<li class="chapter" data-level="11" data-path="nhst.html"><a href="nhst.html"><i class="fa fa-check"></i><b>11</b> (NHST)</a></li>
<li class="chapter" data-level="12" data-path="point-null-hypotheses.html"><a href="point-null-hypotheses.html"><i class="fa fa-check"></i><b>12</b> (Point Null Hypotheses)</a></li>
<li class="chapter" data-level="13" data-path="goals-power-sample-size.html"><a href="goals-power-sample-size.html"><i class="fa fa-check"></i><b>13</b> (Goals, Power, Sample Size)</a></li>
<li class="chapter" data-level="14" data-path="stan.html"><a href="stan.html"><i class="fa fa-check"></i><b>14</b> Stan</a><ul>
<li class="chapter" data-level="14.1" data-path="stan.html"><a href="stan.html#why-stan-might-work-better"><i class="fa fa-check"></i><b>14.1</b> Why Stan might work better</a></li>
<li class="chapter" data-level="14.2" data-path="stan.html"><a href="stan.html#describing-a-model-to-stan"><i class="fa fa-check"></i><b>14.2</b> Describing a model to Stan</a></li>
<li class="chapter" data-level="14.3" data-path="stan.html"><a href="stan.html#samping-from-the-prior"><i class="fa fa-check"></i><b>14.3</b> Samping from the prior</a></li>
<li class="chapter" data-level="14.4" data-path="stan.html"><a href="stan.html#ch14-exercises"><i class="fa fa-check"></i><b>14.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="glm-overview.html"><a href="glm-overview.html"><i class="fa fa-check"></i><b>15</b> GLM Overview</a><ul>
<li class="chapter" data-level="15.1" data-path="glm-overview.html"><a href="glm-overview.html#data-consists-of-observations-of-variables"><i class="fa fa-check"></i><b>15.1</b> Data consists of observations of variables</a><ul>
<li class="chapter" data-level="15.1.1" data-path="glm-overview.html"><a href="glm-overview.html#variable-roles"><i class="fa fa-check"></i><b>15.1.1</b> Variable Roles</a></li>
<li class="chapter" data-level="15.1.2" data-path="glm-overview.html"><a href="glm-overview.html#types-of-variables"><i class="fa fa-check"></i><b>15.1.2</b> Types of Variables</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="glm-overview.html"><a href="glm-overview.html#glm-framework"><i class="fa fa-check"></i><b>15.2</b> GLM Framework</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html"><i class="fa fa-check"></i><b>16</b> Estimating One and Two Means</a><ul>
<li class="chapter" data-level="16.1" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#basic-model-for-two-means"><i class="fa fa-check"></i><b>16.1</b> Basic Model for Two Means</a><ul>
<li class="chapter" data-level="16.1.1" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#data-2"><i class="fa fa-check"></i><b>16.1.1</b> Data</a></li>
<li class="chapter" data-level="16.1.2" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#model"><i class="fa fa-check"></i><b>16.1.2</b> Model</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#an-old-sleep-study"><i class="fa fa-check"></i><b>16.2</b> An Old Sleep Study</a><ul>
<li class="chapter" data-level="16.2.1" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#data-3"><i class="fa fa-check"></i><b>16.2.1</b> Data</a></li>
<li class="chapter" data-level="16.2.2" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#model-1"><i class="fa fa-check"></i><b>16.2.2</b> Model</a></li>
<li class="chapter" data-level="16.2.3" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#separate-standard-deviations-for-each-group"><i class="fa fa-check"></i><b>16.2.3</b> Separate standard deviations for each group</a></li>
<li class="chapter" data-level="16.2.4" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#comparison-to-t-test"><i class="fa fa-check"></i><b>16.2.4</b> Comparison to t-test</a></li>
<li class="chapter" data-level="16.2.5" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#rope-region-of-practical-equivalence"><i class="fa fa-check"></i><b>16.2.5</b> ROPE (Region of Practical Equivalence)</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#variations-on-the-theme"><i class="fa fa-check"></i><b>16.3</b> Variations on the theme</a><ul>
<li class="chapter" data-level="16.3.1" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#other-distributions-for-the-response"><i class="fa fa-check"></i><b>16.3.1</b> Other distributions for the response</a></li>
<li class="chapter" data-level="16.3.2" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#other-priors-for-sigma-or-tau"><i class="fa fa-check"></i><b>16.3.2</b> Other Priors for <span class="math inline">\(\sigma\)</span> (or <span class="math inline">\(\tau\)</span>)</a></li>
<li class="chapter" data-level="16.3.3" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#paired-comparisons"><i class="fa fa-check"></i><b>16.3.3</b> Paired Comparisons</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#how-many-chains-how-long"><i class="fa fa-check"></i><b>16.4</b> How many chains? How long?</a><ul>
<li class="chapter" data-level="16.4.1" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#why-multiple-chains"><i class="fa fa-check"></i><b>16.4.1</b> Why multiple chains?</a></li>
<li class="chapter" data-level="16.4.2" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#what-large-n.eff-does-and-doesnt-do-for-us"><i class="fa fa-check"></i><b>16.4.2</b> What large n.eff does and doesn’t do for us</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#looking-at-likelihood"><i class="fa fa-check"></i><b>16.5</b> Looking at Likelihood</a></li>
<li class="chapter" data-level="16.6" data-path="estimating-one-and-two-means.html"><a href="estimating-one-and-two-means.html#ch16-exercises"><i class="fa fa-check"></i><b>16.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>17</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="17.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#the-deluxe-basic-model"><i class="fa fa-check"></i><b>17.1</b> The deluxe basic model</a><ul>
<li class="chapter" data-level="17.1.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#likelihood-1"><i class="fa fa-check"></i><b>17.1.1</b> Likelihood</a></li>
<li class="chapter" data-level="17.1.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#priors"><i class="fa fa-check"></i><b>17.1.2</b> Priors</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#example-galtons-data"><i class="fa fa-check"></i><b>17.2</b> Example: Galton’s Data</a><ul>
<li class="chapter" data-level="17.2.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#describing-the-model-to-jags-1"><i class="fa fa-check"></i><b>17.2.1</b> Describing the model to JAGS</a></li>
<li class="chapter" data-level="17.2.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#problems-and-how-to-fix-them"><i class="fa fa-check"></i><b>17.2.2</b> Problems and how to fix them</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#centering-and-standardizing"><i class="fa fa-check"></i><b>17.3</b> Centering and Standardizing</a><ul>
<li class="chapter" data-level="17.3.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#beta_0-and-beta_1-are-still-correlated"><i class="fa fa-check"></i><b>17.3.1</b> <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are still correlated</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#weve-fit-a-model-now-what"><i class="fa fa-check"></i><b>17.4</b> We’ve fit a model, now what?</a><ul>
<li class="chapter" data-level="17.4.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#estimate-parameters"><i class="fa fa-check"></i><b>17.4.1</b> Estimate parameters</a></li>
<li class="chapter" data-level="17.4.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#make-predictions"><i class="fa fa-check"></i><b>17.4.2</b> Make predictions</a></li>
<li class="chapter" data-level="17.4.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#posterior-predictive-checks"><i class="fa fa-check"></i><b>17.4.3</b> Posterior Predictive Checks</a></li>
<li class="chapter" data-level="17.4.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#posterior-predictive-checks-with-bayesplot"><i class="fa fa-check"></i><b>17.4.4</b> Posterior predictive checks with bayesplot</a></li>
<li class="chapter" data-level="17.4.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#ppc-with-custom-data"><i class="fa fa-check"></i><b>17.4.5</b> PPC with custom data</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#fitting-models-with-stan"><i class="fa fa-check"></i><b>17.5</b> Fitting models with Stan</a></li>
<li class="chapter" data-level="17.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#two-intercepts-model"><i class="fa fa-check"></i><b>17.6</b> Two Intercepts model</a></li>
<li class="chapter" data-level="17.7" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#ch17-exercises"><i class="fa fa-check"></i><b>17.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html"><i class="fa fa-check"></i><b>18</b> Multiple Metric Predictors</a><ul>
<li class="chapter" data-level="18.1" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#sat"><i class="fa fa-check"></i><b>18.1</b> SAT</a><ul>
<li class="chapter" data-level="18.1.1" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#sat-vs-expenditure"><i class="fa fa-check"></i><b>18.1.1</b> SAT vs expenditure</a></li>
<li class="chapter" data-level="18.1.2" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#sat-vs-expenditure-and-percent-taking-the-test"><i class="fa fa-check"></i><b>18.1.2</b> SAT vs expenditure and percent taking the test</a></li>
<li class="chapter" data-level="18.1.3" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#whats-wrong-with-this-picture"><i class="fa fa-check"></i><b>18.1.3</b> What’s wrong with this picture?</a></li>
<li class="chapter" data-level="18.1.4" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#multiple-predictors-in-pictures"><i class="fa fa-check"></i><b>18.1.4</b> Multiple predictors in pictures</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#interaction"><i class="fa fa-check"></i><b>18.2</b> Interaction</a><ul>
<li class="chapter" data-level="18.2.1" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#sat-with-interaction-term"><i class="fa fa-check"></i><b>18.2.1</b> SAT with interaction term</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#fitting-a-linear-model-with-brms"><i class="fa fa-check"></i><b>18.3</b> Fitting a linear model with brms</a><ul>
<li class="chapter" data-level="18.3.1" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#adjusting-the-model-with-brm"><i class="fa fa-check"></i><b>18.3.1</b> Adjusting the model with brm()</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#interpretting-a-model-with-an-interaction-term"><i class="fa fa-check"></i><b>18.4</b> Interpretting a model with an interaction term</a><ul>
<li class="chapter" data-level="18.4.1" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#thinking-about-the-noise"><i class="fa fa-check"></i><b>18.4.1</b> Thinking about the noise</a></li>
</ul></li>
<li class="chapter" data-level="18.5" data-path="multiple-metric-predictors.html"><a href="multiple-metric-predictors.html#ch18-exercises"><i class="fa fa-check"></i><b>18.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="nominal-predictors.html"><a href="nominal-predictors.html"><i class="fa fa-check"></i><b>19</b> Nominal Predictors</a><ul>
<li class="chapter" data-level="19.1" data-path="nominal-predictors.html"><a href="nominal-predictors.html#fruit-flies-study"><i class="fa fa-check"></i><b>19.1</b> Fruit flies Study</a></li>
<li class="chapter" data-level="19.2" data-path="nominal-predictors.html"><a href="nominal-predictors.html#model-1-out-of-the-box"><i class="fa fa-check"></i><b>19.2</b> Model 1: Out-of-the-box</a></li>
<li class="chapter" data-level="19.3" data-path="nominal-predictors.html"><a href="nominal-predictors.html#model-2-custom-priors"><i class="fa fa-check"></i><b>19.3</b> Model 2: Custom Priors</a></li>
<li class="chapter" data-level="19.4" data-path="nominal-predictors.html"><a href="nominal-predictors.html#models-3-and-4-alternate-parameterizations"><i class="fa fa-check"></i><b>19.4</b> Models 3 and 4: alternate parameterizations</a></li>
<li class="chapter" data-level="19.5" data-path="nominal-predictors.html"><a href="nominal-predictors.html#comparing-groups"><i class="fa fa-check"></i><b>19.5</b> Comparing groups</a><ul>
<li class="chapter" data-level="19.5.1" data-path="nominal-predictors.html"><a href="nominal-predictors.html#comparing-to-the-intercept-group"><i class="fa fa-check"></i><b>19.5.1</b> Comparing to the “intercept group”</a></li>
<li class="chapter" data-level="19.5.2" data-path="nominal-predictors.html"><a href="nominal-predictors.html#comparing-others-pairs-of-groups"><i class="fa fa-check"></i><b>19.5.2</b> Comparing others pairs of groups</a></li>
<li class="chapter" data-level="19.5.3" data-path="nominal-predictors.html"><a href="nominal-predictors.html#contrasts-comparing-groups-of-groups"><i class="fa fa-check"></i><b>19.5.3</b> Contrasts: Comparing “groups of groups”</a></li>
</ul></li>
<li class="chapter" data-level="19.6" data-path="nominal-predictors.html"><a href="nominal-predictors.html#more-variations"><i class="fa fa-check"></i><b>19.6</b> More Variations</a></li>
<li class="chapter" data-level="19.7" data-path="nominal-predictors.html"><a href="nominal-predictors.html#ch19-exercises"><i class="fa fa-check"></i><b>19.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html"><i class="fa fa-check"></i><b>20</b> Multiple Nominal Predictors</a><ul>
<li class="chapter" data-level="20.1" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#crop-yield-by-till-method-and-fertilizer"><i class="fa fa-check"></i><b>20.1</b> Crop Yield by Till Method and Fertilizer</a><ul>
<li class="chapter" data-level="20.1.1" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#what-does-sigma-represent"><i class="fa fa-check"></i><b>20.1.1</b> What does <span class="math inline">\(\sigma\)</span> represent?</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#split-plot-design"><i class="fa fa-check"></i><b>20.2</b> Split Plot Design</a></li>
<li class="chapter" data-level="20.3" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#which-model-should-we-use"><i class="fa fa-check"></i><b>20.3</b> Which model should we use?</a><ul>
<li class="chapter" data-level="20.3.1" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#modeling-choices"><i class="fa fa-check"></i><b>20.3.1</b> Modeling Choices</a></li>
<li class="chapter" data-level="20.3.2" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#measuring-a-model-prediction-error"><i class="fa fa-check"></i><b>20.3.2</b> Measuring a Model – Prediction Error</a></li>
<li class="chapter" data-level="20.3.3" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#overfitting-example"><i class="fa fa-check"></i><b>20.3.3</b> Overfitting Example</a></li>
<li class="chapter" data-level="20.3.4" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#measuring-fit-with-r2"><i class="fa fa-check"></i><b>20.3.4</b> Measuring fit with <span class="math inline">\(r^2\)</span></a></li>
<li class="chapter" data-level="20.3.5" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#leave-one-out-analysis"><i class="fa fa-check"></i><b>20.3.5</b> Leave One Out Analysis</a></li>
<li class="chapter" data-level="20.3.6" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#out-of-sample-prediction-error"><i class="fa fa-check"></i><b>20.3.6</b> Out-of-sample prediction error</a></li>
<li class="chapter" data-level="20.3.7" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#approximating-out-of-sample-prediction-error"><i class="fa fa-check"></i><b>20.3.7</b> Approximating out-of-sample prediction error</a></li>
<li class="chapter" data-level="20.3.8" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#the-deviance-scale"><i class="fa fa-check"></i><b>20.3.8</b> The deviance scale</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#using-loo"><i class="fa fa-check"></i><b>20.4</b> Using loo</a></li>
<li class="chapter" data-level="20.5" data-path="multiple-nominal-predictors.html"><a href="multiple-nominal-predictors.html#ch20-exercses"><i class="fa fa-check"></i><b>20.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="dichotymous-response.html"><a href="dichotymous-response.html"><i class="fa fa-check"></i><b>21</b> Dichotymous Response</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">(Re)Doing Bayesain Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="multiple-metric-predictors" class="section level1">
<h1><span class="header-section-number">18</span> Multiple Metric Predictors</h1>
<div id="sat" class="section level2">
<h2><span class="header-section-number">18.1</span> SAT</h2>
<div id="sat-vs-expenditure" class="section level3">
<h3><span class="header-section-number">18.1.1</span> SAT vs expenditure</h3>
<p>Does spending more on education result in higher SAT scores? Data from 1999
(published in a paper by Gruber) can be used to explore this question. Among other
things, the data includes average total SAT score (on a 400-1600 scale) and
the amount of money spent on education (in 1000s of dollars per student) in each state.</p>
<p>As a first attempt, we could fit a linear model (sat ~ expend). Using centering, the
core of the model looks like this:</p>
<pre><code>  for (i in 1:length(y)) {
    y[i]   ~ dt(mu[i], 1/sigma^2, nu)
    mu[i] &lt;- alpha0 + alpha1 * (x[i] - mean(x))
  }</code></pre>
<p><code>alpha1</code> measures how much better SAT performance is for each $1000 spent
on education in a state. To fit the model, we need priors on our four
parameters:</p>
<ul>
<li><code>nu</code>: We can use our usual shifted exponential.</li>
<li><code>sigma</code>: {Unif}(?, ?)</li>
<li><code>alpha0</code>: {Norm}(?, ?)</li>
<li><code>alpha1</code>: {Norm}(0, ?)</li>
</ul>
<p>The question marks depend on the scale of our variables.
If we build those into our model, and provide the answers as part of our data,
we can use the same model for multiple data sets, even if they are at different
scales.</p>
<pre class="sourceCode r"><code class="sourceCode r">sat_model &lt;-<span class="st"> </span><span class="cf">function</span>() {
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(y)) {
    y[i]   <span class="op">~</span><span class="st"> </span><span class="kw">dt</span>(mu[i], <span class="dv">1</span><span class="op">/</span>sigma<span class="op">^</span><span class="dv">2</span>, nu)
    mu[i] &lt;-<span class="st"> </span>alpha0 <span class="op">+</span><span class="st"> </span>alpha1 <span class="op">*</span><span class="st"> </span>(x[i] <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x))
  }
  nuMinusOne <span class="op">~</span><span class="st"> </span><span class="kw">dexp</span>(<span class="dv">1</span><span class="op">/</span><span class="fl">29.0</span>)
  nu        &lt;-<span class="st"> </span>nuMinusOne <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
  alpha0     <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(alpha0mean, <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>alpha0sd<span class="op">^</span><span class="dv">2</span>) 
  alpha1     <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>alpha1sd<span class="op">^</span><span class="dv">2</span>)
  sigma      <span class="op">~</span><span class="st"> </span><span class="kw">dunif</span>(sigma_lo, sigma_hi <span class="op">*</span><span class="st"> </span><span class="dv">1000</span>)
  log10nu   &lt;-<span class="st"> </span><span class="kw">log</span>(nu) <span class="op">/</span><span class="st"> </span><span class="kw">log</span>(<span class="dv">10</span>)    <span class="co"># log10(nu)</span>
  beta0     &lt;-<span class="st"> </span>alpha0 <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x) <span class="op">*</span><span class="st"> </span>alpha1          <span class="co"># true intercept</span>
}</code></pre>
<p>So how do we fill in the question marks for this data set?</p>
<ul>
<li><p><code>sigma</code>: {Unif}(?,?)</p>
<p>This quantifies the amount of variation from state to state among states
that have the same per student expenditure. The scale of the SAT ranges from
400 to 1600. Statewide averages will not be near the extremes of this scale.
A 6-order of maginitude window around 1 gives <strong>{Unif}(0.001, 1000)</strong>,
both ends of which are plenty far from what we think is reasonable.</p></li>
<li><p><code>alpha0</code>: {Norm}(?, ?)</p>
<p><code>alpha0</code> measures the average SAT score for states that spend an average
amount. Since average SATs are around 1000, something like
<strong>{Norm}(1000, 100)</strong> seems reasable.</p></li>
<li><p><code>alpha1</code>: {Norm}(0, ?)</p>
<p>This is the trickiest one. The slope of a regression line can’t be much more than
<span class="math inline">\(\frac{SD_y}{SD_x}\)</span>, so we can either estimate that ratio or compute it from
our data to guide our choice of prior.</p></li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(R2jags)
sat_jags &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">jags</span>(
    <span class="dt">model =</span> sat_model,
    <span class="dt">data =</span> <span class="kw">list</span>(
      <span class="dt">y =</span> SAT<span class="op">$</span>sat,
      <span class="dt">x =</span> SAT<span class="op">$</span>expend,
      <span class="dt">alpha0mean =</span> <span class="dv">1000</span>,    <span class="co"># SAT scores are roughly 500 + 500</span>
      <span class="dt">alpha0sd   =</span> <span class="dv">100</span>,     <span class="co"># broad prior on scale of 400 - 1600</span>
      <span class="dt">alpha1sd   =</span> <span class="dv">4</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(SAT<span class="op">$</span>sat) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(SAT<span class="op">$</span>expend),
      <span class="dt">sigma_lo =</span> <span class="fl">0.001</span>,     <span class="co"># 3 o.m. less than 1</span>
      <span class="dt">sigma_hi =</span> <span class="dv">1000</span>       <span class="co"># 3 o.m. greater than 1</span>
    ),
    <span class="dt">parameters.to.save =</span> <span class="kw">c</span>(<span class="st">&quot;nu&quot;</span>, <span class="st">&quot;log10nu&quot;</span>, <span class="st">&quot;alpha0&quot;</span>, <span class="st">&quot;beta0&quot;</span>, <span class="st">&quot;alpha1&quot;</span>, <span class="st">&quot;sigma&quot;</span>),
    <span class="dt">n.iter   =</span> <span class="dv">4000</span>,
    <span class="dt">n.burnin =</span> <span class="dv">1000</span>,
    <span class="dt">n.chains =</span> <span class="dv">3</span>
  ) </code></pre>
<pre class="sourceCode r"><code class="sourceCode r">sat_jags</code></pre>
<pre><code>## Inference for Bugs model at &quot;/var/folders/py/txwd26jx5rq83f4nn0f5fmmm0000gn/T//Rtmp5K1frC/modelfeab4654749d.txt&quot;, fit using jags,
##  3 chains, each with 4000 iterations (first 1000 discarded), n.thin = 3
##  n.sims = 3000 iterations saved
##          mu.vect sd.vect     2.5%      25%      50%      75%    97.5%  Rhat n.eff
## alpha0    966.30  10.477  945.217  959.654  966.396  973.052  987.086 1.001  3000
## alpha1    -21.40   7.370  -36.165  -26.181  -21.389  -16.622   -6.772 1.001  2700
## beta0    1092.68  45.112 1003.147 1063.878 1092.556 1121.854 1182.939 1.001  2100
## log10nu     1.51   0.328    0.823    1.295    1.524    1.744    2.105 1.001  3000
## nu         42.31  32.618    6.659   19.731   33.425   55.419  127.370 1.001  3000
## sigma      69.95   7.860   56.467   64.621   69.186   74.728   87.222 1.001  3000
## deviance  568.53   2.742  565.260  566.512  567.872  569.868  575.345 1.002  2700
## 
## For each parameter, n.eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor (at convergence, Rhat=1).
## 
## DIC info (using the rule, pD = var(deviance)/2)
## pD = 3.8 and DIC = 572.3
## DIC is an estimate of expected predictive error (lower deviance is better).</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">diag_mcmc</span>(<span class="kw">as.mcmc</span>(sat_jags))
<span class="kw">mcmc_combo</span>(<span class="kw">as.mcmc</span>(sat_jags))</code></pre>
<p><img src="Redoing_files/figure-html/ch18-sat1-jags-look-1.png" width="65%" /><img src="Redoing_files/figure-html/ch18-sat1-jags-look-2.png" width="65%" /></p>
<p>Our primary interest is <code>alpha1</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary_df</span>(sat_jags) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(param <span class="op">==</span><span class="st"> &quot;alpha1&quot;</span>)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">param</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">2.5%</th>
<th align="right">25%</th>
<th align="right">50%</th>
<th align="right">75%</th>
<th align="right">97.5%</th>
<th align="right">Rhat</th>
<th align="right">n.eff</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">alpha1</td>
<td align="right">-21.4</td>
<td align="right">7.37</td>
<td align="right">-36.16</td>
<td align="right">-26.18</td>
<td align="right">-21.39</td>
<td align="right">-16.62</td>
<td align="right">-6.772</td>
<td align="right">1.001</td>
<td align="right">2700</td>
</tr>
</tbody>
</table>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot_post</span>(<span class="kw">posterior</span>(sat_jags)<span class="op">$</span>alpha1, <span class="dt">xlab =</span> <span class="st">&quot;alpha1&quot;</span>, <span class="dt">ROPE =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>))</code></pre>
<p><img src="Redoing_files/figure-html/ch18-sat-alpha-1.png" width="65%" /></p>
<pre><code>## $posterior
##       ESS  mean median   mode
## var1 3000 -21.4 -21.39 -21.16
## 
## $hdi
##   prob     lo     hi
## 1 0.95 -36.24 -6.892
## 
## $ROPE
##   lo hi P(&lt; ROPE) P(in ROPE) P(&gt; ROPE)
## 1 -5  5     0.986    0.01367 0.0003333</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hdi</span>(<span class="kw">posterior</span>(sat_jags), <span class="dt">pars =</span> <span class="st">&quot;alpha1&quot;</span>, <span class="dt">prob =</span> <span class="fl">0.95</span>)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">par</th>
<th align="right">lo</th>
<th align="right">hi</th>
<th align="right">prob</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">alpha1</td>
<td align="right">-36.24</td>
<td align="right">-6.892</td>
<td align="right">0.95</td>
</tr>
</tbody>
</table>
<p>This seems odd: Nearly all the credible values for <code>alpha1</code> are negative?
Can we really raise SAT scores by cutting funding to schools? Maybe we should look
at the raw data with our model overlaid.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">gf_point</span>(sat <span class="op">~</span><span class="st"> </span>expend, <span class="dt">data =</span> SAT) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gf_abline</span>(<span class="dt">slope =</span> <span class="op">~</span><span class="st"> </span>alpha1, <span class="dt">intercept =</span> <span class="op">~</span><span class="st"> </span>beta0, 
            <span class="dt">data =</span> <span class="kw">posterior</span>(sat_jags) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sample_n</span>(<span class="dv">2000</span>),
            <span class="dt">alpha =</span> <span class="fl">0.01</span>, <span class="dt">color =</span> <span class="st">&quot;steelblue&quot;</span>)</code></pre>
<p><img src="Redoing_files/figure-html/ch18-sat-scatter-1.png" width="65%" /></p>
<p>That’s a lot of scatter, and the negative trend is heavily influenced by the 4 states that
spend the most (and have relatively low SAT scores). We could do a bit more with
this model, for exapmle we could</p>
<pre><code>* fit without those 4 states to see how much they are driving the negative trend;
* do some PPC to see if the model is reasonable.</code></pre>
<p>But instead will will explore another model, one that has two predictors.</p>
</div>
<div id="sat-vs-expenditure-and-percent-taking-the-test" class="section level3">
<h3><span class="header-section-number">18.1.2</span> SAT vs expenditure and percent taking the test</h3>
<p>We have some additional data about each state. Let’s fit a model with two
predictors: <code>expend</code> and <code>frac</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">SAT <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>(<span class="dv">4</span>)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">state</th>
<th align="right">expend</th>
<th align="right">ratio</th>
<th align="right">salary</th>
<th align="right">frac</th>
<th align="right">verbal</th>
<th align="right">math</th>
<th align="right">sat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Alabama</td>
<td align="right">4.405</td>
<td align="right">17.2</td>
<td align="right">31.14</td>
<td align="right">8</td>
<td align="right">491</td>
<td align="right">538</td>
<td align="right">1029</td>
</tr>
<tr class="even">
<td align="left">Alaska</td>
<td align="right">8.963</td>
<td align="right">17.6</td>
<td align="right">47.95</td>
<td align="right">47</td>
<td align="right">445</td>
<td align="right">489</td>
<td align="right">934</td>
</tr>
<tr class="odd">
<td align="left">Arizona</td>
<td align="right">4.778</td>
<td align="right">19.3</td>
<td align="right">32.17</td>
<td align="right">27</td>
<td align="right">448</td>
<td align="right">496</td>
<td align="right">944</td>
</tr>
<tr class="even">
<td align="left">Arkansas</td>
<td align="right">4.459</td>
<td align="right">17.1</td>
<td align="right">28.93</td>
<td align="right">6</td>
<td align="right">482</td>
<td align="right">523</td>
<td align="right">1005</td>
</tr>
</tbody>
</table>
<p>Here’s our model for (robust) multiple linear regression:</p>
<p><img src="images/Fig18-4.png" width="65%" style="display: block; margin: auto;" /></p>
<div id="sat2-jags" class="section level4">
<h4><span class="header-section-number">18.1.2.1</span> JAGS</h4>
<p>Coding it in JAGS requires adding in the additional predictor:</p>
<pre class="sourceCode r"><code class="sourceCode r">sat_model2 &lt;-<span class="st"> </span><span class="cf">function</span>() {
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(y)) {
    y[i]   <span class="op">~</span><span class="st"> </span><span class="kw">dt</span>(mu[i], <span class="dv">1</span><span class="op">/</span>sigma<span class="op">^</span><span class="dv">2</span>, nu)
    mu[i] &lt;-<span class="st"> </span>alpha0 <span class="op">+</span><span class="st"> </span>alpha1 <span class="op">*</span><span class="st"> </span>(x1[i] <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x1)) <span class="op">+</span><span class="st"> </span>alpha2 <span class="op">*</span><span class="st"> </span>(x2[i] <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x2))
  }
  nuMinusOne <span class="op">~</span><span class="st"> </span><span class="kw">dexp</span>(<span class="dv">1</span><span class="op">/</span><span class="fl">29.0</span>)
  nu        &lt;-<span class="st"> </span>nuMinusOne <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
  alpha0     <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(alpha0mean, <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>alpha0sd<span class="op">^</span><span class="dv">2</span>) 
  alpha1     <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>alpha1sd<span class="op">^</span><span class="dv">2</span>)
  alpha2     <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>alpha2sd<span class="op">^</span><span class="dv">2</span>)
  sigma      <span class="op">~</span><span class="st"> </span><span class="kw">dunif</span>(sigma_lo, sigma_hi <span class="op">*</span><span class="st"> </span><span class="dv">1000</span>)
  beta0     &lt;-<span class="st"> </span>alpha0 <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x1) <span class="op">*</span><span class="st"> </span>alpha1 <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x2) <span class="op">*</span><span class="st"> </span>alpha2
  log10nu   &lt;-<span class="st"> </span><span class="kw">log</span>(nu) <span class="op">/</span><span class="st"> </span><span class="kw">log</span>(<span class="dv">10</span>)
}</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(R2jags)
sat2_jags &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">jags</span>(
    <span class="dt">model =</span> sat_model2,
    <span class="dt">data =</span> <span class="kw">list</span>(
      <span class="dt">y =</span> SAT<span class="op">$</span>sat,
      <span class="dt">x1 =</span> SAT<span class="op">$</span>expend,
      <span class="dt">x2 =</span> SAT<span class="op">$</span>frac,
      <span class="dt">alpha0mean =</span> <span class="dv">1000</span>,    <span class="co"># SAT scores are roughly 500 + 500</span>
      <span class="dt">alpha0sd   =</span> <span class="dv">100</span>,     <span class="co"># broad prior on scale of 400 - 1600</span>
      <span class="dt">alpha1sd   =</span> <span class="dv">4</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(SAT<span class="op">$</span>sat) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(SAT<span class="op">$</span>expend),
      <span class="dt">alpha2sd   =</span> <span class="dv">4</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(SAT<span class="op">$</span>sat) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(SAT<span class="op">$</span>frac),
      <span class="dt">sigma_lo =</span> <span class="fl">0.001</span>,
      <span class="dt">sigma_hi =</span> <span class="dv">1000</span>
    ),
    <span class="dt">parameters.to.save =</span> <span class="kw">c</span>(<span class="st">&quot;log10nu&quot;</span>, <span class="st">&quot;alpha0&quot;</span>, <span class="st">&quot;alpha1&quot;</span>, <span class="st">&quot;alpha2&quot;</span>, <span class="st">&quot;beta0&quot;</span>,<span class="st">&quot;sigma&quot;</span>),
    <span class="dt">n.iter   =</span> <span class="dv">4000</span>,
    <span class="dt">n.burnin =</span> <span class="dv">1000</span>,
    <span class="dt">n.chains =</span> <span class="dv">3</span>
  ) </code></pre>
<pre class="sourceCode r"><code class="sourceCode r">sat2_jags</code></pre>
<pre><code>## Inference for Bugs model at &quot;/var/folders/py/txwd26jx5rq83f4nn0f5fmmm0000gn/T//Rtmp5K1frC/modelfeab7e14cfb5.txt&quot;, fit using jags,
##  3 chains, each with 4000 iterations (first 1000 discarded), n.thin = 3
##  n.sims = 3000 iterations saved
##          mu.vect sd.vect    2.5%     25%     50%      75%    97.5%  Rhat n.eff
## alpha0   965.801   4.754 956.565 962.669 965.735  968.869  975.316 1.001  3000
## alpha1    12.906   4.345   4.138  10.061  12.994   15.709   21.563 1.001  3000
## alpha2    -2.885   0.225  -3.318  -3.039  -2.885   -2.734   -2.441 1.001  2000
## beta0    991.250  22.164 947.709 976.934 990.995 1006.116 1035.153 1.001  3000
## log10nu    1.379   0.367   0.661   1.118   1.393    1.642    2.048 1.001  2600
## sigma     31.586   3.807  24.563  28.947  31.409   34.047   39.761 1.001  3000
## deviance 491.060   3.010 487.234 488.830 490.421  492.588  498.706 1.001  2100
## 
## For each parameter, n.eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor (at convergence, Rhat=1).
## 
## DIC info (using the rule, pD = var(deviance)/2)
## pD = 4.5 and DIC = 495.6
## DIC is an estimate of expected predictive error (lower deviance is better).</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">diag_mcmc</span>(<span class="kw">as.mcmc</span>(sat2_jags))
<span class="kw">mcmc_combo</span>(<span class="kw">as.mcmc</span>(sat2_jags))</code></pre>
<p><img src="Redoing_files/figure-html/ch18-sat2-jags-look-1.png" width="65%" /><img src="Redoing_files/figure-html/ch18-sat2-jags-look-2.png" width="65%" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary_df</span>(sat2_jags) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(param <span class="op">==</span><span class="st"> &quot;alpha1&quot;</span>)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">param</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">2.5%</th>
<th align="right">25%</th>
<th align="right">50%</th>
<th align="right">75%</th>
<th align="right">97.5%</th>
<th align="right">Rhat</th>
<th align="right">n.eff</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">alpha1</td>
<td align="right">12.91</td>
<td align="right">4.345</td>
<td align="right">4.138</td>
<td align="right">10.06</td>
<td align="right">12.99</td>
<td align="right">15.71</td>
<td align="right">21.56</td>
<td align="right">1.001</td>
<td align="right">3000</td>
</tr>
</tbody>
</table>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot_post</span>(<span class="kw">posterior</span>(sat2_jags)<span class="op">$</span>alpha1, <span class="dt">xlab =</span> <span class="st">&quot;alpha1&quot;</span>, <span class="dt">ROPE =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>))</code></pre>
<p><img src="Redoing_files/figure-html/ch18-sat2-alpha1-1.png" width="65%" /></p>
<pre><code>## $posterior
##       ESS  mean median  mode
## var1 2662 12.91  12.99 13.58
## 
## $hdi
##   prob    lo    hi
## 1 0.95 3.742 21.12
## 
## $ROPE
##   lo hi P(&lt; ROPE) P(in ROPE) P(&gt; ROPE)
## 1 -5  5         0    0.03733    0.9627</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hdi</span>(<span class="kw">posterior</span>(sat2_jags), <span class="dt">pars =</span> <span class="st">&quot;alpha1&quot;</span>, <span class="dt">prob =</span> <span class="fl">0.95</span>)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">par</th>
<th align="right">lo</th>
<th align="right">hi</th>
<th align="right">prob</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">alpha1</td>
<td align="right">3.742</td>
<td align="right">21.12</td>
<td align="right">0.95</td>
</tr>
</tbody>
</table>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary_df</span>(sat2_jags) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(param <span class="op">==</span><span class="st"> &quot;alpha2&quot;</span>)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">param</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">2.5%</th>
<th align="right">25%</th>
<th align="right">50%</th>
<th align="right">75%</th>
<th align="right">97.5%</th>
<th align="right">Rhat</th>
<th align="right">n.eff</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">alpha2</td>
<td align="right">-2.885</td>
<td align="right">0.225</td>
<td align="right">-3.317</td>
<td align="right">-3.039</td>
<td align="right">-2.885</td>
<td align="right">-2.734</td>
<td align="right">-2.441</td>
<td align="right">1.002</td>
<td align="right">2000</td>
</tr>
</tbody>
</table>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot_post</span>(<span class="kw">posterior</span>(sat2_jags)<span class="op">$</span>alpha2, <span class="dt">xlab =</span> <span class="st">&quot;alpha2&quot;</span>)</code></pre>
<p><img src="Redoing_files/figure-html/ch18-sat2-alpha2-1.png" width="65%" /></p>
<pre><code>## $posterior
##       ESS   mean median  mode
## var1 2504 -2.885 -2.885 -2.88
## 
## $hdi
##   prob     lo     hi
## 1 0.95 -3.329 -2.465</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hdi</span>(<span class="kw">posterior</span>(sat2_jags), <span class="dt">pars =</span> <span class="st">&quot;alpha2&quot;</span>, <span class="dt">prob =</span> <span class="fl">0.95</span>)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">par</th>
<th align="right">lo</th>
<th align="right">hi</th>
<th align="right">prob</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">alpha2</td>
<td align="right">-3.329</td>
<td align="right">-2.465</td>
<td align="right">0.95</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="whats-wrong-with-this-picture" class="section level3">
<h3><span class="header-section-number">18.1.3</span> What’s wrong with this picture?</h3>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">gf_point</span>(sat <span class="op">~</span><span class="st"> </span>expend, <span class="dt">data =</span> SAT) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gf_abline</span>(<span class="dt">slope =</span> <span class="op">~</span><span class="st"> </span>alpha1, <span class="dt">intercept =</span> <span class="op">~</span><span class="st"> </span>beta0, 
            <span class="dt">data =</span> <span class="kw">posterior</span>(sat2_jags) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sample_n</span>(<span class="dv">2000</span>),
            <span class="dt">alpha =</span> <span class="fl">0.01</span>, <span class="dt">color =</span> <span class="st">&quot;steelblue&quot;</span>)</code></pre>
<p><img src="Redoing_files/figure-html/ch18-sat2-scatter-1.png" width="65%" /></p>
</div>
<div id="multiple-predictors-in-pictures" class="section level3">
<h3><span class="header-section-number">18.1.4</span> Multiple predictors in pictures</h3>
<p>Interpretting coefficients in a model with multiple predictors is less straightforward
that it is in a model with one predictor if those predictors happen to be
correlated, as they are in the case of the SAT example above:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">gf_point</span>(expend <span class="op">~</span><span class="st"> </span>frac, <span class="dt">data =</span> SAT) </code></pre>
<p><img src="Redoing_files/figure-html/ch18-x1x2-scatter-1.png" width="65%" /></p>
<div id="if-the-predictors-are-uncorrelated" class="section level4">
<h4><span class="header-section-number">18.1.4.1</span> If the predictors are uncorrelated</h4>
<p>Let’s start with the easier case when the predictors are not correlated.</p>
<p><img src="images/Fig18-1.png" width="65%" style="display: block; margin: auto;" /></p>
</div>
<div id="correlated-predictors" class="section level4">
<h4><span class="header-section-number">18.1.4.2</span> Correlated predictors</h4>
<p><img src="images/Fig18-2.png" width="65%" style="display: block; margin: auto;" /></p>
</div>
<div id="sat-model" class="section level4">
<h4><span class="header-section-number">18.1.4.3</span> SAT model</h4>
<p><img src="images/Fig18-3.png" width="65%" style="display: block; margin: auto;" /></p>
</div>
<div id="so-how-do-we-interpret" class="section level4">
<h4><span class="header-section-number">18.1.4.4</span> So how do we interpret?</h4>
<p>Interpreting the parameters of a multiple regression model
is a bit more subtle than it was for simple linear regression
where <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> could be interpreted as
the intercept and slope of a linear relationship between
the response and the predictor.<br />
It is tempting to interpret <span class="math inline">\(\beta_i\)</span>
as how much the response increases (on average)
if <span class="math inline">\(x_i\)</span> is increased by <span class="math inline">\(1\)</span>
, but this
does not correctly take into account the other variables
in the regression. Tukey described the coefficients
of a multiple regression model this way:
<span class="math inline">\(\beta_i\)</span> tells how the response (<span class="math inline">\(Y\)</span>) responds to change
in <span class="math inline">\(x_i\)</span>
<code>after adjusting for simultaneous linear change in the other predictors  in the data at hand&quot; (Tukey, 1970, Chapter 23). More recently, Hoaglin (Hoaglin, 2016) has written about the  perils of the</code>all other predictors held constant&quot; misunderstanding of
coefficients in multiple regression.</p>
<p>We will continue to refine the interpretation of multiple regression coefficients
as we see examples, but we can already give some reasons
why the ``all other variables being held constant&quot; interpretation fails.
In many situations, it really isn’t possible to adjust one predictor without
other predictors simultaneously changing. Imagine, for example, an economic
model that includes predictors like inflation rate, interest rates, unemployment
rates, etc. A government can take action to affect a variable like interest
rates, but that may result in changes to the other predictors as well.</p>
<p>When predictor variables are correlated, interpretation can become subtle.
For example, if <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are negatively correlated and
<span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> are both positive, it is possible that an increase <span class="math inline">\(x_1\)</span>
could be associated with a  in <span class="math inline">\(Y\)</span> because as <span class="math inline">\(x_1\)</span> increases,
<span class="math inline">\(x_2\)</span> will tend to decrease, and the negative influence on <span class="math inline">\(Y\)</span> from the decrease in
<span class="math inline">\(x_2\)</span> could be larger than the positive influence on <span class="math inline">\(Y\)</span> from the increase
in <span class="math inline">\(x_1\)</span>. In this situation, <span class="math inline">\(\beta_1 &gt; 0\)</span> indicates that  (which in this example are associated
with a decrease in <span class="math inline">\(Y\)</span>), <span class="math inline">\(Y\)</span> tends to increase as <span class="math inline">\(x_1\)</span> increases.</p>
<div id="flights-example" class="section level5">
<h5><span class="header-section-number">18.1.4.4.1</span> Flights example</h5>
<p>In his 2016 eCOTS presentation , Andrew Gelman
discussed a paper  that used models with several
predictors to study the causes of air rage (upset passengers on commercial
airlines). Among the regressors were things like the presence of
first class seats, whether passengers boarded from the front, size of
the aircraft, length of the flight, whether the flight was international,
physical characteristics of economy and first class seats,
and several others. Among the conclusions of the paper were these:
``Physical inequality on airplanes – that is, the presence of a first
class cabin – is associated with more frequent air rage incidents in
economy class. Situational inequality – boarding from the front (requiring
walking through the first class cabin) versus the middle of the plane –
also significantly increases the odds of air rage in both economy and first
class. We show that physical design that highlights inequality can trigger
antisocial behavior on airplanes.&quot;</p>
<p>But since front-boarding planes with first class compartments tend to
be larger, and take longer flights, one must be very careful to avoid
a ``while holding all other variables fixed&quot; interpretation.</p>
</div>
</div>
</div>
</div>
<div id="interaction" class="section level2">
<h2><span class="header-section-number">18.2</span> Interaction</h2>
<p>The model above could be called a ``parallel slopes&quot; model since we can rewrite</p>
<p><span class="math display">\[\begin{align*}
y &amp;= \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \mathrm{noise} \\
y &amp;= (\beta_0 + \beta_1 x_1) + \beta_2 x_2 + \mathrm{noise} \\
y &amp;= (\beta_0 + \beta_2 x_2) + \beta_1 x_1 + \mathrm{noise}
\end{align*}\]</span></p>
<p>So the slope of <span class="math inline">\(y\)</span> with respect to <span class="math inline">\(x_i\)</span> is constant, no matter what value the
other predictor has. (The intercept changes as we change the other predictor, however.)</p>
<p>If we want a model that allows the slopes to also change with the other predictor, we can
add in an interaction term:</p>
<p><span class="math display">\[\begin{align*}
y &amp;= \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2 \mathrm{noise} \\
y &amp;= (\beta_0 + \beta_1 x_1) + (\beta_2 + \beta_3 x_1) x_2 + \mathrm{noise} \\
y &amp;= (\beta_0 + \beta_2 x_2) + (\beta_1 + \beta_3 x_2) x_1\mathrm{noise}
\end{align*}\]</span></p>
<div id="sat-with-interaction-term" class="section level3">
<h3><span class="header-section-number">18.2.1</span> SAT with interaction term</h3>
<pre class="sourceCode r"><code class="sourceCode r">sat_model3 &lt;-<span class="st"> </span><span class="cf">function</span>() {
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(y)) {
    y[i]   <span class="op">~</span><span class="st"> </span><span class="kw">dt</span>(mu[i], <span class="dv">1</span><span class="op">/</span>sigma<span class="op">^</span><span class="dv">2</span>, nu)
    mu[i] &lt;-<span class="st"> </span>alpha0 <span class="op">+</span><span class="st"> </span>alpha1 <span class="op">*</span><span class="st"> </span>(x1[i] <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x1)) <span class="op">+</span><span class="st"> </span>alpha2 <span class="op">*</span><span class="st"> </span>(x2[i] <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x2)) <span class="op">+</span><span class="st">  </span>alpha3 <span class="op">*</span><span class="st"> </span>(x3[i] <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x3))
  }
  nuMinusOne <span class="op">~</span><span class="st"> </span><span class="kw">dexp</span>(<span class="dv">1</span><span class="op">/</span><span class="fl">29.0</span>)
  nu        &lt;-<span class="st"> </span>nuMinusOne <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
  alpha0     <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(alpha0mean, <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>alpha0sd<span class="op">^</span><span class="dv">2</span>) 
  alpha1     <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>alpha1sd<span class="op">^</span><span class="dv">2</span>)
  alpha2     <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>alpha2sd<span class="op">^</span><span class="dv">2</span>)
  alpha3     <span class="op">~</span><span class="st"> </span><span class="kw">dnorm</span>(<span class="dv">0</span>, <span class="dv">1</span> <span class="op">/</span><span class="st"> </span>alpha3sd<span class="op">^</span><span class="dv">2</span>)
  sigma      <span class="op">~</span><span class="st"> </span><span class="kw">dunif</span>(sigma_lo, sigma_hi)
  beta0     &lt;-<span class="st"> </span>alpha0 <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x1) <span class="op">*</span><span class="st"> </span>alpha1 <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x2) <span class="op">*</span><span class="st"> </span>alpha2
  log10nu   &lt;-<span class="st"> </span><span class="kw">log</span>(nu) <span class="op">/</span><span class="st"> </span><span class="kw">log</span>(<span class="dv">10</span>)
}</code></pre>
<div id="sat3-jags" class="section level4">
<h4><span class="header-section-number">18.2.1.1</span> JAGS</h4>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(R2jags)
sat3_jags &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">jags</span>(
    <span class="dt">model =</span> sat_model3,
    <span class="dt">data =</span> <span class="kw">list</span>(
      <span class="dt">y =</span> SAT<span class="op">$</span>sat,
      <span class="dt">x1 =</span> SAT<span class="op">$</span>expend,
      <span class="dt">x2 =</span> SAT<span class="op">$</span>frac,
      <span class="dt">x3 =</span> SAT<span class="op">$</span>frac <span class="op">*</span><span class="st"> </span>SAT<span class="op">$</span>expend,
      <span class="dt">alpha0mean =</span> <span class="dv">1000</span>,    <span class="co"># SAT scores are roughly 500 + 500</span>
      <span class="dt">alpha0sd   =</span> <span class="dv">100</span>,     <span class="co"># broad prior on scale of 400 - 1600</span>
      <span class="dt">alpha1sd   =</span> <span class="dv">4</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(SAT<span class="op">$</span>sat) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(SAT<span class="op">$</span>expend),
      <span class="dt">alpha2sd   =</span> <span class="dv">4</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(SAT<span class="op">$</span>sat) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(SAT<span class="op">$</span>frac),
      <span class="dt">alpha3sd   =</span> <span class="dv">4</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(SAT<span class="op">$</span>sat) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(SAT<span class="op">$</span>frac <span class="op">*</span><span class="st"> </span>SAT<span class="op">$</span>expend),
      <span class="dt">sigma_lo =</span> <span class="fl">0.001</span>,
      <span class="dt">sigma_hi =</span> <span class="dv">1000</span>
    ),
    <span class="dt">parameters.to.save =</span> <span class="kw">c</span>(<span class="st">&quot;log10nu&quot;</span>, <span class="st">&quot;alpha0&quot;</span>, <span class="st">&quot;alpha1&quot;</span>, <span class="st">&quot;alpha2&quot;</span>, <span class="st">&quot;alpha3&quot;</span>, <span class="st">&quot;beta0&quot;</span>,<span class="st">&quot;sigma&quot;</span>),
    <span class="dt">n.iter   =</span> <span class="dv">20000</span>,
    <span class="dt">n.burnin =</span> <span class="dv">1000</span>,
    <span class="dt">n.chains =</span> <span class="dv">3</span>
  ) </code></pre>
<pre class="sourceCode r"><code class="sourceCode r">sat3_jags</code></pre>
<pre><code>## Inference for Bugs model at &quot;/var/folders/py/txwd26jx5rq83f4nn0f5fmmm0000gn/T//Rtmp5K1frC/modelfeab669704dd.txt&quot;, fit using jags,
##  3 chains, each with 20000 iterations (first 1000 discarded), n.thin = 19
##  n.sims = 3000 iterations saved
##           mu.vect sd.vect    2.5%      25%      50%      75%    97.5%  Rhat n.eff
## alpha0    965.850   4.619 956.619  962.852  965.816  968.980  974.627 1.002  2000
## alpha1      1.800   8.261 -14.382   -3.641    1.797    7.296   18.418 1.001  3000
## alpha2     -4.194   0.845  -5.885   -4.740   -4.196   -3.636   -2.569 1.001  3000
## alpha3      0.225   0.140  -0.046    0.135    0.225    0.315    0.508 1.001  3000
## beta0    1103.008  73.409 956.184 1055.468 1102.679 1150.494 1248.924 1.001  3000
## log10nu     1.400   0.364   0.672    1.155    1.417    1.662    2.063 1.001  3000
## sigma      31.154   3.736  24.399   28.571   31.000   33.527   39.057 1.002  1400
## deviance  489.127   3.440 484.564  486.603  488.454  490.832  497.655 1.003  1200
## 
## For each parameter, n.eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor (at convergence, Rhat=1).
## 
## DIC info (using the rule, pD = var(deviance)/2)
## pD = 5.9 and DIC = 495.0
## DIC is an estimate of expected predictive error (lower deviance is better).</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">diag_mcmc</span>(<span class="kw">as.mcmc</span>(sat3_jags))
<span class="kw">mcmc_combo</span>(<span class="kw">as.mcmc</span>(sat3_jags))</code></pre>
<p><img src="Redoing_files/figure-html/ch18-sat3-jags-look-1.png" width="65%" /><img src="Redoing_files/figure-html/ch18-sat3-jags-look-2.png" width="65%" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mcmc_pairs</span>(<span class="kw">as.mcmc</span>(sat3_jags), <span class="dt">regex_pars =</span> <span class="st">&quot;alpha&quot;</span>)</code></pre>
<p><img src="Redoing_files/figure-html/ch18-sat3-jags-look-3.png" width="65%" /></p>
</div>
</div>
</div>
<div id="fitting-a-linear-model-with-brms" class="section level2">
<h2><span class="header-section-number">18.3</span> Fitting a linear model with brms</h2>
<p>The brms package provides a simplified way of describing generalized linear models
and fitting them with Stan. The <code>brm()</code> function turns a terse description of the model
into Stan code, compiles it, and runs it. Here’s a linear model with <code>sat</code> as response, and
<code>expend</code>, <code>frac</code>, and an interaction as predictors. (The <code>*</code> means include the interaction
term. If we used <code>+</code> instead, we would not get the interaction term.)</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(brms)  
sat3_brm &lt;-<span class="st"> </span><span class="kw">brm</span>(sat <span class="op">~</span><span class="st"> </span>expend <span class="op">*</span><span class="st"> </span>frac, <span class="dt">data =</span> SAT)</code></pre>
<pre><code>## Compiling the C++ model</code></pre>
<pre><code>## Start sampling</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">sat3_stan &lt;-<span class="st"> </span><span class="kw">stanfit</span>(sat3_brm)</code></pre>
<p>Stan handles the correlated parameters a bit better than JAGS
(but also takes a bit longer to compile and run for simple models).</p>
<pre class="sourceCode r"><code class="sourceCode r">sat3_stan</code></pre>
<pre><code>## Inference for Stan model: cdbc2f76b7d44b10135d8d5c2b383017.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##                  mean se_mean    sd    2.5%     25%     50%     75%   97.5% n_eff Rhat
## b_Intercept   1057.00    1.15 43.89  971.81 1027.22 1056.75 1086.88 1144.36  1454    1
## b_expend         0.64    0.21  8.15  -15.75   -4.81    0.67    6.20   16.23  1523    1
## b_frac          -4.25    0.02  0.85   -5.89   -4.81   -4.23   -3.66   -2.61  1420    1
## b_expend:frac    0.24    0.00  0.14   -0.03    0.14    0.24    0.33    0.51  1337    1
## sigma           32.56    0.08  3.56   26.60   30.04   32.22   34.80   40.31  2144    1
## lp__          -251.39    0.05  1.69 -255.58 -252.27 -251.06 -250.17 -249.13  1316    1
## 
## Samples were drawn using NUTS(diag_e) at Sat Apr 13 13:44:48 2019.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mcmc_combo</span>(<span class="kw">as.mcmc.list</span>(sat3_stan))</code></pre>
<p><img src="Redoing_files/figure-html/ch18-sat3-brms-look-1.png" width="65%" /></p>
<p>We can use <code>stancode()</code> to extract the Stan code used to fit the model.</p>
<pre class="sourceCode r"><code class="sourceCode r">brms<span class="op">::</span><span class="kw">stancode</span>(sat3_brm)</code></pre>
<pre><code>## // generated with brms 2.7.0
## functions { 
## } 
## data { 
##   int&lt;lower=1&gt; N;  // total number of observations 
##   vector[N] Y;  // response variable 
##   int&lt;lower=1&gt; K;  // number of population-level effects 
##   matrix[N, K] X;  // population-level design matrix 
##   int prior_only;  // should the likelihood be ignored? 
## } 
## transformed data { 
##   int Kc = K - 1; 
##   matrix[N, K - 1] Xc;  // centered version of X 
##   vector[K - 1] means_X;  // column means of X before centering 
##   for (i in 2:K) { 
##     means_X[i - 1] = mean(X[, i]); 
##     Xc[, i - 1] = X[, i] - means_X[i - 1]; 
##   } 
## } 
## parameters { 
##   vector[Kc] b;  // population-level effects 
##   real temp_Intercept;  // temporary intercept 
##   real&lt;lower=0&gt; sigma;  // residual SD 
## } 
## transformed parameters { 
## } 
## model { 
##   vector[N] mu = temp_Intercept + Xc * b;
##   // priors including all constants 
##   target += student_t_lpdf(temp_Intercept | 3, 946, 85); 
##   target += student_t_lpdf(sigma | 3, 0, 85)
##     - 1 * student_t_lccdf(0 | 3, 0, 85); 
##   // likelihood including all constants 
##   if (!prior_only) { 
##     target += normal_lpdf(Y | mu, sigma);
##   } 
## } 
## generated quantities { 
##   // actual population-level intercept 
##   real b_Intercept = temp_Intercept - dot_product(means_X, b); 
## }</code></pre>
<p>Some comments on the code</p>
<pre><code>data { 
  int&lt;lower=1&gt; N;  // total number of observations 
  vector[N] Y;     // response variable 
  int&lt;lower=1&gt; K;  // number of population-level effects 
  matrix[N, K] X;  // population-level design matrix 
  int prior_only;  // should the likelihood be ignored? 
} </code></pre>
<pre><code>transformed data { 
  int Kc = K - 1; 
  matrix[N, K - 1] Xc;    // centered version of X 
  vector[K - 1] means_X;  // column means of X before centering 
  for (i in 2:K) { 
    means_X[i - 1] = mean(X[, i]); 
    Xc[, i - 1] = X[, i] - means_X[i - 1]; 
  } 
} </code></pre>
<ul>
<li>The design matrix <code>X</code> has a column of 1’s followed by a column for each predictor.</li>
<li><code>K</code> is the number of coluns in the design matrix.</li>
<li><code>Xc</code> omits the column of 1’s and centers the other predictors by subtracting their means.
<ul>
<li><code>Kc</code> is the number of columns in this matrix (so it is one less than <code>K</code>)</li>
<li>the compuation of <code>Xc</code> happens in the for loop, which starts at 2 to omit that first column
of 1’s.</li>
</ul></li>
<li>We can use <code>standata()</code> to show the data <code>brm()</code> passes to Stan.</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">standata</span>(sat3_brm) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">lapply</span>(head)  <span class="co"># truncte the output to save some space</span></code></pre>
<pre><code>## $N
## [1] 50
## 
## $Y
## [1] 1029  934  944 1005  902  980
## 
## $K
## [1] 4
## 
## $X
##   Intercept expend frac expend:frac
## 1         1  4.405    8       35.24
## 2         1  8.963   47      421.26
## 3         1  4.778   27      129.01
## 4         1  4.459    6       26.75
## 5         1  4.992   45      224.64
## 6         1  5.443   29      157.85
## 
## $prior_only
## [1] 0</code></pre>
<pre><code>parameters { 
  vector[Kc] b;  // population-level effects 
  real temp_Intercept;  // temporary intercept 
  real&lt;lower=0&gt; sigma;  // residual SD 
} </code></pre>
<ul>
<li><code>b</code> is equivalent to
<span class="math inline">\(\langle \alpha_1, \alpha_2, \alpha_3 \rangle\)</span>
(which is the same as <span class="math inline">\(\langle \beta_1, \beta_2, \beta_3 \rangle\)</span>).</li>
<li><code>temp_Intercept</code> is equivalent to <span class="math inline">\(\alpha_0\)</span>.</li>
<li><code>sigma</code> is just as it has been in our previous models.</li>
</ul>
<pre><code>model { 
  vector[N] mu = temp_Intercept + Xc * b;
  // priors including all constants 
  target += student_t_lpdf(temp_Intercept | 3, 946, 85); 
  target += student_t_lpdf(sigma | 3, 0, 85)
    - 1 * student_t_lccdf(0 | 3, 0, 85); 
  // likelihood including all constants 
  if (!prior_only) { 
    target += normal_lpdf(Y | mu, sigma);
  } 
} </code></pre>
<ul>
<li><code>target</code> is the main thing being calculated – typically the log of the posterior, but there
is an option to compute the log of the prior instead by setting <code>prior_only</code> to true. You can see
that setting <code>prior_only</code> true omits the likelihood portion.</li>
<li>The parts of the log posterior are added together using <code>+=</code>. This is equivalent to multiplying
on the non-log scale. The first two lines handle the prior; the third line, the likelihood.</li>
<li><code>student_t_lpdf()</code> is the log of the pdf of a t distribution. (Notice how this function
uses <code>|</code> to separate its main input from the parameters).</li>
<li>The priors for <code>temp_Intercept</code> and <code>sigma</code> are t distributions with 3 degrees of freedom.
(The <code>brm()</code> wrapper function must be using the data to suggest <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> where needed.
This is much like the order of magnitude reasoning we have been doing.)</li>
<li>It appears that there are components of the prior for <code>temp_Intercept</code> and for <code>sigma</code>,
but not for <code>b</code>. This means that the log-prior for <code>b</code> is 0, so the prior is 1. That is,
the default in brms is to use an improper flat prior (1 everywhere). We’ll see how to adjust
that momentarily.</li>
<li><code>- 1 * student_t_lccdf(0 | 3, 0, 85)</code> is adding a normalizing constant to the prior (and hence to
the posterior).</li>
<li><code>normal_lpdf()</code> indicates that this model is using normal noise.</li>
</ul>
<pre><code>generated quantities { 
  real b_Intercept = temp_Intercept - dot_product(means_X, b); 
} </code></pre>
<ul>
<li>This recovers the ``actual&quot; intercept. It is equivalent to</li>
</ul>
<p><span class="math display">\[\begin{align*}
\beta_0 &amp;= \alpha_0 - \langle \overline{x}_{1}, \overline{x}_{2}, \overline{x}_{3} \rangle \cdot
\langle \alpha_1, \alpha_2, \alpha_3 \rangle \\
&amp;= \alpha_0  - \alpha_1 \overline{x}_1 - \alpha_2 \overline{x}_2 - \alpha_3 \overline{x}_3
\end{align*}\]</span></p>
<p>So this is similar to, but not exactly the same as our previous model. Differences include</p>
<ul>
<li>The priors for <span class="math inline">\(\alpha_0\)</span> and <span class="math inline">\(\sigma\)</span> are t distributions with 3 degrees of freedom rather than
normal distributions. These are flatter (so less informative) than the corresponding normal priors
would be.</li>
<li>The prirs for <span class="math inline">\(\alpha_i\)</span> when <span class="math inline">\(i \ge 1\)</span> are improper “uniform” priors. Again, this is even
less informative than the priors we have been using.</li>
<li>The likelihood is based on normal noise rather than t-distributed noise.</li>
</ul>
<div id="adjusting-the-model-with-brm" class="section level3">
<h3><span class="header-section-number">18.3.1</span> Adjusting the model with brm()</h3>
<p>Suppose we want to construct a model that has the same prior and
likelihood as our <a href="sat3-jags">JAGS model</a>. Here are some values we will need.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="dv">4</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(SAT<span class="op">$</span>sat) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(SAT<span class="op">$</span>expend)</code></pre>
<pre><code>## [1] 219.6</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="dv">4</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(SAT<span class="op">$</span>sat) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(SAT<span class="op">$</span>frac)</code></pre>
<pre><code>## [1] 11.18</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="dv">4</span> <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(SAT<span class="op">$</span>sat) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(SAT<span class="op">$</span>frac <span class="op">*</span><span class="st"> </span>SAT<span class="op">$</span>expend)</code></pre>
<pre><code>## [1] 1.452</code></pre>
<p>To use a t distribution for the response, we use <code>family = student()</code>.
To set the priors, it is handy to know what the parameter names will be and what the default priors
would be if we do noting. (If no prior is listed, a flat improper prior will be used.)</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">get_prior</span>(
  sat <span class="op">~</span><span class="st"> </span>expend <span class="op">*</span><span class="st"> </span>frac, <span class="dt">data =</span> SAT,
  <span class="dt">family =</span> <span class="kw">student</span>()   <span class="co"># distribution for response variable</span>
)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">prior</th>
<th align="left">class</th>
<th align="left">coef</th>
<th align="left">group</th>
<th align="left">resp</th>
<th align="left">dpar</th>
<th align="left">nlpar</th>
<th align="left">bound</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"></td>
<td align="left">b</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">b</td>
<td align="left">expend</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">b</td>
<td align="left">expend:frac</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">b</td>
<td align="left">frac</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">student_t(3, 946, 85)</td>
<td align="left">Intercept</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">gamma(2, 0.1)</td>
<td align="left">nu</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">student_t(3, 0, 85)</td>
<td align="left">sigma</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody>
</table>
<p>We can communicate the priors to <code>brm()</code> as follows (notice the use of <code>coef</code> or <code>class</code>
based on the output above. (<code>class = b</code> could be used to set a common prior for all
coefficients in the <code>b</code> class, if that’s what we wanted.)</p>
<pre class="sourceCode r"><code class="sourceCode r">sat3a_brm &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">brm</span>(
    sat <span class="op">~</span><span class="st"> </span>expend <span class="op">*</span><span class="st"> </span>frac, <span class="dt">data =</span> SAT,
    <span class="dt">family =</span> <span class="kw">student</span>(),
    <span class="dt">prior =</span> <span class="kw">c</span>(
        <span class="kw">set_prior</span>(<span class="st">&quot;normal(0,220)&quot;</span>, <span class="dt">coef =</span> <span class="st">&quot;expend&quot;</span>),
        <span class="kw">set_prior</span>(<span class="st">&quot;normal(0,11)&quot;</span>, <span class="dt">coef =</span> <span class="st">&quot;frac&quot;</span>),
        <span class="kw">set_prior</span>(<span class="st">&quot;normal(0,1.5)&quot;</span>, <span class="dt">coef =</span> <span class="st">&quot;expend:frac&quot;</span>),
        <span class="kw">set_prior</span>(<span class="st">&quot;normal(1000, 100)&quot;</span>, <span class="dt">class =</span> <span class="st">&quot;Intercept&quot;</span>),
        <span class="kw">set_prior</span>(<span class="st">&quot;exponential(1/30.0)&quot;</span>, <span class="dt">class =</span> <span class="st">&quot;nu&quot;</span>),
        <span class="kw">set_prior</span>(<span class="st">&quot;uniform(0.001,1000)&quot;</span>, <span class="dt">class =</span> <span class="st">&quot;sigma&quot;</span>)
    )
  )</code></pre>
<pre><code>## Compiling the C++ model</code></pre>
<pre><code>## Start sampling</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">sat3a_stan &lt;-<span class="st"> </span><span class="kw">stanfit</span>(sat3a_brm)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">sat3a_stan</code></pre>
<pre><code>## Inference for Stan model: 336210773a023f629f18d50263dd2a7f.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##                  mean se_mean    sd    2.5%     25%     50%     75%   97.5% n_eff Rhat
## b_Intercept   1051.35    1.03 42.61  965.03 1023.29 1051.65 1079.86 1133.24  1715    1
## b_expend         1.82    0.19  7.96  -13.80   -3.64    1.87    7.09   17.88  1740    1
## b_frac          -4.17    0.02  0.83   -5.75   -4.74   -4.18   -3.60   -2.55  1761    1
## b_expend:frac    0.22    0.00  0.14   -0.05    0.13    0.22    0.31    0.49  1650    1
## sigma           31.07    0.08  3.67   24.67   28.43   30.93   33.30   39.02  2273    1
## nu              35.54    0.54 30.17    4.71   14.38   27.18   47.13  116.23  3098    1
## lp__          -265.96    0.05  1.73 -270.18 -266.88 -265.66 -264.69 -263.57  1451    1
## 
## Samples were drawn using NUTS(diag_e) at Sat Apr 13 13:45:39 2019.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mcmc_combo</span>(<span class="kw">as.mcmc.list</span>(sat3a_stan))</code></pre>
<p><img src="Redoing_files/figure-html/ch18-sat3a-look-1.png" width="65%" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">stancode</span>(sat3a_brm)</code></pre>
<pre><code>## // generated with brms 2.7.0
## functions { 
## 
##   /* compute the logm1 link 
##    * Args: 
##    *   p: a positive scalar
##    * Returns: 
##    *   a scalar in (-Inf, Inf)
##    */ 
##    real logm1(real y) { 
##      return log(y - 1);
##    }
##   /* compute the inverse of the logm1 link 
##    * Args: 
##    *   y: a scalar in (-Inf, Inf)
##    * Returns: 
##    *   a positive scalar
##    */ 
##    real expp1(real y) { 
##      return exp(y) + 1;
##    }
## } 
## data { 
##   int&lt;lower=1&gt; N;  // total number of observations 
##   vector[N] Y;  // response variable 
##   int&lt;lower=1&gt; K;  // number of population-level effects 
##   matrix[N, K] X;  // population-level design matrix 
##   int prior_only;  // should the likelihood be ignored? 
## } 
## transformed data { 
##   int Kc = K - 1; 
##   matrix[N, K - 1] Xc;  // centered version of X 
##   vector[K - 1] means_X;  // column means of X before centering 
##   for (i in 2:K) { 
##     means_X[i - 1] = mean(X[, i]); 
##     Xc[, i - 1] = X[, i] - means_X[i - 1]; 
##   } 
## } 
## parameters { 
##   vector[Kc] b;  // population-level effects 
##   real temp_Intercept;  // temporary intercept 
##   real&lt;lower=0&gt; sigma;  // residual SD 
##   real&lt;lower=1&gt; nu;  // degrees of freedom or shape 
## } 
## transformed parameters { 
## } 
## model { 
##   vector[N] mu = temp_Intercept + Xc * b;
##   // priors including all constants 
##   target += normal_lpdf(b[1] | 0,220); 
##   target += normal_lpdf(b[2] | 0,11); 
##   target += normal_lpdf(b[3] | 0,1.5); 
##   target += normal_lpdf(temp_Intercept | 1000, 100); 
##   target += uniform_lpdf(sigma | 0.001,1000)
##     - 1 * uniform_lccdf(0 | 0.001,1000); 
##   target += exponential_lpdf(nu | 1/30.0)
##     - 1 * exponential_lccdf(1 | 1/30.0); 
##   // likelihood including all constants 
##   if (!prior_only) { 
##     target += student_t_lpdf(Y | nu, mu, sigma);
##   } 
## } 
## generated quantities { 
##   // actual population-level intercept 
##   real b_Intercept = temp_Intercept - dot_product(means_X, b); 
## }</code></pre>
</div>
</div>
<div id="interpretting-a-model-with-an-interaction-term" class="section level2">
<h2><span class="header-section-number">18.4</span> Interpretting a model with an interaction term</h2>
<p>If the coefficient on the interation term is not 0, then how <span class="math inline">\(y\)</span> depends on <span class="math inline">\(x_i\)</span> depends on
the other predictors in the model. This makes it difficult to talk about ``the effect of <span class="math inline">\(x_i\)</span> on <span class="math inline">\(y\)</span>&quot;.
The best we can do is talk about general patterns or about the effect of <span class="math inline">\(x_i\)</span> on <span class="math inline">\(y\)</span> for particular
values of the other preditors.</p>
<p>In the SAT model, a substantial portion (but not 95%) of the posterior distribution indicates that there
is an interaction, so we need to at least be concerned that this is a possibility.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mcmc_areas</span>(<span class="kw">as.mcmc.list</span>(sat3a_stan), <span class="dt">pars =</span> <span class="st">&quot;b_expend:frac&quot;</span>, <span class="dt">prob =</span> <span class="fl">.90</span>)</code></pre>
<p><img src="Redoing_files/figure-html/ch18-sat3a-interation-1.png" width="65%" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">bind_rows</span>(
  <span class="kw">hdi</span>(<span class="kw">posterior</span>(sat3a_stan), <span class="dt">pars =</span> <span class="st">&quot;b_expend:frac&quot;</span>, <span class="dt">prob =</span> <span class="fl">.90</span>),
  <span class="kw">hdi</span>(<span class="kw">posterior</span>(sat3a_stan), <span class="dt">pars =</span> <span class="st">&quot;b_expend:frac&quot;</span>, <span class="dt">prob =</span> <span class="fl">.95</span>)
)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">par</th>
<th align="right">lo</th>
<th align="right">hi</th>
<th align="right">prob</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">b_expend:frac</td>
<td align="right">-0.0061</td>
<td align="right">0.4445</td>
<td align="right">0.90</td>
</tr>
<tr class="even">
<td align="left">b_expend:frac</td>
<td align="right">-0.0596</td>
<td align="right">0.4807</td>
<td align="right">0.95</td>
</tr>
</tbody>
</table>
<p>If we are primarily interested in how expenditures are related to SAT performance,
one way to deal with this is to think about the slope of the regression line for various
values of the <code>frac</code> variable. By definition, <code>frac</code> is between 0 and 100, and in the data
it spans nearly that full range.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">posterior</span>(sat3a_stan) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">slope20 =</span> b_expend <span class="op">+</span><span class="st"> `</span><span class="dt">b_expend:frac</span><span class="st">`</span> <span class="op">*</span><span class="st"> </span><span class="dv">20</span>,
    <span class="dt">slope40 =</span> b_expend <span class="op">+</span><span class="st"> `</span><span class="dt">b_expend:frac</span><span class="st">`</span> <span class="op">*</span><span class="st"> </span><span class="dv">40</span>,
    <span class="dt">slope60 =</span> b_expend <span class="op">+</span><span class="st"> `</span><span class="dt">b_expend:frac</span><span class="st">`</span> <span class="op">*</span><span class="st"> </span><span class="dv">60</span>,
    <span class="dt">slope80 =</span> b_expend <span class="op">+</span><span class="st"> `</span><span class="dt">b_expend:frac</span><span class="st">`</span> <span class="op">*</span><span class="st"> </span><span class="dv">80</span>
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">gf_density</span>(<span class="op">~</span>slope20,   <span class="dt">fill =</span> <span class="op">~</span><span class="st">&quot;frac = 20&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gf_density</span>(<span class="op">~</span>slope40,  <span class="dt">fill =</span> <span class="op">~</span><span class="st">&quot;frac = 40&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gf_density</span>(<span class="op">~</span>slope60,  <span class="dt">fill =</span> <span class="op">~</span><span class="st">&quot;frac = 60&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gf_density</span>(<span class="op">~</span>slope80,  <span class="dt">fill =</span> <span class="op">~</span><span class="st">&quot;frac = 80&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gf_labs</span>(<span class="dt">x =</span> <span class="st">&quot;b_frac&quot;</span>)</code></pre>
<p><img src="Redoing_files/figure-html/ch18-sat3a-slope-0-100-1.png" width="65%" /></p>
<p>According to this mode, spending more money is definitely associated with higher
SAT scores when many students take the SAT, but might actually be associated with a
small decrease in SAT scores when very few students take the test. The model
provides the sharpest estimates of this effect when the fraction of students taking
the test is near 50%.</p>
<p>Here’s another way to present this sort of comparison using 95% HDIs instead of
density plots.</p>
<p><img src="images/Fig18-9.png" width="65%" style="display: block; margin: auto;" /></p>
<p>We can create our own version of these plot like this</p>
<pre class="sourceCode r"><code class="sourceCode r">NewData &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">tibble</span>(
    <span class="dt">sat =</span> <span class="ot">Inf</span>,   <span class="co"># trick to get ppc_intervals() to almost ignore</span>
    <span class="dt">frac =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">100</span>, <span class="dt">by =</span> <span class="dv">4</span>))
y_slope &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">posterior_calc</span>(
    sat3a_stan, 
    slope_expend <span class="op">~</span><span class="st"> </span>b_expend <span class="op">+</span><span class="st"> `</span><span class="dt">b_expend:frac</span><span class="st">`</span> <span class="op">*</span><span class="st"> </span>frac,    <span class="co"># note required back ticks!</span>
    <span class="dt">data =</span> NewData
  )

<span class="kw">ppc_intervals</span>(NewData<span class="op">$</span>sat, y_slope, <span class="dt">x =</span> NewData<span class="op">$</span>frac) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">gf_labs</span>(<span class="dt">x =</span> <span class="st">&quot;value of frac&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;slope on expend&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">gf_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">alpha =</span> <span class="fl">0.5</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>) </code></pre>
<p><img src="Redoing_files/figure-html/ch18-ppc-interval-1.png" width="65%" /></p>
<div id="thinking-about-the-noise" class="section level3">
<h3><span class="header-section-number">18.4.1</span> Thinking about the noise</h3>
<p>The noise parameter (<span class="math inline">\(\sigma\)</span>) appears to be at least 25, so there is
substantial variability in average SAT scores, even among states with the same
expenditures and fraction of students taking the test.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mcmc_areas</span>(<span class="kw">as.mcmc.list</span>(sat3a_stan), <span class="dt">pars =</span> <span class="st">&quot;sigma&quot;</span>, <span class="dt">prob =</span> <span class="fl">.9</span>, <span class="dt">prob_outer =</span> <span class="fl">0.95</span>)</code></pre>
<p><img src="Redoing_files/figure-html/ch18-sat3a-noise-1.png" width="65%" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hdi</span>(<span class="kw">posterior</span>(sat3a_stan), <span class="dt">pars =</span> <span class="st">&quot;sigma&quot;</span>)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">par</th>
<th align="right">lo</th>
<th align="right">hi</th>
<th align="right">prob</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">sigma</td>
<td align="right">24.3</td>
<td align="right">38.48</td>
<td align="right">0.95</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="ch18-exercises" class="section level2">
<h2><span class="header-section-number">18.5</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li><p>Fit a model that predicts student-teacher ratio (<code>ratio</code>) from ependiture (<code>expend</code>).
Is spending a good predictor of student-teacher ratio?</p></li>
<li><p>Fit a model that predicts SAT scores from student-teacher ratio (<code>ratio</code>) and the
fraction of students who take the SAT (<code>frac</code>).
How does this model compare with the model that uses <code>expend</code> and <code>ratio</code> as predictors?</p></li>
<li><p><code>CalvinBayes::MultLinRegrPlotUnif</code> contains a synthetic data set with variables
<code>x1</code>, <code>x2</code>, and <code>y</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glimpse</span>(MultLinRegrPlotUnif)</code></pre>
<pre><code>## Observations: 400
## Variables: 3
## $ x1 &lt;dbl&gt; 6.2482, 0.5470, 6.2820, 0.5085, 2.8241, 4.7502, 5.1439, 5.7114, 8.3594, 2.3522, 4.4224…
## $ x2 &lt;dbl&gt; 6.4130, 6.0560, 8.8629, 4.9334, 2.2763, 7.1172, 5.8876, 3.6913, 7.8148, 0.9905, 3.9044…
## $ y  &lt;dbl&gt; 27.73, 22.44, 33.69, 22.53, 17.64, 25.87, 25.98, 25.56, 32.55, 11.50, 22.49, 18.57, 28…</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">inspect</span>(MultLinRegrPlotUnif)</code></pre>
<pre><code>## 
## quantitative variables:  
##   name   class      min     Q1 median     Q3    max   mean    sd   n missing
## 1   x1 numeric 0.011432  2.482  5.236  7.692  9.996  5.129 2.983 400       0
## 2   x2 numeric 0.003215  2.433  5.342  7.463  9.985  5.044 2.887 400       0
## 3    y numeric 4.774219 20.371 25.270 30.435 41.955 25.122 6.808 400       0</code></pre>
<p>This is the same data used to make the plots on page 511.
The claim there is that the data were randomly created using the formula</p>
<pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="kw">length</span>(x_<span class="dv">1</span>)
y &lt;-<span class="st"> </span><span class="dv">10</span> <span class="op">+</span><span class="st"> </span>x_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>x_<span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dv">0</span>, <span class="dv">2</span>)</code></pre>
<ol style="list-style-type: lower-alpha">
<li><p>Run a regression model using <code>x1</code> and <code>x2</code> as predictors for <code>y</code> (no interaction).
Use “normal noise” for your model, and <span class="math inline">\({\sf Norm}(0,20)\)</span> priors for the
slope and intercept parameters.
How do the posterior distributions compare to the formula used to
generate the data? (In a real data analysis situation, we won’t know the
“true” relationship like we do here when we simulate the data using
a relationship of our own devisig.)</p></li>
<li><p>Now run a regression model using only <code>x1</code> as a predictor for <code>y</code>.
How do the results compare (to the previous model and to the formula used to
generate the data)?</p></li>
<li><p>Explain why the posterior distribution for <code>sigma</code> changes the way it does.
(You might like to look at the pictures on page 511.)</p></li>
<li><p>Now add an interaction term to the model with two predictors. How does
that change the resulting posterior?</p></li>
</ol></li>
</ol>
<!-- 4. As long as the model has no improper priors, `brm()` makes it easy to  -->
<!-- sample from the prior distribution as well as the posterior.  To do this, set -->
<!-- `sample_prior = "only"` in the call to `brm()`. This provides another way, -->
<!-- in addition to looking at the Stan code, to figure out what priors `brm()` is using. -->
<!--     a. Why do you think `brm()` requires that you not use improper priors when you  -->
<!--     do this? -->
<!--     b. Use prior sampling to recreate the plots on page 522.   -->
<!--         You don't have to make exact replicas, but the main content should be the -->
<!--     same.  `mcmc_pairs()` and `mcmc_areas()` could be used, for example. You -->
<!--     don't need all the fancy labeling of `post_plot()`.) Use the `SAT` data set. -->
<!--     You will need to create a new variable `prop_not_take = 1 - frac/100`. -->
<!-- ```{r ch18-prob-brm-prior, cache = TRUE, results = "hide"}     -->
<!-- sat3p_brm <-  -->
<!--   brm( -->
<!--     sat ~ expend * frac, data = SAT, -->
<!--     family = student(), -->
<!--     prior = c( -->
<!--         set_prior("normal(0,220)", coef = "expend"), -->
<!--         set_prior("normal(0,11)", coef = "frac"), -->
<!--         set_prior("normal(0,1.5)", coef = "expend:frac"), -->
<!--         set_prior("normal(1000, 100)", class = "Intercept"), -->
<!--         set_prior("exponential(1/30.0)", class = "nu"), -->
<!--         set_prior("uniform(0.001,1000)", class = "sigma") -->
<!--     ), -->
<!--     sample_prior = "only", -->
<!--     chains = 1, -->
<!--     control = list(adapt_delta = 0.95) -->
<!--   ) -->
<!-- sat3p_stan <- stanfit(sat3p_brm)     -->
<!-- ``` -->

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="simple-linear-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="nominal-predictors.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["Redoing.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
