
# Heierarchical Models




## Gamma Distributions

We will use gamma distributions for some of our priors in this chapter.
Gamma distributions have support $(0,\infty)$ and are skewed to the right.
Both R and JAGS paramterize the gamma distributions with two parameters 
called shape and rate.

```{r ch09-gamma-plot}
gf_dist("gamma", shape = 2, rate = 3, color = ~"Gamma(2, 3)") %>%
gf_dist("gamma", shape = 4, rate = 3, color = ~"Gamma(4, 3)") %>%
gf_dist("gamma", shape = 2, rate = 6, color = ~"Gamma(2, 6)") %>%
gf_dist("gamma", shape = 4, rate = 6, color = ~"Gamma(4, 6)") %>%
  gf_labs(title = "Some Gamma distributions")
```


The mean, mode, standard deviation can be calcuated from the shape $s$ and rate
$r$ as follows:

\begin{align*}
\mu &= \frac{s}{r}
\\
\omega &= \frac{s−1}{r} \qquad (s > 1)
\\
\sigma & = \frac{\sqrt{s}}{r}
\end{align*}
In addition, the scale parameter (1/rate) is sometimes used in place 
of the rate parameter.
The `gamma_params()` function will automate conversion between various 
parameterizations.  It works just like `beta_params()` that we have seen before.

```{r gamma-params}
gamma_params(mode = 15, sd = 10, plot = TRUE)
```

As the shape parameter gets larger and larger, the gamma distribution becomes 
less and less skewed (and more and more like a normal distribution):

```{r ch09-gamma-normal}
gf_dist("gamma", shape = 25, rate = 5, color = ~"Gamma(25, 5)") %>%
  gf_dist("norm", mean = 5, sd = 1, color = ~"Norm(5, 1)")
gf_dist("gamma", shape = 100, rate = 5, color = ~"Gamma(25, 5)") %>%
  gf_dist("norm", mean = 20, sd = 2, color = ~"Norm(5, 1)")
```


## One coin from one mint

```{r, echo = FALSE}
knitr::include_graphics("images/Fig9-1.png")
```



## Multiple coins from one mint


```{r, echo = FALSE}
knitr::include_graphics("images/Fig9-4.png")
```

## Multiple coins from multiple mints

```{r, echo = FALSE}
knitr::include_graphics("images/Fig9-7.png")
```

```{r ch09-multi-mint-model, include = FALSE}
gamma_params(mean = 1, sd = 10)
model <- function() {
   for ( i in 1:Ntotal ) {
     y[i] ~ dbern(theta[s[i]])
  }
  for ( s in 1:Nsubj ) {
    theat[s] ~ dbeta(omega * (kappa - 2) + 1, (1 - omega) * (kappa - 2) + 1)
  }
  omega ~ dbeta(1, 1)
  kappa <- kappaMinusTwo + 2
  kappaMinusTwo ~ dgamma(0.01, 0.01)     # mean = 1, sd = 10
  }
```


## Therapeutic Touch

The study is described in the text. The article reporting on the study
can be found at <https://jamanetwork.com/journals/jama/fullarticle/187390>.
Here's the abstract:

### Abstract

**Context.**— Therapeutic Touch (TT) is a widely used nursing practice rooted in
mysticism but alleged to have a scientific basis. Practitioners of TT claim to
treat many medical conditions by using their hands to manipulate a "human energy
field" perceptible above the patient's skin.

**Objective.**— To investigate whether TT practitioners can actually perceive a
"human energy field."

**Design.**— Twenty-one practitioners with TT experience for from 1 to 27 years
were tested under blinded conditions to determine whether they could correctly
identify which of their hands was closest to the investigator's hand. Placement
of the investigator's hand was determined by flipping a coin. Fourteen
practitioners were tested 10 times each, and 7 practitioners were tested 20
times each.

**Main Outcome Measure.**— Practitioners of TT were asked to state whether the
investigator's unseen hand hovered above their right hand or their left hand. To
show the validity of TT theory, the practitioners should have been able to
locate the investigator's hand 100% of the time. A score of 50% would be
expected through chance alone.

**Results.**— Practitioners of TT identified the correct hand in only 123 (44%)
of 280 trials, which is close to what would be expected for random chance. There
was no significant correlation between the practitioner's score and length of
experience (r=0.23). The statistical power of this experiment was sufficient to
conclude that if TT practitioners could reliably detect a human energy field,
the study would have demonstrated this.

**Conclusions.**— Twenty-one experienced TT practitioners were unable to detect
the investigator's "energy field." Their failure to substantiate TT's most
fundamental claim is unrefuted evidence that the claims of TT are groundless and
that further professional use is unjustified.


### Data

```{r, ch09-touch-data}
library(mosaic)
head(TherapeuticTouch, 3)
gf_barh(s ~ ., data = TherapeuticTouch, fill = ~ factor(y))
```

### A heierarchical model

Big ideas:
  
* The ten trials for each subject are a sample from the many
  trials that could have been done.
  
    * distribution of results: ${\sf Bern}(\theta_s)$ -- each subject
      has a potentially different $\theta_s$.
  
* The subjects themselves are just a sample from all of the 
  TT practitioners that could have been in the study.
  
    * So the $\theta_s$ values are a sample from a distribution
      of $\theta$ values for all TT practititioners and tell
      us something about that distribution.
      
    * We will assume a beta distribution for this,
      where the parameters are unknown and estimated from the data.
      
* Use the data to estimate both the individual level
  $\theta_s$ values and the group level parameters of the beta
  distribution.
 
* Parameterization of the beta distribution for $\theta_s$.
  
    * We are primarily interested in the mean or mode of 
      this distribution (typical value of $\theta$ for TT
      practitioner).
     
    * Many combinations of shape parameters give the same 
      mean (or mode), and they are highly correlated.  For example,
      ${\sf Beta}(2,4)$,
      ${\sf Beta}(20,40)$, and 
      ${\sf Beta}(200,400)$
      all have a mean of 1/3.
  
    * We will parameterize this Beta distribution with 
      **mode** ($\omega$), and **concentration** ($\kappa$)
      
    * We will need to convert mode and concentration into the 
      two shape parameters, since JAGS and R use the 
      two shape parameters.
      
    \begin{align}
    \alpha &= \omega  (\kappa - 2) + 1\\
    \beta  &= (1 - \omega) (\kappa - 2) + 1)
    \end{align}
      
* $\omega$ and $\kappa$ will need priors
    
    * $\omega$: Beta 
    * $\kappa - 2$: Gamma (because $\kappa >2$)

Putting this altogether we have the following picture:

```{r, echo = FALSE}
knitr::include_graphics("images/Fig9-7.png")
```

Now we code it up for JAGS.

```{r ch09-touch-model}
gamma_params(mean = 1, sd = 10)
touch_model <- function() {
   for (i in 1:Ntotal) {
     y[i] ~ dbern(theta[s[i]])
   }
  for (s in 1:Nsubj) {
    theta[s] ~ dbeta(omega * (kappa - 2) + 1, (1 - omega) * (kappa - 2) + 1)
  }
  omega ~ dbeta(1, 1)
  kappa <- kappaMinusTwo + 2
  kappaMinusTwo ~ dgamma(0.01, 0.01)     # mean = 1, sd = 10
  }
```


```{r ch09-touch-jags, results = "hide"}
set.seed(1234)
TouchData <- list(
  Ntotal = nrow(TherapeuticTouch),
  Nsubj = length(unique(TherapeuticTouch$s)),
  y = TherapeuticTouch$y,
  # must convert subjects to sequence 1:Nsubj
  s = as.numeric(factor(TherapeuticTouch$s))
)
touch_jags <-
  jags(
  data = TouchData,
  model = touch_model,
  parameters.to.save = c("theta", "kappa", "omega"),
)
```

```{r ch09-touch-jags-results}
touch_jags
```

What do we learn from a quick look at this output?

* The Rhat values look good
* The autocorrelation varies from parameter to parameter. For some parameters,
it looks like it will take a much longer run to get a large effective sample size.

So let's do a larger run.

```{r ch09-touch-jags-2, results = "hide"}
touch_jags <-
  jags.parallel(
  data = TouchData,
  model = touch_model,
  parameters.to.save = c("theta", "kappa", "omega"),
  n.burnin = 1000,
  n.iter = 41000,
  n.chains = 5,
  n.thin = 10,
  jags.seed = 54321
)    
```

```{r ch09-touch-jags-2-results}
touch_jags
```

```{r ch09-touch-diag, fig.height = 4}
touch_mcmc <- as.mcmc(touch_jags)
plot_post(touch_mcmc[, "omega"], comparison_value = 0.5)
diag_mcmc(touch_mcmc, par = "omega")
diag_mcmc(touch_mcmc, par = "kappa")
diag_mcmc(touch_mcmc, par = "theta[1]")
mcmc_pairs(touch_mcmc, pars = c("omega", "kappa"))
GGally::ggpairs(posterior(touch_jags) %>% select(omega, kappa))
gf_point(kappa ~ omega, data = posterior(touch_jags), alpha = 0.05) %>%
  gf_density2d(kappa ~ omega, data = posterior(touch_jags))
```

## Other parameterizations we might have tried

### Shape parameters for Beta

Suppose we decided to parameterize the beta distribution with
shape parameters like this?

```{r touch-model-2}
touch_model2 <- function() {
   for (i in 1:Ntotal) {
     y[i] ~ dbern(theta[s[i]])
   }
  for (s in 1:Nsubj) {
    theta[s] ~ dbeta(alpha, beta)
  }
  kappa <- alpha + beta
  mu <- alpha / (alpha + beta)
  alpha <- alphaMinusOne + 1
  beta  <- betaMinusOne + 1
  alphaMinusOne ~ dgamma(0.01, 0.01)
  betaMinusOne ~ dgamma(0.01, 0.01)
  }
```

We'll run it with the same options we used above to faciliate easy
comparisons.

```{r, ch09-touch-jags2, results = "hide"}
touch_jags2 <-
  jags.parallel(
  data = TouchData,
  model = touch_model2,
  parameters.to.save = c("theta", "alpha", "beta", "mu", "omega", "kappa"),
  n.burnin = 1000,
  n.iter = 41000,
  n.chains = 5,
  n.thin = 10,
  jags.seed = 54321
)    
```

The resuls are disasterous: Rhat values well above 1 and effective sample sizes that
are *much* smaller than before.

```{r ch09-touch-jags2-look}
touch_jags2
```

### Mean instead of mode

This change seems less dramatic. Let's see how using mean and concentraion
compares to using mode and concentration.

```{r touch-model-3}
touch_model3 <- function() {
   for (i in 1:Ntotal) {
     y[i] ~ dbern(theta[s[i]])
   }
  for (s in 1:Nsubj) {
    theta[s] ~ dbeta(mu * kappa, (1 - mu) * kappa)
  }
  mu ~ dbeta(2, 2)
  kappa <- kappaMinusTwo + 2
  kappaMinusTwo ~ dgamma(0.01, 0.01)
  }
```


```{r ch09-touch-jags-3, resuls = "hide"}
touch_jags3 <-
  jags.parallel(
  data = TouchData,
  model = touch_model3,
  parameters.to.save = c("theta", "mu", "kappa"),
  n.burnin = 1000,
  n.iter = 41000,
  n.chains = 5,
  n.thin = 10,
  jags.seed = 54321
)    
```

This model seems to perform reasonably well.

```{r ch09-touch-jags3}
touch_jags3
```

```{r ch09-touch-data0}
TouchData0 <- list(
  Ntotal = 0,
  Nsubj = length(unique(TherapeuticTouch$s)),
  # y = TherapeuticTouch$y,
  # must convert subjects to sequence 1:Nsubj
  s = as.numeric(factor(TherapeuticTouch$s))
)
```

So why do we prefer the mode to the mean?  Let's take a look at the prior 
distribution on one of the $\theta$s.

```{r ch09-prior}
touch_jags_prior <-
  jags.parallel(
  data = TouchData0,
  model = touch_model,
  parameters.to.save = c("theta", "kappa", "omega"),
  n.burnin = 1000,
  n.iter = 41000,
  n.chains = 5,
  n.thin = 10,
  DIC = FALSE,
  jags.seed = 54321
)    
```

```{r ch09-prior3}
touch_jags_prior3 <-
  jags.parallel(
  data = TouchData0,
  model = touch_model3,
  parameters.to.save = c("theta", "kappa", "mu"),
  n.burnin = 1000,
  n.iter = 41000,
  n.chains = 5,
  n.thin = 10,
  DIC = FALSE,
  jags.seed = 54321
)    
```

```{r, ch09-compare-prioirs}
gf_dens( ~ theta.1, data = posterior(touch_jags_prior), color = ~"mode") %>%
gf_dens( ~ theta.1, data = posterior(touch_jags_prior3), color = ~"mean") 
```


Using the mean rather than mode corresponds to an unfortunate prior on $\theta_i$.

## Shrinkage

## Example: Baseball Batting Average

## Exerciess {#ch09-exercises}

```{r touch-model-4, eval = FALSE, include = FALSE}
touch_model4 <- function() {
   for (i in 1:Ntotal) {
     y[i] ~ dbern(theta[s[i]])
   }
  for (s in 1:Nsubj) {
    theta[s] ~ dbeta(mu * kappa, (1 - mu) * kappa)
  }
  mu ~ dbeta(10, 10)
  kappa <- kappaMinusTwo + 2
  kappaMinusTwo ~ dgamma(0.01, 0.01)
  }
```


```{r ch09-touch-jags-4, resuls = "hide", eval = FALSE, include = FALSE}
touch_jags_prior4 <-
  jags.parallel(
  data = TouchData0,
  model = touch_model4,
  parameters.to.save = c("theta", "kappa", "mu"),
  n.burnin = 1000,
  n.iter = 41000,
  n.chains = 5,
  n.thin = 10,
  DIC = FALSE,
  jags.seed = 54321
)    

gf_density(~theta.1, data = posterior(touch_jags_prior4)) %>%
  gf_dist("beta", shape1 = 10, shape2 = 10)
```